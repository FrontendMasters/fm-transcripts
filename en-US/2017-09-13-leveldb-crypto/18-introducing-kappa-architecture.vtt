WEBVTT

1
00:00:00.090 --> 00:00:02.850
The Kappa Architecture
is sort of an old idea.

2
00:00:02.850 --> 00:00:05.550
It's not like it was invented.

3
00:00:05.550 --> 00:00:08.650
It's just kind of a practice
that's evolved over time.

4
00:00:08.650 --> 00:00:12.316
You might also hear people talk
about things like event sourcing,

5
00:00:12.316 --> 00:00:13.696
similar kinds of ideas.

6
00:00:13.696 --> 00:00:18.480
They basically all mean this idea.

7
00:00:18.480 --> 00:00:20.157
Sometimes they emphasize
different parts of it and

8
00:00:20.157 --> 00:00:21.600
sometimes they leave out important parts.

9
00:00:21.600 --> 00:00:23.830
So it's important to know
when they're doing that.

10
00:00:23.830 --> 00:00:26.644
Because things like the immutability.

11
00:00:26.644 --> 00:00:31.542
And the Pindell leanness are kind of
important to get the nice properties of

12
00:00:31.542 --> 00:00:32.485
Merkle DAGs.

13
00:00:32.485 --> 00:00:37.310
I see on the chat someone's asking if
Bitcoin uses a Merkle DAG, it does, yeah.

14
00:00:37.310 --> 00:00:42.300
So that's how Bitcoin kind
of has like a single log.

15
00:00:42.300 --> 00:00:43.920
So it doesn't really allow forking,

16
00:00:43.920 --> 00:00:46.930
except with some of the extensions like
side chains and that kind of stuff.

17
00:00:46.930 --> 00:00:51.240
I'm no expert in Bitcoin, but
I know that it is one, all right.

18
00:00:53.860 --> 00:00:59.232
So getting back to the Kappa Architecture,
the main idea with

19
00:00:59.232 --> 00:01:04.390
a Kappa Architecture is that
you have an append only logs.

20
00:01:04.390 --> 00:01:07.731
So you can only add items
to the end of the log and

21
00:01:07.731 --> 00:01:11.610
it's like a log book in a ship or
a store or something.

22
00:01:11.610 --> 00:01:15.430
You're not gonna go back and
erase things, scroll them out.

23
00:01:15.430 --> 00:01:16.580
You can only add things.

24
00:01:16.580 --> 00:01:19.887
In fact, if you want to amend
something you said previously,

25
00:01:19.887 --> 00:01:22.010
you have to do that as a new document.

26
00:01:22.010 --> 00:01:25.520
It's like say, by the way,
I messed up way back there at that hash.

27
00:01:25.520 --> 00:01:29.140
It really ought to have been this way.

28
00:01:31.530 --> 00:01:34.610
This idea is a really important idea for

29
00:01:34.610 --> 00:01:39.850
building systems that kind of have
the certain robustness properties because

30
00:01:41.070 --> 00:01:44.650
there's always a list of what happened.

31
00:01:44.650 --> 00:01:46.490
And you can always take that list.

32
00:01:46.490 --> 00:01:51.373
And because it's the single source of
truth, you can always play it back and

33
00:01:51.373 --> 00:01:56.178
get into the same state that you were
at previously, so long as your indexes

34
00:01:56.178 --> 00:02:00.550
which are also called materialized
views in this in this parlance.

35
00:02:00.550 --> 00:02:04.622
If those materialized views are completely
deterministic, which they ought to be,

36
00:02:04.622 --> 00:02:06.720
then you'll get back to where you started.

37
00:02:09.380 --> 00:02:13.424
So this is a really useful
idea if you're building

38
00:02:13.424 --> 00:02:17.000
an enterprise bus with Kafka or something.

39
00:02:17.000 --> 00:02:18.803
But it's also really handy for

40
00:02:18.803 --> 00:02:22.900
building a peer to peer system where
you don't even have any servers.

41
00:02:22.900 --> 00:02:27.257
If you're just running the software
on people's own computers,

42
00:02:27.257 --> 00:02:30.540
their phones,
web pages even that kind of thing.

43
00:02:32.250 --> 00:02:36.860
So to build an append only log,
we can use the same trick that we've

44
00:02:36.860 --> 00:02:40.600
just seen with hashes to make
that log into a Merkle DAG.

45
00:02:40.600 --> 00:02:44.090
This does mean that the log
might diverge in some cases.

46
00:02:44.090 --> 00:02:48.250
So this would be a constraint
that if you can deal with logs,

47
00:02:48.250 --> 00:02:53.540
then that fork, then you can let
the hashes be whatever you want.

48
00:02:53.540 --> 00:02:58.107
But otherwise, if there's only supposed
to be a single, a non-forking log,

49
00:02:58.107 --> 00:03:02.280
then that's just something you have
to verify in your client software.

50
00:03:02.280 --> 00:03:05.580
And then other clients would have
to verify that property for you.

51
00:03:05.580 --> 00:03:07.420
So for example, if there was a fork,

52
00:03:07.420 --> 00:03:10.050
the clients could just like
reject the slug altogether.

53
00:03:10.050 --> 00:03:10.935
It's like, this is no good.

54
00:03:10.935 --> 00:03:17.220
And that forking couldn't be
caused by an adversary if you do

55
00:03:17.220 --> 00:03:23.022
things like use cryptographic signatures
to verify authorship of that log.

56
00:03:24.710 --> 00:03:29.894
So the best thing about append
only logs is that replication

57
00:03:29.894 --> 00:03:34.050
is literally concatenation
in the naive case.

58
00:03:34.050 --> 00:03:35.374
There's fancier ways to do it but

59
00:03:35.374 --> 00:03:38.750
if you wanna make something really simple,
like we could write some shell scripts.

60
00:03:38.750 --> 00:03:41.063
And just using the cat command,

61
00:03:41.063 --> 00:03:45.270
we could do sync with two logs
just by concatenating them.

62
00:03:46.590 --> 00:03:49.243
This is also true because
with a Merkle DAG,

63
00:03:49.243 --> 00:03:53.834
if you're addressing is based on hashes,
you can always write the document

64
00:03:53.834 --> 00:03:58.590
with the hash as many times as you like
in the graph structure doesn't change.

65
00:03:58.590 --> 00:04:01.850
Because you're not linking
to anything different.

66
00:04:01.850 --> 00:04:05.930
So with concatenation, it doesn't matter
if you've seen the same documents again,

67
00:04:05.930 --> 00:04:08.760
you just, whatever,
I already have them, that's okay.

68
00:04:09.825 --> 00:04:12.275
I'm gonna get the same end
result in either case.

69
00:04:12.275 --> 00:04:17.465
So it's just the easiest
way that you can get

70
00:04:17.465 --> 00:04:20.525
data synchronization is to put
your data into an append only log.

