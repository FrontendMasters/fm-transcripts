WEBVTT

1
00:00:00.000 --> 00:00:03.544
&gt;&gt; Jem Young: All right,
we talked about containers and

2
00:00:03.544 --> 00:00:07.393
orchestration and elastic cloud computing.

3
00:00:07.393 --> 00:00:11.091
Someone remind me what
elastic cloud computing is.

4
00:00:11.091 --> 00:00:12.746
It's what it sounds like.

5
00:00:12.746 --> 00:00:13.448
&gt;&gt; Jem Young: Yes.

6
00:00:13.448 --> 00:00:17.005
&gt;&gt; Speaker 2: It expands and
contracts based on your needs over time.

7
00:00:17.005 --> 00:00:18.937
&gt;&gt; Jem Young: Exactly,
and it's useful for,

8
00:00:18.937 --> 00:00:23.502
I think the example I gave was during
the holidays there's a lot of streaming.

9
00:00:23.502 --> 00:00:25.436
Another example would be Frontend Masters.

10
00:00:25.436 --> 00:00:28.867
At midnight, there might not be
a lot of people watching, so

11
00:00:28.867 --> 00:00:31.240
they can take down some of the resources.

12
00:00:31.240 --> 00:00:34.738
And during the day, when more people
are watching, they bring them back up.

13
00:00:34.738 --> 00:00:38.382
But we do that with a concept of
knowing the load of the servers and

14
00:00:38.382 --> 00:00:42.582
then measuring that and saying like,
hey, this thing is at 90% load.

15
00:00:42.582 --> 00:00:44.546
We need to route traffic somewhere else.

16
00:00:44.546 --> 00:00:48.213
Or we're at 10% load,
we actually don't need these servers.

17
00:00:48.213 --> 00:00:52.459
But a load balancer is what routes all
the traffic to the appropriate cluster.

18
00:00:52.459 --> 00:00:56.912
And it's something that you don't
think about until you're at scale,

19
00:00:56.912 --> 00:00:58.891
when you have even two servers.

20
00:00:58.891 --> 00:01:00.257
We'll take two servers for an example.

21
00:01:00.257 --> 00:01:03.733
One server might get all the traffic
because that's just the way

22
00:01:03.733 --> 00:01:05.545
the traffic's getting routed.

23
00:01:05.545 --> 00:01:07.973
And then the other server,
it's just not doing anything.

24
00:01:07.973 --> 00:01:09.774
It's just wasting cycles.

25
00:01:09.774 --> 00:01:12.810
But the problem with running
a 90% load is that's a bit slow.

26
00:01:12.810 --> 00:01:15.931
Whereas, the other server
is not doing anything.

27
00:01:15.931 --> 00:01:18.253
That's where the concept of
a load balancer comes in.

28
00:01:18.253 --> 00:01:22.599
It makes sure that traffic is split
evenly between all of your servers.

29
00:01:22.599 --> 00:01:25.328
Cuz it doesn't matter if
you have 10,000 servers,

30
00:01:25.328 --> 00:01:29.124
if three of them are doing all the work,
the rest of them aren't doing anything.

31
00:01:30.310 --> 00:01:33.519
&gt;&gt; Jem Young: Load balancers work with
a concept called a scheduling algorithm.

32
00:01:33.519 --> 00:01:39.930
I know, this sounds dull but this, to me,
is some of the most interesting parts.

33
00:01:39.930 --> 00:01:43.358
All right, what do you think some
of these scheduling algorithms do?

34
00:01:43.358 --> 00:01:45.458
They're kinda in the name.

35
00:01:45.458 --> 00:01:48.191
The IP Hashing is a little tricky so
I don't.

36
00:01:48.191 --> 00:01:52.150
So think if you had ten servers and
I have a request coming in.

37
00:01:52.150 --> 00:01:55.411
How does the load balancer
determine which server it goes to?

38
00:01:55.411 --> 00:01:58.187
That's what a scheduling algorithm does.

39
00:01:58.187 --> 00:01:59.919
So, what do you think Round Robin does?

40
00:02:01.736 --> 00:02:04.006
&gt;&gt; Speaker 3: Just goes to
the next one in the sequence.

41
00:02:04.006 --> 00:02:06.500
&gt;&gt; Jem Young: Exactly,
that's exactly right,

42
00:02:06.500 --> 00:02:11.416
that's the default load balancer
strategy for most load balancers.

43
00:02:11.416 --> 00:02:14.056
There's also IP Hashing,
which hashes your IP.

44
00:02:14.056 --> 00:02:17.625
That means it runs it
through a hashing algorithm,

45
00:02:17.625 --> 00:02:23.280
converts it to a set of characters, then
matches that against a other set of IPs.

46
00:02:23.280 --> 00:02:27.163
So the benefit of IP Hashing is that
you're guaranteed to go to the same server

47
00:02:27.163 --> 00:02:29.389
every time based on what
your IP address is.

48
00:02:29.389 --> 00:02:31.332
There's also just random.

49
00:02:31.332 --> 00:02:33.891
And what's funny is we've
spent a lot of time and

50
00:02:33.891 --> 00:02:36.023
research into scheduling algorithms.

51
00:02:36.023 --> 00:02:38.728
But Random Choice actually
works pretty well,

52
00:02:38.728 --> 00:02:41.100
just picking a random server works okay.

53
00:02:41.100 --> 00:02:43.620
It's not the default, but
it's actually not a bad strategy.

54
00:02:43.620 --> 00:02:45.755
There's also Least Connections.

55
00:02:45.755 --> 00:02:49.060
So that means the load balancer needs to
know what the load is on every single

56
00:02:49.060 --> 00:02:52.529
server and it's saying this server
has 20 connections, this one has 10.

57
00:02:52.529 --> 00:02:54.765
I'm gonna go to the one that has 10.

58
00:02:54.765 --> 00:02:55.912
There's also the concept of load.

59
00:02:55.912 --> 00:02:59.681
So if you have really process-intensive
applications, the server with

60
00:02:59.681 --> 00:03:03.710
the least amount of load is gonna get more
of the traffic until it balances out.

61
00:03:03.710 --> 00:03:10.318
And like I said, Round Robin is
the default on most load balancers.

62
00:03:10.318 --> 00:03:18.160
So let's take a look at what our server
load is right now, let's run top.

63
00:03:18.160 --> 00:03:21.361
&gt;&gt; Jem Young: So
to run top, we can say top.

64
00:03:23.120 --> 00:03:27.859
&gt;&gt; Jem Young: And this gives us
a real-time view of what's happening on

65
00:03:27.859 --> 00:03:28.931
our server.

66
00:03:28.931 --> 00:03:31.578
It tells us the amount of
threads we have available,

67
00:03:31.578 --> 00:03:34.359
which is probably gonna be
one cuz we only have one CPU.

68
00:03:34.359 --> 00:03:37.821
How much RAM there is, things like that,
and it's real-time, so

69
00:03:37.821 --> 00:03:39.355
it's always keeping track.

70
00:03:39.355 --> 00:03:41.380
You don't wanna run top all the time,

71
00:03:41.380 --> 00:03:44.042
because top itself takes
resources [LAUGH] to run.

72
00:03:44.042 --> 00:03:48.606
And on our single tiny little server,
if you're running top all the time,

73
00:03:48.606 --> 00:03:51.292
you'd see the resource consumption go up.

74
00:03:51.292 --> 00:03:54.015
But honestly,
this isn't that user friendly.

75
00:03:54.015 --> 00:03:55.893
I could break it down.

76
00:03:55.893 --> 00:04:00.886
I could write a script that extracts
out everything that this is telling me

77
00:04:00.886 --> 00:04:01.698
in detail.

78
00:04:01.698 --> 00:04:05.621
But let's install something
a little bit cleaner.

79
00:04:05.621 --> 00:04:08.789
Let's install htop, and
to quit out of top, Q.

80
00:04:12.514 --> 00:04:17.567
&gt;&gt; Jem Young: And let's install htop,
which is a little bit nicer.

81
00:04:17.567 --> 00:04:19.738
So sudo apt install htop.

82
00:04:21.291 --> 00:04:24.268
&gt;&gt; Jem Young: And
it's actually already installed, I think.

83
00:04:24.268 --> 00:04:28.145
So let's just run htop now.

84
00:04:28.145 --> 00:04:30.112
That's much cooler.

85
00:04:30.112 --> 00:04:33.351
This is one of those things you
can leave up on your computer and

86
00:04:33.351 --> 00:04:36.106
people'll walk by like,
what are they working on?

87
00:04:36.106 --> 00:04:38.814
They must be really smart,
look at all those numbers!

88
00:04:38.814 --> 00:04:42.782
But it's really the same thing as top,
it's just in a prettier format.

89
00:04:42.782 --> 00:04:45.835
And it tells us our CPU load,
our memory consumption.

90
00:04:45.835 --> 00:04:49.812
Funny enough, if we look at what's using
up all the CPU, htop is near the top.

91
00:04:49.812 --> 00:04:53.391
[LAUGH] It's using a lot
of CPU just to run this.

92
00:04:53.391 --> 00:04:57.839
And if we go to Fn+F7, wait,
no I want the tree mode, F5.

93
00:04:57.839 --> 00:05:01.494
Remember I said PM2 can
help with clustering?

94
00:05:01.494 --> 00:05:06.429
It'll actually spin up multiple
instances of your Node

95
00:05:06.429 --> 00:05:11.679
application for you and it adds and
subtracts them for you.

96
00:05:11.679 --> 00:05:17.239
We can see that here, that PM2 is running
node but it's also running all these

97
00:05:17.239 --> 00:05:23.069
different instances of node and there's
all these different instances of PM2.

98
00:05:23.069 --> 00:05:24.467
So that's just tree mode.

99
00:05:25.986 --> 00:05:30.339
&gt;&gt; Jem Young: But really, if your system
is running slow, running top or htop is

100
00:05:30.339 --> 00:05:35.021
a good thing to pull up and say what
exactly is using up all my CPU cycles?

101
00:05:35.021 --> 00:05:38.866
The Mac equivalent would be,
let's say, Activity Monitor.

102
00:05:38.866 --> 00:05:42.731
And I can pull up Activity Monitor for
my Mac in a much cleaner UI.

103
00:05:42.731 --> 00:05:47.719
And we can see that Activity Monitor is
actually [LAUGH] using up all my CPU, but

104
00:05:47.719 --> 00:05:51.810
it's generally gonna be Chrome
as the main culprit or VS Code.

105
00:05:51.810 --> 00:05:54.262
But top is just a good
thing to know your load.

106
00:05:54.262 --> 00:05:59.267
And so when we talk about load balancers,
this is what we're talking about,

107
00:05:59.267 --> 00:06:03.814
understanding the CPU load,
the connection load, the memory load.

108
00:06:03.814 --> 00:06:06.526
And to quit, I can just Ctrl+C,
I think, or actually F10.

109
00:06:06.526 --> 00:06:10.600
&gt;&gt; Speaker 4: What are the color codes
in the memory section, do you know?

110
00:06:10.600 --> 00:06:12.657
&gt;&gt; Jem Young: I don't
know authoritatively, but

111
00:06:12.657 --> 00:06:14.922
I wanna say green is you're still okay.

112
00:06:14.922 --> 00:06:18.759
I think we're in blue, so
we're getting close to halfway.

113
00:06:18.759 --> 00:06:22.500
And I think when you get a little further,
it's gonna change colors.

114
00:06:22.500 --> 00:06:24.861
Wait, I might have that backwards.

115
00:06:24.861 --> 00:06:28.476
I couldn't say authoritatively
what the color codes mean exactly.

116
00:06:30.300 --> 00:06:35.183
&gt;&gt; Jem Young: I wanna say red would be
bad, but sometimes this goes in the red,

117
00:06:35.183 --> 00:06:37.999
which I don't know what that means.

118
00:06:37.999 --> 00:06:41.342
Maybe it means the CPU is being used or
not.

119
00:06:41.342 --> 00:06:43.646
If anybody knows, you can tweet it at me.

120
00:06:43.646 --> 00:06:49.268
And we're just gonna quit out of here,
so F10, and we're back.

121
00:06:49.268 --> 00:06:52.820
&gt;&gt; Jem Young: And earlier I said
Nginx is the jack-of-all-trades.

122
00:06:52.820 --> 00:06:53.504
Well, you know what?

123
00:06:53.504 --> 00:06:57.971
We can use Nginx as a load balancer,
too, because it's just that cool.

124
00:06:57.971 --> 00:07:02.058
We're not gonna implement one today
because we only have one server, so

125
00:07:02.058 --> 00:07:04.339
there's really nothing to balance to.

126
00:07:04.339 --> 00:07:08.960
But if we had two servers or three
servers, we add this upstream backend.

127
00:07:08.960 --> 00:07:11.389
And then we proxy_pass
all connections to one.

128
00:07:11.389 --> 00:07:16.270
So what we can do is we can run a Node
application on different servers or

129
00:07:16.270 --> 00:07:17.856
different clusters.

130
00:07:17.856 --> 00:07:20.525
And then if we proxy_pass to one of them,
and

131
00:07:20.525 --> 00:07:24.757
Nginx decides based on the strategy
we're using which server to go to.

132
00:07:24.757 --> 00:07:26.597
That's pretty nice.

133
00:07:26.597 --> 00:07:31.305
So out of the box, I could probably
run 1,000 servers with one Nginx load

134
00:07:31.305 --> 00:07:35.084
balancer and it's just gonna
handle the traffic perfectly.

135
00:07:35.084 --> 00:07:38.381
We can set the strategy
in the upstream backend.

136
00:07:38.381 --> 00:07:42.346
If you ever get to this point where you
have a very high resource intensive

137
00:07:42.346 --> 00:07:44.305
service, we can say least_conn.

138
00:07:44.305 --> 00:07:48.239
That just means we're gonna use
the least connection service.

139
00:07:48.239 --> 00:07:50.503
Which is awesome that Nginx does this for
you.

140
00:07:50.503 --> 00:07:54.133
Cuz it automatically connects to a server,
gets the load,

141
00:07:54.133 --> 00:07:58.140
reports back every, I don't know,
couple milliseconds or so.

142
00:07:58.140 --> 00:08:01.150
And it reports back how many
connections you have every single time.

143
00:08:01.150 --> 00:08:03.024
We can also do Round Robin.

144
00:08:03.024 --> 00:08:04.667
We could do IP Hashing, things like that.

145
00:08:04.667 --> 00:08:07.118
I don't know if I talked
about sticky sessions.

146
00:08:07.118 --> 00:08:10.251
Honestly, I love Nginx,
it's great software.

147
00:08:10.251 --> 00:08:12.966
It does all these things for you.

148
00:08:12.966 --> 00:08:17.533
Literally, I can run entire web
applications with hundreds of

149
00:08:17.533 --> 00:08:21.505
servers with just Nginx and
it would work seamlessly.

150
00:08:21.505 --> 00:08:25.669
But here's a question for
you, what about session data?

151
00:08:25.669 --> 00:08:28.276
So, what if I log into a server?

152
00:08:28.276 --> 00:08:30.245
I am authorized on this one server.

153
00:08:30.245 --> 00:08:35.937
How do I know that I won't get routed to a
different server where I'm not logged in?

154
00:08:35.937 --> 00:08:39.134
And this is a real
problem that I run into.

155
00:08:39.134 --> 00:08:43.628
It's mostly solved now, but
what do you think would happen there?

156
00:08:43.628 --> 00:08:47.610
&gt;&gt; Speaker 5: Well, it depends on
if you're using sticky sessions.

157
00:08:47.610 --> 00:08:48.736
&gt;&gt; Jem Young: What's a sticky session?

158
00:08:48.736 --> 00:08:51.396
&gt;&gt; Speaker 5: It's sticks you
to a particular server so

159
00:08:51.396 --> 00:08:53.754
you don't get bumped between them.

160
00:08:53.754 --> 00:08:57.353
&gt;&gt; Jem Young: Exactly, it's something
we don't think about until you have to

161
00:08:57.353 --> 00:09:00.568
implement some sort of login or
authorization function.

162
00:09:00.568 --> 00:09:03.332
Be like, yeah,
we'll throw in load balancers,

163
00:09:03.332 --> 00:09:05.386
I'll spin up 20 servers, I'm good.

164
00:09:05.386 --> 00:09:08.321
But then I'm logged in, but
I hit a link or refresh the page and

165
00:09:08.321 --> 00:09:09.573
I'm no longer logged in.

166
00:09:09.573 --> 00:09:10.805
That's frustrating,

167
00:09:10.805 --> 00:09:14.941
because the load balancer can route me
to a different server every single time.

168
00:09:14.941 --> 00:09:16.436
Ways of solving that would be IP Hashing.

169
00:09:16.436 --> 00:09:18.149
So that means when I hash the IP,

170
00:09:18.149 --> 00:09:20.881
I'm always gonna go to
the same server every time.

171
00:09:20.881 --> 00:09:24.053
Another way would just be implementing
an authorization layer before we

172
00:09:24.053 --> 00:09:24.783
even hit Nginx.

173
00:09:24.783 --> 00:09:27.701
So it just makes sure I'm
authorized completely.

174
00:09:27.701 --> 00:09:28.808
If I'm not, it just bounces me out.

175
00:09:28.808 --> 00:09:33.017
If I am authorized, it just goes to the
server and it doesn't matter if I'm logged

176
00:09:33.017 --> 00:09:36.138
it or not, because we know we
passed through that firewall.

177
00:09:36.138 --> 00:09:39.429
It's something to consider when we
think about we can't just blindly

178
00:09:39.429 --> 00:09:40.385
implement things.

179
00:09:40.385 --> 00:09:44.678
As easy as [LAUGH] Nginx makes it to be,
these are considerations we have to make.

