WEBVTT

1
00:00:00.000 --> 00:00:03.809
&gt;&gt; Erik Reinert: So this is an example
of a serverless architecture.

2
00:00:03.809 --> 00:00:07.926
Now, what we have discussed already,
right, is monolith,

3
00:00:07.926 --> 00:00:11.266
you can sign to see how we
started with a monolith.

4
00:00:11.266 --> 00:00:14.413
Then you can see how we moved
to a serverless architecture.

5
00:00:14.413 --> 00:00:18.135
Well, now we're getting even
more granular with serverless.

6
00:00:18.135 --> 00:00:22.186
However, we also made some other changes
to the infrastructure as well, or

7
00:00:22.186 --> 00:00:23.656
the architecture as well.

8
00:00:23.656 --> 00:00:28.356
First off,
what did we change about the frontend?

9
00:00:28.356 --> 00:00:29.210
&gt;&gt; Speaker 2: Static.

10
00:00:29.210 --> 00:00:30.801
&gt;&gt; Erik Reinert: Static, exactly.

11
00:00:30.801 --> 00:00:34.636
So we decided, hey,
I wanna have a serverless frontend and

12
00:00:34.636 --> 00:00:37.321
let that just be hosted
in an S3 bucket and

13
00:00:37.321 --> 00:00:41.561
let Amazon scale all those requests for
me, what does that mean?

14
00:00:41.561 --> 00:00:48.041
I just eliminated potentially hundreds
of processes running in the cloud 24/7,

15
00:00:48.041 --> 00:00:52.278
taking compute resources,
and now it's per request.

16
00:00:52.278 --> 00:00:56.099
That alone,
just by getting your services or

17
00:00:56.099 --> 00:01:01.840
your frontends out of a running
daemon could save you a ton of money.

18
00:01:01.840 --> 00:01:06.396
This is why I like to build
SPAs out of the gate.

19
00:01:06.396 --> 00:01:11.649
Again, going back to Quirk, a lot of the
reason why Quirk is being built the way

20
00:01:11.649 --> 00:01:16.996
it is, is because of cost savings and
maintenance and manageability, right?

21
00:01:16.996 --> 00:01:22.017
Quirk, I did a lot of research on what I
wanted to do to build the frontend for

22
00:01:22.017 --> 00:01:22.589
Quirk.

23
00:01:22.589 --> 00:01:26.303
Next.js has been popping,
everybody's been freaking out over it.

24
00:01:26.303 --> 00:01:29.426
There's a bunch of other really
cool stuff out there too, right?

25
00:01:29.426 --> 00:01:33.505
But how do I solve and
find the best solution that works for me?

26
00:01:33.505 --> 00:01:37.216
Well, first off, I don't wanna have to
think about my frontends going down at 2

27
00:01:37.216 --> 00:01:39.084
o'clock in the morning, [LAUGH] right?

28
00:01:39.084 --> 00:01:40.326
That's my number one.

29
00:01:40.326 --> 00:01:42.381
Hands down, I don't wanna wake up and

30
00:01:42.381 --> 00:01:45.530
know that my users trying to
access their dashboard can't

31
00:01:45.530 --> 00:01:50.042
because the process failed or I pushed a
bad commit or something like that, right?

32
00:01:50.042 --> 00:01:54.254
Going the serverless approach,
I can render the whole file or

33
00:01:54.254 --> 00:01:58.067
render the whole UI,
drop it on a bucket and that's it.

34
00:01:58.067 --> 00:02:01.017
Even the deployment process is easy,
right?

35
00:02:01.017 --> 00:02:03.925
It's just an RF sync basically
to a bucket, and we're done.

36
00:02:03.925 --> 00:02:06.763
You might have to do some cache
invalidation and whatnot.

37
00:02:06.763 --> 00:02:11.128
But it's so much easier from a development
standpoint than having to push code,

38
00:02:11.128 --> 00:02:14.397
wait for it to go to dev, wait for
it to go to staging, wait for

39
00:02:14.397 --> 00:02:18.978
it to go to prod, that probably has like
10 to 15 minutes of interval in between.

40
00:02:18.978 --> 00:02:22.507
Cuz you gotta wait for For the containers
to restart and everything else, right?

41
00:02:22.507 --> 00:02:26.145
This is literally sync and go, right?

42
00:02:26.145 --> 00:02:29.834
So the developer experience as a single
person trying to build a large

43
00:02:29.834 --> 00:02:33.404
architecture, frontends being
serverless is really powerful.

44
00:02:33.404 --> 00:02:38.573
By the way, spoilers,
who here knows what may be related to this

45
00:02:38.573 --> 00:02:43.858
workshop might also be serverless
that a specific company does?

46
00:02:46.851 --> 00:02:50.031
&gt;&gt; Erik Reinert: Frontend Masters
is completely serverless.

47
00:02:50.031 --> 00:02:54.282
So their whole website is
basically on an S3 bucket.

48
00:02:54.282 --> 00:02:59.618
And that is why it is incredibly fast,
it is incredibly easy to maintain and

49
00:02:59.618 --> 00:03:02.497
they can iterate off of it very quickly,

50
00:03:02.497 --> 00:03:07.600
is because they decided to make it
a file serverless frontend, right?

51
00:03:07.600 --> 00:03:11.989
And so, this makes it so that they
don't have to worry about if their

52
00:03:11.989 --> 00:03:16.609
website's down, they just make sure
that the S3 buckets basically,

53
00:03:16.609 --> 00:03:20.844
publicly accessible, and
they do deployments directly to S3.

54
00:03:20.844 --> 00:03:25.978
So even the platform you guys are on
right now, if you're at least on

55
00:03:25.978 --> 00:03:32.119
the frontend master side, that is
a serverless frontend that's being served.

56
00:03:32.119 --> 00:03:37.243
The next thing you're gonna notice is,
what happened to the backend service?

57
00:03:39.280 --> 00:03:41.800
&gt;&gt; Speaker 2: It's not a service anymore,
it's a gateway.

58
00:03:41.800 --> 00:03:44.838
&gt;&gt; Erik Reinert: Exactly, yeah, it's
not a service anymore, it's a gateway.

59
00:03:44.838 --> 00:03:49.926
So it's common within serverless
architecture to couple

60
00:03:49.926 --> 00:03:55.750
all of your endpoints into what's
called an API gateway, right?

61
00:03:55.750 --> 00:03:59.714
Realistically, if you're talking
about functions as a service,

62
00:03:59.714 --> 00:04:04.730
you can't really call them directly from
a website, there's no easy way to do that.

63
00:04:04.730 --> 00:04:10.010
And it's mostly because functions by
default are just executed or invoked

64
00:04:10.010 --> 00:04:15.813
within the Amazon or Google, whatever
cloud provider's internal networking.

65
00:04:15.813 --> 00:04:20.500
However, if we wanted to,
we could figure out a way of hooking

66
00:04:20.500 --> 00:04:25.478
them up to what's called an API Gateway
that is also serverless.

67
00:04:25.478 --> 00:04:28.523
Now, is it actually serverless?

68
00:04:28.523 --> 00:04:30.845
No, but you don't worry about that.

69
00:04:30.845 --> 00:04:35.439
Basically, what the API Gateway acts as,
is a cloud-based

70
00:04:35.439 --> 00:04:40.215
feature which allows you to
expose HTTP endpoint that Amazon,

71
00:04:40.215 --> 00:04:43.654
Google, whoever else may maintain for you.

72
00:04:43.654 --> 00:04:48.561
But then you can connect serverless
functions to those gateways so

73
00:04:48.561 --> 00:04:53.039
that they only fire whenever
you hit that endpoint, right?

74
00:04:53.039 --> 00:04:58.196
And so, this is what makes it so now you
don't need to run a service anymore.

75
00:04:58.196 --> 00:05:03.304
And on top of it, your functions,
or the different functionality of

76
00:05:03.304 --> 00:05:08.775
your application, now scale literally,
individually by components.

77
00:05:08.775 --> 00:05:10.382
This is how Quark is built.

78
00:05:10.382 --> 00:05:16.013
Quark V2 is built this way because we
wanted to go serverless entirely, right?

79
00:05:16.013 --> 00:05:21.130
That was our first goal, was to try
to save as much money as we can.

80
00:05:21.130 --> 00:05:27.315
What that does mean as well, though,
is that Quirk V2 has 50 Lambdas, right?

81
00:05:27.315 --> 00:05:29.703
Because there's a lot
of things that we do.

82
00:05:29.703 --> 00:05:34.206
But each one of those endpoints
are being used for specific use cases,

83
00:05:34.206 --> 00:05:36.887
right, and they each scale on their own.

84
00:05:36.887 --> 00:05:40.151
Which means that if we had
a huge influx of user signups,

85
00:05:40.151 --> 00:05:42.100
we don't have to worry about it.

86
00:05:42.100 --> 00:05:45.709
That function will take care of it,
it'll scale automatically.

87
00:05:45.709 --> 00:05:49.191
And it's out of the box managed by itself.

88
00:05:49.191 --> 00:05:53.286
Same thing for other processes that
happen, and as you can see here,

89
00:05:53.286 --> 00:05:56.972
it's the same thing for
AddToCart or ProcessOrder, right?

90
00:05:56.972 --> 00:06:00.272
What we do first, this is we have
a function that does add to cart,

91
00:06:00.272 --> 00:06:01.842
that can scale indefinitely.

92
00:06:01.842 --> 00:06:05.577
Who here has tried adding something
to their cart and then it just hung?

93
00:06:05.577 --> 00:06:06.316
Because I have.

94
00:06:06.316 --> 00:06:07.474
And it's annoying.

95
00:06:07.474 --> 00:06:11.848
This is one of the reasons why Amazon
moved to such a distributed nature.

96
00:06:11.848 --> 00:06:15.498
It's because again, when you have problems
like that that you need to solve,

97
00:06:15.498 --> 00:06:19.118
it's not really about technically,
it's also about the user experience.

98
00:06:19.118 --> 00:06:22.412
If users are having bad experience,
you need to fix that.

99
00:06:22.412 --> 00:06:24.500
Serverless can really do that.

100
00:06:24.500 --> 00:06:27.342
Same thing with ProcessOrder, right?

101
00:06:27.342 --> 00:06:30.395
You might be in a scenario where
processing orders takes a long

102
00:06:30.395 --> 00:06:33.565
time because there's tons of
orders being waited to process and

103
00:06:33.565 --> 00:06:35.339
you're next in line, basically.

104
00:06:35.339 --> 00:06:38.665
That used to be a pattern that
existed like ten years ago,

105
00:06:38.665 --> 00:06:42.979
where you'd have to wait for other
orders to process before yours could.

106
00:06:42.979 --> 00:06:47.671
Now, because it's separated into its
own function, it can easily scale,

107
00:06:47.671 --> 00:06:50.310
and the idea here is
that your ProcessOrder

108
00:06:50.310 --> 00:06:54.802
does not share the resources of
anybody else's ProcessOrder, right?

109
00:06:54.802 --> 00:06:58.784
So there's no need for a service,
there's no need for scaling that,

110
00:06:58.784 --> 00:07:03.104
It's literally, if you had 5,000
ProcessOrder functions that day,

111
00:07:03.104 --> 00:07:05.482
you ran ProcessOrder 5,000 times.

112
00:07:05.482 --> 00:07:07.375
It's literally one to one.

113
00:07:07.375 --> 00:07:13.108
One other thing I wanted to note
here was the database part as well.

114
00:07:13.108 --> 00:07:14.794
What happened to the database?

115
00:07:14.794 --> 00:07:15.935
&gt;&gt; Speaker 2: It's shared now.

116
00:07:15.935 --> 00:07:19.149
&gt;&gt; Erik Reinert: It's shared, but
there's something else about it.

117
00:07:19.149 --> 00:07:20.609
&gt;&gt; Speaker 2: That it's serverless.

118
00:07:20.609 --> 00:07:21.900
&gt;&gt; Erik Reinert: It's also serverless.

119
00:07:21.900 --> 00:07:27.185
Yeah, so there are technologies out there,
and again, if you're watching

120
00:07:27.185 --> 00:07:32.973
Milk's course, the go build Go services
on AWS, he talks about DynamoDB, right?

121
00:07:32.973 --> 00:07:36.547
These serverless-based solutions for
even databases.

122
00:07:36.547 --> 00:07:41.503
So what you're looking at here
is a completely resource-based

123
00:07:41.503 --> 00:07:44.715
cost allocation for your architecture,

124
00:07:44.715 --> 00:07:49.963
meaning you're only spending what
you need on this architecture.

125
00:07:49.963 --> 00:07:53.579
You're only spending what you need for
your front-end requests and

126
00:07:53.579 --> 00:07:57.256
the data that's saved on S3,
you're only spending what you need for

127
00:07:57.256 --> 00:08:00.272
the request making to the API Gateway and
those Lambdas.

128
00:08:00.272 --> 00:08:03.528
And you're only spending
money on the database and

129
00:08:03.528 --> 00:08:07.323
the request being made to it as
well as the data stored in it.

130
00:08:07.323 --> 00:08:10.511
You're not paying for
uptime of 24 hours a day.

131
00:08:10.511 --> 00:08:14.938
You're not paying for CPU at a certain
scale or anything like that,

132
00:08:14.938 --> 00:08:16.337
because DynamoDB and

133
00:08:16.337 --> 00:08:22.022
these other kinda serverless databases can
scale on their own and know how to, right?

134
00:08:22.022 --> 00:08:26.114
There's advantages and disadvantages
to this type of architecture.

135
00:08:26.114 --> 00:08:32.948
However, again, one of the biggest ones
is scalability and cost effectiveness.

136
00:08:32.948 --> 00:08:37.046
Any questions about serverless and
these changes?

137
00:08:37.046 --> 00:08:39.012
&gt;&gt; Speaker 2: I guess
the way that you see it as,

138
00:08:39.012 --> 00:08:43.448
anything that is provided as a service
fits into the serverless category.

139
00:08:43.448 --> 00:08:46.019
&gt;&gt; Erik Reinert: Absolutely,
yeah, it really is.

140
00:08:46.019 --> 00:08:48.412
And again, that's what's kind
of made it a little confusing,

141
00:08:48.412 --> 00:08:50.908
is because when you think of serverless,
you think of functions.

142
00:08:50.908 --> 00:08:53.548
But you really should
broaden your horizon and

143
00:08:53.548 --> 00:08:58.367
just think of anything that you aren't
managing yourself is serverless, really.

144
00:08:58.367 --> 00:09:02.480
Again, it can be Firebase,
it can be Superbase, it can be anything.

145
00:09:02.480 --> 00:09:07.549
As long as you're not dealing with
the deployment lifecycle or the management

146
00:09:07.549 --> 00:09:13.027
lifecycle of that thing, it's really just
about pushing your code and running it.

147
00:09:13.027 --> 00:09:15.995
Yeah.
&gt;&gt; Speaker 2: For the platform you're

148
00:09:15.995 --> 00:09:20.511
developing, what's the local development

149
00:09:20.511 --> 00:09:25.157
story look like compared
to deploying on AWS?

150
00:09:25.157 --> 00:09:30.752
Like AddToCart,
how do you iterate on that function?

151
00:09:30.752 --> 00:09:35.800
&gt;&gt; Erik Reinert: Right, so
we're gonna talk about this in a second,

152
00:09:35.800 --> 00:09:39.947
but it's not the same, [LAUGH] basically.

153
00:09:39.947 --> 00:09:45.658
There is one massive caveat to this, which
we'll talk about in a second with cons,

154
00:09:45.658 --> 00:09:50.491
and that is that you have to be on
the internet to do all of this, right?

155
00:09:50.491 --> 00:09:54.682
You can't be in an airport on a laptop,
running a service locally and being like,

156
00:09:54.682 --> 00:09:56.466
okay, I'm gonna run functions.

157
00:09:56.466 --> 00:09:59.579
You can, but it's so much harder.

158
00:09:59.579 --> 00:10:04.529
So it does require you to be
on the internet, basically.

159
00:10:04.529 --> 00:10:09.276
And the easiest way to approach this is
really to create dev environments that

160
00:10:09.276 --> 00:10:11.184
are also serverless, right?

161
00:10:11.184 --> 00:10:14.258
That you can synchronize to
push your code to and test in.

162
00:10:14.258 --> 00:10:15.876
And that's what we do.

163
00:10:15.876 --> 00:10:17.392
We have a dev environment.

164
00:10:17.392 --> 00:10:21.066
Again, it's only two developers right now,
so we don't have to worry about it, but

165
00:10:21.066 --> 00:10:23.975
we basically have a dev environment and
then one of us is like, hey,

166
00:10:23.975 --> 00:10:25.683
I'm taking over the dev environment.

167
00:10:25.683 --> 00:10:26.719
Okay, cool, do your thing.

168
00:10:26.719 --> 00:10:30.465
And then they're working with systems and
things like that.

169
00:10:30.465 --> 00:10:33.792
Now, what's nice about
this with serverless and

170
00:10:33.792 --> 00:10:38.858
functions specifically, is my cohort,
Hayden, can work on the AddToCart

171
00:10:38.858 --> 00:10:43.710
functionality while I'm working on
the ProcessOrder functionality.

172
00:10:43.710 --> 00:10:47.583
So there's still a separation there,
even though it's in the cloud,

173
00:10:47.583 --> 00:10:49.454
where we can work separately, and

174
00:10:49.454 --> 00:10:53.213
then not really worry about stepping
on each other's toes, right?

175
00:10:53.213 --> 00:10:57.698
However, if you wanted that logical
separation across the entire environment,

176
00:10:57.698 --> 00:11:00.698
then you'd probably have
an m per developer, right?

177
00:11:00.698 --> 00:11:01.670
Or something like that.

178
00:11:01.670 --> 00:11:06.903
So that you'd have all the functions,
the API Gateway, and everything else.

179
00:11:06.903 --> 00:11:10.936
But the benefit of this, which is really
nice, is that it's serverless, so

180
00:11:10.936 --> 00:11:15.157
you don't have to worry about having five
dev environments that are also running

181
00:11:15.157 --> 00:11:16.477
processes all the time.

182
00:11:16.477 --> 00:11:20.007
And paying for
those computers costs and everything,

183
00:11:20.007 --> 00:11:23.237
it's really just the same
thing of consumption.

184
00:11:23.237 --> 00:11:27.366
And so that's what we'll end up doing,
once we get to a point where we're like,

185
00:11:27.366 --> 00:11:31.316
okay, we wanna have a dev environment
per developer or something like that,

186
00:11:31.316 --> 00:11:33.899
we will just create the infrastructure for
that.

187
00:11:33.899 --> 00:11:37.236
And then, he can have his dev
environment and I can have mine.

188
00:11:37.236 --> 00:11:41.016
But yeah, the biggest caveat to this is,
again, we'll talk about it in a second,

189
00:11:41.016 --> 00:11:42.804
is you need to be on the internet for it.

190
00:11:42.804 --> 00:11:44.758
Yeah, it's all cloud-based.

191
00:11:44.758 --> 00:11:45.716
Yep.

192
00:11:45.716 --> 00:11:49.541
&gt;&gt; Speaker 2: Kind of maybe a bit
specific, but comparing to the diagram we

193
00:11:49.541 --> 00:11:52.109
first started with in the service,
&gt;&gt; Erik Reinert: Yeah.

194
00:11:52.109 --> 00:11:55.480
&gt;&gt; Speaker 2: What's
the potential cost difference?

195
00:11:55.480 --> 00:11:56.625
&gt;&gt; Erik Reinert: Massive, yeah.

196
00:11:56.625 --> 00:11:58.849
&gt;&gt; Speaker 2: Because I just had 500 for
the first.

197
00:11:58.849 --> 00:12:03.001
&gt;&gt; Erik Reinert: So,
if we're talking about the monolith,

198
00:12:03.001 --> 00:12:07.377
at least,
not my original Cork V1 design, so

199
00:12:07.377 --> 00:12:11.643
if we're talking about Cork V1 versus V2,

200
00:12:11.643 --> 00:12:17.051
V1 costs around 350 to $500 a month for
us to run.

201
00:12:17.051 --> 00:12:21.292
V1 costs around 50 to $75.

202
00:12:21.292 --> 00:12:25.634
Yeah, so massive cost, to the point where
I opened up the Cost Explorer on Amazon on

203
00:12:25.634 --> 00:12:29.603
stream one day and I was like, tell me
where you think we did serverless, and

204
00:12:29.603 --> 00:12:31.609
everybody could see the difference.

205
00:12:31.609 --> 00:12:32.380
It was huge.

206
00:12:32.380 --> 00:12:35.253
So yeah, it was a massive drop, right?

207
00:12:35.253 --> 00:12:37.236
But what did we have to take on?

208
00:12:37.236 --> 00:12:40.073
Cold starts,
other challenges with the system, right?

209
00:12:40.073 --> 00:12:42.003
Distribution and things like that, right?

210
00:12:42.003 --> 00:12:43.360
But at the end of the day,

211
00:12:43.360 --> 00:12:46.866
those were trade-offs that we
decided would be more valuable.

