WEBVTT

1
00:00:00.456 --> 00:00:05.637
Any questions about microservices or
this, yeah?

2
00:00:05.637 --> 00:00:10.047
&gt;&gt; Speaker 1: If you have two different
databases, like this example,

3
00:00:10.047 --> 00:00:15.271
does it matter if they are in
the same server, like, MySQL service?

4
00:00:15.271 --> 00:00:19.385
&gt;&gt; Erik Reinert: Yes, yeah, you would
not want them in the same service.

5
00:00:19.385 --> 00:00:24.204
When we talk about microservices, I should
never have to go to another team and

6
00:00:24.204 --> 00:00:28.085
say, hey, is it okay if I do this,
that's friction, right?

7
00:00:28.085 --> 00:00:32.762
The goal of microservices is to alleviate
friction by having logical isolation

8
00:00:32.762 --> 00:00:34.727
between each one of the systems.

9
00:00:34.727 --> 00:00:39.543
And actually, what you see here of
a database per service is probably one of

10
00:00:39.543 --> 00:00:42.996
the cornerstones for
a microservice architecture.

11
00:00:42.996 --> 00:00:44.333
And what makes it so

12
00:00:44.333 --> 00:00:49.862
hard is that a lot of people can't even
structure their data this way, right?

13
00:00:49.862 --> 00:00:54.816
Because at some point, you might have to
look up something somewhere else, right?

14
00:00:54.816 --> 00:00:58.785
And so, it becomes very challenging
to say, okay, well, payments only

15
00:00:58.785 --> 00:01:03.087
exist in payments, but there's gotta be
a way for us to link a payment to a user.

16
00:01:03.087 --> 00:01:04.922
So, how do we do that, right?

17
00:01:04.922 --> 00:01:09.779
And that might mean that there's another
service that is, like invoices, and

18
00:01:09.779 --> 00:01:13.982
maybe that's a service that now
joins payments and users together,

19
00:01:13.982 --> 00:01:17.190
or maybe you find out other
ways of doing it, right?

20
00:01:17.190 --> 00:01:21.107
But there really should be
a clear isolation to where,

21
00:01:21.107 --> 00:01:25.621
if I need to do database migrations,
right, stuff like that,

22
00:01:25.621 --> 00:01:30.155
I'm not really impacting the users
that are using my service.

23
00:01:30.155 --> 00:01:35.716
I'm just impacting myself, and then I can
just say, hey, go update your client.

24
00:01:35.716 --> 00:01:41.309
Microservice architecture and even
service architecture is really focused

25
00:01:41.309 --> 00:01:46.651
on making these, if we go all the way
back to the beginning, modularity.

26
00:01:46.651 --> 00:01:52.911
This is modularity and its most extensive
or almost most extensive, right?

27
00:01:52.911 --> 00:01:57.931
You can think of the LEGOs or
whatever kind of scenario you want, but

28
00:01:57.931 --> 00:02:03.764
you should be able to, like, if I wanted
to, I should be able to pick up users.

29
00:02:03.764 --> 00:02:07.512
And put it somewhere else, and
I'm not impacting payments and

30
00:02:07.512 --> 00:02:09.923
anything that's happening with that.

31
00:02:09.923 --> 00:02:13.172
&gt;&gt; Speaker 1: What's the best way to
communicate between microservices?

32
00:02:13.172 --> 00:02:17.356
&gt;&gt; Erik Reinert: That is a tough question
to answer [LAUGH], mostly because it

33
00:02:17.356 --> 00:02:22.812
depends on your transactions, and
what kind of messaging you need, right?

34
00:02:22.812 --> 00:02:26.315
What we're looking at
here is a very simple,

35
00:02:26.315 --> 00:02:31.850
restful kinda transactional approach
where more than likely what will

36
00:02:31.850 --> 00:02:36.937
happen is that a user will make
a request to the front end, right?

37
00:02:36.937 --> 00:02:40.712
And while this user's waiting, the front
end's going out to the users table,

38
00:02:40.712 --> 00:02:44.733
getting the data it needs, going out to
the payments table, getting what it needs.

39
00:02:44.733 --> 00:02:48.389
And do you remember that reference I said
earlier about the guy in the video who's

40
00:02:48.389 --> 00:02:51.964
like, but then we got to go here,
go here, [INAUDIBLE], that's the problem.

41
00:02:51.964 --> 00:02:57.091
That's the problem, is that at some point,
if you even go with this approach,

42
00:02:57.091 --> 00:03:01.913
somebody's gonna be waiting, basically for
that process to come back and

43
00:03:01.913 --> 00:03:04.458
for it to finally resolve and respond.

44
00:03:04.458 --> 00:03:07.703
And that's what that guy is
talking about in that video,

45
00:03:07.703 --> 00:03:10.609
jokingly, is like,
it might take five minutes for

46
00:03:10.609 --> 00:03:15.093
her request to populate properly just
because it's so distributed, right?

47
00:03:15.093 --> 00:03:19.328
And again, going back to when
I was interviewing at Netflix,

48
00:03:19.328 --> 00:03:23.969
this was a problem that I was gonna
be brought on to solve, which is,

49
00:03:23.969 --> 00:03:26.504
they have such a huge distribution.

50
00:03:26.504 --> 00:03:31.350
How can they avoid the hops to get
people in the system quicker, right?

51
00:03:31.350 --> 00:03:33.661
And so,
what you could lean on then is like,

52
00:03:33.661 --> 00:03:38.219
event-based systems where you say like,
okay, we're gonna remove the front end and

53
00:03:38.219 --> 00:03:40.798
we're gonna put like
an event bus in front of it.

54
00:03:40.798 --> 00:03:44.758
And then everything becomes asynchronous
to where one request pops over here.

55
00:03:44.758 --> 00:03:48.147
And then once that happens,
something else is listening for

56
00:03:48.147 --> 00:03:51.869
that request to be done, so
then it can then take on its next step and

57
00:03:51.869 --> 00:03:54.469
that just makes it a lot
faster in the backend.

58
00:03:54.469 --> 00:04:00.620
So, you have to be really careful with how
even this scenario plays out because you

59
00:04:00.620 --> 00:04:06.072
can easily add a lot of, again,
going back to the UUIDs doesn't scale.

60
00:04:06.072 --> 00:04:09.329
This is actually a good example of that,
if you had these two services, but

61
00:04:09.329 --> 00:04:12.017
then you gotta go to payments and
then you go back to users, and

62
00:04:12.017 --> 00:04:13.229
they go to payments again.

63
00:04:13.229 --> 00:04:18.195
And they go somewhere else that are, hey,
you might have a distributed system,

64
00:04:18.195 --> 00:04:22.650
but it's not really efficient,
right, so it really depends, again,

65
00:04:22.650 --> 00:04:24.348
cues are also really good.

66
00:04:24.348 --> 00:04:26.949
In the scenario where you want to say,

67
00:04:26.949 --> 00:04:32.154
a good example of that is asynchronous
processes where you click a button and

68
00:04:32.154 --> 00:04:36.135
then it says, okay,
we're taking care of your process,

69
00:04:36.135 --> 00:04:40.311
give us some time and
go do whatever else you want to, right?

70
00:04:40.311 --> 00:04:43.891
That's about building a user
experience with your architecture,

71
00:04:43.891 --> 00:04:48.597
where in that scenario, you're telling the
user, hey, it's gonna take a second, but

72
00:04:48.597 --> 00:04:50.628
we're not blocking you to stay here.

73
00:04:50.628 --> 00:04:54.784
You can go and do something else and
then when it's done, we'll come back, and

74
00:04:54.784 --> 00:04:58.880
then that allows all the services to
communicate with each other internally,

75
00:04:58.880 --> 00:05:00.141
do whatever they need.

76
00:05:00.141 --> 00:05:03.778
So, there's a few different approaches,
the most common one though,

77
00:05:03.778 --> 00:05:07.784
is this approach here where you have
services speaking directly to each other.

78
00:05:07.784 --> 00:05:11.438
They have designated endpoints,
and again, GRPC,

79
00:05:11.438 --> 00:05:16.470
I think is a really good approach to that,
not only because it works in go,

80
00:05:16.470 --> 00:05:21.525
but GRPC is also available to be created
clients for almost any language.

81
00:05:21.525 --> 00:05:27.291
So, if you had a front end that was Java,
God, I feel sorry for you.

82
00:05:27.291 --> 00:05:32.379
But if you had a front end that was Java,
you could technically unify

83
00:05:32.379 --> 00:05:37.213
those services with GRPC because
Java can create GRPC clients.

84
00:05:37.213 --> 00:05:42.042
But again, if that Java service has to
make five hops, you might find yourself

85
00:05:42.042 --> 00:05:47.106
going on a queue-based system or an
event-based system or something like that.

86
00:05:47.106 --> 00:05:51.024
That's why we're really not going into
that too much in these slides just because

87
00:05:51.024 --> 00:05:53.194
those are a little bit
more circumstantial.

88
00:05:53.194 --> 00:05:57.014
Most of the time,
as long as you're building good isolation,

89
00:05:57.014 --> 00:05:59.044
good separation, this is fine.

90
00:05:59.044 --> 00:06:04.901
Again, whenever we get a Twitch chat
message, we go out to a API for

91
00:06:04.901 --> 00:06:11.194
our data, we go out to an API for
our AI stuff, and those are separated.

92
00:06:11.194 --> 00:06:16.239
But because they're so fast, and
they are easy to respond, we don't really

93
00:06:16.239 --> 00:06:21.297
worry about it, the latency is maybe,
like 250, 300 milliseconds.

94
00:06:21.297 --> 00:06:24.528
And so, that's another thing
you have to ask yourself,

95
00:06:24.528 --> 00:06:28.580
is how quickly are you concerned
about these requests coming through?

96
00:06:28.580 --> 00:06:30.840
And if you need to adapt
to that requirement,

97
00:06:30.840 --> 00:06:34.714
that's a requirement to me more than
something you just think of naturally.

