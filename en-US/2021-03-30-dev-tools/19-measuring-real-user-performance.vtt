WEBVTT

1
00:00:00.390 --> 00:00:05.157
So the very last thing I wanted to
cover as network stuff is the idea of

2
00:00:05.157 --> 00:00:07.680
measuring real user performance.

3
00:00:07.680 --> 00:00:10.360
So this is a really cool idea.

4
00:00:10.360 --> 00:00:14.347
It was actually something I didn't
get into until later in my career.

5
00:00:14.347 --> 00:00:16.402
So what we would always
do is we would like,

6
00:00:16.402 --> 00:00:18.513
again, we are like authoring a web app,
and

7
00:00:18.513 --> 00:00:22.300
we look at it on our machine and we
are like, it is pretty fast or whatever.

8
00:00:22.300 --> 00:00:24.510
We know the amount of
milliseconds that it takes.

9
00:00:24.510 --> 00:00:28.058
And then somebody even asked
a question earlier about like, but

10
00:00:28.058 --> 00:00:31.310
does it normalize that data based
on your network conditions?

11
00:00:31.310 --> 00:00:32.730
And it does not.

12
00:00:32.730 --> 00:00:37.610
But I think that's hinting at a really a
larger question, which is like, okay, but

13
00:00:37.610 --> 00:00:40.976
how fast is it for your average user or
like how fast is it for

14
00:00:40.976 --> 00:00:43.550
the bottom 10% slowest user computers?

15
00:00:43.550 --> 00:00:44.465
Or something like that.

16
00:00:44.465 --> 00:00:49.330
And so this idea came around a long time
ago of shipping some code that would

17
00:00:49.330 --> 00:00:54.273
like sort of get the time that it actually
takes on their actual computer and

18
00:00:54.273 --> 00:00:56.150
send it back to you.

19
00:00:56.150 --> 00:01:00.576
So at its like absolute simplest, you
could stand up a service that takes like

20
00:01:00.576 --> 00:01:04.456
maybe a username and event like
the page to load and a time, right and

21
00:01:04.456 --> 00:01:07.205
you could have a database
that stores all that.

22
00:01:07.205 --> 00:01:11.310
Then you could ship some JavaScript in
your actual app that looks like this.

23
00:01:11.310 --> 00:01:15.780
And let's say this for loop that's doing
nothing is your page to load or whatever.

24
00:01:15.780 --> 00:01:17.890
So you could do like a start
time using date time.

25
00:01:17.890 --> 00:01:21.410
And then you could do some expensive
thing and then you could do an end time.

26
00:01:21.410 --> 00:01:24.976
And then you can figure out the difference
yourself by doing n minus star and

27
00:01:24.976 --> 00:01:27.540
then you could send that
to this cool service.

28
00:01:27.540 --> 00:01:30.650
You can be like, whoa,
like most people, it takes one second.

29
00:01:30.650 --> 00:01:35.120
But look at this, a few 100 people, it's
taking 30 seconds what's going on there.

30
00:01:35.120 --> 00:01:38.960
And you can learn all sorta cool stuff
like, we have our data centers in the US.

31
00:01:38.960 --> 00:01:43.310
But we're getting a really big,
African bump in users.

32
00:01:43.310 --> 00:01:45.060
We should get a data center out there.

33
00:01:45.060 --> 00:01:46.130
We should do something like that.

34
00:01:46.130 --> 00:01:49.130
So this happens to us a lot
like at Twitter at startups.

35
00:01:49.130 --> 00:01:54.350
You'll see your app will go big in a new
place that it hasn't been big before.

36
00:01:54.350 --> 00:01:58.176
And all of a sudden everybody's kind
of crossing over the the data takes

37
00:01:58.176 --> 00:01:59.200
a long time.

38
00:01:59.200 --> 00:02:03.799
So this can be really cool to A, see what
how it performs on slower computers but B,

39
00:02:03.799 --> 00:02:08.202
to recognize when something has changed,
like you have a new country city zone

40
00:02:08.202 --> 00:02:12.360
that's getting really popular and
you wanna go add some resources to it.

41
00:02:12.360 --> 00:02:14.500
So this is what we used to do.

42
00:02:14.500 --> 00:02:18.150
But then we got this really cool thing
called console time, which is way better.

43
00:02:18.150 --> 00:02:20.473
So instead of doing the math ourselves,

44
00:02:20.473 --> 00:02:23.950
we could just console time
we could pass in a string.

45
00:02:23.950 --> 00:02:27.119
Now we do the thing when it console
time end the same string and

46
00:02:27.119 --> 00:02:28.610
then it keeps track of it.

47
00:02:28.610 --> 00:02:31.220
It prints it out for us,
which is like super cool.

48
00:02:31.220 --> 00:02:36.110
And it's also more accurate it prints
it out down to a more finite number.

49
00:02:36.110 --> 00:02:40.420
So then that was the cool thing to do for
a really long time.

50
00:02:40.420 --> 00:02:44.646
And now we have an even cooler thing,
[LAUGH] which I get really excited about,

51
00:02:44.646 --> 00:02:46.350
which is the performance API.

52
00:02:46.350 --> 00:02:49.810
And so, again, these are all doing
the exact same thing, right?

53
00:02:49.810 --> 00:02:53.437
But it's like, instead of console time and
console time end,

54
00:02:53.437 --> 00:02:58.229
you do performance, which is a global, dot mark,
and then performance.markend, and

55
00:02:58.229 --> 00:03:01.719
then you can print out, mark and
measure is the technology,

56
00:03:01.719 --> 00:03:05.980
so then I print out a random string,
and then which two things to compare.

57
00:03:05.980 --> 00:03:10.330
So this is very much the same as, up here
where I would do like console and start.

58
00:03:10.330 --> 00:03:14.727
But the cool thing about doing it this
way is not only do you get that time, but

59
00:03:14.727 --> 00:03:19.300
it actually is like a standardized
thing that other browsers recognize.

60
00:03:19.300 --> 00:03:24.770
So if you run some code like this,
and let me see if I have some going,

61
00:03:28.370 --> 00:03:32.049
Yeah, so if you run some code like this
and you do a performance measurement,

62
00:03:32.049 --> 00:03:34.270
which is what the tab
we're gonna cover next.

63
00:03:34.270 --> 00:03:37.183
But if you do a record, and
then you refresh the page, and

64
00:03:37.183 --> 00:03:40.180
then you stop the recording,
we can ignore a lot of stuff.

65
00:03:40.180 --> 00:03:44.449
But we can see that my mark and measure
actually made it into a brand new section

66
00:03:44.449 --> 00:03:48.860
called Timings in the Performance tab
where I can actually see how long it took.

67
00:03:48.860 --> 00:03:50.130
I can interact with that.

68
00:03:50.130 --> 00:03:53.480
So it's like way cooler than console
logging out, end minus start or

69
00:03:53.480 --> 00:03:56.716
whatever you do a performance mark and
a performance measure, and

70
00:03:56.716 --> 00:04:00.471
it'll actually show you in the Performance
tab, exactly how long it took and

71
00:04:00.471 --> 00:04:02.585
what it was doing and
cool stuff like that.

72
00:04:02.585 --> 00:04:05.170
So these are really cool
to add something like this,

73
00:04:05.170 --> 00:04:07.315
whichever approach you take is fine.

74
00:04:07.315 --> 00:04:10.375
And to stand up some kind of
service that receives all of it.

75
00:04:10.375 --> 00:04:13.930
And you can really see how long it's
taking your actual users to load your

76
00:04:13.930 --> 00:04:14.635
actual code.

77
00:04:15.705 --> 00:04:18.445
The performance API also has
a bunch of really cool stuff.

78
00:04:18.445 --> 00:04:23.069
I'm not gonna cover it in depth, but I did
just wanna show you so just on any random

79
00:04:23.069 --> 00:04:26.879
site, you can do something like
Performance get entries by type,

80
00:04:26.879 --> 00:04:28.460
and then you pass in a type.

81
00:04:28.460 --> 00:04:31.580
So I'll print this get
entries by type of resource.

82
00:04:31.580 --> 00:04:34.681
And it'll actually show me all
eight of the resources at grab,

83
00:04:34.681 --> 00:04:37.270
which is the exact same stuff
that you see over here.

84
00:04:37.270 --> 00:04:41.502
But you can start like brainstorming like
as you get more into this stuff that you

85
00:04:41.502 --> 00:04:44.848
could totally build your own Tooling,
around, for example,

86
00:04:44.848 --> 00:04:48.280
you could just take this, and
you could send it to your service.

87
00:04:48.280 --> 00:04:51.983
So your user sending it in, and
now you can see the network waterfall, for

88
00:04:51.983 --> 00:04:55.230
your users in real time,
as opposed to just you using your app.

89
00:04:55.230 --> 00:04:57.820
Things like that.
You could do paints.

90
00:04:57.820 --> 00:05:00.781
So every time the browser
has to do a repaint, and

91
00:05:00.781 --> 00:05:02.670
you can see what was it called?

92
00:05:02.670 --> 00:05:03.290
What did it?

93
00:05:03.290 --> 00:05:03.880
What triggered it?

94
00:05:03.880 --> 00:05:04.840
How long did it take?

95
00:05:04.840 --> 00:05:06.030
All these really cool things.

96
00:05:06.030 --> 00:05:09.977
So it's basically the same API that
Dev Tools is using to do its like network

97
00:05:09.977 --> 00:05:11.570
stuff and things like that.

98
00:05:11.570 --> 00:05:15.335
But now you can not only harness it by
making custom scripts where you can

99
00:05:15.335 --> 00:05:18.158
actually grab that user data and
send it to a service,

100
00:05:18.158 --> 00:05:22.210
you can way better understand how
long all these things are taking.

101
00:05:22.210 --> 00:05:22.952
This was really cool.

102
00:05:22.952 --> 00:05:26.238
I would just if I were you,
I just do like a performance.

103
00:05:26.238 --> 00:05:28.927
And then do a dot and
just check out all these like very,

104
00:05:28.927 --> 00:05:30.520
very cool things that it can do.

105
00:05:30.520 --> 00:05:32.918
And MDN has really great
docs on the performance API,

106
00:05:32.918 --> 00:05:34.310
which I've linked to up here.

107
00:05:34.310 --> 00:05:36.525
It really opens up like a whole
world of stuff you can do.

