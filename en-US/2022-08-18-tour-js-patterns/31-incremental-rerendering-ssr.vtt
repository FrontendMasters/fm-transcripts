WEBVTT

1
00:00:00.420 --> 00:00:03.636
Another thing you could do,
now for cell with Next.js,

2
00:00:03.636 --> 00:00:06.252
we call it incremental
static regeneration.

3
00:00:06.252 --> 00:00:10.201
But there are frameworks that have other
approaches with kind of a stale while

4
00:00:10.201 --> 00:00:11.423
revalidate approach.

5
00:00:11.423 --> 00:00:13.514
And this is also to kind
of add this dynamic data.

6
00:00:13.514 --> 00:00:17.550
So we can opt into only pre-render,
a subset of all the pages, and

7
00:00:17.550 --> 00:00:19.725
render everything else on demand.

8
00:00:19.725 --> 00:00:23.446
So let's say we know we
have 1,000 listings.

9
00:00:23.446 --> 00:00:27.012
We only want to make sure that we
pre-render the latest 20 listings

10
00:00:27.012 --> 00:00:31.196
that are maybe visible instantly to the
user and that the user is likely to click.

11
00:00:31.196 --> 00:00:34.522
But everything else will
be generated on demand.

12
00:00:34.522 --> 00:00:39.453
So in that case, the statically generated
page, when a user requests a page that

13
00:00:39.453 --> 00:00:44.330
hasn't been generated yet, can still
be cached by a CDN because it's static.

14
00:00:44.330 --> 00:00:47.473
So it's really only the first user
that request those pages that

15
00:00:47.473 --> 00:00:51.037
haven't been generated yet
that might experience worst performance.

16
00:00:51.037 --> 00:00:54.567
But everyone else can still
experience from this cache or

17
00:00:54.567 --> 00:00:57.260
benefit from this cache response.

18
00:00:57.260 --> 00:00:59.630
And then also we have
the stale while revalidate.

19
00:00:59.630 --> 00:01:04.239
So we can automatically invalidate
the cache of this static page after

20
00:01:04.239 --> 00:01:05.780
a certain time.

21
00:01:05.780 --> 00:01:09.693
So if a user requests a stale page, so it
has been cached for longer than we showed,

22
00:01:09.693 --> 00:01:13.582
it will automatically regenerate that in
the background and replace the cache.

23
00:01:13.582 --> 00:01:16.151
So a user will initially
see the stale content, but

24
00:01:16.151 --> 00:01:19.694
the next time they request it,
they automatically see this new data.

25
00:01:19.694 --> 00:01:24.686
Because the getStaticProps method again
run in the background, in Next.js's case,

26
00:01:24.686 --> 00:01:28.271
in a serverless function, but
it could also be in your server.

27
00:01:28.271 --> 00:01:32.099
So this is a great way to have this
dynamic data maybe based on a certain

28
00:01:32.099 --> 00:01:36.059
interval and to make sure that your
users are still able to see something

29
00:01:36.059 --> 00:01:38.580
because there's always a cached response.

30
00:01:38.580 --> 00:01:43.344
I won't really go too much into the
implementation of this one just because

31
00:01:43.344 --> 00:01:45.319
this is so Next.js specific.

32
00:01:45.319 --> 00:01:48.144
And it's more about the possibilities
with static rendering and

33
00:01:48.144 --> 00:01:49.949
how you could possibly add dynamic data.

34
00:01:52.473 --> 00:01:56.774
Now, the other very popular
pattern is server-side rendering.

35
00:01:56.774 --> 00:01:59.974
So with server-side rendering,
we generate the HTML, so

36
00:01:59.974 --> 00:02:03.623
all the HTML on the server or
serverless function on every request.

37
00:02:03.623 --> 00:02:06.459
So the user request the page,
we just generate it and

38
00:02:06.459 --> 00:02:08.077
we show it to them right away.

39
00:02:08.077 --> 00:02:12.697
And then, of course, we have to create or
make an additional request to

40
00:02:12.697 --> 00:02:16.403
fetch the bundle to hydrate
those static HTML elements.

41
00:02:16.403 --> 00:02:21.240
And this is a great way if the page that
you're rendering is highly dynamic or

42
00:02:21.240 --> 00:02:24.575
just contains any data that
is within that request.

43
00:02:24.575 --> 00:02:28.788
Maybe a user cookie, I don't know,
maybe missing authentication states.

44
00:02:28.788 --> 00:02:31.988
But in general, you probably wanna
avoid server-side rendering cuz,

45
00:02:31.988 --> 00:02:35.253
as you can see, the page still had to
be generated or the user requests it.

46
00:02:35.253 --> 00:02:37.692
And this could take a while.

47
00:02:37.692 --> 00:02:42.427
So it's still great for
those dynamic pages, but for

48
00:02:42.427 --> 00:02:48.015
just a normal standalone application,
you might not need it.

49
00:02:48.015 --> 00:02:51.449
So in React, we can actually implement
server-side rendering with, for

50
00:02:51.449 --> 00:02:54.729
example, a renderToString, and
then the hydrateRoot on the client.

51
00:02:54.729 --> 00:02:58.376
So it gets that, it makes the DOM tree,
and it then hydrates it.

52
00:02:58.376 --> 00:03:02.865
Hydrating, you're adding
those event listeners.

53
00:03:02.865 --> 00:03:06.690
Again, yeah, so next, we can use
server-side rendering with instead of

54
00:03:06.690 --> 00:03:09.922
using getStaticProps,
we can just use getServerSideProps.

55
00:03:09.922 --> 00:03:13.737
And this will automatically
server render this page.

56
00:03:13.737 --> 00:03:18.749
So for example here, If I,

57
00:03:21.284 --> 00:03:23.871
Go in here.

58
00:03:23.871 --> 00:03:28.164
Now, from a user perspective,
this won't be that much different compared

59
00:03:28.164 --> 00:03:32.605
to static rendering because the return
HTML is the exact same as we saw before.

60
00:03:32.605 --> 00:03:36.843
However, this HTML is generated on
demand on the server instead of

61
00:03:36.843 --> 00:03:42.003
pre-generated at build time, maybe on
your own device, on some built server.

62
00:03:43.833 --> 00:03:46.654
Now, the performance for
server-side rendering and

63
00:03:46.654 --> 00:03:48.745
static rendering look pretty similar.

64
00:03:48.745 --> 00:03:50.644
But the biggest difference here
is the time to first byte.

65
00:03:50.644 --> 00:03:53.577
Because it can take a while from when
a user requests it to when the server can

66
00:03:53.577 --> 00:03:56.012
actually respond with the data
that it still has to generate.

67
00:03:56.012 --> 00:03:59.760
So when the time to first byte is slow,
the user just looks at a blank page,

68
00:03:59.760 --> 00:04:00.795
which is not great.

69
00:04:00.795 --> 00:04:03.367
You probably wanna avoid that.

70
00:04:03.367 --> 00:04:06.746
But it's still great for
having those very personalized pages or

71
00:04:06.746 --> 00:04:09.094
any page that's render blocking, really.

72
00:04:09.094 --> 00:04:11.138
Cuz we can just say,
you don't have the right cookie,

73
00:04:11.138 --> 00:04:13.012
you don't have the right
authentication state.

74
00:04:13.012 --> 00:04:14.620
I don't want to render this page.

75
00:04:16.410 --> 00:04:20.555
And another downside to server-side
rendering is if you're using a server or

76
00:04:20.555 --> 00:04:23.942
a Lambda, and your server goes down or
your region goes down, so

77
00:04:23.942 --> 00:04:25.031
does your website.

78
00:04:25.031 --> 00:04:29.319
Cuz there's usually not a cached version,
unless you add a cache control.

79
00:04:29.319 --> 00:04:33.105
But in most cases when you use SSR,
you don't wanna use cache control.

80
00:04:33.105 --> 00:04:36.525
Because there shouldn't be a cached
version cuz it's personalized on every

81
00:04:36.525 --> 00:04:37.743
request, or it should be.

82
00:04:37.743 --> 00:04:42.261
That's the best use case for
server rendering.

83
00:04:42.261 --> 00:04:43.289
So that's definitely a downside.

84
00:04:43.289 --> 00:04:45.890
It's just more to maintain.

85
00:04:45.890 --> 00:04:46.698
Now, currently,

86
00:04:46.698 --> 00:04:50.700
a lot of people are also exploring
with streaming server-side rendering.

87
00:04:50.700 --> 00:04:54.428
So the biggest difference
here is with normal SSR,

88
00:04:54.428 --> 00:04:58.935
we had to create the entire HTML and
fetch the entire bundle and

89
00:04:58.935 --> 00:05:02.679
parse this bundle before
any hydration can begin.

90
00:05:02.679 --> 00:05:03.500
We had to wait for

91
00:05:03.500 --> 00:05:08.230
all the components to be ready before
any component could be ready, really.

92
00:05:08.230 --> 00:05:10.425
While with streaming server rendering,

93
00:05:10.425 --> 00:05:14.610
the components get streamed as soon
as they're generated on the server.

94
00:05:14.610 --> 00:05:17.034
So we see it can be generated
in smaller parts, and

95
00:05:17.034 --> 00:05:19.640
also something called
progressively hydrated.

96
00:05:19.640 --> 00:05:23.451
So whereas normal hydration, we had to
wait for the entire bundle to be ready,

97
00:05:23.451 --> 00:05:25.670
parsed before the entire
tree was hydrated.

98
00:05:25.670 --> 00:05:28.120
With progressive hydration,
we can actually say, okay,

99
00:05:28.120 --> 00:05:31.560
just hydrate this component, just hydrate
that component as soon as it's ready.

100
00:05:32.630 --> 00:05:37.607
So this is great for performance as we
can instantly show our users like, okay,

101
00:05:37.607 --> 00:05:40.240
these smaller components are ready.

102
00:05:40.240 --> 00:05:44.489
So show them, don't wait for these larger
components to generate on the server cuz

103
00:05:44.489 --> 00:05:46.749
that could end up in
a bad time to first byte.

104
00:05:46.749 --> 00:05:49.856
So the performance here looks interesting.

105
00:05:49.856 --> 00:05:54.432
So as it streamed down,
we don't really have one big,

106
00:05:54.432 --> 00:05:59.418
I guess the blue was, wait,
I just gotta make sure of that.

107
00:05:59.418 --> 00:06:00.977
I guess that is parsing HTML.

108
00:06:00.977 --> 00:06:04.903
Yeah, so here, it parses the HTML layout
panes and parses it again, layout pane,

109
00:06:04.903 --> 00:06:06.766
because it's constantly getting it.

110
00:06:06.766 --> 00:06:09.583
It's like a stream,
which is great for, as you can see,

111
00:06:09.583 --> 00:06:13.111
the time to first byte is extremely
fast because the smallest component

112
00:06:13.111 --> 00:06:14.843
can stream as soon as it's ready.

113
00:06:14.843 --> 00:06:18.341
And also the first contentful pane can be
really fast because the first component

114
00:06:18.341 --> 00:06:19.276
can already render.

115
00:06:19.276 --> 00:06:23.780
And it can be interactive if it
uses a progressive hydration.

116
00:06:23.780 --> 00:06:28.154
The largest contentful pane is still the
same as with normal server-side rendering

117
00:06:28.154 --> 00:06:28.960
in most cases.

118
00:06:28.960 --> 00:06:34.240
Because we still have to wait for
that entire component to be generated and

119
00:06:34.240 --> 00:06:37.488
then rendered, hydrated, all that stuff.

120
00:06:37.488 --> 00:06:41.241
Yeah, it's also great for
the network backpressure.

121
00:06:41.241 --> 00:06:46.017
And the only downside is that the HTTP
streaming is not supported on

122
00:06:46.017 --> 00:06:47.530
all runtimes yet.

123
00:06:47.530 --> 00:06:51.360
So in some cases,
I believe that Lambda doesn't support it.

124
00:06:51.360 --> 00:06:55.819
I may be wrong here, but maybe you've
deployed your server rendered app

125
00:06:55.819 --> 00:06:59.122
somewhere in a runtime that
does support streaming.

126
00:06:59.122 --> 00:07:00.979
In that case, you can't use it.

127
00:07:00.979 --> 00:07:03.347
But yeah, that's really the only downside.

128
00:07:03.347 --> 00:07:07.655
Now, I didn't cover this here, but
with the new React server components,

129
00:07:07.655 --> 00:07:09.686
this is actually a big part of that.

130
00:07:09.686 --> 00:07:14.433
Because streaming SSR kind of allows us
to have a partially statically generated

131
00:07:14.433 --> 00:07:16.612
page, and then partially SSR page.

132
00:07:16.612 --> 00:07:18.229
Because we can SSR certain components.

133
00:07:18.229 --> 00:07:20.481
It's not like the entire
page like we saw before.

134
00:07:20.481 --> 00:07:24.768
So we can static render the static parts
of a page, which is great for performance.

135
00:07:24.768 --> 00:07:30.549
And then only server render any components
that need that server-specific data.

136
00:07:30.549 --> 00:07:31.687
So that's very exciting.

