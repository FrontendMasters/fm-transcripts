WEBVTT

1
00:00:00.000 --> 00:00:03.389
&gt;&gt; Steve Kinney: There was a theme in
the beginning which is like taking over

2
00:00:03.389 --> 00:00:05.196
someone's session, right?

3
00:00:05.196 --> 00:00:11.464
That's bad, because once you can take
someone's session, you can be them.

4
00:00:11.464 --> 00:00:15.922
And that's obviously a compelling target,
but like, you protect those cookies,

5
00:00:15.922 --> 00:00:20.271
you put a bunch of safeguards in your
business logic, you sanitize your queries.

6
00:00:20.271 --> 00:00:24.531
You're getting to the point where you're
getting, obviously there's, again,

7
00:00:24.531 --> 00:00:27.471
all security vulnerabilities
are not the obvious thing,

8
00:00:27.471 --> 00:00:31.623
they are some tiny, little edge case,
and we certainly didn't get to 100%.

9
00:00:31.623 --> 00:00:35.178
But what I think is important
to do is at least call

10
00:00:35.178 --> 00:00:39.621
out that there are still more
ways that your life can be hard.

11
00:00:39.621 --> 00:00:44.965
And this one is, it's like one of those
ones where I think the danger is that,

12
00:00:44.965 --> 00:00:48.992
kind of on that theme I just said,
where it's like, yes,

13
00:00:48.992 --> 00:00:53.546
there are a lot of tools and
safeguards in place that protect you.

14
00:00:53.546 --> 00:00:56.881
But you're not protected simultaneously,
right?

15
00:00:56.881 --> 00:01:00.273
There are still avenues where this works.

16
00:01:00.273 --> 00:01:03.606
And so
this is called cross-site request forgery.

17
00:01:03.606 --> 00:01:09.204
You're not trying to be the person,
you are trying to trick the person's

18
00:01:09.204 --> 00:01:14.819
browser into doing something that
they didn't intend on doing, right?

19
00:01:14.819 --> 00:01:17.095
So you'd at no point get their token,

20
00:01:17.095 --> 00:01:21.516
you don't even technically get
the information from a request, right?

21
00:01:21.516 --> 00:01:28.874
But you are effectively seeking to trick
their browser into doing something, right?

22
00:01:28.874 --> 00:01:35.082
And they legitimately have a cookie
that says that they are them, right?

23
00:01:35.082 --> 00:01:39.824
And so if you are able to trick them into
doing something, yes, you didn't become

24
00:01:39.824 --> 00:01:44.933
them, you didn't steal their cookie, but
you could theoretically get some benefit.

25
00:01:44.933 --> 00:01:50.686
And so, for this, and
when we talk about cross-site scripting,

26
00:01:50.686 --> 00:01:55.840
which is a different form of an attack,
there is prior art.

27
00:01:55.840 --> 00:02:00.940
So for instance,
in 2010 there was a Twitter worm, and

28
00:02:00.940 --> 00:02:06.762
a worm is basically a attack that
then spreads itself, basically.

29
00:02:06.762 --> 00:02:09.594
In the case studies in this course,
did I include every Twitter attack?

30
00:02:09.594 --> 00:02:14.498
No, because after a certain point where
it was getting hard to name them all.

31
00:02:14.498 --> 00:02:19.413
So this is a CSRF worm,
where Twitter used to have an API, right?

32
00:02:19.413 --> 00:02:22.924
Twitter.com/share/update, and

33
00:02:22.924 --> 00:02:27.205
then a query param with your message,
right?

34
00:02:27.205 --> 00:02:33.493
And so basically, by calling a GET request
to that URL, you would post a message.

35
00:02:33.493 --> 00:02:38.371
You can put GET requests lots of places,
every image is a get request.

36
00:02:38.371 --> 00:02:42.234
Right, just clicking on
a link is a get request.

37
00:02:42.234 --> 00:02:47.939
You can call it a fetch without
even worrying about, of course,

38
00:02:47.939 --> 00:02:53.976
you can put a background CSS class
that calls a GET request, right?

39
00:02:53.976 --> 00:02:57.380
And so I won't tell you the details
of what this one posts,

40
00:02:57.380 --> 00:03:00.384
because it's not appropriate for
this audience.

41
00:03:00.384 --> 00:03:05.324
But basically, by seeing the link and
then hovering over it,

42
00:03:05.324 --> 00:03:07.707
you too would tweet the link.

43
00:03:07.707 --> 00:03:12.560
And this will be a theme that
we'll see of one of the easiest

44
00:03:12.560 --> 00:03:16.918
ways you could still be
vulnerable to CSRF attacks,

45
00:03:16.918 --> 00:03:22.487
is by just sheerly breaking
the principles of HTTP verbs, right?

46
00:03:22.487 --> 00:03:25.862
GET should always be idempotent,
which it means it shouldn't change state.

47
00:03:25.862 --> 00:03:26.994
You might get something back, but

48
00:03:26.994 --> 00:03:28.801
it shouldn't change anything
on the server, right?

49
00:03:28.801 --> 00:03:34.789
And this violates that and
creates a security hole as we go along.

50
00:03:34.789 --> 00:03:40.191
Netflix had, again,
a similar idea with a GET request,

51
00:03:40.191 --> 00:03:44.819
where you could just do
this JSON/AddToQueue?

52
00:03:44.819 --> 00:03:49.219
And now if you had at any point
visited a page with that image,

53
00:03:49.219 --> 00:03:53.361
the image wouldn't load,
cuz that's not an image, but

54
00:03:53.361 --> 00:03:56.399
the GET request is gonna be sent, right?

55
00:03:56.399 --> 00:04:01.146
Which means all of a sudden you
had brand-new DVDs in your queue,

56
00:04:01.146 --> 00:04:05.978
and like yeah, I guess that's
not like a life-changing attack,

57
00:04:05.978 --> 00:04:09.361
it depends on what the DVDs are,
doesn't it?

58
00:04:09.361 --> 00:04:14.044
And depends on who's looking at your
queue next, it could make for a bad day.

59
00:04:14.044 --> 00:04:17.035
In 2008 there was this paper that came

60
00:04:17.035 --> 00:04:21.655
out that really kind of talked
about about the breadth of these.

61
00:04:21.655 --> 00:04:26.556
And they, for most of these, they had
disclosed them before they put them out,

62
00:04:26.556 --> 00:04:28.914
but there were some bad ones in there.

63
00:04:28.914 --> 00:04:32.333
So this is kind of another way
of just data exfiltration,

64
00:04:32.333 --> 00:04:36.678
which is New York Times had this form
on every article called email this,

65
00:04:36.678 --> 00:04:39.978
that made a post request and
sent out an email, right?

66
00:04:39.978 --> 00:04:43.442
But the thing about CSRF attacks,
it's like send and forget.

67
00:04:43.442 --> 00:04:45.117
You don't get the response back.

68
00:04:45.117 --> 00:04:49.777
So what they would do, is they would cause
your browser to send a post request with

69
00:04:49.777 --> 00:04:54.522
basically you emailing them the article,
which at least will leak what your email address was.

70
00:04:54.522 --> 00:04:59.388
They could put on spam lists and build
up nice, ugly, list that they could sell,

71
00:04:59.388 --> 00:05:01.190
and stuff along those lines.

72
00:05:01.190 --> 00:05:04.252
Right, and it was just a wide open,
like a tactic could just collect.

73
00:05:04.252 --> 00:05:08.690
And if technically using both the site
as it was intended to be used and

74
00:05:08.690 --> 00:05:13.586
tricking your browser into doing it,
and we'll see how to do it in a second,

75
00:05:13.586 --> 00:05:15.290
for nefarious purposes.

76
00:05:15.290 --> 00:05:19.303
And kinda like, one of those things,
they found it in this research paper and

77
00:05:19.303 --> 00:05:23.583
they disclosed it, but who knows how
long it was happening before then, right?

78
00:05:23.583 --> 00:05:26.518
This is where we get to that logging and
stuff along those lines.

79
00:05:26.518 --> 00:05:30.364
If you had logs and you had some
way to at least check to see, hey,

80
00:05:30.364 --> 00:05:35.941
it's weird that 10,000 articles this month
all got sent to the same address, right?

81
00:05:35.941 --> 00:05:37.910
This is where that thinking
about the vulnerabilities,

82
00:05:37.910 --> 00:05:39.475
you're not gonna catch
on that code review.

83
00:05:39.475 --> 00:05:42.339
You're not gonna even catch
that probably in a scan maybe.

84
00:05:42.339 --> 00:05:45.331
Maybe now you would, but
back then you wouldn't have, right?

85
00:05:45.331 --> 00:05:50.540
It comes of like thinking of,
if I were a bad person, not that I am,

86
00:05:50.540 --> 00:05:55.299
occasionally, what would I do and
how would I exploit this?

87
00:05:55.299 --> 00:05:58.488
In that same article,
they found this fun one,

88
00:05:58.488 --> 00:06:02.794
where you could open additional
accounts on behalf of the user or

89
00:06:02.794 --> 00:06:06.641
transfer funds from one user's
account to another one.

90
00:06:06.641 --> 00:06:11.412
Now this one again, we don't know
if it ever got exploited, right?

91
00:06:11.412 --> 00:06:16.239
Because researchers found it, but we don't
know if it didn't get exploited either.

92
00:06:16.239 --> 00:06:19.822
And it's one of those things where
some of these things just in the wild,

93
00:06:19.822 --> 00:06:20.780
in real use cases.

94
00:06:20.780 --> 00:06:25.390
YouTube in 2008, it's the same study,
had one we could basically do almost every

95
00:06:25.390 --> 00:06:27.739
action a YouTube user
could do at that time.

96
00:06:27.739 --> 00:06:31.913
Add stuff onto playlists, like,
all sorts of stuff like that, right?

97
00:06:31.913 --> 00:06:36.773
And again,
it was legit user sessions in browsers

98
00:06:36.773 --> 00:06:40.360
doing things that neither the site or

99
00:06:40.360 --> 00:06:45.462
the people whose browser
is expected to do, right?

100
00:06:45.462 --> 00:06:50.713
And as recently as 2020, there was
one that allowed account takeovers

101
00:06:50.713 --> 00:06:56.216
through third party applications that
could then trigger a password reset for

102
00:06:56.216 --> 00:07:00.240
TikTok and allow someone to
fully take over the account.

103
00:07:00.240 --> 00:07:04.051
Cuz again, that's a legit request, but
the end result is the changed password.

104
00:07:04.051 --> 00:07:07.935
Now, again, well, and then when I go
over the kind of definition of a CSRF,

105
00:07:07.935 --> 00:07:10.696
but I'll say it now,
it's fire and forget, right?

106
00:07:10.696 --> 00:07:12.298
Cuz you're taking their browser and

107
00:07:12.298 --> 00:07:14.886
making it do something,
you don't get the response back.

108
00:07:14.886 --> 00:07:19.843
But if one had a bunch of emails from
any kind of leaked data set, even that

109
00:07:19.843 --> 00:07:25.154
New York Times one, and one was changing
all the passwords to the same thing.

110
00:07:25.154 --> 00:07:30.756
Yeah, you gotta do some brute force
work to put two and two together,

111
00:07:30.756 --> 00:07:35.788
but on a large enough data set,
right, you will do it as well.

