WEBVTT

1
00:00:00.000 --> 00:00:05.479
We have the functionality to click on
the button and start keeping some data,

2
00:00:05.479 --> 00:00:10.552
in memory or at least, not the old ones,
but the latest ones in memory.

3
00:00:10.552 --> 00:00:12.899
And we have our function to get the image.

4
00:00:12.899 --> 00:00:17.817
So maybe below we have a training button
that we declared at the beginning here

5
00:00:17.817 --> 00:00:19.338
to start the training.

6
00:00:19.338 --> 00:00:25.495
So we're going to add a onClick event so
train button.

7
00:00:25.495 --> 00:00:28.959
Once we're ready to train,
we have an async function.

8
00:00:28.959 --> 00:00:34.096
And we are going to call
the function we haven't called yet.

9
00:00:34.096 --> 00:00:35.712
Basically, we're gonna call it train.

10
00:00:35.712 --> 00:00:40.697
And what we want is to maybe update
the UI as well to say that now we're

11
00:00:40.697 --> 00:00:42.626
kind of in training mode.

12
00:00:42.626 --> 00:00:47.798
So the status element, we were hiding
it before when the model was loaded,

13
00:00:47.798 --> 00:00:50.026
so now we can just bring it back.

14
00:00:50.026 --> 00:00:51.943
But just change, its innerHTML.

15
00:00:51.943 --> 00:00:56.437
So we have statusElement, innerHTML,

16
00:00:56.437 --> 00:01:00.276
and just gonna set it to training.

17
00:01:00.276 --> 00:01:05.508
So, we have a function that we need to
declare, but at least the UI is updating

18
00:01:05.508 --> 00:01:10.192
to tell the users like, wait a minute,
I'm training, basically.

19
00:01:10.192 --> 00:01:15.598
Okay, so
now let's create our train function.

20
00:01:15.598 --> 00:01:19.405
And this is where we're
gonna declare a new model.

21
00:01:19.405 --> 00:01:23.381
So const train and
then I'm opening function here.

22
00:01:23.381 --> 00:01:27.967
And because we're just
starting the train function,

23
00:01:27.967 --> 00:01:33.157
what I want is to set my isTraining
variable to true this time.

24
00:01:33.157 --> 00:01:37.613
And before I move on,
very important before we crash

25
00:01:37.613 --> 00:01:42.982
everyone's browser is that
remember a little bit earlier when

26
00:01:42.982 --> 00:01:48.063
I'm setting mouse down here
when I'm adding the example.

27
00:01:48.063 --> 00:01:51.287
Let's make sure that when we have
an on mouse up event as well,

28
00:01:51.287 --> 00:01:53.967
we're actually setting
that mouse down to false.

29
00:01:53.967 --> 00:01:57.047
Otherwise we'll be stuck in a loop for
long time.

30
00:01:57.047 --> 00:02:00.623
So if you find, again, that block or
you can write it anywhere.

31
00:02:00.623 --> 00:02:02.362
But I just like to keep it together.

32
00:02:02.362 --> 00:02:06.313
So here in the buttons container,
we have an unmatched up.

33
00:02:06.313 --> 00:02:10.236
So once we stop actually
pressing that button,

34
00:02:10.236 --> 00:02:14.562
we're just want to set that
variable back to false.

35
00:02:14.562 --> 00:02:18.084
So that means that once we
stop clicking on the button,

36
00:02:18.084 --> 00:02:20.241
the mouse down will not be false.

37
00:02:20.241 --> 00:02:24.366
And we will not be stuck
forever into this loop.

38
00:02:24.366 --> 00:02:26.718
I've done that before and
it crashed my browser.

39
00:02:26.718 --> 00:02:28.614
So that's what I'm telling you.

40
00:02:28.614 --> 00:02:35.182
We can now go back to our
training function, okay?

41
00:02:35.182 --> 00:02:39.727
So here we're setting
isTraining to true and

42
00:02:39.727 --> 00:02:43.202
maybe the first thing we wanna do.

43
00:02:43.202 --> 00:02:46.256
I like doing that it's not mandatory.

44
00:02:46.256 --> 00:02:50.016
But usually I say, okay,
if, oops, not that.

45
00:02:50.016 --> 00:02:54.608
If there is no examples
that we already added,

46
00:02:54.608 --> 00:02:59.690
I just want to either console.error or
anything.

47
00:02:59.690 --> 00:03:04.387
And I want to tell the user you forgot

48
00:03:04.387 --> 00:03:08.934
to add examples before training.

49
00:03:08.934 --> 00:03:13.087
Because if you call this, and
actually you should probably

50
00:03:13.087 --> 00:03:17.083
throw this error cuz we want
to stop the rest of the logic.

51
00:03:17.083 --> 00:03:20.061
It's not gonna do anything if it's
gonna try to create a model and

52
00:03:20.061 --> 00:03:21.807
training on data that does not exist.

53
00:03:21.807 --> 00:03:26.966
So if the user did not yet
created or added some examples in

54
00:03:26.966 --> 00:03:33.107
the function that we created here,
we should tell the user, stop.

55
00:03:33.107 --> 00:03:39.047
And yeah, and then hopefully
the user will add some examples and

56
00:03:39.047 --> 00:03:42.795
then we'll be able to run the training.

57
00:03:42.795 --> 00:03:49.328
So okay, we are slowly getting there.

58
00:03:49.328 --> 00:03:54.073
Okay, so to be able to train something,
we need something to train.

59
00:03:54.073 --> 00:03:55.402
So we need a model.

60
00:03:55.402 --> 00:03:59.568
So at the beginning we created
a variable called newModels.

61
00:03:59.568 --> 00:04:04.012
So now we're gonna actually do something
with it, and this is where you're going to

62
00:04:04.012 --> 00:04:07.468
see the syntax on how to actually
create a TensorFlow.js model.

63
00:04:07.468 --> 00:04:11.563
So we have our new model variable, and
I was talking a little bit earlier about

64
00:04:11.563 --> 00:04:14.716
the two types of models,
like sequential and functional.

65
00:04:14.716 --> 00:04:16.905
So here we're going to create
a sequential model, and

66
00:04:16.905 --> 00:04:18.339
we're gonna add multiple layers.

67
00:04:18.339 --> 00:04:22.594
So the way you do this is tf.sequential.

68
00:04:22.594 --> 00:04:25.954
And this going to take an object here, and

69
00:04:25.954 --> 00:04:30.083
the parameter that we're
gonna pass it is layers.

70
00:04:30.083 --> 00:04:36.737
So we have a layer, and that's going
to be an array of TensorFlow.js layers.

71
00:04:36.737 --> 00:04:41.621
So first of all,
we are going to pass it something

72
00:04:41.621 --> 00:04:46.638
related to the initial
model that we had at first.

73
00:04:46.638 --> 00:04:49.523
So we have tf.layers.

74
00:04:49.523 --> 00:04:52.676
It's like how you start to create layers.

75
00:04:52.676 --> 00:04:56.016
And the way that the did it.

76
00:04:56.016 --> 00:04:59.179
The first layer is flattened and

77
00:04:59.179 --> 00:05:04.930
the inputShape is going be
what is expected by MobileNet.

78
00:05:04.930 --> 00:05:06.942
Because again,
we're building on top of that model.

79
00:05:06.942 --> 00:05:12.314
So we have the initial model,
oops, initialModel.

80
00:05:12.314 --> 00:05:16.611
And the output of this model's outputs,

81
00:05:16.611 --> 00:05:19.939
and then we are shape and slice.

82
00:05:19.939 --> 00:05:23.079
So that will return to you the input

83
00:05:23.079 --> 00:05:27.966
shape that is expected by
the next layer of the model.

84
00:05:27.966 --> 00:05:31.016
So it is a bit complicated.

85
00:05:31.016 --> 00:05:34.191
It's not really something
that you can know at first.

86
00:05:34.191 --> 00:05:37.731
It's just, to me, I just know that
that worked for my application.

87
00:05:37.731 --> 00:05:42.722
But there are times when you might have to
try different methods on the object and

88
00:05:42.722 --> 00:05:43.327
seeing.

89
00:05:43.327 --> 00:05:46.582
So we have, in the very first layer,

90
00:05:46.582 --> 00:05:52.365
we kinda have an input shape of
what's expected from MobileNet.

91
00:05:52.365 --> 00:05:58.004
And then we can create another layer
that starts to be a bit more custom.

92
00:05:58.004 --> 00:06:05.295
So we can do tf.layers and
that's gonna be a dense layer.

93
00:06:05.295 --> 00:06:09.383
And that's the ones I've
mostly worked with as well.

94
00:06:09.383 --> 00:06:14.935
But there's different parameters that
you can start to set into this layer.

95
00:06:14.935 --> 00:06:18.604
And it's kind of related to what I was
talking when I introduced this section

96
00:06:18.604 --> 00:06:20.569
about activation and things like that.

97
00:06:20.569 --> 00:06:24.761
So first of all, we have units,
which is the dense units here,

98
00:06:24.761 --> 00:06:29.440
the variable that we declared at
the top that I think was set to 100.

99
00:06:29.440 --> 00:06:30.898
Let me scroll back.

100
00:06:30.898 --> 00:06:35.789
Yes, so it's like we're kind of
expecting that the output of

101
00:06:35.789 --> 00:06:39.281
the first layer is going to be 100 units.

102
00:06:39.281 --> 00:06:41.509
And they're gonna be fed
into the second layer.

103
00:06:41.509 --> 00:06:46.837
And here we have
an activation function that

104
00:06:46.837 --> 00:06:51.733
is going to be set to relu and
I forgot what

105
00:06:51.733 --> 00:06:57.071
relu means let me maybe
check quickly can I.

106
00:06:57.071 --> 00:07:04.181
I know that sometimes it's
a rectified linear unit.

107
00:07:04.181 --> 00:07:09.011
So sometimes because it's all about
data and algorithms and stuff.

108
00:07:09.011 --> 00:07:11.406
Sometimes you might not know
exactly what they do, but

109
00:07:11.406 --> 00:07:14.701
you might know the ones that you want
to use depending on your application.

110
00:07:14.701 --> 00:07:19.169
So it's been a trial and
error thing as well for this.

111
00:07:19.169 --> 00:07:21.948
But for now let's use that one.

112
00:07:21.948 --> 00:07:26.217
Again, then we have a next parameter

113
00:07:26.217 --> 00:07:31.037
that's called kernelInitializer, and

114
00:07:31.037 --> 00:07:36.556
this is also,
I think it's varianceScaling.

115
00:07:36.556 --> 00:07:41.091
And these ones as well, sometimes I do
not know exactly why they're better.

116
00:07:41.091 --> 00:07:45.903
But I know that in the context of doing
transfer learning this has worked for me.

117
00:07:45.903 --> 00:07:50.209
I think tomorrow when you create our own
model and we have different parameters,

118
00:07:50.209 --> 00:07:52.180
we can try and see what works better.

119
00:07:52.180 --> 00:07:56.965
But for now, we're gonna use that one and

120
00:07:56.965 --> 00:08:00.531
useBias is a habit set to true.

121
00:08:00.531 --> 00:08:01.577
Let me check.

122
00:08:04.501 --> 00:08:09.197
Okay, bias vector.

123
00:08:09.197 --> 00:08:12.773
I'm not sure that's
necessarily completely needed.

124
00:08:12.773 --> 00:08:14.332
Let's leave it to true.

125
00:08:14.332 --> 00:08:16.207
Use, sorry, not us.

126
00:08:16.207 --> 00:08:21.686
Use and it could be fun to actually
see we're gonna make this thing work.

127
00:08:21.686 --> 00:08:25.788
And then we can try and tweak some
parameters and see if maybe when we set it

128
00:08:25.788 --> 00:08:29.234
to false, it changes the output or
things like this, okay?

129
00:08:29.234 --> 00:08:33.616
So we need one more layer because
at this point, we need the units.

130
00:08:33.616 --> 00:08:38.483
You want your last layer to have a number
of units that's equals to the number of

131
00:08:38.483 --> 00:08:39.088
labels.

132
00:08:39.088 --> 00:08:42.322
So here, 100 is too much because
our labels are only two.

133
00:08:42.322 --> 00:08:44.295
So we're gonna just create one last layer.

134
00:08:44.295 --> 00:08:49.605
You could have a lot more,
if you if you want, as well, tf.layers.

135
00:08:49.605 --> 00:08:54.344
But in this case here, we're not gonna do
too much, we're just gonna have three.

136
00:08:54.344 --> 00:08:59.250
And as I said, the units here is supposed
to be the number of output based on

137
00:08:59.250 --> 00:09:02.034
the labels, at least for the last layer.

138
00:09:02.034 --> 00:09:05.427
So we have a labels, so it should be two.

139
00:09:05.427 --> 00:09:09.398
And then in terms of kernel initializer,
we're just gonna use the same.

140
00:09:09.398 --> 00:09:11.408
Let's keep it simple.

141
00:09:11.408 --> 00:09:15.131
Maybe we can also use bias
as the same value as well.

142
00:09:15.131 --> 00:09:20.051
And in terms of activation, for
example, for that particular layer,

143
00:09:20.051 --> 00:09:23.582
I use softmax, but
it would be fun to try it, okay?

144
00:09:23.582 --> 00:09:28.004
Does using actually don't know yeah.

145
00:09:28.004 --> 00:09:30.648
So we can try with this and then tweak and

146
00:09:30.648 --> 00:09:34.416
that's what is usually called
kind of parameter tuning

147
00:09:34.416 --> 00:09:39.241
is that you try different things and
see what works better for your model

