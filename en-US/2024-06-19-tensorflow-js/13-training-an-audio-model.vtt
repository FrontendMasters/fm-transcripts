WEBVTT

1
00:00:00.510 --> 00:00:05.150
But just to get back to
teachable machine itself.

2
00:00:05.150 --> 00:00:09.510
Yeah, so I was gonna talk
briefly about using sound.

3
00:00:09.510 --> 00:00:12.840
So we've mostly talked about using images.

4
00:00:12.840 --> 00:00:16.108
But you can use transfer learning
on sound samples as well.

5
00:00:16.108 --> 00:00:19.978
So the first thing that's
a little bit more annoying for

6
00:00:19.978 --> 00:00:24.174
sound is that you have to have
a background noise of at least,

7
00:00:24.174 --> 00:00:29.627
I think it's 20 seconds, because
the samples are taking a second at a time.

8
00:00:29.627 --> 00:00:36.180
So maybe I'll just be quiet for 20 seconds
just to have an empty background noise.

9
00:00:36.180 --> 00:00:39.738
I'm gonna allow, so
I'm just gonna be quiet.

10
00:00:39.738 --> 00:00:42.724
Cool, okay, so
we're gonna extract the samples.

11
00:00:42.724 --> 00:00:45.205
And as you can see here,
while it requires audio,

12
00:00:45.205 --> 00:00:47.167
it also creates little spectrograms.

13
00:00:48.537 --> 00:00:53.183
And because what happens in the background
is that even though we're working with

14
00:00:53.183 --> 00:00:57.966
audio, it's still using a convolutional
neural network in the background because

15
00:00:57.966 --> 00:00:59.597
it's working with images.

16
00:00:59.597 --> 00:01:04.269
Especially tiny images of like these kind
of pixels goes a lot faster than using raw

17
00:01:04.269 --> 00:01:05.023
audio data.

18
00:01:05.023 --> 00:01:08.302
Raw audio data would be,
if you've ever used the Web Audio API,

19
00:01:08.302 --> 00:01:10.874
it's like thousands or
millions of data points.

20
00:01:10.874 --> 00:01:12.057
That would take a lot longer.

21
00:01:12.057 --> 00:01:16.319
So instead, we're transforming raw audio
data into these little images, and

22
00:01:16.319 --> 00:01:20.642
this is what's going to be then fed to
a convolutional neural network that allows

23
00:01:20.642 --> 00:01:22.690
you to have training in a few seconds.

24
00:01:22.690 --> 00:01:26.834
And so here in terms of background noise,
it's pretty consistent.

25
00:01:26.834 --> 00:01:31.800
But let's say that I
want to record a clap.

26
00:01:31.800 --> 00:01:34.244
That's gonna be an easy one, okay?

27
00:01:34.244 --> 00:01:37.152
And if I do once again, [SOUND].

28
00:01:37.152 --> 00:01:39.442
Okay, so
you can see here I'm extracting it.

29
00:01:39.442 --> 00:01:41.559
I mean, I don't know if you can,
you can see a little bit.

30
00:01:41.559 --> 00:01:45.152
So here you can see that that's a little
bit different from the background noise

31
00:01:45.152 --> 00:01:46.449
where we could see nothing.

32
00:01:46.449 --> 00:01:49.027
Here, we can see that in terms of the, and

33
00:01:49.027 --> 00:01:52.360
I guess it's frequency,
it's a little bit higher.

34
00:01:52.360 --> 00:01:54.313
And as I record more and more,

35
00:01:54.313 --> 00:01:58.469
[SOUND] you can start to see
a pattern here in the two claps, yes?

36
00:01:58.469 --> 00:02:01.324
&gt;&gt; So it's recording the amplitude and
the frequency range?

37
00:02:01.324 --> 00:02:02.084
&gt;&gt; Yep.

38
00:02:02.084 --> 00:02:05.158
&gt;&gt; And then just kind of like, I guess,

39
00:02:05.158 --> 00:02:10.626
in terms of comparing it to an image,
kind of reducing the pixel?

40
00:02:10.626 --> 00:02:11.745
&gt;&gt; Exactly, yes.

41
00:02:11.745 --> 00:02:16.686
And then it's gonna be able to do the same
thing as usually do in image recognition,

42
00:02:16.686 --> 00:02:20.639
where if you transform your picture
into just a long, basically,

43
00:02:20.639 --> 00:02:22.283
a one dimensional tensor.

44
00:02:22.283 --> 00:02:26.483
So just a long array of numbers that
represent this, then it will see that,

45
00:02:26.483 --> 00:02:31.218
however, you can see here the difference
that this clap kinda looks like this clap,

46
00:02:31.218 --> 00:02:33.033
but it doesn't look like this.

47
00:02:33.033 --> 00:02:35.869
And here I only recorded two, but

48
00:02:35.869 --> 00:02:41.451
let's try maybe another class as
well where I'm going to cough.

49
00:02:41.451 --> 00:02:45.526
Okay, and you should see that the pattern
of what this is is different as well.

50
00:02:45.526 --> 00:02:49.455
So if I do, [COUGH],
I see it is really quite different.

51
00:02:49.455 --> 00:02:50.859
So, [COUGH].

52
00:02:50.859 --> 00:02:55.387
[LAUGH] Okay, and here you can see that,
again, even you visually,

53
00:02:55.387 --> 00:03:00.312
you can see that in the background noise,
there's not much going on, and

54
00:03:00.312 --> 00:03:03.427
then clap is kind of like a short,
snap thing.

55
00:03:03.427 --> 00:03:06.967
And here when I'm coughing,
if you've ever done voice recognition,

56
00:03:06.967 --> 00:03:10.153
you can see that your voice is
made of multiple frequencies, and

57
00:03:10.153 --> 00:03:12.756
you can kinda almost see,
so it's really reduced.

58
00:03:12.756 --> 00:03:14.222
You can see it's quite pixelated.

59
00:03:14.222 --> 00:03:19.291
But it doesn't necessarily need to be much
bigger to kind of start seeing a pattern.

60
00:03:19.291 --> 00:03:21.380
The bigger the image is,
if you don't resize them,

61
00:03:21.380 --> 00:03:23.423
it's also going to take a lot longer.

62
00:03:23.423 --> 00:03:26.609
And a lot of the times to be able
to see a pattern in an image,

63
00:03:26.609 --> 00:03:28.783
you don't need it to be that big.

64
00:03:28.783 --> 00:03:32.334
So here it's not enough sample,
actually it's eight minimum.

65
00:03:32.334 --> 00:03:34.641
Let me try to do eight minimum and
then we'll see.

66
00:03:34.641 --> 00:03:37.473
So I have to clap, oops.

67
00:03:37.473 --> 00:03:40.022
[SOUND] I'm just gonna try.

68
00:03:40.022 --> 00:03:46.228
[SOUND] Even when I do it here, visually,

69
00:03:46.228 --> 00:03:53.177
you will be able to
recognize what's a clap.

70
00:03:53.177 --> 00:03:58.027
[SOUND] Okay, we have eight and
then I have six or more coughs.

71
00:03:58.027 --> 00:04:04.449
[COUGH]
It's not

72
00:04:04.449 --> 00:04:11.859
recorded at all.

73
00:04:11.859 --> 00:04:15.476
[COUGH] Okay, and here let's say
that's just eight samples, but

74
00:04:15.476 --> 00:04:18.416
that's the minimum, so
it should still work.

75
00:04:18.416 --> 00:04:23.286
So we're going to train the model
with our audio/images data, and

76
00:04:23.286 --> 00:04:24.916
we'll have the same.

77
00:04:24.916 --> 00:04:27.664
So at first if I'm speaking,
it doesn't quite know what it is, so

78
00:04:27.664 --> 00:04:29.098
it's just gonna say background.

79
00:04:29.098 --> 00:04:32.910
But then if I do, [SOUND], okay,
so you see there's a bit of delay.

80
00:04:32.910 --> 00:04:36.470
I mean, there's an overlap factor where
it could be, I think, shorter and

81
00:04:36.470 --> 00:04:37.372
it will do it more.

82
00:04:37.372 --> 00:04:39.259
But [COUGH].

83
00:04:39.259 --> 00:04:42.302
Yeah, so again,
I think if you play with sounds,

84
00:04:42.302 --> 00:04:44.773
there's always a little bit of a delay.

85
00:04:44.773 --> 00:04:47.758
Let's see if, I actually didn't do that,
if we do 0.10.

86
00:04:47.758 --> 00:04:49.443
I don't know whether it's longer, okay.

87
00:04:51.300 --> 00:04:53.061
[COUGH] Okay, that's much faster.

88
00:04:53.061 --> 00:04:56.852
So I think the bigger the overlap factor,
the kind of faster it is.

89
00:04:56.852 --> 00:05:02.942
[SOUND] Okay, so in the same thing,
this one you can export it as well,

90
00:05:02.942 --> 00:05:07.774
and I'm not sure if the code
would be exactly the same.

91
00:05:07.774 --> 00:05:11.491
Instead of taking the webcam,
there's probably a teachable machine

92
00:05:11.491 --> 00:05:15.347
thing to have access to the microphone and
things like that, question?

93
00:05:15.347 --> 00:05:18.829
&gt;&gt; Just to confirm, it's comparing
the audio files, did you say it's

94
00:05:18.829 --> 00:05:22.268
also comparing the images, or
the image is just for the user to see?

95
00:05:22.268 --> 00:05:24.233
&gt;&gt; It's only comparing the images.

96
00:05:24.233 --> 00:05:27.527
So it's transforming the sound
inputs into a spectrogram, and

97
00:05:27.527 --> 00:05:30.032
then it's feeding these
images into the model.

98
00:05:30.032 --> 00:05:34.142
It's not using audio data,
because audio data would be too much.

99
00:05:34.142 --> 00:05:38.477
And in general,
when you do some kind of data processing,

100
00:05:38.477 --> 00:05:43.165
it's a lot easier to find patterns
when you visualize some data

101
00:05:43.165 --> 00:05:46.713
than if you just see an array
of a lot of numbers.

102
00:05:46.713 --> 00:05:50.962
I mean, for us it's easier to visualize,
but yes, when it's fed into the model,

103
00:05:50.962 --> 00:05:54.306
it's transforming the images
into what's called tensors, and

104
00:05:54.306 --> 00:05:56.637
the machine learning
model works with that.

105
00:05:56.637 --> 00:05:59.751
But at least for us,
we're able to see, in advance,

106
00:05:59.751 --> 00:06:03.227
do I think my model is going to
be able to figure it out or not?

107
00:06:03.227 --> 00:06:07.447
Because if my claps and my coughs
looked too similar to my background,

108
00:06:07.447 --> 00:06:11.325
there's less of a chance that
the prediction will be accurate.

109
00:06:11.325 --> 00:06:16.063
So it's helpful for us, but
it's also too sure as well that it's

110
00:06:16.063 --> 00:06:20.039
an image model that's used
in the background as well.

