WEBVTT

1
00:00:00.280 --> 00:00:03.420
Welcome to my workshop on
machine learning in JavaScript.

2
00:00:03.420 --> 00:00:07.206
My name's Charlie Gerard, I'm a staff
engineer at Socket and overall,

3
00:00:07.206 --> 00:00:09.840
I'm a self-proclaimed
creative technologist.

4
00:00:09.840 --> 00:00:13.886
So what that means is that I like to push
the boundaries of what can be done with

5
00:00:13.886 --> 00:00:16.750
technology and
more specifically with JavaScript.

6
00:00:16.750 --> 00:00:20.395
So I've been doing front-end
development for the past ten years.

7
00:00:20.395 --> 00:00:22.494
And on my personal time,
I like to explore and

8
00:00:22.494 --> 00:00:24.327
see what else I can do with JavaScript.

9
00:00:24.327 --> 00:00:28.227
So on your day-to-day, if you're
currently working as a front-end dev,

10
00:00:28.227 --> 00:00:31.291
you're probably building
business minded applications.

11
00:00:31.291 --> 00:00:34.496
But there's actually a lot more things
that you can do with JavaScript, and

12
00:00:34.496 --> 00:00:36.865
one of the things is machine learning.

13
00:00:36.865 --> 00:00:41.053
So I'm really excited to be here today
with you and to show you kind of what I've

14
00:00:41.053 --> 00:00:44.422
been doing with TensorFlow.js,
over the past six years now.

15
00:00:44.422 --> 00:00:46.970
I think the first time that
I actually built a little

16
00:00:46.970 --> 00:00:49.352
TensorFlow.js application was in 2018.

17
00:00:49.352 --> 00:00:52.454
So before we get started, I kind of wanted
to maybe show you a few things that

18
00:00:52.454 --> 00:00:54.962
I've built to kind of give you
an idea of what is possible.

19
00:00:54.962 --> 00:00:58.042
So I think maybe on the kind
of more useful side,

20
00:00:58.042 --> 00:01:00.738
you can build a dark mode clap extension.

21
00:01:00.738 --> 00:01:03.807
So you can use a machine
learning model and

22
00:01:03.807 --> 00:01:06.798
train it with the sound of you clapping.

23
00:01:06.798 --> 00:01:09.900
So if you do clap clap and then it just
turns on, [LAUGH] the dark mode and

24
00:01:09.900 --> 00:01:12.588
light mode, I was doing this
when I was working at Netlify.

25
00:01:12.588 --> 00:01:16.350
So it was an extension that was customized
to just work on the Netlify website,

26
00:01:16.350 --> 00:01:19.378
but it's something that
you could do as well.

27
00:01:19.378 --> 00:01:23.188
Another one of this is maybe also on
the useful side is an application,

28
00:01:23.188 --> 00:01:27.273
a little mobile, a website that you
that was kind of optimized for mobile.

29
00:01:27.273 --> 00:01:30.115
Where you could take pictures
of things around you and

30
00:01:30.115 --> 00:01:34.198
kind of tell you which bin you should
throw it into, [LAUGH] like recycle.

31
00:01:34.198 --> 00:01:38.346
But that depends on the regulations
of wherever you're living, but

32
00:01:38.346 --> 00:01:43.279
it was using image detection and then you
can find public resources of your city and

33
00:01:43.279 --> 00:01:46.303
tells you where you should
throw certain things.

34
00:01:47.313 --> 00:01:51.526
And then another one on the more kind
of creative side is to actually build

35
00:01:51.526 --> 00:01:55.949
a custom machine learning model with
your own body movements using a piece of

36
00:01:55.949 --> 00:01:56.657
hardware.

37
00:01:56.657 --> 00:02:00.698
And just recreate a prototype of a street
fighter game, so you play air street

38
00:02:00.698 --> 00:02:04.941
fighters, you're punching the air and
then it makes your character do things.

39
00:02:04.941 --> 00:02:07.191
So it is a prototype,
it's not like a real street fighter.

40
00:02:07.191 --> 00:02:10.100
There's only one character
that reflects my movements.

41
00:02:10.100 --> 00:02:14.421
I could push it further and
also make it like a real fighting game.

42
00:02:14.421 --> 00:02:16.722
But it's also something that
you can do with TensorFlow.js.

43
00:02:16.722 --> 00:02:20.594
You gather live data from movements and
then you create your own model, and

44
00:02:20.594 --> 00:02:23.729
you use the output to
control an interface as well.

45
00:02:23.729 --> 00:02:27.772
And in the same kind of in
a more pre-trained model thing,

46
00:02:27.772 --> 00:02:32.898
it's like a clone of Fruit Ninja that
uses body movements to play as well.

47
00:02:32.898 --> 00:02:37.661
So it uses Three.js as well, so it's
all in client side JavaScript where you

48
00:02:37.661 --> 00:02:42.224
track your body movements and then you
actually apply that to a 3D world.

49
00:02:42.224 --> 00:02:44.769
And you can see I'm not really
good at it in this demo, but

50
00:02:44.769 --> 00:02:47.388
you can see that as I'm moving,
there's a bit of a delay.

51
00:02:47.388 --> 00:02:51.747
But it's a game where you can play Fruit
Ninja instead of having to exploit on

52
00:02:51.747 --> 00:02:55.506
a screen, you can play it with your
hands in front of your webcam.

53
00:02:55.506 --> 00:02:57.972
And maybe just like one
more before we move on,

54
00:02:57.972 --> 00:03:01.842
it's also experimenting with building
UIs with body movement as well.

55
00:03:01.842 --> 00:03:06.132
So Figma allows you to create some
plugins and with a bit of a hacky way,

56
00:03:06.132 --> 00:03:08.492
you can actually have it as well.

57
00:03:08.492 --> 00:03:14.267
Use TensorFlow.js to track, let's say
the movements of your body on the camera,

58
00:03:14.267 --> 00:03:17.248
and then you apply that
to layers on Figma.

59
00:03:17.248 --> 00:03:19.748
And I mean, obviously,
it's still a prototype as well.

60
00:03:19.748 --> 00:03:23.698
But I like to experiment with
seeing what else you could do,

61
00:03:23.698 --> 00:03:29.080
then just type on the keyboard and use the
mouse to be able to create experiences.

62
00:03:29.080 --> 00:03:31.756
And this is not a website,
this is also on Figma, so

63
00:03:31.756 --> 00:03:36.320
it's using JavaScript to do things
that are even outside of the browser.

64
00:03:36.320 --> 00:03:38.597
So hopefully by the end of this workshop,

65
00:03:38.597 --> 00:03:41.797
you'll understand better how
to build things like this.

66
00:03:41.797 --> 00:03:46.521
You don't have to be doing creative things
at all, you could do more useful things

67
00:03:46.521 --> 00:03:50.920
for your job, but it's just understanding
what TensorFlow can offer you.

68
00:03:50.920 --> 00:03:54.064
And how to actually in
practice put that together and

69
00:03:54.064 --> 00:03:57.217
then however creative you
wanna be will be up to you.

70
00:03:58.267 --> 00:04:03.033
In terms of prerequisites, it's just
hopefully things that you're kind of

71
00:04:03.033 --> 00:04:07.501
working with every day, a git, Node,
a code editor, I use VS code, and

72
00:04:07.501 --> 00:04:12.810
your browser, I use Chrome, but there is
hopefully nothing more that you will need.

73
00:04:12.810 --> 00:04:15.953
Everything will be in the repository,
we'll just run npm install and

74
00:04:15.953 --> 00:04:17.734
then write some code.

75
00:04:17.734 --> 00:04:21.975
So throughout this workshop, we're going
to learn about three main features for

76
00:04:21.975 --> 00:04:22.963
TensorFlow.js.

77
00:04:22.963 --> 00:04:27.163
So there is using pre-trained models,
then doing transfer learning.

78
00:04:27.163 --> 00:04:30.763
I think at the moment with
more of a AI movement,

79
00:04:30.763 --> 00:04:35.804
sometimes it's called RAG for
retrieval augmented generation.

80
00:04:35.804 --> 00:04:38.483
I'm not sure about why we call it RAG now,
but it feels so

81
00:04:38.483 --> 00:04:40.035
similar to transfer learning.

82
00:04:40.035 --> 00:04:42.553
In the context of Tensor.js,
we use transfer, well,

83
00:04:42.553 --> 00:04:44.329
I'm gonna call it transfer learning.

84
00:04:44.329 --> 00:04:48.109
And it's basically using a pre-trained
model, but adding custom input.

85
00:04:48.109 --> 00:04:50.636
So if you're using an image
recognition model,

86
00:04:50.636 --> 00:04:53.534
but it's not trained with
the images I want to predict,

87
00:04:53.534 --> 00:04:58.199
then you can kinda merge these together
and create an application as well.

88
00:04:58.199 --> 00:05:02.493
And at the end of this workshop, we're
going to create our own custom model.

89
00:05:02.493 --> 00:05:06.996
So from scratch, we're going to create
an object, or not object detection, but

90
00:05:06.996 --> 00:05:08.380
image detection model.

91
00:05:08.380 --> 00:05:11.714
So we're gonna gather our data,
split it between the training set and

92
00:05:11.714 --> 00:05:12.613
the testing set.

93
00:05:12.613 --> 00:05:16.148
We're gonna write a model,
talk about layers and things like that.

94
00:05:16.148 --> 00:05:20.305
And in the end, we'll have an application
in the browser where we can draw

95
00:05:20.305 --> 00:05:25.440
certain things and feed that to a machine
learning model and get a label out of it.

96
00:05:25.440 --> 00:05:29.080
And then we'll talk about where
you can go from there as well.

