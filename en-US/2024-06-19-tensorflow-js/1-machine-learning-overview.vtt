WEBVTT

1
00:00:00.100 --> 00:00:04.417
First of all, let's start to dive
into talking about pre-trained model,

2
00:00:04.417 --> 00:00:07.390
or maybe as an overview,
what is machine learning?

3
00:00:07.390 --> 00:00:11.650
So we're talking a lot about it maybe for
the past year, year and a half.

4
00:00:11.650 --> 00:00:15.417
So I'm not gonna spend too much time
on this, but it's basically giving

5
00:00:15.417 --> 00:00:19.450
the ability to computers to do things
without being explicitly programmed.

6
00:00:19.450 --> 00:00:22.593
So It's a bit different from the usual
programming that we do because

7
00:00:22.593 --> 00:00:24.870
usually if you're working,
you type your code,

8
00:00:24.870 --> 00:00:27.543
it's supposed to do exactly
what you're writing.

9
00:00:27.543 --> 00:00:31.977
And in machine learning, it's more about
finding patterns and being able to predict

10
00:00:31.977 --> 00:00:36.373
things without being told exactly
what you're actually giving it.

11
00:00:36.373 --> 00:00:40.259
And the difference between machine
learning and AI, it's kind of people

12
00:00:40.259 --> 00:00:44.520
use AI a lot as the umbrella for things,
but under it you have machine learning and

13
00:00:44.520 --> 00:00:48.219
deep learning, which is machine
learning with neural networks, and

14
00:00:48.219 --> 00:00:51.721
then even computer vision and
natural language programing.

15
00:00:51.721 --> 00:00:53.811
I wrote processing, but it's programing.

16
00:00:53.811 --> 00:00:57.357
And I usually call it machine
learning because, well, I mean,

17
00:00:57.357 --> 00:01:02.559
usually TensorFlow.js when it came out,
it was more machine learning specific.

18
00:01:02.559 --> 00:01:08.819
We can say AI, we can use both terms
because now that's what people use a lot.

19
00:01:08.819 --> 00:01:13.279
And before we get started as well,
so when you do machine learning,

20
00:01:13.279 --> 00:01:17.446
there's kind of like a new
terminology that we're gonna use.

21
00:01:17.446 --> 00:01:20.401
And I can define a few words,
I can start doing that now, but

22
00:01:20.401 --> 00:01:24.808
I feel like as we're gonna write some
code, it's gonna make more sense.

23
00:01:24.808 --> 00:01:28.568
But basically, when I talk about a model,
it's a function that takes an input,

24
00:01:28.568 --> 00:01:32.938
runs some calculation inside, and then
produces an output with probabilities.

25
00:01:32.938 --> 00:01:37.140
And then these models, to create a model
you need machine learning algorithms, and

26
00:01:37.140 --> 00:01:39.466
there's a lot of types of algorithms.

27
00:01:39.466 --> 00:01:44.011
I think the ones that you might hear
about more often is convolutional neural

28
00:01:44.011 --> 00:01:48.996
network, that is abbreviated as CNN, that
is one that is mostly used with images.

29
00:01:48.996 --> 00:01:50.818
So if you wanna do image detection,

30
00:01:50.818 --> 00:01:54.536
you're probably going to use
a convolutional neural network.

31
00:01:54.536 --> 00:01:57.656
Then there's Naive Bayes,
or long short-term memory.

32
00:01:57.656 --> 00:02:02.505
And I'm not gonna go into defining
the internals of the algorithms,

33
00:02:02.505 --> 00:02:07.688
because for what we're doing in this
workshop, what's interesting and

34
00:02:07.688 --> 00:02:12.151
what is more useful is to know
what they're good at doing.

35
00:02:12.151 --> 00:02:15.031
So that then you know that if you're
doing things with text, you might not

36
00:02:15.031 --> 00:02:17.971
use a convolutional neural network,
you might wanna try something else.

37
00:02:17.971 --> 00:02:20.904
Or if you have data that's
maybe a spreadsheet of numbers,

38
00:02:20.904 --> 00:02:25.011
you might use Naive Bayes more, but it's
more something that you can research over

39
00:02:25.011 --> 00:02:27.137
time as you're learning more about this.

40
00:02:28.357 --> 00:02:32.298
Sometimes, I mean, especially more
recently in kind of AI discussions,

41
00:02:32.298 --> 00:02:34.936
you might have heard of
the word weight a bit more.

42
00:02:34.936 --> 00:02:38.504
And we'll probably talk about it
a bit later in the workshop because

43
00:02:38.504 --> 00:02:42.582
we're gonna build our own model,
there's gonna be the concept of weights.

44
00:02:42.582 --> 00:02:46.238
But it's how much importance you
give to each feature of the data set

45
00:02:46.238 --> 00:02:49.521
to improve the model's accuracy
to perform a certain task.

46
00:02:49.521 --> 00:02:52.569
So when you're feeding
a data set to a model,

47
00:02:52.569 --> 00:02:55.779
depending on what you
are actually feeding it,

48
00:02:55.779 --> 00:03:01.412
if we're taking the example of a data
set to recognize flowers, for example.

49
00:03:01.412 --> 00:03:06.406
You have the color or you have the length,
or you have the length of the petals, or

50
00:03:06.406 --> 00:03:11.641
you might have, I don't know, if they're
fluffy flowers or something like that.

51
00:03:11.641 --> 00:03:14.998
And each of these features have
a different importance in terms of be able

52
00:03:14.998 --> 00:03:16.326
to recognize what they are.

53
00:03:16.326 --> 00:03:21.184
So weights is basically
the importance of a specific feature

54
00:03:21.184 --> 00:03:24.525
to generate more accurate predictions.

55
00:03:24.525 --> 00:03:27.781
And then there's
the concept of overfitting.

56
00:03:27.781 --> 00:03:31.201
And it's when the model fits too
closely to the training data set.

57
00:03:31.201 --> 00:03:35.412
So at the end, usually the accuracy
that you get from your

58
00:03:35.412 --> 00:03:38.939
model is usually a number between zero and
one.

59
00:03:38.939 --> 00:03:41.627
At the end of your training process,
if you get the number one,

60
00:03:41.627 --> 00:03:44.927
it means that the model has successfully
predicted what's in a data set, but

61
00:03:44.927 --> 00:03:45.771
really only that.

62
00:03:45.771 --> 00:03:48.987
So if you give it a new image and
it wasn't part of that data set,

63
00:03:48.987 --> 00:03:52.208
it's less likely to actually give
it a good prediction because

64
00:03:52.208 --> 00:03:55.851
the model has gotten used too much to
the actual data that you gave it, so

65
00:03:55.851 --> 00:03:59.164
it's not really good at
predicting new ones.

66
00:03:59.164 --> 00:04:03.506
And then mostly throughout this course,
I'm gonna say the word class, or classes,

67
00:04:03.506 --> 00:04:04.634
or labels a lot.

68
00:04:04.634 --> 00:04:07.924
And it's usually a description of
an individual piece of data, and

69
00:04:07.924 --> 00:04:10.194
it's usually one word, that's easier.

70
00:04:10.194 --> 00:04:15.491
So if we're doing image detection, a label
could be a dog for the image of the dog.

71
00:04:15.491 --> 00:04:18.436
Basically, in the way
that the model works,

72
00:04:18.436 --> 00:04:23.317
you have to have a piece of data and the
description of it so that the model can

73
00:04:23.317 --> 00:04:27.899
really make a correlation between
the label and the piece of data.

74
00:04:27.899 --> 00:04:29.525
When you're doing machine learning,

75
00:04:29.525 --> 00:04:32.159
there's different types of
machine learning as well.

76
00:04:32.159 --> 00:04:36.519
We're mostly going to focus on
supervised learning in this workshop,

77
00:04:36.519 --> 00:04:40.363
and it's when you give
a labeled dataset to the model.

78
00:04:40.363 --> 00:04:43.888
And the algorithm is going to find
the correlation between the data and

79
00:04:43.888 --> 00:04:44.553
the labels.

80
00:04:44.553 --> 00:04:49.188
So again, if you're looking at an open
source data set, usually you'll have

81
00:04:49.188 --> 00:04:53.913
a bunch of images and you'll also have
the label associated with these images.

82
00:04:53.913 --> 00:04:58.799
And then when you do unsupervised
learning, you're giving a dataset,

83
00:04:58.799 --> 00:05:03.459
but you're not telling the algorithm
what the pieces of data is.

84
00:05:03.459 --> 00:05:07.617
So in terms of why you would want
an unsupervised learning is if you're more

85
00:05:07.617 --> 00:05:09.809
interested in clustering data.

86
00:05:09.809 --> 00:05:12.552
So if you're doing, for example,

87
00:05:12.552 --> 00:05:18.219
you're looking at customer feedback
on a product, for example.

88
00:05:18.219 --> 00:05:21.743
You are mostly interested in maybe
the sentiment of what they're saying.

89
00:05:21.743 --> 00:05:26.743
So you don't want to label a specific
piece of of comment or of data,

90
00:05:26.743 --> 00:05:32.073
but you want to know if customers
are happy or disappointed or angry.

91
00:05:32.073 --> 00:05:36.435
So when you're feeding that data to
the algorithm to create the model,

92
00:05:36.435 --> 00:05:39.600
you don't want to label
every piece of comment.

93
00:05:39.600 --> 00:05:43.720
You're just feeding it and it will find
patterns between the kind of vibe.

94
00:05:43.720 --> 00:05:47.603
So you'll end up with different clusters,
and you'll be able to see,

95
00:05:47.603 --> 00:05:51.380
there's more comments in the disappointed
pile or something like that.

96
00:05:51.380 --> 00:05:55.138
And then in terms of semi-supervised
learning, I've never done this one, but

97
00:05:55.138 --> 00:05:57.250
it's a mix of supervised and unsupervised.

98
00:05:57.250 --> 00:06:01.326
So some of the data is labelled, some
is not, and apparently you can achieve

99
00:06:01.326 --> 00:06:04.726
a higher accuracy and
efficiency with that one as well.

100
00:06:04.726 --> 00:06:07.640
I haven't done it and I'm not sure
exactly that there's a way to do it with

101
00:06:07.640 --> 00:06:11.026
TensorFlow.js, but it's good to know
that there's also that type as well.

102
00:06:11.026 --> 00:06:15.153
And finally, reinforcement learning,
you might have heard of it if you

103
00:06:15.153 --> 00:06:19.361
are interested in more gaming and
little agents that can act on their own.

104
00:06:19.361 --> 00:06:23.671
So in reinforcement learning,
the training method is based on rewarding

105
00:06:23.671 --> 00:06:26.949
the desired behavior and
punishing the undesired one.

106
00:06:26.949 --> 00:06:31.079
So I haven't done this one as well, I
just know that it's mostly used in games.

107
00:06:31.079 --> 00:06:34.055
So throughout the learning process,

108
00:06:34.055 --> 00:06:39.639
the model is kind of tweaked towards
learning through trial and error.

109
00:06:39.639 --> 00:06:43.796
So if it made a good prediction, then
it's rewarded somehow, and then if not,

110
00:06:43.796 --> 00:06:44.984
then it's punished.

111
00:06:44.984 --> 00:06:48.244
And then it kind of learns a little by
little what's the expected behavior.

112
00:06:49.644 --> 00:06:53.052
In terms of tools of machine learning
that you can do, like in JavaScript,

113
00:06:53.052 --> 00:06:55.880
we're gonna use TensorFlow.js today,
but there's more.

114
00:06:55.880 --> 00:06:58.003
Another one is Ml5.js and

115
00:06:58.003 --> 00:07:04.129
it's an even simpler library that's
kind of built on top of TensorFlow.js.

116
00:07:04.129 --> 00:07:07.858
So it's like another layer
of abstraction as well.

117
00:07:07.858 --> 00:07:10.319
There's a few more specific ones.

118
00:07:10.319 --> 00:07:13.301
There's, for example, brain.js,
or confident.js that would

119
00:07:13.301 --> 00:07:16.178
be more specifically if you want
to use convolutional networks,

120
00:07:16.178 --> 00:07:17.189
the neural networks.

121
00:07:17.189 --> 00:07:18.936
And then there's Keras.js,

122
00:07:18.936 --> 00:07:22.639
so that's like a JavaScript version
of the Keras tool in Python.

123
00:07:23.799 --> 00:07:28.242
Okay, so as an overview of
machine learning in general,

124
00:07:28.242 --> 00:07:30.099
that is pretty much it.

125
00:07:30.099 --> 00:07:32.598
There's probably a lot
more that I can say, but

126
00:07:32.598 --> 00:07:36.863
I want to start diving a little bit more
into what you can do with TensorFlow.js.

