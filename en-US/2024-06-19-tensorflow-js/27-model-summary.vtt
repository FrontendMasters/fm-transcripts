WEBVTT

1
00:00:00.130 --> 00:00:04.066
Okay, so hopefully at this point,
if you've been following along,

2
00:00:04.066 --> 00:00:08.016
you should have a machine learning
model that you created on your own.

3
00:00:08.016 --> 00:00:12.093
So congrats for creating your first
custom machine learning model.

4
00:00:12.093 --> 00:00:16.368
Even if the accuracy is about 0.5 and
it's not the best right now,

5
00:00:16.368 --> 00:00:21.172
you still created a custom measuring
model with your custom data set as well.

6
00:00:21.172 --> 00:00:24.755
So first of all, pat on the back
to yourself for doing that.

7
00:00:24.755 --> 00:00:28.192
And as we were talking before,
there's a lot of tweaks that you can do.

8
00:00:28.192 --> 00:00:33.016
You can generate a lot of new images,
or you can add layers or change them.

9
00:00:33.016 --> 00:00:36.076
And there's not really, as you can see,
machine learning models,

10
00:00:36.076 --> 00:00:37.870
it's not really a pure function where,

11
00:00:37.870 --> 00:00:40.940
if you give it the same input,
it will give you the same output.

12
00:00:40.940 --> 00:00:45.140
It seems to be changing and the weights
are updated and things like that.

13
00:00:45.140 --> 00:00:50.950
So it's kind of hard to be able to get
the same kind of output out of the model.

14
00:00:50.950 --> 00:00:54.110
But one thing that is for
sure is that we only created for

15
00:00:54.110 --> 00:00:57.010
the images of each type of each label.

16
00:00:57.010 --> 00:01:00.494
And that in general, if you start to talk
to you people who do machine learning day

17
00:01:00.494 --> 00:01:03.827
to day and you told them that you only
have one images that are probably tell you

18
00:01:03.827 --> 00:01:06.816
well, you need a lot more to be able
to find patterns in these images.

19
00:01:06.816 --> 00:01:09.697
So if you're using open
source models that've been

20
00:01:09.697 --> 00:01:13.807
created on at least thousands of images,
if not millions.

21
00:01:13.807 --> 00:01:18.592
But there's one thing that I forgot to
show you that I wanted to add here,

22
00:01:18.592 --> 00:01:21.841
is if you go to the train
drawings.js file.

23
00:01:21.841 --> 00:01:26.695
There's just also a little
function that you can add

24
00:01:26.695 --> 00:01:30.261
here that is called model.summary.

25
00:01:30.261 --> 00:01:34.339
And what this does is just it's going
to print to the terminal the different

26
00:01:34.339 --> 00:01:37.526
layers of your model and
the input shape and output shape.

27
00:01:37.526 --> 00:01:39.751
And just kind of gives you an idea,
and I thought it was interesting.

28
00:01:39.751 --> 00:01:41.313
It's not necessary at all.

29
00:01:41.313 --> 00:01:45.541
As you can see, when we were running
things before, it was running fine and

30
00:01:45.541 --> 00:01:49.049
you could see the different
training stages with the epochs.

31
00:01:49.049 --> 00:01:53.153
But calling model.summary,
if we go to the terminal and

32
00:01:53.153 --> 00:01:58.653
we rerun node train drawings,
it will output this table above here.

33
00:01:58.653 --> 00:02:01.608
That kind of tells you, you can see
the different layers of our model.

34
00:02:01.608 --> 00:02:05.048
So our first layer is a Conv2D, then we
have a max_pooling2d, then we flatten.

35
00:02:05.048 --> 00:02:06.938
And then we have two dense layers.

36
00:02:06.938 --> 00:02:10.389
And here we can see,
over time, the first inputs,

37
00:02:10.389 --> 00:02:14.738
kind of structure that we passed,
it was like 28, 28, 4.

38
00:02:14.738 --> 00:02:19.535
And you can see that the output
of that layer becomes 26, 26, 32.

39
00:02:19.535 --> 00:02:23.330
And here, 32, I believe it's
the filters that we passed in.

40
00:02:23.330 --> 00:02:28.789
And 26,26, I forgot why it just removes 2.

41
00:02:28.789 --> 00:02:32.069
But here, for example,
in our MaxPooling2D,

42
00:02:32.069 --> 00:02:36.309
the input shape is the same as
the output of the previous layer.

43
00:02:36.309 --> 00:02:39.365
And you can see here that
we end up with 13,13.

44
00:02:39.365 --> 00:02:44.040
And because I believe that our
MaxPooling2D was an area of 2 and

45
00:02:44.040 --> 00:02:47.425
2, so
I think it just divides the input by 2.

46
00:02:47.425 --> 00:02:52.642
And here again,
now we move on to our Flatten layer.

47
00:02:52.642 --> 00:02:55.782
And you can see here you have
an array within an array and

48
00:02:55.782 --> 00:02:57.974
what comes out of it is a single array.

49
00:02:57.974 --> 00:03:02.528
And this 5408 is actually 13 by 13 by 32.

50
00:03:02.528 --> 00:03:03.697
So this is what flatten does.

51
00:03:03.697 --> 00:03:09.177
It takes some kinda this multidimensional
array, it flattened it into single one.

52
00:03:09.177 --> 00:03:10.979
And then here in the dense layer for

53
00:03:10.979 --> 00:03:14.095
some reason it still actually
has an array within an array.

54
00:03:14.095 --> 00:03:20.927
But the format here is the 5,408 and
it comes out with 10.

55
00:03:20.927 --> 00:03:24.549
And, again, 10 is the number
that we use for the units.

56
00:03:24.549 --> 00:03:27.803
And, again, units is the kind
of the shape of your output or

57
00:03:27.803 --> 00:03:29.729
the number of your output.

58
00:03:29.729 --> 00:03:34.529
And thenin our final layer, because
we have two classes, if you remember,

59
00:03:34.529 --> 00:03:38.204
we have a final dense layer that
takes that as an input, and

60
00:03:38.204 --> 00:03:43.335
we have an output just the number 2
because the center number of our classes.

61
00:03:43.335 --> 00:03:47.966
So when you call the model.summary, it
kind of gives you a bit of a visualization

62
00:03:47.966 --> 00:03:50.185
as a table of the different steps.

63
00:03:50.185 --> 00:03:53.035
So sometimes you could also maybe use
this to kinda give you an idea of

64
00:03:53.035 --> 00:03:55.285
maybe certain things
that you should change.

65
00:03:55.285 --> 00:03:59.300
But I thought that it was just
a nice thing to mention to more of.

66
00:03:59.300 --> 00:04:03.045
Have a visualization of what's
going on in your training process.

