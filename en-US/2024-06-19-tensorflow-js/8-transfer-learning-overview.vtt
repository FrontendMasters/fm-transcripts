WEBVTT

1
00:00:00.000 --> 00:00:03.238
All right, so for
transfer learning, just a recap.

2
00:00:03.238 --> 00:00:06.267
So, we're using a pre-trained model still,
but

3
00:00:06.267 --> 00:00:09.656
we're adding some samples to
make it perform a new task.

4
00:00:09.656 --> 00:00:13.088
So in terms of, for example,
using image detection models,

5
00:00:13.088 --> 00:00:15.008
we're able to add custom images.

6
00:00:15.008 --> 00:00:19.691
So for example, in the projects
that we built in the first project,

7
00:00:19.691 --> 00:00:24.622
like the different tasks, we were
relying on the classes that the model

8
00:00:24.622 --> 00:00:29.656
had been trained with so that it
recognized a person pretty well or a cat.

9
00:00:29.656 --> 00:00:33.064
But, as I was telling you
before about my risotto story,

10
00:00:33.064 --> 00:00:35.980
it did not recognize
the picture of the risotto.

11
00:00:35.980 --> 00:00:40.656
But with transfer learning, we can use
the image recognition model as well, and

12
00:00:40.656 --> 00:00:44.463
I can add all pictures of risotto
if I want with the label risotto.

13
00:00:44.463 --> 00:00:47.427
And then it will be able
to recognize risotto or

14
00:00:47.427 --> 00:00:50.472
anything else that you
want to predict as well.

15
00:00:50.472 --> 00:00:55.701
So it's a pretty quick way to be able
to leverage the work that has already

16
00:00:55.701 --> 00:01:01.034
been done and add your samples as well,
and you can do that in the browser.

17
00:01:01.034 --> 00:01:05.370
So you can build experiments where
people can add their own images and

18
00:01:05.370 --> 00:01:08.598
be able to have that kind
of functionality as well.

19
00:01:08.598 --> 00:01:12.821
So I'll talk a little bit about the quick
start about how to do it quickly.

20
00:01:12.821 --> 00:01:16.557
There's an easy way and
a more difficult way.

21
00:01:16.557 --> 00:01:19.748
I'm gonna try to do both as
part of this second section.

22
00:01:19.748 --> 00:01:25.362
But in the section about transfer
learning, I'm going to introduce

23
00:01:25.362 --> 00:01:30.600
some terminology that I'm gonna
try to explain as best I could.

24
00:01:30.600 --> 00:01:34.772
Also, it's gonna probably hopefully make
a bit more sense once we actually write

25
00:01:34.772 --> 00:01:38.235
the code, that's part of the more
complicated ways of doing this.

26
00:01:38.235 --> 00:01:41.568
So you might have heard of epochs or no.

27
00:01:41.568 --> 00:01:43.632
So epochs is the number of iterations.

28
00:01:43.632 --> 00:01:46.246
So it's when you're training
a machine learning model,

29
00:01:46.246 --> 00:01:49.783
you don't only give the data once and
then it's done, you have predictions.

30
00:01:49.783 --> 00:01:54.139
It's like depending on the a machine
learning model has different layers, or

31
00:01:54.139 --> 00:01:56.845
at least a neural network
has different layers.

32
00:01:56.845 --> 00:02:00.541
And you can pass a number of iteration
that you want the model to go through, and

33
00:02:00.541 --> 00:02:02.901
it kind of like refines
its prediction over time.

34
00:02:02.901 --> 00:02:06.491
So if I say the word epoch,
you should think about iterations, but

35
00:02:06.491 --> 00:02:09.130
we'll see that when we
write some code later on.

36
00:02:09.130 --> 00:02:13.482
You have the notion of an activation
function, and it's something added to

37
00:02:13.482 --> 00:02:17.638
a neural network to help the network
learn complex patterns in the data.

38
00:02:17.638 --> 00:02:20.370
So there's different types
of activation functions.

39
00:02:20.370 --> 00:02:22.995
I don't know necessarily all of them, so

40
00:02:22.995 --> 00:02:25.925
we'll see the one that
we use later on as well.

41
00:02:25.925 --> 00:02:30.727
And in terms of batch size, it's the
number of training examples that are used.

42
00:02:30.727 --> 00:02:35.708
So if you record 10 or 20 new images,
then your batch size could either be,

43
00:02:35.708 --> 00:02:38.575
if you want to feed them
every step of the way,

44
00:02:38.575 --> 00:02:42.898
then maybe your batch size would be 40 and
you use the same images.

45
00:02:42.898 --> 00:02:47.282
But what you want is maybe split your data
set into different chunks and the batch

46
00:02:47.282 --> 00:02:51.351
size would be the size of one chunk,
and you just pass them along as you go.

47
00:02:51.351 --> 00:02:53.537
The learning rate is like
a hyper parameter, and

48
00:02:53.537 --> 00:02:55.682
that's kind of a new
word I didn't introduce.

49
00:02:55.682 --> 00:02:59.522
But hyper parameter is something that
you can tune when you use the model.

50
00:02:59.522 --> 00:03:02.888
And there's not a set
way that if you use 0.1,

51
00:03:02.888 --> 00:03:06.270
then it will always work or
something like that.

52
00:03:06.270 --> 00:03:08.902
It's a hyperparameter tuning,
usually we call that,

53
00:03:08.902 --> 00:03:12.487
where you start with a certain value and
then you see the output that you get.

54
00:03:12.487 --> 00:03:16.230
And you kind of tune that and you see how
it affects the accuracy of your model.

55
00:03:16.230 --> 00:03:19.504
So there's no real way to know in advance.

56
00:03:19.504 --> 00:03:22.767
Maybe the best thing that you can
do is something that you'll tune.

57
00:03:22.767 --> 00:03:26.288
And we can see that later in the examples,
we can try to maybe tweak and

58
00:03:26.288 --> 00:03:28.617
see how it affects
the accuracy of our model.

59
00:03:28.617 --> 00:03:32.383
But it's basically the learning rate
is how much the model change each time

60
00:03:32.383 --> 00:03:33.955
that the weights are updated.

61
00:03:33.955 --> 00:03:39.066
And if you remember what I
mentioned about the weights before,

62
00:03:39.066 --> 00:03:45.152
it's how important certain attributes
are when you're using that data.

63
00:03:45.152 --> 00:03:50.898
So the learning rate is, well, when the
weights are updated based on, I think that

64
00:03:50.898 --> 00:03:56.349
parameter is more important than how many
times you should be updating your model.

65
00:03:56.349 --> 00:04:00.455
So in terms of Tensor, so, well,
part of TensorFlow, TensorFlow.js,

66
00:04:00.455 --> 00:04:04.384
it's a mathematical object that is
to describe physical properties.

67
00:04:04.384 --> 00:04:07.168
So you could think about
it as a data type or

68
00:04:07.168 --> 00:04:12.118
a data structure that is more specific
to working with machine learning.

69
00:04:12.118 --> 00:04:15.612
And then an optimizer, we'll see
that again when we write code, but

70
00:04:15.612 --> 00:04:19.349
it's a function that adjust different
attributes of the neural networks

71
00:04:19.349 --> 00:04:21.595
such as the weights and
the learning rates.

72
00:04:21.595 --> 00:04:25.267
So if right now these terms don't
really make sense, it's normal,

73
00:04:25.267 --> 00:04:28.832
as long as you don't write some code,
they're kind of abstract.

74
00:04:28.832 --> 00:04:33.101
But I wanted to mention them to
kind of give you an idea of maybe

75
00:04:33.101 --> 00:04:36.138
certain terms that you might come across.

76
00:04:36.138 --> 00:04:39.679
Maybe you've heard already when
working with transfer learning or

77
00:04:39.679 --> 00:04:41.425
building your own model as well.

78
00:04:41.425 --> 00:04:45.853
So we're starting with transfer learning,
so that then it's like a nice intro

79
00:04:45.853 --> 00:04:50.299
towards building our custom model as that
will be the last part of the workshop.

80
00:04:50.299 --> 00:04:55.117
But before we start writing some code,
I just wanted to show quickly a tool that

81
00:04:55.117 --> 00:04:58.110
allows you to do transfer
learning pretty fast.

82
00:04:58.110 --> 00:05:01.386
It's also made by Google
to work with TensorFlow.js.

83
00:05:01.386 --> 00:05:06.897
But it's called Teachable Machine, and
it allows you to train in the browser and

84
00:05:06.897 --> 00:05:09.745
you model on top of a pre-trained model.

85
00:05:09.745 --> 00:05:14.522
So the one that we'll use is
going to be standard image model.

86
00:05:14.522 --> 00:05:19.802
And this UI here allows you to
actually train more labels or

87
00:05:19.802 --> 00:05:22.943
more classes on top of your model.

88
00:05:22.943 --> 00:05:23.976
So you don't need to do that now.

89
00:05:23.976 --> 00:05:25.871
What we'll do a little bit,
I'll just do a quick intro here.

90
00:05:25.871 --> 00:05:31.007
But for example, if I do tilt right,

91
00:05:31.007 --> 00:05:33.833
oops, tilt right.

92
00:05:33.833 --> 00:05:36.791
I'm gonna enable the webcam.

93
00:05:36.791 --> 00:05:39.841
And I'm gonna tilt right,
hold to record it.

94
00:05:39.841 --> 00:05:41.104
It records a lot of data.

95
00:05:41.104 --> 00:05:42.357
Oops, you can see my hand here.

96
00:05:42.357 --> 00:05:48.112
Anyway, so I have 39 sample
images with the label tilt right,

97
00:05:48.112 --> 00:05:50.678
and then I'll do tilt left.

98
00:05:50.678 --> 00:05:53.638
And again, I do the same thing,
and I tilt left.

99
00:05:53.638 --> 00:05:57.929
And you don't have to use exactly
the same number of images, and

100
00:05:57.929 --> 00:06:00.009
then you can train it on the go.

101
00:06:00.009 --> 00:06:03.110
Just, all you need to do is sit back and
not close your browser.

102
00:06:03.110 --> 00:06:07.247
And it's basically retraining a new model
on top of the image recognition model

103
00:06:07.247 --> 00:06:08.984
that's used in the background.

104
00:06:08.984 --> 00:06:13.209
So you have a little progress bar and
then right away you get it tilt right,

105
00:06:13.209 --> 00:06:15.332
tilt left, tilt right, till left.

106
00:06:15.332 --> 00:06:17.477
And now we have a model that's
trained on our custom input.

107
00:06:17.477 --> 00:06:22.723
So we're going to see how to
actually export that model and

108
00:06:22.723 --> 00:06:25.838
then implement that in a project.

109
00:06:25.838 --> 00:06:30.367
So that first part is going to be shorter
because all the training is done here.

110
00:06:30.367 --> 00:06:34.341
But then there's a second part where we're
kind of going to build and interface,

111
00:06:34.341 --> 00:06:36.368
basically that interface not as pretty.

112
00:06:36.368 --> 00:06:40.695
But really instead of linking your
users to go to Teachable Machine and

113
00:06:40.695 --> 00:06:44.746
export your model instead doing
all of that in your application.

