WEBVTT

1
00:00:00.000 --> 00:00:04.586
Now if I go back to the code, so
we have our file to get the data,

2
00:00:04.586 --> 00:00:09.442
our file to create the model,
our file to do the training steps and

3
00:00:09.442 --> 00:00:13.325
we are saving it into a public,
not a public folder,

4
00:00:13.325 --> 00:00:16.459
but to me it's like in the public folder.

5
00:00:16.459 --> 00:00:21.397
And I created two, if you just remember in
my model folder, I had one that had a very

6
00:00:21.397 --> 00:00:25.834
good accuracy all of a sudden, and
then I just tweaked some parameters and

7
00:00:25.834 --> 00:00:30.867
saved it into a new folder so I could test
things without ruining my original model.

8
00:00:30.867 --> 00:00:34.410
But now that we have created a custom
machine learning model, well,

9
00:00:34.410 --> 00:00:37.294
we need to use it in the front end and
see if it works well.

10
00:00:37.294 --> 00:00:42.306
So, if we go to our index.js file,
at the moment you should

11
00:00:42.306 --> 00:00:48.647
only have the clear button, event
handler to clear what's on the Canvas.

12
00:00:48.647 --> 00:00:52.840
And what we need here in the front end,
we need to actually import our model kinda

13
00:00:52.840 --> 00:00:55.606
like the same way that we
did yesterday a little bit.

14
00:00:55.606 --> 00:01:00.489
So, first of all, we are just going
to declare a viable code model.

15
00:01:00.489 --> 00:01:05.035
And under we're going
to specify the URL like

16
00:01:05.035 --> 00:01:10.176
the path to our model file,
so we can do model path,

17
00:01:10.176 --> 00:01:14.498
and then that is in the model folder for
me.

18
00:01:14.498 --> 00:01:17.119
If you've made changes and
one of your model is more accurate,

19
00:01:17.119 --> 00:01:19.498
then maybe use the one that
has a better accuracy for now.

20
00:01:19.498 --> 00:01:24.962
And we are going to specifically
use the model.json file.

21
00:01:24.962 --> 00:01:28.093
And then, what we can do is,

22
00:01:28.093 --> 00:01:33.311
we can just have a function
to load the model, so

23
00:01:33.311 --> 00:01:38.400
called, const loadmodel = async function,

24
00:01:38.400 --> 00:01:43.768
we're gonna pass the,
let's say, that path.

25
00:01:43.768 --> 00:01:46.455
We're gonna call it later, but
for now, we're just declaring it.

26
00:01:46.455 --> 00:01:54.489
And we're going to await tf, did I?

27
00:01:54.489 --> 00:01:55.154
No, yeah, okay.

28
00:01:55.154 --> 00:01:58.322
So, here I can call tf because, oops,

29
00:01:58.322 --> 00:02:04.373
tf.loadLayersModel(path) because
here in the index.html, again,

30
00:02:04.373 --> 00:02:10.147
I require sensor just as like a script
tag, but we could also import it.

31
00:02:10.147 --> 00:02:14.910
The way that you decide to do this,
doesn't really matter here,

32
00:02:14.910 --> 00:02:19.163
but here it means that we have,
access to the, tf object.

33
00:02:19.163 --> 00:02:22.286
So, at this point,
it's just a simple function that loads.

34
00:02:22.286 --> 00:02:25.997
You don't have to have that in a function,
but

35
00:02:25.997 --> 00:02:30.944
sometimes if you do more things
related to loading the model,

36
00:02:30.944 --> 00:02:34.479
then I just like to
have smaller functions.

37
00:02:34.479 --> 00:02:39.497
And okay, so we have loaded our model,
and now, what we want to

38
00:02:39.497 --> 00:02:45.459
be able to do is to predict, so if we
look back at our, if I just rerun my app,

39
00:02:45.459 --> 00:02:51.657
and, if you remember here we have a
predict button that for now does nothing.

40
00:02:51.657 --> 00:02:55.912
So, we need to actually add also like
a event handler, onto this side as well.

41
00:02:55.912 --> 00:02:59.944
So, below,
like under you declare your clear ban,

42
00:02:59.944 --> 00:03:06.009
we can have a const predictButton
= document.getElementById(""").

43
00:03:08.534 --> 00:03:14.462
I think in the HTML I called it
check-button, so let's just use that.

44
00:03:14.462 --> 00:03:18.202
Probably would have been
better to call it predict, but

45
00:03:18.202 --> 00:03:20.679
I guess we're checking the images.

46
00:03:20.679 --> 00:03:25.999
Okay, so we have predictButton and
now we need to have the onclick handler.

47
00:03:25.999 --> 00:03:32.246
So predictButton.onclick = ().

48
00:03:32.246 --> 00:03:35.956
Okay, so in our onclick function
here on the predictButton, so

49
00:03:35.956 --> 00:03:40.012
the first thing we're gonna do is
we're gonna get the Canvas here, so

50
00:03:40.012 --> 00:03:42.849
we're just going to return
the Canvas element.

51
00:03:42.849 --> 00:03:46.435
The getCanvas method come
from the utl file, so oops.

52
00:03:46.435 --> 00:03:49.676
So you can just have,
you can just import it here, and

53
00:03:49.676 --> 00:03:54.288
that returns the Canvas element, but
sometimes the way that what needs to be

54
00:03:54.288 --> 00:03:58.058
fed to then to TensorFlow.js
might be just an image element.

55
00:03:58.058 --> 00:04:02.322
Maybe not what's on in
the canvas itself so

56
00:04:02.322 --> 00:04:09.309
what I the way that I've done it,
that's maybe all the ways to do it but

57
00:04:09.309 --> 00:04:15.246
I create a variable,
const drawing = anvas.toData URL.

58
00:04:15.246 --> 00:04:19.641
And then we are going to actually
use that as like the source

59
00:04:19.641 --> 00:04:21.803
attribute on the new image.

60
00:04:21.803 --> 00:04:25.897
So if we look at our index.html file,
this is what I had here.

61
00:04:25.897 --> 00:04:29.846
When I have like an empty image and
with a class that image to check or

62
00:04:29.846 --> 00:04:33.946
something, we're going to get that
image that is currently empty.

63
00:04:33.946 --> 00:04:39.001
I'm gonna call it const newImg =

64
00:04:39.001 --> 00:04:48.760
document.getElementsByClassName("imageToC-
heck").

65
00:04:48.760 --> 00:04:51.174
Terrible name,
I feel free to refactor it afterwards, and

66
00:04:51.174 --> 00:04:52.493
we're gonna get the first one.

67
00:04:52.493 --> 00:04:56.401
Again, I could have used ID,
but class works fine, and

68
00:04:56.401 --> 00:05:00.073
we are going to set the source
to our actual drawing.

69
00:05:00.073 --> 00:05:05.747
So, newImg.src = drawing.

70
00:05:05.747 --> 00:05:11.535
Okay, and now when this image is loaded,
then we're calling a predict on that.

71
00:05:11.535 --> 00:05:15.702
So we have newImg.onload, so when we're
sure that the data that's from the canvas

72
00:05:15.702 --> 00:05:17.989
has been really used as a source for
the image,

73
00:05:17.989 --> 00:05:21.511
then we have an onload function here
to make sure that we're not calling

74
00:05:21.511 --> 00:05:24.110
predict with when the data
on the image is not ready.

75
00:05:24.110 --> 00:05:28.872
So, here we're calling a predict function
that we have not written yet, but

76
00:05:28.872 --> 00:05:31.745
we will, and
autocomplete is not helping me.

77
00:05:31.745 --> 00:05:38.824
And we are going to just
call predict(newImg).

78
00:05:38.824 --> 00:05:44.176
And then because we're predicting,
we can also resetCanvas() after.

79
00:05:44.176 --> 00:05:47.204
So we can draw a new shape and
then predict again and things like that.

80
00:05:47.204 --> 00:05:49.587
So at this point,
we have our event handler, so

81
00:05:49.587 --> 00:05:53.285
when we click on the predict button,
we're getting the canvas element,

82
00:05:53.285 --> 00:05:56.702
we're extracting the data and
appending it to a new image element.

83
00:05:56.702 --> 00:05:59.099
And when that image element Has loaded,

84
00:05:59.099 --> 00:06:03.555
then we're feeding it to a predict
function that we are going to right now.

85
00:06:03.555 --> 00:06:11.472
So here we're declaring
a const predict = async(Img),

86
00:06:11.472 --> 00:06:16.548
and it expects an image as parameter.

87
00:06:16.548 --> 00:06:20.698
And then, just to be sure,
we need to set the width and

88
00:06:20.698 --> 00:06:25.884
height to 200 because that's
the original size of our canvas.

89
00:06:25.884 --> 00:06:29.394
So if we do img.width = 200, and

90
00:06:29.394 --> 00:06:35.188
then the height is going to
be the same img.width =200.

91
00:06:37.584 --> 00:06:42.008
To do do do, okay, and
then what we're gonna do next is we

92
00:06:42.008 --> 00:06:46.639
need to transform that image
before we give it to the model.

93
00:06:46.639 --> 00:06:51.018
So I'm going to declare a variable

94
00:06:51.018 --> 00:06:55.548
called const processedImg = await

95
00:06:55.548 --> 00:07:02.494
tf.browser.fromPixelsAsync(Img,4); which

96
00:07:02.494 --> 00:07:09.290
we're passing the image and
the number of channels.

97
00:07:09.290 --> 00:07:11.854
And here, RGBA, there was four channels.

98
00:07:11.854 --> 00:07:17.376
And this is the same channels that we used
when we created our model here, the input

99
00:07:17.376 --> 00:07:22.998
shape, because the input shape of
the first layer is expecting a 28, 28, 4.

100
00:07:22.998 --> 00:07:27.784
So we did the first thing of transforming
the data into intensive with

101
00:07:27.784 --> 00:07:31.760
channels of four, but
we have not resized yet our image.

102
00:07:31.760 --> 00:07:34.974
So we need to do that now before
we actually feed it to the model.

103
00:07:34.974 --> 00:07:38.759
So, const

104
00:07:38.759 --> 00:07:43.806
resizedImg =

105
00:07:43.806 --> 00:07:53.806
tf.image.resizeNearestNeighbour.

106
00:07:58.530 --> 00:08:00.165
&gt;&gt; Do you or I think.

107
00:08:00.165 --> 00:08:02.418
&gt;&gt; Or you just or?

108
00:08:02.418 --> 00:08:03.107
&gt;&gt; Just be or.

109
00:08:03.107 --> 00:08:07.919
&gt;&gt; Okay just or and
we need to proceed the processed image and

110
00:08:07.919 --> 00:08:12.229
then the shape that we
actually trained our model or

111
00:08:12.229 --> 00:08:16.452
that we created a model with them so
28 and 28.

112
00:08:16.452 --> 00:08:20.274
Okay, so what,
another thing that I had as well,

113
00:08:20.274 --> 00:08:24.278
is we're gonna because we
had an issue before with,

114
00:08:24.278 --> 00:08:29.101
like, some one hot tensors that
were expecting, what was it,

115
00:08:29.101 --> 00:08:32.300
that was expecting data in a certain way?

116
00:08:32.300 --> 00:08:36.118
Actually, we changed it from int to 32,
but when it comes to the image,

117
00:08:36.118 --> 00:08:39.522
I found out what works is to actually
cast the type to a float 32.

118
00:08:39.522 --> 00:08:44.638
So we can declare a variable to,

119
00:08:44.638 --> 00:08:49.185
I don't know how to call it,

120
00:08:49.185 --> 00:08:56.579
const updatedImg = tf.cast(resizedImg,

121
00:08:56.579 --> 00:09:00.189
"float32");.

122
00:09:00.189 --> 00:09:04.996
I'm just trying to make sure that here,
something's going to work as I expect,

123
00:09:04.996 --> 00:09:09.380
but actually we can test that later and
see if that's actually required or

124
00:09:09.380 --> 00:09:12.864
if by default is 432, so
we might not actually need it.

125
00:09:12.864 --> 00:09:17.970
But for now, let's leave it like this, and

126
00:09:17.970 --> 00:09:26.112
then we're gonna let shape here that
we're not giving a value to yet,

127
00:09:26.112 --> 00:09:31.219
but then we are getting our predictions,
so

128
00:09:31.219 --> 00:09:36.616
const predictions = await model.predict.

129
00:09:36.616 --> 00:09:39.826
And here,
because when we trained our model,

130
00:09:39.826 --> 00:09:44.447
we had a model of like four,
a shape of like four different values.

131
00:09:44.447 --> 00:09:47.871
When I expanded the dimensions,
we can see that later.

132
00:09:47.871 --> 00:09:53.559
But we're passing into it,

133
00:09:53.559 --> 00:09:59.010
we're gonna reshape [SOUND]

134
00:09:59.010 --> 00:10:06.120
tf.reshape(updatedImg (shape

135
00:10:06.120 --> 00:10:12.284
=1,28,28, 4)).

136
00:10:12.284 --> 00:10:16.457
So, the 28 and
28 is the size of our image,

137
00:10:16.457 --> 00:10:21.593
the 4 is the number of channels and
the 1 here might not be

138
00:10:21.593 --> 00:10:27.692
needed if we remove the expandDims
function that we called when we,

139
00:10:27.692 --> 00:10:32.310
here when we used expandDims
on our training data.

140
00:10:32.310 --> 00:10:35.306
And that was adding
a dimension to our data.

141
00:10:35.306 --> 00:10:39.544
So here I think it was, if I don't have
that, then it will complain about like,

142
00:10:39.544 --> 00:10:42.854
your input data has only three values and
we're expecting four.

143
00:10:42.854 --> 00:10:45.982
So we can try it like this and
then we might be able to test that.

144
00:10:45.982 --> 00:10:50.938
Well, if we remove 1 and we remove
expandDims, then will that work as well.

145
00:10:50.938 --> 00:10:51.440
But for now,

146
00:10:51.440 --> 00:10:54.201
let's leave it like this, cause at
least under that this way it works.

147
00:10:54.201 --> 00:10:58.243
And we need to call .data
on our predictions as well.

148
00:10:58.243 --> 00:11:02.017
And that's gonna extract
the data that we can really like,

149
00:11:02.017 --> 00:11:03.912
extract our predictions on.

150
00:11:03.912 --> 00:11:09.188
Okay, so it's returning the predictions,
but now we need to extract the label.

151
00:11:09.188 --> 00:11:12.053
So const label

152
00:11:12.053 --> 00:11:21.641
=
predictions.indexOf(Math.max(...predictio-

153
00:11:21.641 --> 00:11:25.428
ns).

154
00:11:25.428 --> 00:11:31.307
And we can then call or give that label as
a parameter to util function that I called

155
00:11:31.307 --> 00:11:37.286
a displayPrediction(label) and we can
import that as well from the utils file.

156
00:11:37.286 --> 00:11:41.427
So here, again, so
we have display prediction,

157
00:11:41.427 --> 00:11:45.678
and don't forget to import
it from the utils file.

158
00:11:45.678 --> 00:11:48.918
And here we could have just
console logged the label, but

159
00:11:48.918 --> 00:11:51.830
I think it's a bit nicer if
you see it on the screen.

160
00:11:51.830 --> 00:11:56.774
And what this function does is really just
looking at our predictions element and

161
00:11:56.774 --> 00:11:58.890
just replacing the text content.

162
00:11:58.890 --> 00:12:01.587
So really not much.

163
00:12:01.587 --> 00:12:07.053
Okay, so at this point, we have not yet
called that load model function.

164
00:12:07.053 --> 00:12:10.979
So what we can do at the bottom,

165
00:12:10.979 --> 00:12:16.120
at the end loadModel(modelpath);.

166
00:12:16.120 --> 00:12:22.345
So, I think this should work,
but let's try it out.

167
00:12:22.345 --> 00:12:29.642
Okay, so if I am in the UI here,
and I have my browser tools open,

168
00:12:29.642 --> 00:12:33.845
just in case, and I draw a triangle.

169
00:12:33.845 --> 00:12:41.219
&gt;&gt; That line needs to be model
equals a weight tf load layer model.

170
00:12:41.219 --> 00:12:44.041
&gt;&gt; Yes, you're right, in my solutions
folder actually needed it differently.

171
00:12:44.041 --> 00:12:49.750
Yes, well yeah, I didn't give,
&gt;&gt; It in your notes as a condition like if

172
00:12:49.750 --> 00:12:51.180
&gt;&gt; Yes, I mean, yeah,

173
00:12:51.180 --> 00:12:56.901
I do have a condition, I'm not sure it's
like, okay, let's do just to make sure but

174
00:12:56.901 --> 00:13:01.119
that shouldn't necessarily be needed but
yes you're right.

175
00:13:01.119 --> 00:13:03.620
I didn't actually give a value
to the model variable, so

176
00:13:03.620 --> 00:13:05.139
then we can't call predict on it.

177
00:13:05.139 --> 00:13:09.276
Okay so hopefully that should now work.

178
00:13:09.276 --> 00:13:15.202
Okay, so if I saved, refreshed,
I'm gonna draw my triangle.

179
00:13:18.458 --> 00:13:24.261
Triangle [LAUGH] okay,
let's try with like a circle.

180
00:13:24.261 --> 00:13:29.739
So I'm clearing it and then if I do, okay,
that's a terrible circle, but square.

181
00:13:29.739 --> 00:13:31.362
Achieve, wait, I know why, I know why.

182
00:13:31.362 --> 00:13:34.592
So I square because originally in
my solutions folder when I did it,

183
00:13:34.592 --> 00:13:37.766
I called it square, so
it's only because in the utils somewhere,

184
00:13:37.766 --> 00:13:39.371
I probably have a square region.

185
00:13:39.371 --> 00:13:42.887
Yes, okay, so in my labels here,
I have square, but it's actually circle.

186
00:13:42.887 --> 00:13:45.956
So technically, it still worked,
so let's refresh.

187
00:13:45.956 --> 00:13:49.368
If I do a circle again.

188
00:13:49.368 --> 00:13:52.073
Circle, okay, so I was actually, okay.

189
00:13:52.073 --> 00:13:54.931
So here, what would be interesting is,
obviously,

190
00:13:54.931 --> 00:13:58.560
I saved the model that had a 95% accuracy,
so it's pretty good.

191
00:13:58.560 --> 00:14:02.127
So if we try maybe like another triangle,
I don't know if that's going to,

192
00:14:02.127 --> 00:14:03.925
well, let's forget that happened.

193
00:14:03.925 --> 00:14:06.764
Okay, [LAUGH] so the thing is, you know,

194
00:14:06.764 --> 00:14:10.365
95% is still not a hundred,
but let's try and.

195
00:14:10.365 --> 00:14:15.119
So the thing is, even with 95% accuracy,
you can see that if I sometimes do

196
00:14:15.119 --> 00:14:19.877
a right, like, draw a shape, it will
actually have another label because we

197
00:14:19.877 --> 00:14:22.677
only again drew 40 shapes for
each of them.

198
00:14:22.677 --> 00:14:26.912
So even if I was using the less accurate
model that I have in my model 1 folder,

199
00:14:26.912 --> 00:14:28.230
it would be even worse.

200
00:14:28.230 --> 00:14:33.720
It's like it would only be accurate 50% of
the time which is not which is not great.

201
00:14:33.720 --> 00:14:36.097
But hopefully, if it works for you,

202
00:14:36.097 --> 00:14:40.470
then we now have a custom model that
we created with our own data, and

203
00:14:40.470 --> 00:14:45.482
we have then used it in the browser, and
we can recognize images that we drew.

204
00:14:45.482 --> 00:14:50.363
But obviously then, if you want to be
maybe a bit cheeky and you're like,

205
00:14:50.363 --> 00:14:53.297
well, what if I draw a candle or
something?

206
00:14:53.297 --> 00:14:56.831
Obviously it doesn't know what a candle
is, so it will just look at, well,

207
00:14:56.831 --> 00:15:00.276
what's the closest thing that I know and
it thinks it's a circle, okay?

208
00:15:00.276 --> 00:15:04.148
And the thing is that then if you want
to create more drinks that you want to

209
00:15:04.148 --> 00:15:08.085
predict, then you do have to give that
data to the model when you train it,

210
00:15:08.085 --> 00:15:09.753
otherwise, it will not know.

211
00:15:09.753 --> 00:15:12.860
It will really just base that out
of the data that we fed it and

212
00:15:12.860 --> 00:15:17.087
the way that we're resizing stuff, then
it just knows a circle and a triangles,

213
00:15:17.087 --> 00:15:19.222
it doesn't really know anything else.

214
00:15:19.222 --> 00:15:23.972
But yes, for like a very small machine
learning model that can predict

215
00:15:23.972 --> 00:15:29.046
the drawings, then it's working,
okay, depending on the accuracy that

216
00:15:29.046 --> 00:15:34.545
you had again maybe you right now when
you're trying it, it's not as accurate.

217
00:15:34.545 --> 00:15:38.541
So you can try to change a few different
parameters in the way that we created

218
00:15:38.541 --> 00:15:39.183
our model.

219
00:15:39.183 --> 00:15:44.126
Again, you can have more images or
add more layers, or

220
00:15:44.126 --> 00:15:48.967
test with the epochs batch size and
things like that.

221
00:15:48.967 --> 00:15:51.338
There's not really a set
rule of how to do it.

222
00:15:51.338 --> 00:15:54.013
I wish I could tell you, hey,
if you just use this, this, this,

223
00:15:54.013 --> 00:15:56.459
then it will be perfect, but
it's not really how it works.

