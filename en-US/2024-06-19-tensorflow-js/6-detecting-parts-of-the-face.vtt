WEBVTT

1
00:00:00.188 --> 00:00:04.843
So here, what we're gonna do
next as a first step is we're

2
00:00:04.843 --> 00:00:09.120
gonna use the values that
are in this box object here.

3
00:00:09.120 --> 00:00:13.603
So as this is not TensorFlow specific
code, I wrote it in the utils, but

4
00:00:13.603 --> 00:00:17.812
we can have a look at it as well,
cuz it's basically using Canvas.

5
00:00:17.812 --> 00:00:21.803
So if you've worked with
Canvas in frontend before.

6
00:00:21.803 --> 00:00:26.995
We're creating a Canvas element and
we know the image size of the image

7
00:00:26.995 --> 00:00:31.574
that we're taking when we're
clicking the capture button.

8
00:00:31.574 --> 00:00:36.393
And yes, here is just styling
a position date in a weird position,

9
00:00:36.393 --> 00:00:38.209
but you can change that.

10
00:00:38.209 --> 00:00:42.493
And here what we're doing is that we're
going to pass the image that we're

11
00:00:42.493 --> 00:00:43.105
taking and

12
00:00:43.105 --> 00:00:47.614
also faces is going to be the coordinates
that I just showed you in the console.

13
00:00:47.614 --> 00:00:50.765
And here, if you are used
to you working with Canvas,

14
00:00:50.765 --> 00:00:53.495
you might be used to it,
but just in case here,

15
00:00:53.495 --> 00:00:57.787
you always call like beginPath before
you draw something on the Canvas.

16
00:00:57.787 --> 00:01:01.520
And strokeStyle is going to be
our line and it's just the color.

17
00:01:01.520 --> 00:01:04.874
So we are gonna draw a red
box around a face, and

18
00:01:04.874 --> 00:01:10.298
the rectangle is going to be using
the values that were in the faces object.

19
00:01:10.298 --> 00:01:13.914
So, because there's only one face in
the image or only have one face that was

20
00:01:13.914 --> 00:01:16.981
returned in the prediction,
we're going to use the first one.

21
00:01:16.981 --> 00:01:20.051
But you could try it
yourself with two people and

22
00:01:20.051 --> 00:01:25.054
then you'll have to maybe duplicate
this and use a face 1 instead of face 0.

23
00:01:25.054 --> 00:01:28.673
And then we have xMin and
yMin for the top left corner.

24
00:01:28.673 --> 00:01:29.908
Yes, and then width and height.

25
00:01:29.908 --> 00:01:33.240
So if we look back,
if I didn't refresh, yes.

26
00:01:33.240 --> 00:01:34.920
Here, you have xMax and yMax.

27
00:01:34.920 --> 00:01:39.786
I think that will probably be
the coordinate of the bottom right point.

28
00:01:39.786 --> 00:01:42.037
But if you already have width and height,

29
00:01:42.037 --> 00:01:44.555
you might not actually
need these two as well.

30
00:01:44.555 --> 00:01:47.950
And then we're just appending
that onto the image.

31
00:01:47.950 --> 00:01:54.723
So if we go back to part three,
and we just import drawFaceBox.

32
00:01:54.723 --> 00:01:59.003
And here,
where we have our console.log(faces),

33
00:01:59.003 --> 00:02:04.965
we just have FaceBox and we give it faces,
so the prediction from the model.

34
00:02:04.965 --> 00:02:11.885
What should happen if I kind of rerun
the thing, so I turn on the webcam and

35
00:02:11.885 --> 00:02:17.110
I capture the face and
then I predict, [LAUGH] I forgot.

36
00:02:17.110 --> 00:02:19.215
So if we look back to
the details function,

37
00:02:19.215 --> 00:02:21.794
the first argument is not
faces is the image itself.

38
00:02:21.794 --> 00:02:23.390
So here we pass it photo,

39
00:02:23.390 --> 00:02:27.654
the same way that we passed it in
our estimate faces method as well.

40
00:02:27.654 --> 00:02:32.172
And now we should work, I understand
that you could not find min X and

41
00:02:32.172 --> 00:02:36.701
stuff in photos because it's not
that wasn't the correct object.

42
00:02:36.701 --> 00:02:42.117
So start again [LAUGH] and predict.

43
00:02:42.117 --> 00:02:46.238
[SOUND] You have a [LAUGH]
square around your face.

44
00:02:46.238 --> 00:02:50.377
In this particular example,
that's just what it does.

45
00:02:50.377 --> 00:02:54.152
But you could see how maybe if
you were maybe not using, well,

46
00:02:54.152 --> 00:02:58.155
if you wanted to like track people,
that sounds not really good.

47
00:02:58.155 --> 00:03:01.048
But if you wanted maybe to work
with like a cars or something,

48
00:03:01.048 --> 00:03:04.985
if you wanted to see how many cars go past
you like every day or something like that.

49
00:03:04.985 --> 00:03:09.332
Sometimes if you look at examples, they do
have these little rectangles to kind of

50
00:03:09.332 --> 00:03:11.796
isolate the object and
to know where they are.

51
00:03:11.796 --> 00:03:17.466
But you could, let's say if you were
building even an art installation or

52
00:03:17.466 --> 00:03:22.314
something and you wanna know how
many people pass by everyday,

53
00:03:22.314 --> 00:03:26.171
then you could kind of like
draw things like that.

54
00:03:26.171 --> 00:03:30.920
So basically, to be able to
see your face on an image and

55
00:03:30.920 --> 00:03:34.019
then draw something in the Canvas,

56
00:03:34.019 --> 00:03:38.900
then that's basically the lines
of code that you need.

57
00:03:38.900 --> 00:03:43.365
So hopefully you can see how you can
start with a small idea of using an image

58
00:03:43.365 --> 00:03:47.543
detection model with a file picker,
and then you can experiment with

59
00:03:47.543 --> 00:03:51.450
either changing the model or
changing the type of interaction.

60
00:03:51.450 --> 00:03:53.620
And you can explore
that type of things and

61
00:03:53.620 --> 00:03:56.663
see what's available with
the TensorFlow.js library.

62
00:03:56.663 --> 00:04:00.185
And then you can even come up with
different applications that you want to

