[00:00:00]
>> First of all, let's start to dive into talking about pre-trained model, or maybe as an overview, what is machine learning? So we're talking a lot about it maybe for the past year, year and a half. So I'm not gonna spend too much time on this, but it's basically giving the ability to computers to do things without being explicitly programmed.

[00:00:19]
So It's a bit different from the usual programming that we do because usually if you're working, you type your code, it's supposed to do exactly what you're writing. And in machine learning, it's more about finding patterns and being able to predict things without being told exactly what you're actually giving it.

[00:00:36]
And the difference between machine learning and AI, it's kind of people use AI a lot as the umbrella for things, but under it you have machine learning and deep learning, which is machine learning with neural networks, and then even computer vision and natural language programing. I wrote processing, but it's programing.

[00:00:53]
And I usually call it machine learning because, well, I mean, usually TensorFlow.js when it came out, it was more machine learning specific. We can say AI, we can use both terms because now that's what people use a lot. And before we get started as well, so when you do machine learning, there's kind of like a new terminology that we're gonna use.

[00:01:17]
And I can define a few words, I can start doing that now, but I feel like as we're gonna write some code, it's gonna make more sense. But basically, when I talk about a model, it's a function that takes an input, runs some calculation inside, and then produces an output with probabilities.

[00:01:32]
And then these models, to create a model you need machine learning algorithms, and there's a lot of types of algorithms. I think the ones that you might hear about more often is convolutional neural network, that is abbreviated as CNN, that is one that is mostly used with images.

[00:01:48]
So if you wanna do image detection, you're probably going to use a convolutional neural network. Then there's Naive Bayes, or long short-term memory. And I'm not gonna go into defining the internals of the algorithms, because for what we're doing in this workshop, what's interesting and what is more useful is to know what they're good at doing.

[00:02:12]
So that then you know that if you're doing things with text, you might not use a convolutional neural network, you might wanna try something else. Or if you have data that's maybe a spreadsheet of numbers, you might use Naive Bayes more, but it's more something that you can research over time as you're learning more about this.

[00:02:28]
Sometimes, I mean, especially more recently in kind of AI discussions, you might have heard of the word weight a bit more. And we'll probably talk about it a bit later in the workshop because we're gonna build our own model, there's gonna be the concept of weights. But it's how much importance you give to each feature of the data set to improve the model's accuracy to perform a certain task.

[00:02:49]
So when you're feeding a data set to a model, depending on what you are actually feeding it, if we're taking the example of a data set to recognize flowers, for example. You have the color or you have the length, or you have the length of the petals, or you might have, I don't know, if they're fluffy flowers or something like that.

[00:03:11]
And each of these features have a different importance in terms of be able to recognize what they are. So weights is basically the importance of a specific feature to generate more accurate predictions. And then there's the concept of overfitting. And it's when the model fits too closely to the training data set.

[00:03:31]
So at the end, usually the accuracy that you get from your model is usually a number between zero and one. At the end of your training process, if you get the number one, it means that the model has successfully predicted what's in a data set, but really only that.

[00:03:45]
So if you give it a new image and it wasn't part of that data set, it's less likely to actually give it a good prediction because the model has gotten used too much to the actual data that you gave it, so it's not really good at predicting new ones.

[00:03:59]
And then mostly throughout this course, I'm gonna say the word class, or classes, or labels a lot. And it's usually a description of an individual piece of data, and it's usually one word, that's easier. So if we're doing image detection, a label could be a dog for the image of the dog.

[00:04:15]
Basically, in the way that the model works, you have to have a piece of data and the description of it so that the model can really make a correlation between the label and the piece of data. When you're doing machine learning, there's different types of machine learning as well.

[00:04:32]
We're mostly going to focus on supervised learning in this workshop, and it's when you give a labeled dataset to the model. And the algorithm is going to find the correlation between the data and the labels. So again, if you're looking at an open source data set, usually you'll have a bunch of images and you'll also have the label associated with these images.

[00:04:53]
And then when you do unsupervised learning, you're giving a dataset, but you're not telling the algorithm what the pieces of data is. So in terms of why you would want an unsupervised learning is if you're more interested in clustering data. So if you're doing, for example, you're looking at customer feedback on a product, for example.

[00:05:18]
You are mostly interested in maybe the sentiment of what they're saying. So you don't want to label a specific piece of of comment or of data, but you want to know if customers are happy or disappointed or angry. So when you're feeding that data to the algorithm to create the model, you don't want to label every piece of comment.

[00:05:39]
You're just feeding it and it will find patterns between the kind of vibe. So you'll end up with different clusters, and you'll be able to see, there's more comments in the disappointed pile or something like that. And then in terms of semi-supervised learning, I've never done this one, but it's a mix of supervised and unsupervised.

[00:05:57]
So some of the data is labelled, some is not, and apparently you can achieve a higher accuracy and efficiency with that one as well. I haven't done it and I'm not sure exactly that there's a way to do it with TensorFlow.js, but it's good to know that there's also that type as well.

[00:06:11]
And finally, reinforcement learning, you might have heard of it if you are interested in more gaming and little agents that can act on their own. So in reinforcement learning, the training method is based on rewarding the desired behavior and punishing the undesired one. So I haven't done this one as well, I just know that it's mostly used in games.

[00:06:31]
So throughout the learning process, the model is kind of tweaked towards learning through trial and error. So if it made a good prediction, then it's rewarded somehow, and then if not, then it's punished. And then it kind of learns a little by little what's the expected behavior. In terms of tools of machine learning that you can do, like in JavaScript, we're gonna use TensorFlow.js today, but there's more.

[00:06:55]
Another one is Ml5.js and it's an even simpler library that's kind of built on top of TensorFlow.js. So it's like another layer of abstraction as well. There's a few more specific ones. There's, for example, brain.js, or confident.js that would be more specifically if you want to use convolutional networks, the neural networks.

[00:07:17]
And then there's Keras.js, so that's like a JavaScript version of the Keras tool in Python. Okay, so as an overview of machine learning in general, that is pretty much it. There's probably a lot more that I can say, but I want to start diving a little bit more into what you can do with TensorFlow.js.

