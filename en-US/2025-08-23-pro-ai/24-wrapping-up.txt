[00:00:00]
>> Steve Kinney: One thing that I will say is there are some tools outside of cursor and Claude code that I think are super useful. One is, if you haven't seen before, Google has this tool called NotebookLM. And NotebookLM lets you drag in a bunch of stuff, paste in text.

[00:00:18]
The most powerful is YouTube videos, right? Where it will transcribe the entire YouTube video and grab all of that stuff, right? PDFs, books, whatever. You drop it all in and then when you ask it questions, it only looks at the stuff you dropped in, right? It's not like using its big LLM brain.

[00:00:41]
It does this weird thing where it'll make a podcast with two people talk about it. The craziest feature. No, it gets crazier. It's two people talking about it. You can now interrupt, you put it in interactive mode. You hit unmute, like on a Zoom call. Hey, I got a question.

[00:01:02]
And they stop talking and answer your question with a lot of treating you [LAUGH] like a child. But you know, that's a great question. So glad you asked it. Which is sometimes validating cause it wasn't a good question. And you can make study guides and briefing docs, but you can throw in again, a whole bunch of YouTube videos and discover button.

[00:01:27]
You can actually just kind of do a Google search and add a bunch of things in there at once. So you can build up. There's 100 sources in here right now about multi agent orchestration and Chrome extensions, which is why I chose to mix that. Whatever. But it actually transcribed a bunch of YouTube videos and it will reference everything, right?

[00:01:48]
So then you can go and actually read more like hyper fix it, like focus it down to something, so on and so forth. And so that thing is really cool. The other thing that you can do in Gemini, and I think you can do it in ChatGPT, I just do it in Gemini, is you can make these things called gems.

[00:02:12]
We talked a lot before about building those implementation plans and product requirements. You can create one. How do I edit you? Okay, I can't edit you because on a business plan, which is my own custom domain, anyway, you give it effectively a prompt, like a sub agent and you say, here's the structure of an architecture plan.

[00:02:36]
Only respond to me in this way very much like those sub agents that you can chat with and work on a bunch of those ideas. But like we said before, Gemini, O3 and Opus have absolutely huge context windows. One thing that I really like is this website called repomix.

[00:03:02]
What repomix does is you can either take a zip file of a code repository, a folder or a link to the GitHub repo and you can say I want. It'll basically smush it all down into a single file that is parsable by an LLM and you can even say ignore the test files or ignore some other stuff.

[00:03:23]
Or if the docs of a site use docusaurus and they have a GitHub repo and they're all MDX files, you can be like grab all the MDX files out of this repo and put it in this manifest where it'll be all those files concatenated with a file structure and some other notes of what you either want to include or exclude.

[00:03:44]
So you can get it down to the size and then you can drop that entire repo into Gemini and start asking questions about how it's structured and what it's doing. Which is great for getting a sense even sometimes your own code base. I've done it for help me get a sense of if I wanted to do this thing, what are the moving pieces, right?

[00:04:06]
And I can like process a whole bunch of information really, really fast and like get a sense of the entire thing. So let's go, I don't know, let's grab this repo just for the funsies of it. So paste that in. Sure, sure, sure. It feels pretty small, so we'll grab the entire thing.

[00:04:26]
You can like compress the code so on and so forth. If it's really big, you should probably download it because they all get angry if you try to paste that much stuff in. And you can go ahead and download it and then just feed it, upload it back into Gemini and be like, explain to me what this project does, what is the architecture for, how do they test it, what's the state management of this?

[00:04:51]
And kind of get a sense of all of these things and see what they are. And again, you can kinda see the beginning of this. It'll show you the repository information, some things that guide the LLM, the file structure, so on and so forth, and then effectively all the contents of every file put together.

[00:05:12]
So I think a lot of these tools both for generating code, but also I like to pull the train back into the station. I kind of believe that for everyone who's just generated a bunch of code and they don't know what it does, it is going to end poorly.

[00:05:27]
I do think that again, the output of the code has never really been the hard part. It's about trade offs, it's about Complexity, it's about all of these things. And that has always been the tricky part. And that doesn't change, right? And so I think that all of the automated code and pumping, because again, yeah, you're like, I write a lot of JavaScript.

[00:05:50]
Cool. Your JavaScript gets compiled into C, which gets compiled into assembly. You were far away from the electrons going through the copper wire. Anyway, don't worry about it. But I think it does raise the premium on the human clarity, all of the structure around it. I get less craziness out of these LLMs because I have the draconian ESLINT rules, because I have a lot of those hooks in there now because I have the commands and the tests and stuff like that.

[00:06:18]
You know what I mean? And having those fundamentals and understand how it works, even if you're not producing all the code. Because if you do start to wrap, wrap your head around this stuff, maybe fixing lint rules wasn't the best use of your time anyway. Or taking stuff from one data structure into another.

[00:06:35]
And again, you can get more design reviews, you can get more refactors, you can throw in real systems, you can get stuff explained to you. And those have always been the promotion paths. And the way up in your career is thinking of those things so on and so forth, and not just the raw production of the code.

[00:06:52]
But like I said, learning how to harness these tools is a skill in and of itself. Suspicion is needing to know how to code is never gonna go away. Cause you know, like, I think it's still code at the end of the day. And some like these things create enough messes as we've seen, that like, occasionally you're gonna have to go in there yourself and fix it.

[00:07:11]
But like, it's also a way to get exposure to things that I think that like, it is harder to get exposure early in your career as well. And like, see a bunch of stuff and like learn really, really fast. And then as you kind of get a sense for how to wield it and how to use it, even if it's just a weird suspicion about what model to use for what, right?

[00:07:31]
And that'll change every few weeks. Don't worry about it. I think you end up with a lot of like, interesting insights. And like I said, there will be a lot of engineers with 20, 25 years experience who go like, this isn't real, right? And it gives you the ability to get that ability to build up those skills so that when we need somebody who knows about this stuff, it turns out that you are on equal footing with somebody who's got a decade more experience than you.

[00:07:57]
I think it's a great opportunity to both generate code and like play with side projects and like honestly be productive on a day to day basis knowing that there are caveats and that it can go wildly wrong. And again, I had a few. I had a good day or two with stuff like this mid last week, I had a bad day on Friday and I rewrote it all by hand on Monday.

[00:08:20]
Right. But arguably did even working through these processes and defining what I wanted, did that make writing by hand easier at the end? Probably just seeing the shape. There are some pieces of that garbage code that I threw away that I have on a branch. I'm like, I did like that idea over there and I am better off for that stuff.

[00:08:39]
And so kind of don't treat it as I'm gonna make an entire thing or the fact that when you tried it, it didn't work. I don't think it works for anyone. Maybe I'm wrong, but I do think that there is a lot of value in diving in deep.

[00:08:52]
And I say that maybe I'm just, I don't know, two and a half, three months, four months of doing this every day. I could have just lied to myself too. But I'm pretty sure that there's a there there. And I think like a lot of what we're doing to harness it is just tests and lengths and like get disciplined, so on and so forth, right?

[00:09:11]
Just at a higher level of abstraction in a lot of cases. Yeah. So thank you so much.

