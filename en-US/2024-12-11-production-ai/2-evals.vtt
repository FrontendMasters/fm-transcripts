WEBVTT

1
00:00:00.000 --> 00:00:00.856
&gt;&gt; Scott Moss: Let's dive into it.

2
00:00:00.856 --> 00:00:04.806
So evals, honestly,
this could be a course by itself, and

3
00:00:04.806 --> 00:00:08.525
it would last a week, and
still wouldn't be that good.

4
00:00:08.525 --> 00:00:14.223
[LAUGH] It's just really hard stuff but
it's necessary, you have to do eval.

5
00:00:14.223 --> 00:00:16.914
So what are evals?

6
00:00:16.914 --> 00:00:21.670
TLDR, and I know people who are in
data science or machine learning or

7
00:00:21.670 --> 00:00:26.262
LLMOps, when they hear this,
they're gonna cringe, but TLDR,

8
00:00:26.262 --> 00:00:29.870
evals are essentially tests for
your LLMS, right?

9
00:00:29.870 --> 00:00:34.447
So that's the best way
I can describe it but

10
00:00:34.447 --> 00:00:39.547
not exactly, you use it for
testing your LLMS.

11
00:00:39.547 --> 00:00:44.738
Imagine writing a test for a function and
the function returned a date,

12
00:00:44.738 --> 00:00:49.581
but the way that the function got
the date was using math.random,

13
00:00:49.581 --> 00:00:53.928
and the test was supposed to
test what the date was gonna be.

14
00:00:53.928 --> 00:00:57.108
How would you write tests for that?

15
00:00:57.108 --> 00:00:58.288
You really couldn't, and

16
00:00:58.288 --> 00:01:01.575
that's what it's like testing an LLM
because it's non-deterministic.

17
00:01:01.575 --> 00:01:05.196
There's a bunch of randomness
associated with it, so

18
00:01:05.196 --> 00:01:09.856
you can't write deterministic tests
to get an output to some degree.

19
00:01:09.856 --> 00:01:11.663
So that's where evals come in.

20
00:01:11.663 --> 00:01:16.440
So evals not only help us test
the outputs of our systems, but

21
00:01:16.440 --> 00:01:22.810
also the accuracy, the quality and not
just the output but all the moving parts,

22
00:01:22.810 --> 00:01:28.636
once we talk about RAG,
there's retrieval, there's hallucination.

23
00:01:28.636 --> 00:01:32.110
There's so many things that you can test,

24
00:01:32.110 --> 00:01:35.982
the moving parts of your
agent-based system.

25
00:01:35.982 --> 00:01:39.497
And I would say a lot of the research
that's happening today in

26
00:01:39.497 --> 00:01:44.310
this space is around evals, it's around
new metrics that people are discovering.

27
00:01:44.310 --> 00:01:48.883
How to discover, how to plan,
how to execute these things,

28
00:01:48.883 --> 00:01:51.495
how to improve once you run evals.

29
00:01:51.495 --> 00:01:55.452
This is a team of people,
this is their job to do this, so

30
00:01:55.452 --> 00:02:00.931
I also recommend if you're looking for
a new skill to pick up to be relevant and

31
00:02:00.931 --> 00:02:05.342
the job force of tomorrow,
this is the skill, in my opinion.

32
00:02:05.342 --> 00:02:09.714
This is one of those skills that I
think if you knew very well, yeah,

33
00:02:09.714 --> 00:02:14.964
you would be highly valuable on a team
because everybody's gonna be using LLMS.

34
00:02:14.964 --> 00:02:19.071
And I promise you, if your team doesn't
know how to use LLMS and you go grab

35
00:02:19.071 --> 00:02:23.789
OpenAI and you do a wrapper around it, you
put it in production, it's gonna be bad.

36
00:02:23.789 --> 00:02:26.899
It's gonna be really bad, and you're gonna
have to figure out how to improve it and

37
00:02:26.899 --> 00:02:28.689
this is the next thing
you're gonna have to do.

38
00:02:28.689 --> 00:02:32.543
So they're gonna want someone
who can do this already,

39
00:02:32.543 --> 00:02:37.955
because there really aren't any all-in-one
platforms that will do this for

40
00:02:37.955 --> 00:02:42.713
you and improve it, so this is a very
critical skill, in my opinion.

41
00:02:42.713 --> 00:02:47.915
Unlike testing, yeah, cool, maybe you
don't like writing, test, and react.

42
00:02:47.915 --> 00:02:52.587
Yeah, you probably could still get a job,
no one's gonna hire you unless you're QA,

43
00:02:52.587 --> 00:02:56.619
no one's gonna hire you cuz you can
write good just tests, but evals, no,

44
00:02:56.619 --> 00:02:58.228
that would be your whole job.

45
00:02:58.228 --> 00:03:01.296
That would literally be your
whole job is just to do this.

46
00:03:01.296 --> 00:03:04.383
All right, enough ranting about that, so

47
00:03:04.383 --> 00:03:07.831
I talked about the challenges
of evaluations.

48
00:03:07.831 --> 00:03:10.603
Yeah, it's non-deterministic for
the most part,

49
00:03:10.603 --> 00:03:12.643
so how do you write tests against that?

50
00:03:12.643 --> 00:03:14.395
And then let's talk about
the different types of evaluations.

51
00:03:14.395 --> 00:03:19.481
So you have what I call
the automated evaluations

52
00:03:19.481 --> 00:03:25.188
which are basically,
you ever use ChatGPT or Claude or

53
00:03:25.188 --> 00:03:30.289
anything and
they have a thumbs up on a response?

54
00:03:30.289 --> 00:03:33.511
You'd be like cool, this was good, or
this was bad, and you can explain why?

55
00:03:33.511 --> 00:03:38.293
The reason they'd have that is because
what you're doing is you're labeling

56
00:03:38.293 --> 00:03:39.235
data for them so

57
00:03:39.235 --> 00:03:43.308
they can use that in an evaluation
that they have set up on ChatGPT.

58
00:03:43.308 --> 00:03:48.678
They're evaluating it, but the best way to
evaluate something is to have some data,

59
00:03:48.678 --> 00:03:53.079
and you'll see in a minute,
where you can say, here is the input, and

60
00:03:53.079 --> 00:03:57.049
here was the expected output,
and here's the actual output.

61
00:03:57.049 --> 00:04:01.170
And with those three things,
you can check that against tons of

62
00:04:01.170 --> 00:04:05.927
different metrics to determine whether or
not the system is doing good.

63
00:04:05.927 --> 00:04:09.344
So the part that they're missing
is the expected output, and

64
00:04:09.344 --> 00:04:11.919
that's what the thumbs up and
thumbs down is.

65
00:04:11.919 --> 00:04:15.120
If you put thumbs down, then you didn't
expect that, if you put thumbs up,

66
00:04:15.120 --> 00:04:16.633
that is exactly what you expected.

67
00:04:16.633 --> 00:04:19.373
So they can use that to help
them create data sets for

68
00:04:19.373 --> 00:04:23.008
their evaluation cuz that's probably
the hardest part, I think or

69
00:04:23.008 --> 00:04:26.537
the most time-consuming part,
I think, not the hardest part.

70
00:04:26.537 --> 00:04:33.289
The hardest part is coming up with
metrics, so different types of metrics.

71
00:04:33.289 --> 00:04:35.817
This is where all
the science is happening.

72
00:04:35.817 --> 00:04:40.183
I read some of this stuff every day,
and I have no idea what any of it is,

73
00:04:40.183 --> 00:04:44.495
it's just beyond me,
it's like research scientists level stuff.

74
00:04:44.495 --> 00:04:48.629
But for the most part there are things
there that you can grok and

75
00:04:48.629 --> 00:04:51.520
understand to use to
help you check things.

76
00:04:51.520 --> 00:04:56.608
So you have things like response
quality metrics, these are things

77
00:04:56.608 --> 00:05:01.617
that measure coherence,
relevance, toxicity, classifiers.

78
00:05:01.617 --> 00:05:08.180
So, for instance, you might have an LLM,
a smaller LLM that you use to test things,

79
00:05:08.180 --> 00:05:12.167
and then production,
you go to something bigger.

80
00:05:12.167 --> 00:05:16.566
So you wanna check if the responses
of the smaller LLM generates

81
00:05:16.566 --> 00:05:19.305
answers to the questions and whether or

82
00:05:19.305 --> 00:05:24.217
not they're relevant before you go
to a bigger LLM or even vice versa.

83
00:05:24.217 --> 00:05:28.890
So it's like checking the relevance of
a question, tasks completion verification.

84
00:05:28.890 --> 00:05:32.896
This is a really good one, this is just
ensuring that your agent went all the way

85
00:05:32.896 --> 00:05:34.729
through a workflow and did a thing.

86
00:05:34.729 --> 00:05:36.969
For instance,
if we were generating an image,

87
00:05:36.969 --> 00:05:39.041
I would wanna know that
if given this input,

88
00:05:39.041 --> 00:05:42.464
it went all the way through the right
steps that I thought it was gonna do.

89
00:05:42.464 --> 00:05:46.563
It went through an approval, the approval
said, yes, it went through and

90
00:05:46.563 --> 00:05:49.902
the next thing that did was call
the generate tool function.

91
00:05:49.902 --> 00:05:52.332
It generated the tool
based off this output, and

92
00:05:52.332 --> 00:05:55.421
then it responded back with this,
so the whole flow, right?

93
00:05:55.421 --> 00:05:59.292
I wanna be able to know that it did that
based on this input that I gave it, and

94
00:05:59.292 --> 00:06:01.202
I can come up with different inputs.

95
00:06:01.202 --> 00:06:04.943
Whether they're user defined ones that
I log or synthetic ones that I made,

96
00:06:04.943 --> 00:06:07.403
which is something you'll
probably start with.

97
00:06:07.403 --> 00:06:11.698
And tool accuracy is just a smaller
step in that of just being like,

98
00:06:11.698 --> 00:06:17.009
did you call the right tool at the right
time and interpret the outputs correctly?

99
00:06:17.009 --> 00:06:21.129
So something that I realized
a lot in production is,

100
00:06:21.129 --> 00:06:26.853
if the more tools you give one LLM,
the worse it gets at picking the tool.

101
00:06:26.853 --> 00:06:29.385
So then there's different
strategies on how to break that up.

102
00:06:29.385 --> 00:06:34.621
Do I have multiple LLMS,
each with a group of tools?

103
00:06:34.621 --> 00:06:38.953
Do I have an intent classifier that's in
front of this LLM and that LLM job is to

104
00:06:38.953 --> 00:06:43.232
decide what tool to pick so the LLM
doesn't have to, they could just run it?

105
00:06:43.232 --> 00:06:44.525
There's so many things you can do there.

106
00:06:44.525 --> 00:06:49.722
And then even if the tool was decided
correctly, and it was executed and you fed

107
00:06:49.722 --> 00:06:55.031
the answer back to the LLM, it still might
get the answer wrong for some reason.

108
00:06:55.031 --> 00:06:58.381
If you have a tool that
gets the current time, and

109
00:06:58.381 --> 00:07:03.204
it returns the current time, and
then LLM still gives you an answer for

110
00:07:03.204 --> 00:07:07.493
the wrong time, then, yeah,
you would wanna fix that part.

111
00:07:07.493 --> 00:07:10.299
That would be something you
would wanna email like,

112
00:07:10.299 --> 00:07:14.572
why is the question answering part of my
system really bad when the retrieval and

113
00:07:14.572 --> 00:07:16.450
the tool accuracy is really good?

114
00:07:16.450 --> 00:07:17.345
So what's going on there?

115
00:07:17.345 --> 00:07:20.627
So you would have to take that
part out and run an eval for it.

116
00:07:20.627 --> 00:07:27.338
So it really is like doing science, and
that's the best way I can describe it.

117
00:07:27.338 --> 00:07:30.577
Dataset creation, I talked about it
a little bit, at the end of the day,

118
00:07:30.577 --> 00:07:34.691
there's really just, I don't know, there's
two main ways, there might be a third way.

119
00:07:34.691 --> 00:07:38.382
You either create synthetic data,
so you just make up the data.

120
00:07:38.382 --> 00:07:40.425
Some of the stuff is actually
really easy to make up for,

121
00:07:40.425 --> 00:07:41.739
we'll be making up our data today.

122
00:07:41.739 --> 00:07:45.766
Cuz, for instance,
if I know my agent can generate images and

123
00:07:45.766 --> 00:07:51.033
I know if I ask it to generate an image,
it should select the generate image tool,

124
00:07:51.033 --> 00:07:54.054
then I can just make data
sets that are inputs of

125
00:07:54.054 --> 00:07:58.799
users asking to generate some type of
image and whatever phrases I want.

126
00:07:58.799 --> 00:08:01.631
I can even ask an AI to come up
with those inputs for me and

127
00:08:01.631 --> 00:08:03.059
put them in there, right?

128
00:08:03.059 --> 00:08:07.543
I could also have an AI generate
inverse inputs, give me some inputs

129
00:08:07.543 --> 00:08:12.262
that a user might say that has nothing
to do with generating an image, so

130
00:08:12.262 --> 00:08:16.059
I can eval that my agent
doesn't call this tool, right?

131
00:08:16.059 --> 00:08:20.163
So those are examples of synthetic
data where you kinda know, so

132
00:08:20.163 --> 00:08:21.915
you just make some of them.

133
00:08:21.915 --> 00:08:26.743
The other way is obviously getting data
from users in real world scenario.

134
00:08:26.743 --> 00:08:28.237
So if it's a chat app,

135
00:08:28.237 --> 00:08:33.670
if it's just an input bar that you have
that's a one-off thing, you lock those,

136
00:08:33.670 --> 00:08:38.589
you capture those inputs, and then you
can use those as a golden data set.

137
00:08:38.589 --> 00:08:42.411
And then if you offer that ability for
a user to give feedback on the output,

138
00:08:42.411 --> 00:08:46.415
whether or not this was good or not, now
you have the expected output to go along

139
00:08:46.415 --> 00:08:49.044
with it,
very similar to what I said with ChatGPT.

