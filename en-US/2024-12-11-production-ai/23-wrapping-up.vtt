WEBVTT

1
00:00:00.000 --> 00:00:04.583
Cool, here's some emerging research areas,
although everything's emerging research.

2
00:00:04.583 --> 00:00:06.125
So, just some things to keep you busy.

3
00:00:06.125 --> 00:00:08.999
One thing that I think is
interesting is re-ranking.

4
00:00:08.999 --> 00:00:10.405
Highly recommend looking up re-ranking.

5
00:00:10.405 --> 00:00:11.963
I talked a little bit about this, but

6
00:00:11.963 --> 00:00:14.483
this is you get the results
back from your vector database.

7
00:00:14.483 --> 00:00:17.599
You still need to rank them based on
how relevant they are according to

8
00:00:17.599 --> 00:00:21.308
the original user message, cuz the vector
database doesn't know anything about

9
00:00:21.308 --> 00:00:22.887
relevance, that's a big thing.

10
00:00:22.887 --> 00:00:27.602
Creating feedback loops, highly recommend
incorporating that into your app so

11
00:00:27.602 --> 00:00:30.387
you get that free data for
your golden data set.

12
00:00:30.387 --> 00:00:36.950
Evals, evals, evals, look, start with
evaluation, please do your evals.

13
00:00:36.950 --> 00:00:41.200
And yeah, from there, it's all about
identifying specific use cases,

14
00:00:41.200 --> 00:00:43.267
getting data and things like that.

15
00:00:43.267 --> 00:00:45.286
So there's a lot to learn, but again,

16
00:00:45.286 --> 00:00:48.298
it's just more of the same of
what I just taught you today.

17
00:00:48.298 --> 00:00:49.548
There isn't anything new.

18
00:00:49.548 --> 00:00:53.633
It's just a new technique to
do this thing, increase RAG,

19
00:00:53.633 --> 00:00:55.606
make this eval number go up.

20
00:00:55.606 --> 00:00:59.272
Make it faster, make it cheaper.

21
00:00:59.272 --> 00:01:01.764
Error handling, that's really it.

22
00:01:01.764 --> 00:01:04.796
A better way to do human in the loop,
but you understand human in the loop.

23
00:01:04.796 --> 00:01:08.971
So, everything is just from here on out
it's just keeping up with the new ways

24
00:01:08.971 --> 00:01:12.376
that folks are doing it and
figuring out if that's relevant for

25
00:01:12.376 --> 00:01:15.738
your implementation or not and
being aware of all this stuff.

26
00:01:15.738 --> 00:01:20.724
So, this right here, is literally so much
is a team of people doing all this stuff.

27
00:01:20.724 --> 00:01:24.898
So, again, having this skill set
I think is extremely relevant.

28
00:01:24.898 --> 00:01:28.353
And I think going forward, I think
a lot of this is gonna be required for

29
00:01:28.353 --> 00:01:29.826
a lot of people in my opinion.

30
00:01:29.826 --> 00:01:33.873
I think you're just gonna have to know
this stuff because having an LLM stack in

31
00:01:33.873 --> 00:01:36.953
your company is gonna be
synonymous with having Postgres.

32
00:01:36.953 --> 00:01:39.666
So I think you're just gonna
have to know this stuff.

33
00:01:39.666 --> 00:01:43.782
And right now there's specialties,
people are specialists at this.

34
00:01:43.782 --> 00:01:46.809
But I think eventually this is gonna be
a generalist thing that everybody just

35
00:01:46.809 --> 00:01:47.470
knows how to do.

36
00:01:47.470 --> 00:01:51.583
Just like in 2012, if you were a frontend,
you never touch the backend.

37
00:01:51.583 --> 00:01:55.570
Now, I don't even know if there's even
such a thing as just frontend anymore.

38
00:01:55.570 --> 00:01:59.282
You kinda just do everything and really
just frontend, only frontend is probably

39
00:01:59.282 --> 00:02:03.101
a designer that knows how to code, whereas
most frontend people can definitely spin

40
00:02:03.101 --> 00:02:05.881
up a full stack app and
set up Postgres and do stuff like that.

41
00:02:05.881 --> 00:02:10.797
Whereas in 2012 there was no way your
frontend engineer was ever gonna do that,

42
00:02:10.797 --> 00:02:13.692
they would probably never
even touch Firebase.

43
00:02:13.692 --> 00:02:17.805
Well, Firebase was 2013, 2014,
but still, it's different.

44
00:02:17.805 --> 00:02:20.571
So I think a lot of people will
be doing a lot of this stuff.

45
00:02:20.571 --> 00:02:23.502
So, any other questions?

46
00:02:23.502 --> 00:02:28.417
&gt;&gt; Student 1: What do you think about SDKs
for LLMs, like Vercel's or LangChain?

47
00:02:28.417 --> 00:02:32.214
Do you think OpenAI is all
you need to launch an AI app?

48
00:02:32.214 --> 00:02:35.860
&gt;&gt; Scott Moss: I personally do not
recommend, so I can't talk too much

49
00:02:35.860 --> 00:02:40.825
about Vercel's AI SDK cuz I haven't used
it since when they first made it and

50
00:02:40.825 --> 00:02:42.001
it was a preview.

51
00:02:42.001 --> 00:02:44.664
I thought it was cool back then,
and it probably is good now.

52
00:02:44.664 --> 00:02:48.365
From what I understand
from their documentation,

53
00:02:48.365 --> 00:02:53.800
their AI SDK is heavily geared towards
using it in a Next.js environment.

54
00:02:53.800 --> 00:02:58.015
Actually have this really
cool thing in there.

55
00:02:58.015 --> 00:02:59.164
Let me show you.

56
00:02:59.164 --> 00:03:00.885
I think this is really cool.

57
00:03:00.885 --> 00:03:04.916
You can give your AI a render function
the same way you would give React a render

58
00:03:04.916 --> 00:03:05.546
function.

59
00:03:05.546 --> 00:03:09.971
You can use a generator to send back and
stream back a React component,

60
00:03:09.971 --> 00:03:14.552
which works pretty much only in
Next,js because of server components.

61
00:03:14.552 --> 00:03:15.408
So that's really cool.

62
00:03:15.408 --> 00:03:18.779
So if you're using Next.js in Vercel,
yeah, I would check out the AI SDK.

63
00:03:18.779 --> 00:03:20.073
I think it's really cool.

64
00:03:20.073 --> 00:03:23.499
It looks like they have a lot more things
in here now than what they did have.

65
00:03:23.499 --> 00:03:27.823
As far as LangChain, I personally would
never use it, I think it's an overkill.

66
00:03:27.823 --> 00:03:29.546
I think the patterns are bad.

67
00:03:29.546 --> 00:03:34.031
It looks like the AI SDK has really good
patterns because it's people who know

68
00:03:34.031 --> 00:03:34.867
JavaScript.

69
00:03:34.867 --> 00:03:39.163
The LangChain SDK looks like people who've
never written JavaScript in their life,

70
00:03:39.163 --> 00:03:42.744
only use Python, and then ran all
their code through ChatGPT and said,

71
00:03:42.744 --> 00:03:44.072
turn this to JavaScript.

72
00:03:44.072 --> 00:03:45.120
That's what it looks like.

73
00:03:45.120 --> 00:03:50.031
Honestly, the abstractions that
they have are just so insane to me.

74
00:03:50.031 --> 00:03:51.222
I don't know anybody uses it.

75
00:03:51.222 --> 00:03:55.526
So, me personally, no,
I would never use LangChain.

76
00:03:55.526 --> 00:03:57.104
Vercel AI looks really cool.

77
00:03:57.104 --> 00:03:58.224
I might give it another look.

78
00:03:58.224 --> 00:04:01.543
But I I'm not using Next.js right now,
I'm using a mobile app, so

79
00:04:01.543 --> 00:04:03.999
I don't think I'll get
a lot of the value from it.

80
00:04:03.999 --> 00:04:07.944
But for me, I think just using
the OpenAI SDK is probably the best move.

81
00:04:07.944 --> 00:04:10.880
They're kinda like the Tesla
charger of OpenAI SDKs.

82
00:04:10.880 --> 00:04:14.749
Everybody just uses their standard, so
if you wanna swap out to Anthropic,

83
00:04:14.749 --> 00:04:18.012
you change out the URL,
you change that API key, you're done,

84
00:04:18.012 --> 00:04:21.397
everything's the same,
assuming the same for functionality for

85
00:04:21.397 --> 00:04:24.317
those models, and
every model is just adhering to that.

86
00:04:24.317 --> 00:04:27.253
So I would just use
OpenAI SDK in my opinion.

87
00:04:27.253 --> 00:04:31.813
Maybe there's some tiny mom and
pop open-source things out there that

88
00:04:31.813 --> 00:04:36.298
hasn't blown up that are quite useful and
they do one thing very well.

89
00:04:36.298 --> 00:04:37.019
Go check those out.

90
00:04:37.019 --> 00:04:42.317
But for the most part,
no, just OpenAI SDK.

91
00:04:42.317 --> 00:04:46.386
&gt;&gt; Student 2: For doing evals on real user
input, do you need to have a mechanism for

92
00:04:46.386 --> 00:04:50.256
users to grade your output such
as like a thumbs up, thumbs down?

93
00:04:50.256 --> 00:04:53.548
&gt;&gt; Scott Moss: Yeah, exactly,
almost every chat app has that.

94
00:04:53.548 --> 00:04:55.119
They have a thumbs up or

95
00:04:55.119 --> 00:04:59.931
a thumbs down to indicate whether or
not this was the expected input.

96
00:04:59.931 --> 00:05:01.512
That way, they can annotate that or not.

97
00:05:01.512 --> 00:05:07.669
And frameworks,
&gt;&gt; Scott Moss: Let me see,

98
00:05:07.669 --> 00:05:14.684
Humanloop, humanloop.com,
it's a prompt tool thing.

99
00:05:14.684 --> 00:05:18.231
They have this ability, you could do that
as well, so you can collect the data.

100
00:05:18.231 --> 00:05:22.822
They even give you APIs for
you to hit when someone hits thumbs up or

101
00:05:22.822 --> 00:05:23.833
thumbs down.

102
00:05:23.833 --> 00:05:25.435
I mean, Braintrust does this too.

103
00:05:25.435 --> 00:05:29.097
Almost any tool that helps you do evals
and stuff is gonna have that ability.

104
00:05:29.097 --> 00:05:32.544
So yeah, if you're doing evals,
you need to collect that feedback and

105
00:05:32.544 --> 00:05:34.910
try to encourage users to
do it through some way.

106
00:05:34.910 --> 00:05:39.808
For instance, thumbs up, thumbs down
is cool, but almost nobody presses it.

107
00:05:39.808 --> 00:05:43.372
So, we're experimenting with different
ways to incentivize the user to tell

108
00:05:43.372 --> 00:05:43.916
us things.

109
00:05:43.916 --> 00:05:48.481
So one thing that we're thinking
of doing is showing the user

110
00:05:48.481 --> 00:05:52.867
an accuracy score of how
accurate their assistant is, and

111
00:05:52.867 --> 00:05:58.702
then once a week send them a push
notification like, hey, it's been a week.

112
00:05:58.702 --> 00:06:00.249
Do you wanna review my work for the week?

113
00:06:00.249 --> 00:06:03.072
And then,
we kinda just go over this email came in,

114
00:06:03.072 --> 00:06:05.838
I said it was important,
do you agree, yes or no?

115
00:06:05.838 --> 00:06:08.295
And then it's a swipe thing, and
they can just do that really quickly, and

116
00:06:08.295 --> 00:06:09.582
they can see their score go up and down.

117
00:06:09.582 --> 00:06:14.061
So it's kinda gamified, but it's giving us
that data to be, they didn't expect this,

118
00:06:14.061 --> 00:06:17.721
they did expect this, they did expect
this, they didn't expect this.

119
00:06:17.721 --> 00:06:18.776
And we get that data for free.

120
00:06:18.776 --> 00:06:23.242
So trying to create some incentive for
them to label that data for us.

121
00:06:23.242 --> 00:06:26.737
And then maybe, hey,
if you get your accuracy to 90%, you know,

122
00:06:26.737 --> 00:06:30.859
we'll give you a cuz because it's cheaper
for us if your thing is more accurate.

123
00:06:30.859 --> 00:06:32.678
So that might be an incentive.

124
00:06:32.678 --> 00:06:33.646
You got to play around with it.

125
00:06:33.646 --> 00:06:37.712
You gotta figure out what works for you,
but yeah, you definitely wanna do that.

126
00:06:37.712 --> 00:06:40.591
Okay, well, if there are no
other questions, that's it.

127
00:06:40.591 --> 00:06:42.476
Thanks for coming to the course and

128
00:06:42.476 --> 00:06:46.583
I hope you all have learned a lot about
getting AI LLM apps into production.

129
00:06:46.583 --> 00:06:50.700
&gt;&gt; [APPLAUSE]

