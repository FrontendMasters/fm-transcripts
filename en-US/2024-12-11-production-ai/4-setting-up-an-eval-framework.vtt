WEBVTT

1
00:00:00.018 --> 00:00:01.380
&gt;&gt; Scott Moss: We're not
gonna do anything crazy.

2
00:00:01.380 --> 00:00:04.944
[LAUGH] We're not gonna do anything crazy.

3
00:00:04.944 --> 00:00:06.693
Cuz, one, I don't wanna look like a fool.

4
00:00:06.693 --> 00:00:12.097
And two, it gets so scientific,
I just wanna give you the framework and

5
00:00:12.097 --> 00:00:15.083
the idea of how to eval things, right?

6
00:00:15.083 --> 00:00:17.750
So, let's follow along.

7
00:00:17.750 --> 00:00:20.573
The first thing we need to do is,

8
00:00:20.573 --> 00:00:25.187
we need to create our own custom scorer,
or metric.

9
00:00:25.187 --> 00:00:27.026
There's so many that we can use,

10
00:00:27.026 --> 00:00:30.060
I just chose one that I think
is a little easier to grok.

11
00:00:30.060 --> 00:00:33.688
And this is not an LLM-based one,
although we can do that.

12
00:00:33.688 --> 00:00:36.704
This one is just a tool called match,
and I just made one from scratch.

13
00:00:36.704 --> 00:00:41.478
And essentially what it does is,
it checks to see if

14
00:00:41.478 --> 00:00:46.147
the LLM made the correct
tool call given an input.

15
00:00:46.147 --> 00:00:49.396
It actually doesn't do a good
job of checking the inverse, so

16
00:00:49.396 --> 00:00:53.408
we could fix it for that, but I left that
for folks to implement if they want.

17
00:00:53.408 --> 00:00:56.603
So it's only gonna check if
it called the right tool.

18
00:00:56.603 --> 00:00:57.947
If it did, it'll give you a 1.

19
00:00:57.947 --> 00:00:59.589
If it didn't, it'll give you a 0.

20
00:00:59.589 --> 00:01:00.852
Pretty simple.

21
00:01:00.852 --> 00:01:04.045
It's deterministic,
because it's all just code.

22
00:01:04.045 --> 00:01:07.715
There's no LLM involved, but you will
be able to run through the whole thing.

23
00:01:07.715 --> 00:01:12.598
So before I do that, I need to run you
through the framework that I created

24
00:01:12.598 --> 00:01:15.971
to do evals and
kinda the landscape of all of that.

25
00:01:15.971 --> 00:01:18.787
Okay, so, actually,
let me check out to the other branch,

26
00:01:18.787 --> 00:01:20.081
I'm on the finished branch.

27
00:01:21.222 --> 00:01:22.915
So I'm gonna check out the step 1.

28
00:01:22.915 --> 00:01:25.842
If you're not there,
follow me there, step/1.

29
00:01:28.696 --> 00:01:32.502
&gt;&gt; Scott Moss: Little tour of the app,
as far as evals go.

30
00:01:32.502 --> 00:01:35.971
There's an evals folder here on the root.

31
00:01:35.971 --> 00:01:39.214
&gt;&gt; Scott Moss: And inside of there
you might see three files in this

32
00:01:39.214 --> 00:01:40.353
app folder here.

33
00:01:40.353 --> 00:01:47.189
So evalTools is gonna be the framework
that I created to run our evals.

34
00:01:47.189 --> 00:01:51.433
I couldn't find any good one in
TypeScript that you can just run.

35
00:01:51.433 --> 00:01:54.959
They're all in Python,
they're just all in Python.

36
00:01:54.959 --> 00:01:57.270
And the ones that are in
TypeScript are paid products.

37
00:01:57.270 --> 00:02:02.913
So I just made one, so I made one for
us today that we're gonna use.

38
00:02:02.913 --> 00:02:05.251
So I'm just gonna walk
through what's going on here.

39
00:02:05.251 --> 00:02:09.785
Essentially, what this one's gonna do is,
it's just a function that take,

40
00:02:09.785 --> 00:02:13.883
the way that you typically see evals is,
like I said, it's science.

41
00:02:13.883 --> 00:02:16.910
You have an experiment, so
you give your experiment a name.

42
00:02:16.910 --> 00:02:20.744
So in our case we might have
an experiment called Reddit, or

43
00:02:20.744 --> 00:02:24.053
generate-image, or
whatever you wanna call it.

44
00:02:24.053 --> 00:02:26.846
You can call your experiment whatever
you want, just a way to keep,

45
00:02:26.846 --> 00:02:30.080
you need an experiment cuz you need to
keep track of historical reference of how

46
00:02:30.080 --> 00:02:31.412
you're improving the system.

47
00:02:31.412 --> 00:02:35.829
So an experiment is a unique name
associated with the thing that you're

48
00:02:35.829 --> 00:02:40.394
testing so you can track the improvement
on whether or not it's going up or

49
00:02:40.394 --> 00:02:41.733
going down, right?

50
00:02:41.733 --> 00:02:43.018
So, just science there.

51
00:02:43.018 --> 00:02:47.341
And then typically what you have is
three things for this eval to run.

52
00:02:47.341 --> 00:02:49.511
You have a task,
this is some async function.

53
00:02:49.511 --> 00:02:51.932
This is typically where
you run your AI system.

54
00:02:51.932 --> 00:02:53.419
Let me run my thing and get a result.

55
00:02:53.419 --> 00:02:55.602
It could be whatever you want.

56
00:02:55.602 --> 00:02:59.823
It doesn't even need to be AI, it's
just some async function that runs and

57
00:02:59.823 --> 00:03:01.173
it spits back a result.

58
00:03:01.173 --> 00:03:08.330
Data is typically an array of inputs and
expected outputs.

59
00:03:08.330 --> 00:03:12.781
So I'll say the input is this thing
that this user might have typed,

60
00:03:12.781 --> 00:03:15.998
what I expect the system
to output is this thing.

61
00:03:15.998 --> 00:03:19.560
And you have an array of that, so this is
your data set that I was talking about.

62
00:03:19.560 --> 00:03:23.381
Whether you got that from users,
whether you generated it yourself,

63
00:03:23.381 --> 00:03:26.502
whether you had AI do it for
you, this would be your data.

64
00:03:26.502 --> 00:03:31.461
And then scorers are an array of metrics
you want to score these inputs and

65
00:03:31.461 --> 00:03:32.890
expected data on.

66
00:03:32.890 --> 00:03:38.225
So these might be scientific
things like Levenshtein distance,

67
00:03:38.225 --> 00:03:43.274
or in our case, testing if the AI
called the right tool or not.

68
00:03:43.274 --> 00:03:46.711
You can have as many scores as you want.

69
00:03:46.711 --> 00:03:52.038
And then, this function kinda
just does all that for you,

70
00:03:52.038 --> 00:03:59.223
calculates the scores and saves them to
a file that we can then read from an app.

71
00:03:59.223 --> 00:04:01.721
So that's essentially what this is doing.

72
00:04:01.721 --> 00:04:04.466
We won't be making this framework,
there's no reason to go through and

73
00:04:04.466 --> 00:04:05.324
make this framework.

74
00:04:05.324 --> 00:04:07.128
So this is why this is here for
you already, but

75
00:04:07.128 --> 00:04:10.581
this is what we'll be using and I just
wanted you to see that as a reference.

76
00:04:10.581 --> 00:04:14.991
There's some other files here, like run,
that gives us a command from the package

77
00:04:14.991 --> 00:04:17.583
JSON that allows us to run
our evals very simply.

78
00:04:17.583 --> 00:04:21.869
You'll use that, I'll show you how
to use it, it's pretty simple.

79
00:04:21.869 --> 00:04:25.465
And then this scores file is where we're
gonna make our own custom scores that we

80
00:04:25.465 --> 00:04:26.441
can use in our evals.

81
00:04:26.441 --> 00:04:30.070
One thing to just look at right quick
is if you look at the package JSON,

82
00:04:30.070 --> 00:04:32.110
you should see three commands in here.

83
00:04:32.110 --> 00:04:36.390
You have start, that's to actually execute
the agent, eval, is to run an eval, and

84
00:04:36.390 --> 00:04:39.838
it takes the name of a file,
we'll get into making those eval files,

85
00:04:39.838 --> 00:04:42.349
if you don't give it a name
it'll run every eval.

86
00:04:42.349 --> 00:04:45.578
And then, don't worry about this one,
we'll get into this one later.

87
00:04:45.578 --> 00:04:47.582
So let's do it.

88
00:04:47.582 --> 00:04:51.238
So the first thing we wanna do is
we wanna make a custom scorer.

89
00:04:52.298 --> 00:04:55.764
Again, we wanna check to make sure
you're calling the right tool calls, so

90
00:04:55.764 --> 00:04:57.183
we're gonna make a function.

91
00:04:57.183 --> 00:05:02.414
I'm using a project called AutoEvals,
it's a set of scorers written

92
00:05:02.414 --> 00:05:08.666
in TypeScript based off of OpenAI's
evals framework written in Python.

93
00:05:08.666 --> 00:05:14.133
So, thank god we have this, because
without this, this would be hard, I think.

94
00:05:14.133 --> 00:05:15.971
There's some really cool stuff in here, so

95
00:05:15.971 --> 00:05:18.016
we're just gonna implement
a lot of this stuff.

96
00:05:18.016 --> 00:05:22.631
So if you haven't already, make sure you
do npm-install to get all your packages.

97
00:05:22.631 --> 00:05:23.826
So, let's do it.

98
00:05:23.826 --> 00:05:27.975
So I'll implement evals, or
this type (Scorer) from autoevals.

99
00:05:27.975 --> 00:05:34.276
And I'm gonna export
const ToolCallMatch here.

100
00:05:34.276 --> 00:05:40.419
It's of type Scorer,
I'm just gonna say any any like that.

101
00:05:40.419 --> 00:05:45.627
And then,
every score always takes in an input,

102
00:05:45.627 --> 00:05:49.576
an output, and the expected value.

103
00:05:50.966 --> 00:05:54.561
Some of them take in some extra ones,
a lot of them never use the input.

104
00:05:54.561 --> 00:05:57.396
Really just depends on
the thing you're testing.

105
00:05:57.396 --> 00:05:58.359
Typically, it's just these two.

106
00:05:58.359 --> 00:06:00.446
These are typically what you're testing.

107
00:06:00.446 --> 00:06:01.344
I wanna see,

108
00:06:01.344 --> 00:06:06.922
I'm comparing the thing that the AI said
versus what you told me should be right.

109
00:06:06.922 --> 00:06:10.662
And that's typically, I would say,
more than 50% of the evals are doing.

110
00:06:10.662 --> 00:06:12.525
They're comparing that in some way.

111
00:06:12.525 --> 00:06:16.214
So, we have our input,

112
00:06:16.214 --> 00:06:21.200
our output, and our expected.

113
00:06:24.904 --> 00:06:26.683
&gt;&gt; Scott Moss: Expected.

114
00:06:30.056 --> 00:06:31.219
&gt;&gt; Scott Moss: Cool.

115
00:06:31.219 --> 00:06:33.251
&gt;&gt; Scott Moss: Now, what do we want to do?

116
00:06:33.251 --> 00:06:35.892
For the tool call one, if you remember,

117
00:06:35.892 --> 00:06:40.321
if you have any experience making LLMs and
tool calls, when an LLM,

118
00:06:40.321 --> 00:06:45.157
at least in this case, one that's
based off of open AI's API structure.

119
00:06:45.157 --> 00:06:49.737
When it makes a tool call, it returns
a message with a role of assistant.

120
00:06:51.067 --> 00:06:58.543
And that message has
a tool called array on it.

121
00:06:58.543 --> 00:07:01.359
And if the tool call in there, basically,

122
00:07:01.359 --> 00:07:06.146
we want to grab that object that's in
that array and check the name of it.

123
00:07:06.146 --> 00:07:09.504
And if that name matches the one
that we expect it to be,

124
00:07:09.504 --> 00:07:11.405
then they call the right tool.

125
00:07:11.405 --> 00:07:16.182
So essentially, just checking to
see if the tool call that the AI

126
00:07:16.182 --> 00:07:21.235
sent to us to call is the same name
as the one that we expect it to be.

127
00:07:21.235 --> 00:07:23.213
It's just a triple equals check here.

128
00:07:23.213 --> 00:07:25.055
So that's what we're gonna do.

129
00:07:25.055 --> 00:07:26.130
And that's gonna be our score.

130
00:07:26.130 --> 00:07:32.225
So, I'm not gonna write all that,
but let's walk through it.

131
00:07:32.225 --> 00:07:36.603
So the first thing is, the output
is gonna be a message from the AI.

132
00:07:36.603 --> 00:07:39.534
It's an object that has a role and
content and

133
00:07:39.534 --> 00:07:44.180
things on that, we wanna check to see,
again, is it type-assisted?

134
00:07:44.180 --> 00:07:48.114
Because for some reason, maybe your data
is messed up and this is type tool or

135
00:07:48.114 --> 00:07:49.474
type system or type user.

136
00:07:49.474 --> 00:07:52.873
So first, let's make sure this
AI actually sent this message.

137
00:07:52.873 --> 00:07:57.409
Then we just make, this is just a sanity
check just to make sure that, hey,

138
00:07:57.409 --> 00:08:00.737
did the AI send an assisted
message with tool_calls?

139
00:08:00.737 --> 00:08:04.819
Because the AI can send two
different types of messages.

140
00:08:04.819 --> 00:08:07.743
It can send a tool-called message,
or it can send a final response.

141
00:08:07.743 --> 00:08:10.807
And a final response,
if you remember from the other course, or

142
00:08:10.807 --> 00:08:14.629
just practice with LLMs in general,
it'll have a content property on it.

143
00:08:14.629 --> 00:08:16.783
So if there's a content property on it,
that's the final response.

144
00:08:16.783 --> 00:08:21.169
If there's not a content property on it,
it's probably a tool call.

145
00:08:21.169 --> 00:08:24.539
So we're checking to see if, hey,
is there a tool call array here?

146
00:08:24.539 --> 00:08:28.594
If so, is there at least one thing
in there, which it should be?

147
00:08:28.594 --> 00:08:32.164
I don't think, if it isn't,
then that LLM is broken.

148
00:08:32.164 --> 00:08:33.474
That's nothing on your system.

149
00:08:33.474 --> 00:08:36.594
If that LLM didn't give you content but
gave you a tool call array but

150
00:08:36.594 --> 00:08:38.635
no tool calls in it, that thing's busted.

151
00:08:38.635 --> 00:08:42.788
But just to make sure my code doesn't
break, I'm checking for that.

152
00:08:42.788 --> 00:08:44.849
And then I grab the first one in there,

153
00:08:44.849 --> 00:08:47.500
which is an object that
has a function property.

154
00:08:47.500 --> 00:08:49.812
And that object has a name property, and

155
00:08:49.812 --> 00:08:52.583
I'm checking to see if
that function's name.

156
00:08:52.583 --> 00:08:54.902
The one that AI told me to call,

157
00:08:54.902 --> 00:09:00.279
is the one that the expected value
name is, to see if they're the same.

158
00:09:00.279 --> 00:09:03.606
And if it is, you get a 1,
if not, you get a 0.

159
00:09:07.434 --> 00:09:14.340
&gt;&gt; Scott Moss: It's so silly, but at
the same time, it's actually pretty good.

160
00:09:14.340 --> 00:09:16.212
And then from there, yeah,

161
00:09:16.212 --> 00:09:21.132
I'm just gonna return this object that
has the name, put the name on here.

162
00:09:21.132 --> 00:09:24.299
So that way,
if we go look at it on a chart,

163
00:09:24.299 --> 00:09:27.205
I can see what scorer gave this score.

164
00:09:27.205 --> 00:09:31.235
So that way I know what to improve,
I know that this tool called match-fail,

165
00:09:31.235 --> 00:09:33.661
then it's not good at
picking the right tool.

166
00:09:33.661 --> 00:09:37.806
So I would have to go fix that, right,
and we'll demonstrate that in a minute.

167
00:09:37.806 --> 00:09:39.907
So I'm just gonna return the name and
the score here.

168
00:09:45.835 --> 00:09:47.831
&gt;&gt; Scott Moss: And then scorer.

169
00:09:47.831 --> 00:09:53.222
And again, like I said, you will probably
not use the input a lot, unless you're

170
00:09:53.222 --> 00:09:58.556
doing some type of LLM-based metric,
which we probably won't get into today.

171
00:09:58.556 --> 00:10:03.487
Cuz it's a rabbit hole, and I think that's
where a lot of all the subjectivity is,

172
00:10:03.487 --> 00:10:06.816
and that's where a lot of
white papers are coming from.

173
00:10:06.816 --> 00:10:08.720
So we're just gonna keep it simple.

174
00:10:08.720 --> 00:10:13.361
&gt;&gt; Speaker 2: When running evals,
do you store the inputs, outputs, and

175
00:10:13.361 --> 00:10:19.462
expected results to analyze later, or
do you just store the final eval result?

176
00:10:19.462 --> 00:10:23.132
&gt;&gt; Scott Moss: That's such a great
question, somebody's thinking over there.

177
00:10:23.132 --> 00:10:25.707
So, that's a great question.

178
00:10:25.707 --> 00:10:29.694
Yes, you typically want
to store these data sets,

179
00:10:29.694 --> 00:10:34.608
and that is why there are products
out there that help you run and

180
00:10:34.608 --> 00:10:41.612
visualize your evals, because of just that
one part of, how do I collect this data?

181
00:10:41.612 --> 00:10:42.803
Where is it stored?

182
00:10:42.803 --> 00:10:44.880
So I can reuse it when I run my evals.

183
00:10:44.880 --> 00:10:47.239
Even though I'm running my
evals offline on my machine,

184
00:10:47.239 --> 00:10:48.574
where is this data coming from.

185
00:10:48.574 --> 00:10:52.211
If you have megabytes of data, hopefully
you're not storing that in your repo and

186
00:10:52.211 --> 00:10:54.916
push that up every time, so
it needs to be stored somewhere.

187
00:10:54.916 --> 00:10:56.320
We're not gonna do that today,

188
00:10:56.320 --> 00:10:59.031
obviously, we're just gonna
just hard code some some data.

189
00:10:59.031 --> 00:11:03.842
But yeah, typically you would have
some paid platform that you use, like,

190
00:11:03.842 --> 00:11:07.751
I don't wanna, you guys know I
hate promoting products, but

191
00:11:07.751 --> 00:11:12.286
we are using their open source tools,
so I guess I should mention them.

192
00:11:12.286 --> 00:11:16.219
So, Braintrust data is one that I
personally use, I think it's pretty good.

193
00:11:16.219 --> 00:11:20.829
And they give you a dashboard, where you
can see all your evals and scores and

194
00:11:20.829 --> 00:11:23.653
things that fail,
they give you an analysis.

195
00:11:23.653 --> 00:11:26.468
They store your data,
you can use it locally.

196
00:11:26.468 --> 00:11:28.683
You can just run the evals
on their platform.

197
00:11:28.683 --> 00:11:30.800
There's a lot of different
things you can do here.

198
00:11:30.800 --> 00:11:33.353
This is just one of many,
I'm not even gonna say, go use this one.

199
00:11:33.353 --> 00:11:34.253
This is just one of minis.

200
00:11:34.253 --> 00:11:36.093
This is the one that I use.

201
00:11:36.093 --> 00:11:38.815
But if you're not there yet,
you don't have a lot of data,

202
00:11:38.815 --> 00:11:42.644
maybe it's just all synthetic and it's
in the file, you don't really need this.

203
00:11:42.644 --> 00:11:44.322
You can just do what
we're doing right now.

204
00:11:44.322 --> 00:11:47.401
It's when you start getting a lot of
data and collecting it from users,

205
00:11:47.401 --> 00:11:49.779
where you're like, all right,
where do we put this?

206
00:11:49.779 --> 00:11:52.794
There's nothing stopping from just putting
that in your own database too, and

207
00:11:52.794 --> 00:11:54.372
just put that stuff in your own database.

208
00:11:54.372 --> 00:11:56.472
But if you're really serious about it,

209
00:11:56.472 --> 00:11:59.745
you're gonna need a place where
you can go label these things,

210
00:11:59.745 --> 00:12:03.913
another human in the loop thing that I
didn't talk about is labeling this data.

211
00:12:03.913 --> 00:12:08.737
You might have a human whose job is
to go in and label the data that your

212
00:12:08.737 --> 00:12:12.969
users didn't label, and
then you would have to hire a SME,

213
00:12:12.969 --> 00:12:17.220
a subject matter expert on that topic,
to label that data.

214
00:12:17.220 --> 00:12:19.349
To make sure if it's good or not.

215
00:12:19.349 --> 00:12:20.672
What is the expected thing here?

216
00:12:20.672 --> 00:12:22.353
So like, it can get really crazy.

217
00:12:22.353 --> 00:12:24.301
So this is why you would
use a tool like this,

218
00:12:24.301 --> 00:12:27.783
cuz they give you a platform where
you can do that and visualize it.

219
00:12:27.783 --> 00:12:32.138
So, we're not gonna be doing that today,
because they're stupid expensive.

220
00:12:32.138 --> 00:12:33.139
But yes, great question.

