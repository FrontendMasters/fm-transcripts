[00:00:00]
>> Scott Moss: Let's do a quick recap. So again, if you don't know anything about LLMs, agents, take the other course, this is just a little recap, a little refresher. I have everything you need to know about all that stuff in here, but I'm just gonna go over it in my own words of what an LLM is, what an agent is, kinda those basics.

[00:00:16]
So as you may or may not know, an LLM is just a large language model It's some form of weights and balances, which are like probabilities and statistics on what decisions to make to help it predict, in this case, in a large language model, predict the next word.

[00:00:34]
And other models like diffusion-based models, which are models used to generate images like we saw, it's very similar, except for it's not predicting the next word. It's more about denoising pixels and coming back to some image that was very similar to a description of another image, but still about predicting things.

[00:00:55]
At the end of the day, there's statistics, there's weights and balances, and you have a model with neural networks that use it. The thing that's special about LLMS is they have something called attention, which basically just allows it to keep in memory the whole sentence, the whole set of characters while predicting the next character.

[00:01:15]
Whereas previous attempts of text prediction based AI models did not have the ability to keep the entire part in memory. They only knew what the previous letter was and not the whole sentence before it, and every letter before it. So that is the innovation here. And then a agents kind of build on LLMS.

[00:01:39]
So you think of LLMs are just like, you'll hear these terms a lot. You'll hear single turn and multi turn. So single turn it's just a, what I'd like to call a transactional LLM call. It's very similar to what you would do in cursor or VS Code or GitHub Copilot, where you say, do this thing, and it does the thing and it's done.

[00:02:00]
Agent is multi turn. So, you saw how I was able to do the approval, generate an image, and do this stuff. That is the agent taking, it's calling an LLM multiple times. It's getting the results, it's feeding it back. It's thinking, it's getting a result. It's feeding it back until it doesn't have to think anymore.

[00:02:17]
So, that's kind of what an agent is. It's an LLM. On a loop that has typically access to tools, and also in the form of a chat-based agent memory. So it can remember all the messages that you've said before.

