WEBVTT

1
00:00:00.050 --> 00:00:04.160
&gt;&gt; Kyle Simpson: We just mentioned that
those blog posts aren't getting kind of

2
00:00:04.160 --> 00:00:05.640
proactively cashed.

3
00:00:05.640 --> 00:00:08.332
They're only getting cashed
when we have visited them,

4
00:00:08.332 --> 00:00:10.813
which might entirely be
the strategy you wanna use.

5
00:00:10.813 --> 00:00:15.257
You might not want to stuff
stuff into somebody's cache

6
00:00:15.257 --> 00:00:18.720
if they haven't actually utilized it.

7
00:00:18.720 --> 00:00:23.670
But you might want to load
old historical blog posts

8
00:00:23.670 --> 00:00:27.730
kind of slowly in the background
while they browse around the site.

9
00:00:27.730 --> 00:00:29.880
That way, if they happen to go offline and

10
00:00:29.880 --> 00:00:34.050
happen to be clicking around, they're just
pleasantly delighted to find out that

11
00:00:34.050 --> 00:00:36.570
there's a lot of content
that's already there.

12
00:00:36.570 --> 00:00:39.241
So we're gonna do a very
basic form of that.

13
00:00:39.241 --> 00:00:41.100
I've updated my version, and

14
00:00:41.100 --> 00:00:45.300
I'm gonna keep track of whether or
not I'm actually doing this.

15
00:00:45.300 --> 00:00:46.742
But it's gonna not be all at once,

16
00:00:46.742 --> 00:00:49.640
it's gonna kinda be with long
delays in the background.

17
00:00:49.640 --> 00:00:55.480
So I'm going to, when I start up
my service worker the first time,

18
00:00:55.480 --> 00:00:58.240
start trying to cache all of the posts.

19
00:00:58.240 --> 00:01:02.870
And here's my strategy, I'm gonna make
a request to the server to ask for

20
00:01:02.870 --> 00:01:05.930
all the current post IDs,
that API request.

21
00:01:05.930 --> 00:01:10.485
And I'm gonna use all those post IDs
to generate the URLs that I wanna make

22
00:01:10.485 --> 00:01:12.630
a request and cache for.

23
00:01:12.630 --> 00:01:17.760
So here's my cacheAllPosts function.

24
00:01:17.760 --> 00:01:22.161
If I'm already caching, because that's
been spun off by something else,

25
00:01:22.161 --> 00:01:23.269
then just return.

26
00:01:23.269 --> 00:01:27.429
Go ahead and delay five seconds,
this is just a promise if I'd set timeout,

27
00:01:27.429 --> 00:01:28.350
by the way.

28
00:01:28.350 --> 00:01:33.455
Just go ahead and wait five seconds so
that we're allowing other stuff,

29
00:01:33.455 --> 00:01:36.870
the initial page load and
initialization to happen.

30
00:01:36.870 --> 00:01:39.200
We don't wanna take over
their bandwidth right away.

31
00:01:39.200 --> 00:01:41.090
But then, just kind of in the background,

32
00:01:41.090 --> 00:01:44.870
what we're gonna do is make a request for
get-posts.

33
00:01:44.870 --> 00:01:47.446
If we don't already have it,
we're gonna stick it in the cache.

34
00:01:49.785 --> 00:01:52.959
&gt;&gt; Kyle Simpson: If we are not online,
we're gonna try to get it out of the cache

35
00:01:52.959 --> 00:01:55.720
and use the cached version for
what we wanna pull out.

36
00:01:56.960 --> 00:01:59.200
So once I have a list of post IDs,

37
00:01:59.200 --> 00:02:04.730
if there's greater than zero,
if there are posts that I wanna deal with,

38
00:02:04.730 --> 00:02:09.420
I'm gonna call this cachePost function
with whatever the first post is.

39
00:02:09.420 --> 00:02:12.080
So I'm gonna work from current
all the way backwards.

40
00:02:12.080 --> 00:02:15.480
We want the most recent ones first,
and then we'll get the older and

41
00:02:15.480 --> 00:02:16.774
older ones as we go.

42
00:02:16.774 --> 00:02:22.220
So cachePost just constructs
the URL from that post ID.

43
00:02:22.220 --> 00:02:26.580
If we're not telling
the cache function that it

44
00:02:26.580 --> 00:02:31.190
should forcibly get all these, then we'll
just check to see if we already have it.

45
00:02:31.190 --> 00:02:33.770
So if we already have it,
no reason to re-request it.

46
00:02:33.770 --> 00:02:36.340
But when we've done
a service worker update,

47
00:02:36.340 --> 00:02:40.132
just like we get all of the other stuff,
we should get all of the new blog posts,

48
00:02:40.132 --> 00:02:44.650
in case any of them have been
updated with new fixes, the typos.

49
00:02:44.650 --> 00:02:49.220
Okay, so if we're not checking the cache
or it's not in the cache, then if we know

50
00:02:49.220 --> 00:02:53.140
that we need to cache it, let's just
wait ten seconds between each request.

51
00:02:53.140 --> 00:02:55.810
Cuz again,
we wanna be very friendly to the network,

52
00:02:55.810 --> 00:02:59.880
we don't wanna overload the network
with a bunch of requests unnecessarily.

53
00:02:59.880 --> 00:03:04.250
So we'll just wait ten seconds,
make the request for that blog post.

54
00:03:04.250 --> 00:03:06.679
If we find it, put it into the cache.

55
00:03:07.830 --> 00:03:12.540
And then if that failed,
then we'll retry it again.

56
00:03:12.540 --> 00:03:16.540
So we'll try it, and if that failed, try
again in ten seconds, and if that failed,

57
00:03:16.540 --> 00:03:18.090
try again in ten seconds.

58
00:03:18.090 --> 00:03:21.190
And it'll just sort of sit there,
going over there on the page,

59
00:03:21.190 --> 00:03:23.799
it'll be attempting to
get these old blog posts.

60
00:03:25.010 --> 00:03:29.160
If that has all succeeded, then we check
to see if we have any more caches and

61
00:03:29.160 --> 00:03:30.570
then we do it again.

62
00:03:30.570 --> 00:03:33.568
So we're just gonna, every ten seconds,
just try to keep loading ones,

63
00:03:33.568 --> 00:03:35.640
we're successful, move on to the next one.

64
00:03:35.640 --> 00:03:37.020
And if we add thousands of posts,

65
00:03:37.020 --> 00:03:40.950
just eventually, over time, somebody
would have gotten all of those posts.

66
00:03:40.950 --> 00:03:43.770
But they won't get all of
them necessarily all at once,

67
00:03:43.770 --> 00:03:46.831
they'll get a few dozen each
time they visit, for example.

68
00:03:48.412 --> 00:03:51.590
&gt;&gt; Kyle Simpson: Okay, so
let's demo that working.

69
00:03:53.210 --> 00:03:57.710
So the first thing I'm gonna do,
we need to go back online, and

70
00:03:57.710 --> 00:04:01.150
I'm gonna go ahead and clear out my cache.

71
00:04:01.150 --> 00:04:04.906
I'm gonna kill my service worker,

72
00:04:04.906 --> 00:04:09.795
clear out the network,
clear out my console.

73
00:04:13.682 --> 00:04:19.750
&gt;&gt; Kyle Simpson: And
we'll start up on the about page.

74
00:04:21.780 --> 00:04:24.598
And I'm gonna come over here,
and I want us to watch,

75
00:04:24.598 --> 00:04:29.550
there's our get-posts,
we were waiting five seconds for it.

76
00:04:29.550 --> 00:04:32.042
Now we're waiting ten seconds.

77
00:04:32.042 --> 00:04:38.810
And in about four more seconds,
we should see the first post got cashed.

78
00:04:38.810 --> 00:04:42.344
And now we're waiting ten more seconds,
and

79
00:04:42.344 --> 00:04:48.100
then,
&gt;&gt; Kyle Simpson: The last post got cached.

80
00:04:48.100 --> 00:04:50.370
We check our cache.

81
00:04:50.370 --> 00:04:52.670
Sure enough, even though we haven't yet

82
00:04:52.670 --> 00:04:57.380
visited these blog posts,
the blog posts are in our cache.

83
00:04:57.380 --> 00:05:01.616
And if we go offline,
we'll be able to go visit them.

84
00:05:08.734 --> 00:05:10.772
&gt;&gt; Kyle Simpson: This still
feels like a website, and

85
00:05:10.772 --> 00:05:14.470
that's kind of the point that
I wanna make here, above all.

86
00:05:14.470 --> 00:05:16.660
We're not trying to turn
this into an application.

87
00:05:16.660 --> 00:05:21.033
We're just trying to turn this into
the kind of user experience that somebody

88
00:05:21.033 --> 00:05:25.542
would expect if they weren't thinking
about all the vagaries of bad networks or

89
00:05:25.542 --> 00:05:27.308
servers being down or things.

90
00:05:27.308 --> 00:05:29.729
They would just kind of expect it to work,
and

91
00:05:29.729 --> 00:05:33.318
we're now giving them that extra effort,
we're making it work.

