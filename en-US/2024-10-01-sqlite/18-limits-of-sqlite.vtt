WEBVTT

1
00:00:00.000 --> 00:00:02.631
&gt;&gt; Brian Holt: I just want to throw
some notes in about the limits.

2
00:00:02.631 --> 00:00:06.572
Some people think that SQLite
is more limited than it is, and

3
00:00:06.572 --> 00:00:11.153
I just wanted to kind of disabuse
you of that notion it's not, right?

4
00:00:11.153 --> 00:00:15.691
Max row size is a gigabyte,
about right, give or

5
00:00:15.691 --> 00:00:21.353
take some if you're doing
anything remotely close to this.

6
00:00:21.353 --> 00:00:23.499
What's wrong with you and
what's wrong with what you're doing?

7
00:00:23.499 --> 00:00:25.307
That's my question for you.

8
00:00:25.307 --> 00:00:29.824
If you had anything that big,
just put it in like a bucket, right?

9
00:00:29.824 --> 00:00:31.641
Like an honest three or
something like that.

10
00:00:31.641 --> 00:00:37.831
I would not store anything of that nature,
of in size, in an SQL unless I'm like,

11
00:00:37.831 --> 00:00:42.677
some embedded use case where I
didn't have another way to do it,

12
00:00:42.677 --> 00:00:45.843
but it just all of it
seems terrible to me.

13
00:00:45.843 --> 00:00:48.369
Doesn't seem like it's intended use case.

14
00:00:48.369 --> 00:00:52.482
You can have 2000 columns
by default on a table, and

15
00:00:52.482 --> 00:00:56.595
if you actually go in and
compile the source yourself and

16
00:00:56.595 --> 00:01:02.131
kind of remove some of the checks,
you can get up to 32,000 columns.

17
00:01:02.131 --> 00:01:05.812
Again, I post to you
what is wrong with you,

18
00:01:05.812 --> 00:01:09.602
who hurt you, and
why you like this, right?

19
00:01:09.602 --> 00:01:15.039
At that point, you need JSON or
a different database.

20
00:01:15.039 --> 00:01:17.042
If you have 2,000 columns
in your database,

21
00:01:17.042 --> 00:01:18.623
you really wanted Mongo to start with.

22
00:01:18.623 --> 00:01:21.098
I'm just gonna throw that out there,
I think, right?

23
00:01:23.606 --> 00:01:26.308
&gt;&gt; Brian Holt: So we'll talk
about JSON here in a little bit.

24
00:01:26.308 --> 00:01:29.456
But, yeah, a document based
database would be better for that.

25
00:01:29.456 --> 00:01:34.424
But, I mean,
what is comforting is that the limit is so

26
00:01:34.424 --> 00:01:40.796
high that you have approached and
ran past insanity so far behind you.

27
00:01:40.796 --> 00:01:47.616
That there should never be any sort
of limitation on what you're doing.

28
00:01:47.616 --> 00:01:49.534
You will notice some theme here,

29
00:01:49.534 --> 00:01:54.056
like some of these you have to recompile
SQLite yourself from source and remove

30
00:01:54.056 --> 00:01:58.461
the checks in the in the compilation
step to allow it to reach these heights.

31
00:01:58.461 --> 00:02:01.481
I suggest that you never do that ever.

32
00:02:01.481 --> 00:02:05.149
It just doesn't make any sense to me.

33
00:02:05.149 --> 00:02:09.305
A query can be, what is that,
a billion characters?

34
00:02:09.305 --> 00:02:12.338
Yeah, a billion characters.

35
00:02:12.338 --> 00:02:15.259
And if you can write a query that long,

36
00:02:15.259 --> 00:02:20.663
you have successfully written like
a turing complete SQL statement.

37
00:02:20.663 --> 00:02:21.381
Why?

38
00:02:21.381 --> 00:02:23.872
Right?
Write us several more queries,

39
00:02:23.872 --> 00:02:27.367
I feel like you're rendering
whole UIs in in SQL.

40
00:02:27.367 --> 00:02:29.271
I'm impressed and upset.

41
00:02:29.271 --> 00:02:32.299
Tables and adjoin, 64.

42
00:02:32.299 --> 00:02:37.079
This is the only one I could fathom
myself possibly ever reaching, right?

43
00:02:37.079 --> 00:02:41.844
Still 64 tables and adjoin them together,
I'm gonna assert you probably could've

44
00:02:41.844 --> 00:02:45.769
made some of those the same table,
nut possibilities, I don't know.

45
00:02:45.769 --> 00:02:49.801
Maybe we're like joining
atoms to molecules,

46
00:02:49.801 --> 00:02:54.751
to amoebas, to people to like,
maybe have 64 of those?

47
00:02:54.751 --> 00:02:57.988
That seems, unlikely.

48
00:03:00.017 --> 00:03:02.739
&gt;&gt; Brian Holt: Max link of like terms.

49
00:03:02.739 --> 00:03:05.878
Again, 50,000 characters
seems wild to me to try and

50
00:03:05.878 --> 00:03:08.026
do some sort of match based on that long.

51
00:03:08.026 --> 00:03:13.652
But they limit you to 50,000 I think.

52
00:03:13.652 --> 00:03:17.889
Yeah, and they start saying,
it can go further than that, but there's,

53
00:03:17.889 --> 00:03:21.929
some strong performance implications
when you start going that long,

54
00:03:21.929 --> 00:03:25.630
that it starts going into N complexity,
which is bad for sqlite,

55
00:03:25.630 --> 00:03:27.675
so they don't allow you to do that.

56
00:03:27.675 --> 00:03:28.772
Attached databases.

57
00:03:28.772 --> 00:03:31.249
I can see someone hitting
this one as well.

58
00:03:31.249 --> 00:03:34.999
So I told you that you can do connect
to connect to more than one database.

59
00:03:34.999 --> 00:03:37.621
Maybe you can connect to ten databases.

60
00:03:37.621 --> 00:03:39.859
That's a limitation there.

61
00:03:39.859 --> 00:03:43.574
At that point if you're connecting to so
many different databases,

62
00:03:43.574 --> 00:03:47.928
I'm gonna say that maybe you't need to
have some sort of data ingestion pipeline

63
00:03:47.928 --> 00:03:52.110
that dumps you out into maybe, you could
dump into another SQLite database.

64
00:03:52.110 --> 00:03:56.909
That's one aggregation of many
you could dump into BigQuery,

65
00:03:56.909 --> 00:04:01.899
Snowflakes, some sort of like data lake or
something like that.

66
00:04:01.899 --> 00:04:07.130
Rows in a database or slash size,
a database can be 281 terabytes, if you

67
00:04:07.130 --> 00:04:13.043
have that much data and you're putting it
in SQLite that now I'm impressed, right?

68
00:04:13.043 --> 00:04:14.667
I'm not even upset.

69
00:04:14.667 --> 00:04:19.791
In theory, you can address 1.8 to 10 to

70
00:04:19.791 --> 00:04:27.694
the 19th rows inside of SQLite in
terms of how big the registry is.

71
00:04:27.694 --> 00:04:32.938
However, effectively, based on how
small a row can possibly be and

72
00:04:32.938 --> 00:04:36.618
how quickly you would reach 281 terabytes,

73
00:04:36.618 --> 00:04:41.402
the actual physical upper limit
of this is about 2 to the third

74
00:04:41.402 --> 00:04:45.634
times 10 of the 13th rows,
which is a lot, right?

75
00:04:45.634 --> 00:04:49.399
You probably don't need that many rows.

76
00:04:49.399 --> 00:04:53.336
The reason why I bring all this stuff up
is I'm gonna just assert that like this

77
00:04:53.336 --> 00:04:55.290
works for almost all of our use cases.

78
00:04:55.290 --> 00:05:00.615
Only the most absurd use cases would
exceed almost any one of these.

79
00:05:00.615 --> 00:05:03.045
So SQLite can scale.

80
00:05:03.045 --> 00:05:07.325
I feel pretty confident
in saying that it does,

81
00:05:07.325 --> 00:05:12.461
at least from the perspective of querying,
inserting,

82
00:05:12.461 --> 00:05:17.716
updating, deleting,
it can handle load, a lot of load.

83
00:05:17.716 --> 00:05:22.588
The question is just, do you want it to?

84
00:05:22.588 --> 00:05:24.110
Yeah, cool.

85
00:05:26.894 --> 00:05:29.541
&gt;&gt; Brian Holt: It's powerful
enough to talk about any problem.

