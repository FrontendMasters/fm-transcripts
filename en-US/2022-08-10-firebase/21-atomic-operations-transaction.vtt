WEBVTT

1
00:00:00.340 --> 00:00:03.420
All right, so I'm gonna cover one
last bit just going through it,

2
00:00:03.420 --> 00:00:06.120
it's good to know we're not
gonna do any exercises on it.

3
00:00:06.120 --> 00:00:10.687
But this is a very important thing cuz
you'll get yourself stuck in situations

4
00:00:10.687 --> 00:00:14.430
sometimes where you care about
having an atomic process.

5
00:00:14.430 --> 00:00:19.452
So atomicity, basically means
if one operation of a series

6
00:00:19.452 --> 00:00:23.980
of many operation fails,
let's roll them all back.

7
00:00:23.980 --> 00:00:28.614
So I don't wanna be in an incomplete state
because if I let's say I wanna run 10

8
00:00:28.614 --> 00:00:32.993
operations to update a table or a database
in any database for that matter.

9
00:00:32.993 --> 00:00:39.571
I don't want if three of them fail in the
process but then seven of them succeed.

10
00:00:39.571 --> 00:00:43.057
It becomes difficult to know
what state my data is in,

11
00:00:43.057 --> 00:00:47.713
especially if one of the other pieces
relied on the other piece of data.

12
00:00:47.713 --> 00:00:49.939
So in order to make sure
that doesn't happen,

13
00:00:49.939 --> 00:00:54.400
I want the whole process to be atomic, if
one thing failed, let's just do it again.

14
00:00:54.400 --> 00:00:58.858
Because I don't wanna just fail even
cuz I don't want it to process through.

15
00:00:58.858 --> 00:01:03.310
And in fire store you have two tools at
your disposal for atomic transaction,

16
00:01:03.310 --> 00:01:06.420
you have Batch Writes and transactions.

17
00:01:06.420 --> 00:01:11.225
A Batch Write basically is a big
collection of operations that you want to

18
00:01:11.225 --> 00:01:15.560
run, you can call batch.set Batch.update,
batch.delete,

19
00:01:15.560 --> 00:01:19.610
and you pass in the operation
you want to run inside of there.

20
00:01:19.610 --> 00:01:21.724
And then when you run batch.commit,

21
00:01:21.724 --> 00:01:25.170
it will attempt to put all those
together in one transaction.

22
00:01:26.320 --> 00:01:31.487
So the way it works is, is that I
can set a batch, so batch.set I call

23
00:01:31.487 --> 00:01:36.772
it with a document and then I just
pass the date I want batch.update.

24
00:01:36.772 --> 00:01:40.497
Saying you pass in a document,
the data that you need to update and

25
00:01:40.497 --> 00:01:43.360
then same thing with delete
the document as well.

26
00:01:43.360 --> 00:01:46.890
And then since it's asynchronous,
you will run a try catch and

27
00:01:46.890 --> 00:01:50.960
you await the commit and if there's
a problem, you can catch it in here.

28
00:01:50.960 --> 00:01:52.288
And if there's a problem,

29
00:01:52.288 --> 00:01:57.030
that's great because I'd rather have it
all fail than be in some incomplete state.

30
00:01:57.030 --> 00:02:00.723
So at anytime in your app where you're
really relying on multiple transactions

31
00:02:00.723 --> 00:02:01.889
that happen all at once.

32
00:02:01.889 --> 00:02:04.958
Or multiple operations that
happen all together and

33
00:02:04.958 --> 00:02:08.864
if they were to happen together and
really make things difficult,

34
00:02:08.864 --> 00:02:11.387
this is the tool you use so
Batched Writes.

35
00:02:11.387 --> 00:02:14.921
And it's important to note that Batched
Writes have a limit of 500 documents

36
00:02:14.921 --> 00:02:15.456
per batch.

37
00:02:15.456 --> 00:02:20.354
So if you're doing something that
goes well beyond 500 you'll need to

38
00:02:20.354 --> 00:02:22.730
split it up into multiple batches.

39
00:02:22.730 --> 00:02:27.050
And while that is a fairly frustrating
limitation, what I found is is that most

40
00:02:27.050 --> 00:02:31.577
of the time if you are updating more
than 500 or something, several thousand.

41
00:02:31.577 --> 00:02:36.066
It's good to do it in small batches if
you're doing something like fan out which

42
00:02:36.066 --> 00:02:38.620
we'll show with con
functions here in a bit.

43
00:02:38.620 --> 00:02:43.164
Where I say hey, I wanna update all of
my user profile information that I have

44
00:02:43.164 --> 00:02:45.360
spread out or denormalized.

45
00:02:45.360 --> 00:02:47.767
I may only wanna do that 500 at a time,
and

46
00:02:47.767 --> 00:02:52.193
it's okay if my data is in an inconsistent
state as long as I eventually get it into

47
00:02:52.193 --> 00:02:54.140
the consistent state.

48
00:02:54.140 --> 00:02:57.084
And you'll see that a lot in systems
where you update your profile and

49
00:02:57.084 --> 00:03:00.660
you might see it on yours but then on
another screen, it's not available yet.

50
00:03:00.660 --> 00:03:03.641
Because it somewhere in
the background is running all of that.

51
00:03:03.641 --> 00:03:07.160
And then maybe a minute later, maybe an
hour later, depending on how their system

52
00:03:07.160 --> 00:03:09.562
works, you'll be like
everything is consistent now.

53
00:03:09.562 --> 00:03:14.940
So that's known as eventual consistency
and it's another hallmark of no SQL.

54
00:03:16.390 --> 00:03:19.090
And so yeah, updating over a period
of time with this is fairly common.

55
00:03:20.360 --> 00:03:22.267
So then there's also transactions, so

56
00:03:22.267 --> 00:03:26.460
transactions are similar to Batched Writes
where something fails everything fails.

57
00:03:26.460 --> 00:03:29.660
But Batched Writes are more so I don't
care about the current state of data,

58
00:03:29.660 --> 00:03:32.140
I want to overwrite
the current state of data.

59
00:03:32.140 --> 00:03:37.610
Transactions, they work off of something
called optimistic concurrency control.

60
00:03:37.610 --> 00:03:41.962
So in a lot of databases when you want to
do a transaction, it's gonna have to lock

61
00:03:41.962 --> 00:03:46.170
at the database to say no one else can
touch these parts of the database.

62
00:03:46.170 --> 00:03:48.500
Because I'm doing something
important here and

63
00:03:48.500 --> 00:03:52.210
it would really mess everything up
if someone tried to access this.

64
00:03:52.210 --> 00:03:56.843
Well in Firestore that could be
detrimental because of on a client level,

65
00:03:56.843 --> 00:04:00.206
cuz let's say you access
the lock from your web app and

66
00:04:00.206 --> 00:04:02.950
then you're lost connection.

67
00:04:02.950 --> 00:04:03.930
What happens?

68
00:04:03.930 --> 00:04:08.600
Do we just hold lock until they regain?

69
00:04:08.600 --> 00:04:11.488
You can basically be locking
parts of your database for

70
00:04:11.488 --> 00:04:14.198
indeterminate periods of time,
so we do not lock.

71
00:04:14.198 --> 00:04:19.329
What we say is is we're going to assume
that the transaction is going to work but

72
00:04:19.329 --> 00:04:22.360
if it doesn't work,
if the data has changed,

73
00:04:22.360 --> 00:04:25.808
then we're gonna retry it
again until it does work.

74
00:04:25.808 --> 00:04:31.080
So it gets around locking, so no parts
get locked, and it just gets reran.

75
00:04:32.300 --> 00:04:35.976
So in this case,
let's say that we're building a game and

76
00:04:35.976 --> 00:04:38.770
new points were awarded to the user.

77
00:04:38.770 --> 00:04:41.735
And we didn't wanna just
overwrite with the new points,

78
00:04:41.735 --> 00:04:44.963
we wanted to say hey add these
new points to the current state.

79
00:04:44.963 --> 00:04:49.653
Or you can start by running a transaction
and this gives us a transaction object.

80
00:04:49.653 --> 00:04:53.349
Where we can say get data at this
location, and usually check to see if

81
00:04:53.349 --> 00:04:57.581
the document exists because otherwise
you don't wanna run the transaction.

82
00:04:57.581 --> 00:05:02.451
Then you mutate the data here,
so we're gonna add the score,

83
00:05:02.451 --> 00:05:06.113
and then we're going to
run the transaction.

84
00:05:06.113 --> 00:05:10.188
And so what's important is that
at this point, Firestore knows,

85
00:05:10.188 --> 00:05:13.185
all right,
we got the data at this point in time.

86
00:05:13.185 --> 00:05:16.984
Now let's say before I
run transaction.update,

87
00:05:16.984 --> 00:05:19.690
that this data gets updated.

88
00:05:19.690 --> 00:05:24.274
Well, I don't want it to overwrite with
whatever, so if my credit score was 10,

89
00:05:24.274 --> 00:05:27.691
and I was gonna get 10 more points,
so my score will be 20.

90
00:05:27.691 --> 00:05:30.852
But during the meantime,
let's say I got 10 more points, well,

91
00:05:30.852 --> 00:05:32.860
I want my score to be 30, not 20 again.

92
00:05:32.860 --> 00:05:36.775
This one would be 10 plus 10,
it would know that,

93
00:05:36.775 --> 00:05:39.658
I wouldn't know about the new update.

94
00:05:39.658 --> 00:05:43.197
So when this reaches
the server FireStore knows

95
00:05:43.197 --> 00:05:46.830
you thought that happened
when the score was 10.

96
00:05:46.830 --> 00:05:52.920
Now the score is 20 let's run it again and
so then it will do that again and

97
00:05:52.920 --> 00:05:59.814
so that way it'll will continue to try to
update without messing with the old data.

98
00:05:59.814 --> 00:06:03.178
So transactions are a really good
way if you're building games or

99
00:06:03.178 --> 00:06:06.847
anything that really relies on turns and
state they all have to be run and

100
00:06:06.847 --> 00:06:11.671
transaction All right,

101
00:06:11.671 --> 00:06:16.541
so that was all the FireStore we made
it through, that's the biggest section,

102
00:06:16.541 --> 00:06:19.390
they're all pretty
relaxed from here on out.

103
00:06:19.390 --> 00:06:23.620
We're gonna get into authentication and
then we're gonna focus on security.

104
00:06:23.620 --> 00:06:26.220
And then we'll probably speed run
through some stuff with Cloud Functions,

105
00:06:26.220 --> 00:06:28.180
the Cloud Functions they're
pretty easy to get through.

