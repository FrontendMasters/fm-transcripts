WEBVTT

1
00:00:00.672 --> 00:00:04.033
So for this first part,
this is just going to be lecture, so

2
00:00:04.033 --> 00:00:07.953
you can kind of chill out for
a second before we get into the big stuff.

3
00:00:07.953 --> 00:00:12.656
But I wanna introduce you to some
tools that we're gonna use to

4
00:00:12.656 --> 00:00:14.292
look at algorithms.

5
00:00:14.292 --> 00:00:17.357
And again, if you're gonna be
doing interviews anytime soon,

6
00:00:17.357 --> 00:00:20.817
this is gonna be something that you
should really kind of get in depth on,

7
00:00:20.817 --> 00:00:23.620
probably more in depth than
even that I'm gonna get on it.

8
00:00:23.620 --> 00:00:29.800
But knowing how to talk about Big O is,
I don't know I put that in air quotes,

9
00:00:29.800 --> 00:00:36.482
it's actually called Big O, anyway,
let's talk about Big O is very important.

10
00:00:36.482 --> 00:00:43.961
So Big O is a way of talking about
how efficient an algorithm is.

11
00:00:43.961 --> 00:00:47.012
And when I say algorithm, I'm actually
meaning more in the mathematical sense.

12
00:00:47.012 --> 00:00:50.735
We like to talk about algorithms in
the sense of computer science, but

13
00:00:50.735 --> 00:00:52.060
algorithm is, I think,

14
00:00:52.060 --> 00:00:56.366
originally a mathematics term that we
kind of just applied to computer science.

15
00:00:56.366 --> 00:01:01.424
You'll find that mathematics and computer
science end up having a lot of crossover.

16
00:01:01.424 --> 00:01:05.440
That's also not to say that you need to be
very good at math to be able to do this.

17
00:01:05.440 --> 00:01:08.319
So if you don't have a math background,
do not worry,

18
00:01:08.319 --> 00:01:10.772
this stuff can still make
a lot of sense to you.

19
00:01:10.772 --> 00:01:11.974
A lot of people will say,

20
00:01:11.974 --> 00:01:15.197
I don't do computer science because
I don't know math that well.

21
00:01:15.197 --> 00:01:22.117
Nothing I'm gonna do here today is
going to be any worse than algebra.

22
00:01:22.117 --> 00:01:22.812
Is that true?

23
00:01:22.812 --> 00:01:28.012
Yeah, we're not doing any calculus or
anything like that, no algebra too,

24
00:01:28.012 --> 00:01:33.297
this is just college are not college
algebra, but high school algebra level.

25
00:01:33.297 --> 00:01:39.136
So anyway, going back to Big O, Big O was
this concept of taking a algorithm kind of

26
00:01:39.136 --> 00:01:44.485
zooming out and saying, just on a very
broad stroke how efficient is this.

27
00:01:44.485 --> 00:01:50.615
And that's useful because then we
can kind of compare algorithms and

28
00:01:50.615 --> 00:01:55.273
broad strokes, and
not get to mired in the details.

29
00:01:55.273 --> 00:01:59.013
So I like to describe the O
part cuz it's a big open O,

30
00:01:59.013 --> 00:02:03.433
that is a vacuum that sucks out
all the unimportant details and

31
00:02:03.433 --> 00:02:07.951
you're kind of left with the heavy,
very important details.

32
00:02:07.951 --> 00:02:11.969
So, allow me to get mathematical for

33
00:02:11.969 --> 00:02:16.383
just one second, 3x squared + x + 1.

34
00:02:16.383 --> 00:02:21.181
Just zoom in a second.

35
00:02:21.181 --> 00:02:25.804
So we have 3x squared + x + 1,
that's a formula that maybe that

36
00:02:25.804 --> 00:02:29.848
describes how much time it takes for
an algorithm to run.

37
00:02:29.848 --> 00:02:33.296
Where x is how long the array is, right?

38
00:02:33.296 --> 00:02:37.967
So if I have an array of one,
it's gonna be 3 times 1 squared,

39
00:02:37.967 --> 00:02:41.596
which is 1, + 1 plus, so it'd be 5, right?

40
00:02:47.510 --> 00:02:52.753
Now, if we try and plug in something
like 5, the first term would be 75, and

41
00:02:52.753 --> 00:02:57.845
when I say term, I just mean the first
thing between the plus signs, right?

42
00:02:57.845 --> 00:03:01.787
That's the mathematics, which just
means like 3x squared is one term,

43
00:03:01.787 --> 00:03:03.575
x is one term, and 1 is one term.

44
00:03:03.575 --> 00:03:08.807
So if we plug in 5 to the first term,
we'd get 75, we get 5, and we get 1.

45
00:03:08.807 --> 00:03:10.946
So you can see this first term,

46
00:03:10.946 --> 00:03:14.829
it carries most of the weight
of the algorithm, right?

47
00:03:14.829 --> 00:03:18.271
So if I plug in, again, if I do 5 million,

48
00:03:18.271 --> 00:03:22.866
this ends up being the first
term was that 75 trillion,

49
00:03:22.866 --> 00:03:27.962
the second term is 5 million,
and the last one is one, right?

50
00:03:27.962 --> 00:03:32.292
So 75 trillion is so
much bigger than 5 million and one, for

51
00:03:32.292 --> 00:03:36.039
the sake of Big O analysis,
we can just ignore the plus

52
00:03:36.039 --> 00:03:40.820
x+1 because they don't really
affect the final product so much.

53
00:03:40.820 --> 00:03:45.737
I'm not worried about
the difference between 300 and 303,

54
00:03:45.737 --> 00:03:51.021
I'm worried about the difference
between 300 and 300 million.

55
00:03:51.021 --> 00:03:52.438
Does that make sense?

56
00:03:52.438 --> 00:03:57.261
I'm trying to just focus on
the very broad strokes of this.

57
00:03:57.261 --> 00:04:01.308
So that's what Big O does, instead of
saying that we have this complexity of

58
00:04:01.308 --> 00:04:05.877
3x squared +x+1, we're just gonna say
that we have the complexity of x squared.

59
00:04:05.877 --> 00:04:11.802
Or they like to use n instead of x
squared, so we're gonna say n squared.

60
00:04:11.802 --> 00:04:17.838
So the complexity, the Big O of this
3x squared+x+1, is gonna be n squared.

61
00:04:17.838 --> 00:04:23.750
So basically, the life hack here is this,
you just look for the biggest term, right?

62
00:04:23.750 --> 00:04:26.485
So 3x squared would be
the biggest term here.

63
00:04:26.485 --> 00:04:30.807
And we even ignore the coefficient,
the number next to it, so

64
00:04:30.807 --> 00:04:33.230
we just look at x squared, right?

65
00:04:33.230 --> 00:04:37.824
So the Big O of 3x squared
+x+1 is just n squared,

66
00:04:37.824 --> 00:04:44.725
because that's gonna carry most of
the weight of this particular algorithm.

67
00:04:44.725 --> 00:04:45.492
Now, why do we care?

68
00:04:45.492 --> 00:04:48.985
Why am I talking about math in
this Frontend Masters Course?

69
00:04:48.985 --> 00:04:54.654
You didn't sign up for a math class, and
you certainly don't wanna take it from me.

70
00:04:54.654 --> 00:05:01.143
Well, we're gonna use the same
methodology, we just applied it to math,

71
00:05:01.143 --> 00:05:06.400
but we're gonna now apply it
to a computer science problem.

72
00:05:06.400 --> 00:05:10.672
So in particular,
what we're gonna be concerned about the x

73
00:05:10.672 --> 00:05:13.952
that we're worried here
about is this input.

74
00:05:13.952 --> 00:05:15.988
This input is gonna be an array, right?

75
00:05:15.988 --> 00:05:20.173
And we're worried about what
the difference is if I have one item in

76
00:05:20.173 --> 00:05:23.161
the array or
if I have 100 items in the array or

77
00:05:23.161 --> 00:05:25.573
if I have a million items in the array.

78
00:05:25.573 --> 00:05:28.183
So this function here, crossAdd,

79
00:05:28.183 --> 00:05:33.231
all it does is it takes the beginning and
the end and adds it together.

80
00:05:33.231 --> 00:05:37.107
Then the second item and
the second last item adds them together,

81
00:05:37.107 --> 00:05:41.488
the third, the last, and the third
item and adds them together, right?

82
00:05:41.488 --> 00:05:49.605
So it kind of crosses each other to
kind of make this crossAdd array.

83
00:05:49.605 --> 00:05:54.869
So here, I have this for
loop that goes over the array and

84
00:05:54.869 --> 00:05:58.580
it just adds all the numbers together.

85
00:05:58.580 --> 00:06:02.560
So the question you wanna
be asking yourself is,

86
00:06:02.560 --> 00:06:08.784
how many instructions am I gonna give
the CPU based on how long this array is?

87
00:06:11.494 --> 00:06:15.738
Well, the thing that you really wanna be
looking at here is this for loop, right?

88
00:06:15.738 --> 00:06:19.522
Cuz this var answer equals array and
this return answer here,

89
00:06:19.522 --> 00:06:22.958
those execute once no matter
how long input is, right?

90
00:06:22.958 --> 00:06:26.956
This would be like the plus two part
of our equation up here, right?

91
00:06:26.956 --> 00:06:31.607
The +1, which is to say we can ignore it.

92
00:06:31.607 --> 00:06:36.247
But this here, this four loop,
this is gonna happen more and more and

93
00:06:36.247 --> 00:06:39.452
more, depending on how long input is,
right?

94
00:06:39.452 --> 00:06:42.814
So if this is 1,
input is of length 1, right?

95
00:06:42.814 --> 00:06:46.378
We give it the array of 0
inside of square brackets,

96
00:06:46.378 --> 00:06:49.619
that's only gonna take one four loop,
right?

97
00:06:49.619 --> 00:06:52.601
It's only gonna go through
this one iteration.

98
00:06:52.601 --> 00:06:56.541
But if this is of length 1 million,
this four loop,

99
00:06:56.541 --> 00:07:00.853
this body here is gonna happen
1 million times, right?

100
00:07:00.853 --> 00:07:03.300
So you can see here this
is getting stretched out,

101
00:07:03.300 --> 00:07:05.935
depending on how it's gonna
be happen more and more.

102
00:07:05.935 --> 00:07:10.060
So it's gonna take longer and
more computational power to execute,

103
00:07:10.060 --> 00:07:11.988
depending on how long input is.

104
00:07:11.988 --> 00:07:19.840
So this is gonna be our most significant
term in this function, right?

105
00:07:19.840 --> 00:07:23.444
So how many times is this for
loop gonna happen?

106
00:07:23.444 --> 00:07:26.172
Well, it's gonna happen
however long input is, right?

107
00:07:26.172 --> 00:07:30.560
That's how long this for loop is gonna go
for, it goes for through input.length.

108
00:07:30.560 --> 00:07:32.516
So this is gonna be of n, right?

109
00:07:32.516 --> 00:07:36.174
Or x, but
we're gonna stick with n from now on.

110
00:07:36.174 --> 00:07:42.179
So the complexity of this
is gonna be o of n, right?

111
00:07:42.179 --> 00:07:42.725
Does that make sense?

112
00:07:42.725 --> 00:07:44.450
Where n is just the length of the array.

113
00:07:47.037 --> 00:07:51.048
Here's the life hack here, here's where
I'm burying the lead a little bit.

114
00:07:51.048 --> 00:07:54.725
Just look for for loops,
not just loops in general, right?

115
00:07:54.725 --> 00:07:56.874
So val loops would count as well.

116
00:07:56.874 --> 00:07:58.597
Just look for loops, right?

117
00:07:58.597 --> 00:08:01.551
So if you have a loop, that's gonna be n,
if you don't have any loops,

118
00:08:01.551 --> 00:08:03.490
it's gonna be what we call constant,
right?

119
00:08:03.490 --> 00:08:08.353
So that's gonna be Big O of 1, which
means no matter how long the input is,

120
00:08:08.353 --> 00:08:10.919
it's not gonna take that much longer.

121
00:08:13.083 --> 00:08:16.081
Now, you might ask, what if I'm doing
a lot of things inside of this for loop?

122
00:08:16.081 --> 00:08:17.659
Does that affect it?

123
00:08:17.659 --> 00:08:21.220
Well, that would be like
the three here and the x squared.

124
00:08:21.220 --> 00:08:24.748
It's a coefficient, Big O just
ignores all of that stuff, right?

125
00:08:24.748 --> 00:08:29.577
We're just looking really for the loops.

126
00:08:31.382 --> 00:08:32.287
Okay?

127
00:08:32.287 --> 00:08:33.890
How about this one here?

128
00:08:35.495 --> 00:08:38.688
You can cheat by looking down the page,
but maybe just bear with me for

129
00:08:38.688 --> 00:08:39.967
a second and don't cheat.

130
00:08:39.967 --> 00:08:44.673
[LAUGH] Just find one here.

131
00:08:44.673 --> 00:08:48.347
So I have a needle,
which will be like I'm looking for 5, and

132
00:08:48.347 --> 00:08:52.322
I have an array of 15 and
I'm looking for wherever 5 is, right?

133
00:08:52.322 --> 00:08:56.965
It's like a typical linear
search in an array.

134
00:08:56.965 --> 00:09:01.636
So, I'm gonna loop through this and
I'm going to look for the needle, and

135
00:09:01.636 --> 00:09:05.430
if I find that in the haystack,
then I'm gonna return true.

136
00:09:05.430 --> 00:09:08.431
What's the Big O of this?

137
00:09:08.431 --> 00:09:10.253
Well, it might not go through
the entire loop, right?

138
00:09:10.253 --> 00:09:13.603
It actually might find
it on the first thing.

139
00:09:13.603 --> 00:09:17.453
So if 5 is the first item in the array,
and I'm looking at an array of 1 billion,

140
00:09:17.453 --> 00:09:21.872
it doesn't matter, it just takes 1 second,
or one second, it definitely doesn't take,

141
00:09:21.872 --> 00:09:23.085
it takes a millisecond.

142
00:09:23.085 --> 00:09:25.127
What's that?

143
00:09:25.127 --> 00:09:30.625
Well, that's gonna be still Big O of n,
because this short circuiting here, right?

144
00:09:30.625 --> 00:09:37.106
Where we could just return true,
that's still just a coefficient, right?

145
00:09:37.106 --> 00:09:38.383
So we're still gonna say n,

146
00:09:38.383 --> 00:09:42.054
keep in mind that it actually could be the
last thing in the array, which means that

147
00:09:42.054 --> 00:09:45.481
we would look at literally either every
item in the array to find it, right?

148
00:09:45.481 --> 00:09:49.811
So if it was of length 1 billion,
we will look at a billion things.

149
00:09:49.811 --> 00:09:51.551
So we're still gonna call this Big O of n.

150
00:09:54.246 --> 00:09:57.766
And what I'm trying to demonstrate to you
here is there's a difference between best

151
00:09:57.766 --> 00:10:00.953
case scenario, worst case scenario,
and average case scenario, right?

152
00:10:00.953 --> 00:10:04.527
Best case scenario, first item in
the array just finds the returns and

153
00:10:04.527 --> 00:10:07.385
you're done,
that's called the best case scenario.

154
00:10:07.385 --> 00:10:11.310
The worst case scenario is,
it is the last item in the array, and

155
00:10:11.310 --> 00:10:14.089
we'll take the entire array looking for
it.

156
00:10:14.089 --> 00:10:19.407
So what's the average case
scenario in this array?

157
00:10:19.407 --> 00:10:23.538
Somewhere in the middle,
like it'd be, like a half n, right?

158
00:10:23.538 --> 00:10:27.798
But again, Big O doesn't care, so
we're still gonna say this is Big O of n,

159
00:10:27.798 --> 00:10:30.279
despite the fact that
it could exit sooner.

160
00:10:30.279 --> 00:10:33.366
Does that make sense?

161
00:10:33.366 --> 00:10:36.281
Okay, I promise I'm gonna let
you write code here in a second,

162
00:10:36.281 --> 00:10:39.483
you're not gonna be stuck listening
to me lecture this entire time.

163
00:10:41.586 --> 00:10:46.427
All right, so let's talk about this
one here, I love asking people,

164
00:10:46.427 --> 00:10:48.160
how do you say this word?

165
00:10:48.160 --> 00:10:49.339
Is it tuples?

166
00:10:49.339 --> 00:10:50.466
Is it tuples?

167
00:10:50.466 --> 00:10:53.399
There is a correct answer and
I don't like it.

168
00:10:53.399 --> 00:10:56.247
[LAUGH] I've always said
tuples my entire life and

169
00:10:56.247 --> 00:11:00.774
I will probably continue to say tuples
because it's just buried in my brain.

170
00:11:00.774 --> 00:11:03.094
I don't know how to fix that.

171
00:11:03.094 --> 00:11:05.968
I believe the correct way
to say that is tuples.

172
00:11:05.968 --> 00:11:08.476
It's not really a JavaScript concept,

173
00:11:08.476 --> 00:11:13.578
it's more of a Python concept in general,
but the idea is, it's a pair, right?

174
00:11:13.578 --> 00:11:16.737
You have an array of length 2, right?

175
00:11:16.737 --> 00:11:20.539
And you have one first item and
one second item, and

176
00:11:20.539 --> 00:11:26.032
that's a pair of values, and
we call those tuples, tuples, whatever.

177
00:11:26.032 --> 00:11:28.068
So what if I wanted to take an array and

178
00:11:28.068 --> 00:11:32.360
I wanted to make a tuple out of every
single possibility in the array, right?

179
00:11:32.360 --> 00:11:37.193
So if I had an item that was or had
an array here, an input of length three,

180
00:11:37.193 --> 00:11:41.730
then I would end up, I think,
with nine items in the array, right?

181
00:11:41.730 --> 00:11:45.947
Because I'd make every pair possible,
right?

182
00:11:45.947 --> 00:11:49.907
Again, not something that
you would typically do, but

183
00:11:49.907 --> 00:11:51.686
what is the Big O of this?

184
00:11:55.032 --> 00:12:01.432
And so, how did we get to this
n squared kinda solution here?

185
00:12:01.432 --> 00:12:05.154
Well, we have this outer loop that's gonna
run over every item in the array, and

186
00:12:05.154 --> 00:12:06.686
then for every item in the array,

187
00:12:06.686 --> 00:12:09.777
we're going to run through every
item in the array again, right?

188
00:12:09.777 --> 00:12:12.980
So if I have something of length 3,
then it's gonna run 9 times,

189
00:12:12.980 --> 00:12:15.745
Ii I have length 4,
it's gonna run 16 times, right?

190
00:12:15.745 --> 00:12:19.901
And you can see here, that number
just keeps going up and up and up.

191
00:12:19.901 --> 00:12:23.296
If I have something of length 10,
it's gonna run 100 times, right?

192
00:12:23.296 --> 00:12:26.262
And it gets kind of out of
control really quickly.

193
00:12:26.262 --> 00:12:29.607
So if input here was like, 500, right?

194
00:12:29.607 --> 00:12:32.928
This is gonna take a really long time.

195
00:12:32.928 --> 00:12:37.589
Which is bad,
we don't wanna do that, right?

196
00:12:37.589 --> 00:12:39.879
So that's n squared.

197
00:12:39.879 --> 00:12:40.825
So how did we get n squared?

198
00:12:40.825 --> 00:12:43.687
Well, we have an outer loop and
then we have an inner loop.

199
00:12:43.687 --> 00:12:50.271
And when you see nested loops, then you
can kind of assume n squared, right?

200
00:12:50.271 --> 00:12:54.307
And if you saw another one inside of here,
another for loop inside of that,

201
00:12:54.307 --> 00:12:55.988
that would be n cubed, right?

202
00:12:55.988 --> 00:12:57.265
Or n to the third.

203
00:13:00.137 --> 00:13:05.251
There's not really any n cubed algorithms,
and please don't write any [LAUGH].

204
00:13:05.251 --> 00:13:08.244
That's kind of like a bridge too far.

205
00:13:08.244 --> 00:13:11.702
There are n squared,
there's reasons to write n squared, but

206
00:13:11.702 --> 00:13:14.376
it's a,
you wanna be pretty careful with that,

207
00:13:14.376 --> 00:13:17.658
cuz those n squared ones get
out of control pretty quickly.

208
00:13:17.658 --> 00:13:22.354
But that being said, you and I are gonna
write some n squared algorithms today.

209
00:13:22.354 --> 00:13:27.618
&gt;&gt; It's best practice to avoid
the n squared just to go for

210
00:13:27.618 --> 00:13:30.371
constant time complexity?

211
00:13:30.371 --> 00:13:32.750
And I guess,
how are we gonna make that trade off?

212
00:13:32.750 --> 00:13:36.512
If this is further down the line
then answer it then answer it then.

213
00:13:36.512 --> 00:13:39.997
&gt;&gt; It's a good question and
we're basically gonna

214
00:13:39.997 --> 00:13:44.588
be answering that question for
the rest of the damn class [LAUGH].

215
00:13:44.588 --> 00:13:50.726
But it's a super valid question and
I'm glad you asked it.

216
00:13:50.726 --> 00:13:52.405
There's no right answer to it, right?

217
00:13:52.405 --> 00:13:58.237
The reason why there's no just one
sorting algorithm in one data structure,

218
00:13:58.237 --> 00:14:03.351
that'd be a much shorter and
better class is these algorithms are so

219
00:14:03.351 --> 00:14:08.128
fit for different problems that
you're gonna have to choose.

220
00:14:08.128 --> 00:14:11.099
They're definitely gonna
be time to n squared

221
00:14:11.099 --> 00:14:15.830
algorithm is gonna be way better
than a log(n) algorithm or n log(n).

222
00:14:15.830 --> 00:14:19.943
But anyway, things that are judged to be
better algorithms are not always better

223
00:14:19.943 --> 00:14:21.103
algorithms, right?

224
00:14:21.103 --> 00:14:25.618
And I'm gonna show you that kinda, again,
throughout the rest of the course.

225
00:14:25.618 --> 00:14:29.246
Frequently, you're not gonna
have a choice as well, right?

226
00:14:29.246 --> 00:14:32.207
Sometimes you just kinda have
to do something in a really

227
00:14:32.207 --> 00:14:35.360
inefficient way because you
wanna do inefficient things.

228
00:14:35.360 --> 00:14:39.539
And that's really what I want you to learn
today is how to make that trade off in

229
00:14:39.539 --> 00:14:40.197
your head.

230
00:14:40.197 --> 00:14:44.045
And we'll yeah, we'll be making lots of
examples, but I want you to continue to

231
00:14:44.045 --> 00:14:47.062
ask yourself that question
throughout the rest of the course.

232
00:14:47.062 --> 00:14:50.516
Cool, good question.

233
00:14:54.028 --> 00:14:58.611
All right, so let's talk about this one
here, function get middle of array.

234
00:14:58.611 --> 00:15:02.069
What do you think the time
complexity of that one's gonna be?

235
00:15:02.069 --> 00:15:04.181
&gt;&gt; O(1).

236
00:15:04.181 --> 00:15:05.607
&gt;&gt; There you go.

237
00:15:05.607 --> 00:15:10.531
So this is gonna be O(1),
you can see it's written like that here.

238
00:15:14.431 --> 00:15:17.580
So array, this can be a very large array.

239
00:15:17.580 --> 00:15:21.056
It could be of length a million,
it can be of length a billion, but

240
00:15:21.056 --> 00:15:23.017
there's no loop here in the middle,

241
00:15:23.017 --> 00:15:27.025
we're just gonna go find the middle
item in the array and then return that.

242
00:15:27.025 --> 00:15:29.046
So that's said to be O(1), or

243
00:15:29.046 --> 00:15:32.889
the way that you say that out
loud is its constant time, right?

244
00:15:32.889 --> 00:15:37.135
And I guess I should tell you
how to say the rest of these, so

245
00:15:37.135 --> 00:15:41.222
O(n) squared,
you would say this is quadratic time.

246
00:15:41.222 --> 00:15:46.099
You can also just say, O(n) squared, but
people will call that quadratic time.

247
00:15:46.099 --> 00:15:50.180
And then here Big O of n, again,
feel free to just say Big O of n,

248
00:15:50.180 --> 00:15:55.263
that's accurate and people say that,
but you can also call this linear time.

249
00:15:57.834 --> 00:16:03.667
I don't hardly ever say the word quadratic
time out loud, I don't know why,

250
00:16:03.667 --> 00:16:08.536
but I will say linear time, and
then I always say constant time.

251
00:16:08.536 --> 00:16:13.029
Basically, the question you need to
ask yourself to find out something's

252
00:16:13.029 --> 00:16:17.394
constant time or not is, does this
take more time if the array is longer?

253
00:16:17.394 --> 00:16:22.974
And in this case, no, it doesn't, so we're
just gonna say this is constant time.

254
00:16:26.548 --> 00:16:28.646
Okay, so
let's zoom out here just a second.

255
00:16:28.646 --> 00:16:33.206
I kinda tried to give you a little
bit of a graph of how this looks

256
00:16:33.206 --> 00:16:36.114
in terms of how many items in the array.

257
00:16:36.114 --> 00:16:40.994
And I swear, I think there's only
one more graph left in this course,

258
00:16:40.994 --> 00:16:43.238
there's not a lot more graphs.

259
00:16:43.238 --> 00:16:47.584
So if you have some PTSD
from school from graphs,

260
00:16:47.584 --> 00:16:51.942
like I do,
I swear there's not too many of them.

261
00:16:51.942 --> 00:16:57.230
But you can see here, this red line here,
this is gonna be what it represents.

262
00:16:57.230 --> 00:17:00.288
If I have eight items in the array,
is still gonna only take me,

263
00:17:00.288 --> 00:17:04.230
let's just say that it's one millisecond
to run this particular item, right?

264
00:17:04.230 --> 00:17:06.596
So no matter how many items in the array,

265
00:17:06.596 --> 00:17:10.435
it's a constant amount of time
it'll take to run the algorithm.

266
00:17:10.435 --> 00:17:11.124
This blue line,

267
00:17:11.124 --> 00:17:14.244
we could say this is linear time,
this is why it's called linear, right?

268
00:17:14.244 --> 00:17:17.250
Cuz it's literally just
a straight line that goes up.

269
00:17:17.250 --> 00:17:21.898
If I have six items in the array,
it takes a constant amount of time.

270
00:17:21.898 --> 00:17:26.395
So we're adding just a constant amount
over time depending on how many items

271
00:17:26.395 --> 00:17:27.456
are in the array.

272
00:17:27.456 --> 00:17:33.788
And this green one here, that's going up
and you can see it's going up faster and

273
00:17:33.788 --> 00:17:38.462
faster, that would be quadratic time or
Big O of n squared.

274
00:17:38.462 --> 00:17:44.721
Because the more items we add to
the array, it's gonna just take off and

275
00:17:44.721 --> 00:17:48.488
go, we add an exponential amount of time.

276
00:17:48.488 --> 00:17:51.417
Does that kinda make sense?

277
00:17:51.417 --> 00:17:57.675
As you might imagine,
if I put Big O of n cubed,

278
00:17:57.675 --> 00:18:05.873
that's just gonna be basically
a straight line up, right?

279
00:18:12.000 --> 00:18:14.868
All right, so
there's one I haven't talked about yet.

280
00:18:14.868 --> 00:18:19.488
We're gonna talk about it when we get
to recursion, and merge sort, and

281
00:18:19.488 --> 00:18:24.060
quick sort, it's this purple line here,
which is logarithmic time.

282
00:18:24.060 --> 00:18:28.008
And you can see here,
it does go up if we add more and

283
00:18:28.008 --> 00:18:33.465
more items into the array, but
it goes up at a very slow pace, right?

284
00:18:33.465 --> 00:18:38.965
So the difference between doing it with 10
items versus 100 items versus 1,000 items,

285
00:18:38.965 --> 00:18:43.675
it does take longer to do 1,000 items
versus 100 items, but not a lot more.

286
00:18:43.675 --> 00:18:44.657
And basically,

287
00:18:44.657 --> 00:18:48.877
we can use algorithms as kind of
shortcuts to cut out pieces of the work.

288
00:18:48.877 --> 00:18:52.426
And by doing that,
we kinda get an economy of scale, right?

289
00:18:52.426 --> 00:18:54.942
So if we add like 10,000 things,

290
00:18:54.942 --> 00:18:59.986
it still is able to go fairly fast because
we can do things in logarithmic time.

291
00:18:59.986 --> 00:19:04.941
And again, I just wanted to get that
kind of in front of you before we

292
00:19:04.941 --> 00:19:09.115
got to recursion, so
you can kind of see where that fit.

293
00:19:09.115 --> 00:19:13.809
But I'll explain logarithmic
Big O later in two sections, so

294
00:19:13.809 --> 00:19:16.346
just buckle up and wait for that.

295
00:19:17.769 --> 00:19:23.977
Okay, so
that is really a summary of what Big O is.

296
00:19:23.977 --> 00:19:28.128
I'm sure mathematicians would have about
two more hours that they'd like to talk to

297
00:19:28.128 --> 00:19:29.830
you about Big O, and I am not that.

298
00:19:29.830 --> 00:19:35.781
This is in as much as I ever use Big O,
which is, I'm trying to say here.

299
00:19:35.781 --> 00:19:39.891
I just gave you kind of a very surface
level overview of what I think is useful

300
00:19:39.891 --> 00:19:43.806
for a computer science, like a web
developer, to know about Big O, but

301
00:19:43.806 --> 00:19:45.326
there's a lot more there.

302
00:19:45.326 --> 00:19:47.770
So I'm not gonna claim that I've
taught you everything about Big O.

