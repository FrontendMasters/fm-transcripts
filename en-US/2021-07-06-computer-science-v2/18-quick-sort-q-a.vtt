WEBVTT

1
00:00:00.690 --> 00:00:03.002
I have a quick question
about an error that I

2
00:00:03.002 --> 00:00:03.720
cause
&gt;&gt; Sure.

3
00:00:04.900 --> 00:00:08.532
&gt;&gt; When I first made it,
I forgot to put the in for loop,

4
00:00:08.532 --> 00:00:11.650
the number dot length minus 1.

5
00:00:11.650 --> 00:00:14.410
And basically it seemed to
cause a stack overflow and

6
00:00:14.410 --> 00:00:18.000
I was wondering I was trying to
figure out why that would cause that.

7
00:00:18.000 --> 00:00:21.170
And I was wondering if you
could give me some idea.

8
00:00:21.170 --> 00:00:24.388
&gt;&gt; Sure, so he's saying he forgot
to put the minus 1 here and

9
00:00:24.388 --> 00:00:27.240
that was causing a stack overflow.

10
00:00:27.240 --> 00:00:29.080
&gt;&gt; That's it looks like, yeah.

11
00:00:29.080 --> 00:00:32.890
&gt;&gt; Because so it means you're inserting
your pivot into the left and right.

12
00:00:35.390 --> 00:00:37.393
It probably means that eventually,

13
00:00:37.393 --> 00:00:41.120
you're gonna run into an array
that's always of link 2, right?

14
00:00:41.120 --> 00:00:43.410
So it's going to keep calling that.

15
00:00:43.410 --> 00:00:47.470
Right array or left array, which is
never gonna hit that base case, right?

16
00:00:47.470 --> 00:00:49.320
Because it's never gonna hit link one,

17
00:00:49.320 --> 00:00:52.540
because those arrays have to get
progressively smaller and smaller.

18
00:00:55.270 --> 00:00:57.260
&gt;&gt; Okay, and why would it be stuck at 2?

19
00:00:58.740 --> 00:01:01.867
&gt;&gt; So
let me see if I can invent an example.

20
00:01:05.193 --> 00:01:09.652
I think if you did this where
your number is equal to

21
00:01:13.418 --> 00:01:18.268
1, let's do 9, 8, 7,

22
00:01:18.268 --> 00:01:22.125
so 7 would be the pivot

23
00:01:24.446 --> 00:01:27.910
And then it would try and
break this down and 7 would always get.

24
00:01:27.910 --> 00:01:32.285
So basically, this would just keep calling
recursively endlessly on 9 and 8, 9, 8, 7,

25
00:01:32.285 --> 00:01:34.543
assuming everything went
into the right array.

26
00:01:39.197 --> 00:01:41.410
Or 9 or so maybe this is better,

27
00:01:45.806 --> 00:01:47.702
Because everything would
always go into the left array.

28
00:01:51.233 --> 00:01:51.910
No, I had a right before okay.

29
00:01:53.010 --> 00:01:55.105
So seven Because this
is not equal to this or

30
00:01:55.105 --> 00:01:59.890
this is equal to this rather everything
would always get put into the right array.

31
00:01:59.890 --> 00:02:06.398
So then it would call quicksort on right
which would always endlessly be 9,8,7.

32
00:02:06.398 --> 00:02:12.348
&gt;&gt; Yeah I have chosen the question
from movement of especially convexity,

33
00:02:12.348 --> 00:02:17.126
and when we call quicksort,
left and quicksort, right,

34
00:02:17.126 --> 00:02:23.780
if we just our wide left and right array,
so we don't create a new one every time.

35
00:02:23.780 --> 00:02:27.858
So maybe it's whatever improve
the spatial complexity.

36
00:02:27.858 --> 00:02:32.462
&gt;&gt; Specifically here, he's asked,
I think you're asking me online set 37,

37
00:02:32.462 --> 00:02:36.800
38 instead of storing these variables,
what if we just overrode them?

38
00:02:38.050 --> 00:02:41.840
The amount that you would affects the
memory would be trivial to the point that

39
00:02:41.840 --> 00:02:43.790
I say it wouldn't matter.

40
00:02:43.790 --> 00:02:46.450
Because sort of left and sorted,
these are actually just gonna be pointers.

41
00:02:46.450 --> 00:02:49.636
They're actually not
gonna be full copies and

42
00:02:49.636 --> 00:02:54.220
pointers are the smallest thing
you can possibly store in memory.

43
00:02:55.520 --> 00:02:59.241
So that would be a optimization that
I don't think would really help you

44
00:02:59.241 --> 00:02:59.870
very much.

45
00:03:01.190 --> 00:03:01.928
Might help a little bit.

46
00:03:01.928 --> 00:03:08.520
But it's like grabbing a bucket
out of the ocean, right?

47
00:03:08.520 --> 00:03:15.102
It's gonna be such a small amount versus
the much bigger things that are going on.

48
00:03:15.102 --> 00:03:19.220
&gt;&gt; I tried to be smart and
use for off instead of for loop.

49
00:03:19.220 --> 00:03:21.050
And I had the same problem
essentially right?

50
00:03:21.050 --> 00:03:23.950
I wasn't removing pivot and
I were just stuck.

51
00:03:23.950 --> 00:03:26.838
&gt;&gt; Yep, so
he's saying instead of using a for

52
00:03:26.838 --> 00:03:31.585
loop he used like the functional like for
each or something like that.

53
00:03:31.585 --> 00:03:32.694
&gt;&gt; For off.

54
00:03:32.694 --> 00:03:36.314
&gt;&gt; For off loop yeah, so a for

55
00:03:36.314 --> 00:03:40.922
off loop here which looks like for

56
00:03:40.922 --> 00:03:46.200
lead item of numbers like this right?

57
00:03:47.930 --> 00:03:51.861
The unfortunate thing about this is, it's
always going to capture the last item in

58
00:03:51.861 --> 00:03:55.343
the array, which means your pivot is
gonna be put into your left or right,

59
00:03:55.343 --> 00:03:59.069
which means that you're gonna probably
end up in a stack overflow situation.

60
00:04:00.870 --> 00:04:05.060
So a lot of just normal for loops.

61
00:04:05.060 --> 00:04:07.948
I know they're not the most
appealing looking piece of code, but

62
00:04:07.948 --> 00:04:09.220
they are extremely useful.

63
00:04:11.750 --> 00:04:17.090
&gt;&gt; Poke the pivots and
use the for off without problem.

64
00:04:17.090 --> 00:04:24.240
&gt;&gt; Yep, so you could absolutely just say,
pivot equals instead of doing this,

65
00:04:24.240 --> 00:04:29.080
he would say const pivot
equals nums dot pop right and

66
00:04:29.080 --> 00:04:34.910
this would actually remove the pivot
from the from the array and

67
00:04:34.910 --> 00:04:39.520
then you could absolutely do a for
of loop here.

68
00:04:39.520 --> 00:04:40.036
That would work great.

69
00:04:44.765 --> 00:04:46.166
Many ways to skin this cat.

70
00:04:50.182 --> 00:04:56.910
&gt;&gt; Can you please walk us through
the time complexity of this code?

71
00:04:58.300 --> 00:05:04.230
&gt;&gt; Yeah, so the time complexity of this
is average case scenario and login.

72
00:05:06.550 --> 00:05:09.310
So let's look down here a unit test case.

73
00:05:10.500 --> 00:05:13.871
So here,
we're gonna put 5 as the pivot and

74
00:05:13.871 --> 00:05:18.795
then, 10,8,6,9,7 are gonna
go on the right array and

75
00:05:18.795 --> 00:05:22.735
then everything else is
gonna go on the left array.

76
00:05:22.735 --> 00:05:26.270
So this is to say every item is going
to be looked at the at least once,

77
00:05:26.270 --> 00:05:29.810
right because we're splitting
it into different pieces.

78
00:05:29.810 --> 00:05:32.220
So let's just say that there's at least n.

79
00:05:32.220 --> 00:05:34.976
So that's where the n part of this is
because we're gonna look at everything at

80
00:05:34.976 --> 00:05:37.210
least once and make comparisons
at least once for everything.

81
00:05:38.250 --> 00:05:41.898
However, when we're doing the yeah, so

82
00:05:41.898 --> 00:05:45.964
when we're putting 7
into the right array and

83
00:05:45.964 --> 00:05:49.925
we're putting 4 into the left array, 4 and

84
00:05:49.925 --> 00:05:55.370
7 are actually never going to
be compared to each other ever.

85
00:05:56.410 --> 00:06:00.269
We're doing this by virtue of the fact
that if we know something is smaller than

86
00:06:00.269 --> 00:06:03.160
4 and we know something is larger than 5,
right?

87
00:06:03.160 --> 00:06:05.946
That means that we can make
the fundamental assumption using

88
00:06:05.946 --> 00:06:07.210
the transitive property.

89
00:06:07.210 --> 00:06:09.250
And I don't know I did air quotes there.

90
00:06:09.250 --> 00:06:12.630
It's literally called the transitive
property in mathematics.

91
00:06:12.630 --> 00:06:16.080
4 must be smaller than 7, right?

92
00:06:16.080 --> 00:06:19.080
So we can use that property of
mathematics to say like cool.

93
00:06:19.080 --> 00:06:22.751
4 and 7 never have to be compared to each
other because I already compare them both

94
00:06:22.751 --> 00:06:24.070
to 5, right?

95
00:06:24.070 --> 00:06:28.370
So that means that we're going to
get these like economies of scale.

96
00:06:28.370 --> 00:06:30.908
So if we do a huge
quicksort on a huge array,

97
00:06:30.908 --> 00:06:35.212
that means that there's a bunch of
comparisons that we never have to do,

98
00:06:35.212 --> 00:06:39.868
as opposed to something like insertion
sort, which where everything has to be

99
00:06:39.868 --> 00:06:44.620
compared against everything else every
single time an average case scenario.

100
00:06:45.870 --> 00:06:48.737
That's why that one ends up
being n squared and this one,

101
00:06:48.737 --> 00:06:52.981
it's average case scenario ends up being n
log n because normally they don't have to

102
00:06:52.981 --> 00:06:56.110
be compared to each other because
we can look at those pivots.

103
00:06:57.340 --> 00:06:59.100
So that's why it ends up as n log n.

104
00:07:00.750 --> 00:07:03.830
&gt;&gt; Yeah, but
there's something I'm struggling with.

105
00:07:04.900 --> 00:07:09.820
How could I get to the login
part from the code?

106
00:07:09.820 --> 00:07:16.180
So I guess maybe mathematically,
help me understand it better.

107
00:07:16.180 --> 00:07:20.974
But yeah, I understand that
it's because it's a divide and

108
00:07:20.974 --> 00:07:25.204
conquer algorithm is getting smaller and
smaller and

109
00:07:25.204 --> 00:07:30.186
we're working with the smaller lists but
getting to that login

110
00:07:30.186 --> 00:07:35.980
just by looking at the code i.e,
I'm struggling with that.

111
00:07:35.980 --> 00:07:41.030
&gt;&gt; Unfortunately there's no and hopefully
answering your question that you have.

112
00:07:42.140 --> 00:07:45.504
Like you there's no hack here for
us to look at and say,

113
00:07:45.504 --> 00:07:48.943
we have nested for loops,
therefore we have n squared,

114
00:07:48.943 --> 00:07:53.650
right, unfortunately, there's not
really a good way of doing that here.

115
00:07:54.970 --> 00:08:00.710
The best indication that you have this is
gonna be log in is that it's recursive.

116
00:08:00.710 --> 00:08:06.390
But still that's that's an indication it's
indicates to you that it might be login.

117
00:08:06.390 --> 00:08:11.206
But it's not necessarily like we saw,
for example that count two or

118
00:08:11.206 --> 00:08:15.950
factorial for example, those are not,
those are just n, right?

119
00:08:15.950 --> 00:08:16.710
They're not login.

120
00:08:20.040 --> 00:08:24.763
So the way that you have to conceptualize
in your head to figure out what the login

121
00:08:24.763 --> 00:08:27.794
is, is that just what I was
telling you before those

122
00:08:27.794 --> 00:08:32.660
diminishing the more items I throw out
this, the less comparisons that it adds.

123
00:08:32.660 --> 00:08:35.700
As we add more we get those
kind of economies of scale.

124
00:08:35.700 --> 00:08:39.662
Once you kind of realize that like you're
using these kind of transitive properties

125
00:08:39.662 --> 00:08:43.566
to avoid making some of the comparisons,
that's where it's gonna say like okay,

126
00:08:43.566 --> 00:08:47.584
this is definitely login right that's the
indication that's the proof that you need

127
00:08:47.584 --> 00:08:50.481
in your head for you to say this
is login because I don't have to

128
00:08:50.481 --> 00:08:52.490
compare everything to everything else.

129
00:08:54.190 --> 00:08:58.990
I don't really know if I have
a more succinct answer than that.

130
00:08:58.990 --> 00:09:02.695
Yeah, it, it's hard [LAUGH] And
like even when I'm sitting there,

131
00:09:02.695 --> 00:09:05.360
like I've messed this up
in interviews as well,

132
00:09:05.360 --> 00:09:09.700
I remember specifically that I messed
this up in a Facebook interview.

133
00:09:09.700 --> 00:09:15.650
So it's not apparent and
it's pretty difficult, right?

134
00:09:15.650 --> 00:09:18.009
Which is probably why they choose
to ask you these questions.

135
00:09:19.530 --> 00:09:24.174
&gt;&gt; Assuming we have some
data set that we know,

136
00:09:24.174 --> 00:09:28.067
a statistical distribution about,

137
00:09:28.067 --> 00:09:34.740
does it make sense to choose
a pivot with outside the data sets?

138
00:09:34.740 --> 00:09:38.946
Like okay, I these are student grades and

139
00:09:38.946 --> 00:09:44.353
I know the they are in
the range of 4200 usually and

140
00:09:44.353 --> 00:09:47.597
the mean value is about 70, so

141
00:09:47.597 --> 00:09:53.180
I can start with 70 without
actually including it.

142
00:09:53.180 --> 00:09:57.523
Just for the first iteration,
does it make sense?

143
00:09:57.523 --> 00:10:01.684
&gt;&gt; So the question is if you have some
knowledge of the distribution and

144
00:10:01.684 --> 00:10:06.356
the average and the median, perhaps,
maybe the medians rather than most,

145
00:10:06.356 --> 00:10:10.890
actually, it's definitely
the most useful thing there.

146
00:10:10.890 --> 00:10:15.763
Would you be better off selecting
something that you know to be a good pivot

147
00:10:15.763 --> 00:10:18.760
that might be outside
of the normal data set.

148
00:10:25.367 --> 00:10:30.010
I guess, yeah,
I can see that definitely being helpful.

149
00:10:30.010 --> 00:10:31.815
And just not including the pivot, right,

150
00:10:31.815 --> 00:10:34.470
cuz the pivot wouldn't be
actually in the data set.

151
00:10:34.470 --> 00:10:37.070
That's only gonna help you for
the first pivot though, right?

152
00:10:38.280 --> 00:10:41.271
And the disadvantage that
we're gonna have here is,

153
00:10:41.271 --> 00:10:45.656
now we have to have a specialized case
that the first level of recursion is gonna

154
00:10:45.656 --> 00:10:48.990
be different than every other
level of recursion, right?

155
00:10:48.990 --> 00:10:52.834
Because at that point, once we go down
into the lower level of recursion,

156
00:10:52.834 --> 00:10:55.630
all bets are off,
we can't use the same pivot again.

157
00:10:57.810 --> 00:11:03.130
&gt;&gt; I was thinking like since we
are already iterating over everything

158
00:11:03.130 --> 00:11:08.070
in the first pass,
maybe while we're sorting it into left and

159
00:11:08.070 --> 00:11:14.260
right parts we could be Just taking
a running average or something like that?

160
00:11:16.740 --> 00:11:18.820
&gt;&gt; So,
&gt;&gt; For the next pivot,

161
00:11:18.820 --> 00:11:21.688
I mean
&gt;&gt; The issue with like, you could always

162
00:11:21.688 --> 00:11:26.840
like, you could write a piece of code to
always select the perfect pivot, right?

163
00:11:26.840 --> 00:11:32.132
But then when you're looking at every
item in the array every single time,

164
00:11:32.132 --> 00:11:34.910
which greatly adds to the complexity.

165
00:11:34.910 --> 00:11:40.186
[LAUGH] So that that in and of itself,
always looking for the perfect pivot,

166
00:11:40.186 --> 00:11:46.210
you're actually ruining what makes
this algorithm efficient at all right?

167
00:11:46.210 --> 00:11:48.740
Which is the fact that you don't have to
look at every item every single time.

168
00:11:50.460 --> 00:11:58.580
In the sense of, yeah, that you would
have to first find the perfect pivot.

169
00:12:01.860 --> 00:12:04.198
Yeah, and then that would kind
of ruin the fact that you,

170
00:12:04.198 --> 00:12:07.395
you had to search through at once to find
the median, pivot and then split it.

171
00:12:10.072 --> 00:12:14.791
I think the thing that points to after
that is like there are more efficient

172
00:12:14.791 --> 00:12:16.780
ways of selecting that pivot.

173
00:12:17.860 --> 00:12:19.560
The one that I'm familiar
again is Quicksort.

174
00:12:19.560 --> 00:12:22.810
Three, we look at the first item,
the middle item and the last item.

175
00:12:22.810 --> 00:12:27.523
And that that mostly solves almost all of
the distribution problems that you'd run

176
00:12:27.523 --> 00:12:31.696
into And that's kind of the one that
people tend to favorite because one,

177
00:12:31.696 --> 00:12:35.127
it's fairly simple and
easy to understand and to it it like,

178
00:12:35.127 --> 00:12:37.920
prevents you from having
worst case scenarios.

179
00:12:40.070 --> 00:12:43.288
But there are some other ways of selecting
that pivot that I'm actually not familiar

180
00:12:43.288 --> 00:12:45.330
with submit one of them might do that.

181
00:12:45.330 --> 00:12:50.607
I just can't conceptualize
a pyramid off the top, my head.

182
00:12:50.607 --> 00:12:56.030
&gt;&gt; So very simple sample just
source 80% of the problem maybe.

183
00:12:56.030 --> 00:13:00.178
&gt;&gt; Yeah, you could still have
the problem where you were always

184
00:13:00.178 --> 00:13:03.269
selecting the top three
items in the array But

185
00:13:03.269 --> 00:13:07.676
the statistical probability of
that is not very large, right?

186
00:13:11.432 --> 00:13:13.258
Cuz if you're always
selecting the bottom three or

187
00:13:13.258 --> 00:13:15.944
the top three items in the array you
still run into the worst case scenario.

188
00:13:19.246 --> 00:13:23.980
Which is not great, but the fact that
you go from doing that frequently

189
00:13:23.980 --> 00:13:28.314
with just one pivot to almost never
if you select three pivots and

190
00:13:28.314 --> 00:13:30.260
then choose the median one.

191
00:13:31.570 --> 00:13:34.890
&gt;&gt; It's kind of complicated
depending on data set.

192
00:13:34.890 --> 00:13:39.080
Maybe there are some
specific cases where just

193
00:13:39.080 --> 00:13:43.060
the guessing a good
pivot would make sense.

194
00:13:43.060 --> 00:13:48.360
But I think what you say covers so
much ground just by itself.

195
00:13:48.360 --> 00:13:53.970
That's what I said, it probably
becomes unnecessary in most cases?

196
00:13:53.970 --> 00:13:57.722
&gt;&gt; Well, and I think another thing that
you might be thinking, you should think

197
00:13:57.722 --> 00:14:01.705
about is if you have that much knowledge
about what your dataset is gonna look for,

198
00:14:01.705 --> 00:14:03.321
or is what it's gonna look like,

199
00:14:03.321 --> 00:14:06.580
quicksorts' probably not the best
choice at that point, right?

200
00:14:06.580 --> 00:14:09.419
It might be like something insertion sort,
cuz if it's already nearly sorted,

201
00:14:09.419 --> 00:14:10.860
then insertion sort is gonna be better.

202
00:14:10.860 --> 00:14:15.404
And if you already know the median,
I guess if you know the median and

203
00:14:15.404 --> 00:14:18.315
you know it's totally shuffled, maybe.

204
00:14:18.315 --> 00:14:19.778
[LAUGH]
&gt;&gt; I mean,

205
00:14:19.778 --> 00:14:21.920
student grades are a good example.

206
00:14:21.920 --> 00:14:27.090
You know the distribution, but
they may come in any order.

207
00:14:27.090 --> 00:14:28.198
&gt;&gt; But at that point,

208
00:14:28.198 --> 00:14:32.370
if it's gonna come in any order
quicksort is already very good at that.

209
00:14:35.080 --> 00:14:38.460
And having the perfect pivot doesn't make
it a whole lot more effective, right?

210
00:14:38.460 --> 00:14:39.500
As long as it's an okay pivot.

211
00:14:39.500 --> 00:14:40.860
It usually works pretty well.

