WEBVTT

1
00:00:00.370 --> 00:00:02.779
&gt;&gt; Bianca Gandolfo: So
we talked about pseudo classical and

2
00:00:02.779 --> 00:00:07.600
instantiation pattern, which we'll
be using, mostly starting tomorrow.

3
00:00:07.600 --> 00:00:10.420
Today we won't be using it, but
I wanna do a quick refresher.

4
00:00:10.420 --> 00:00:16.940
What were the main components of making
a class in JavaScript using that pattern?

5
00:00:19.660 --> 00:00:22.030
&gt;&gt; Speaker 2: We have a function
that's the constructor.

6
00:00:22.030 --> 00:00:25.260
And that has the properties, and
then you have the prototype.

7
00:00:27.780 --> 00:00:29.360
Is that what you call it,
or is there another name?

8
00:00:29.360 --> 00:00:30.370
&gt;&gt; Bianca Gandolfo: Yeah,
it's a prototype object.

9
00:00:30.370 --> 00:00:32.710
&gt;&gt; Speaker 2: Yeah, and
then you have the methods on that.

10
00:00:32.710 --> 00:00:35.690
&gt;&gt; Bianca Gandolfo: Cool, yeah,
exactly, so those are the three parts.

11
00:00:35.690 --> 00:00:39.620
The first part is
the constructor function,

12
00:00:39.620 --> 00:00:41.920
then inside of that you
define the properties.

13
00:00:41.920 --> 00:00:46.070
You put that on this keyword,
this .blah blah blah.

14
00:00:46.070 --> 00:00:48.740
In our example,
we said this.floors yesterday.

15
00:00:49.810 --> 00:00:53.547
And then for the third part, is our
methods that we want to have shared over

16
00:00:53.547 --> 00:00:57.580
all the instances and
we put that in on the prototype object.

17
00:00:57.580 --> 00:01:00.599
Yeah, cool,
any questions about how all that works?

18
00:01:01.840 --> 00:01:06.494
We use the keyword new in
there whenever we want to

19
00:01:06.494 --> 00:01:10.710
instantiate an instance of our class.

20
00:01:10.710 --> 00:01:12.282
Yeah, questions?

21
00:01:14.029 --> 00:01:16.895
&gt;&gt; Bianca Gandolfo: Cool, what were some
different recursion patterns that we

22
00:01:16.895 --> 00:01:18.168
talked about yesterday?

23
00:01:24.595 --> 00:01:28.230
&gt;&gt; Bianca Gandolfo: There are two
main ones that we kinda pointed out.

24
00:01:28.230 --> 00:01:31.310
&gt;&gt; Speaker 2: One was a wrapper that you
actually had the recursive function inside

25
00:01:31.310 --> 00:01:36.120
another function, and then you could
store state within the wrapper.

26
00:01:36.120 --> 00:01:37.270
&gt;&gt; Bianca Gandolfo: Yep,
we have a wrapper,

27
00:01:37.270 --> 00:01:40.400
where we have just the recursive function
that lives inside of another function.

28
00:01:40.400 --> 00:01:45.695
And we're saving into a variable
outside of our function, absolutely.

29
00:01:45.695 --> 00:01:48.237
What's another pattern, and
these aren't the only patterns,

30
00:01:48.237 --> 00:01:50.279
there's lots of different
patterns in recursion.

31
00:01:51.721 --> 00:01:55.147
&gt;&gt; Bianca Gandolfo: There was another
pattern where we were passing

32
00:01:55.147 --> 00:01:59.350
our data through every time
we call a recursive function?

33
00:02:00.710 --> 00:02:04.090
Cool, and
then from the chat we have signs or

34
00:02:04.090 --> 00:02:07.150
tips on when to use
recursion versus loops.

35
00:02:07.150 --> 00:02:08.860
That's a great question,

36
00:02:08.860 --> 00:02:12.700
we are gonna get into that a little bit
more starting tomorrow when we do trees.

37
00:02:12.700 --> 00:02:16.980
But the idea is you can always
use a loop for recursion,

38
00:02:16.980 --> 00:02:22.380
it just gets a little more complicated
when you get into nested data structures.

39
00:02:22.380 --> 00:02:25.520
And so that's when it really
becomes valuable to use recursion.

40
00:02:25.520 --> 00:02:30.980
It simplifies sort of
complicated operations or

41
00:02:30.980 --> 00:02:36.520
procedures for nested things that you
don't know how nested it will be, right.

42
00:02:36.520 --> 00:02:40.570
So if we know how nested an array is,

43
00:02:40.570 --> 00:02:44.930
for example, like say we have an array and
inside that there's three more arrays, and

44
00:02:44.930 --> 00:02:49.670
inside of that there's three more arrays,
so you have a triply-nested array.

45
00:02:49.670 --> 00:02:53.950
We know that we can use three loops,
and that's fine, but what if,

46
00:02:53.950 --> 00:02:58.590
for the case where our arrays are nested,
who knows how many times.

47
00:02:58.590 --> 00:03:00.730
It could be different for each case.

48
00:03:00.730 --> 00:03:05.050
In those cases, that's the classic
recursion use case in JavaScript.

49
00:03:08.490 --> 00:03:11.440
Cool, recursions are expensive,
they are slow.

50
00:03:11.440 --> 00:03:13.429
True, so is looping.

51
00:03:16.236 --> 00:03:19.570
&gt;&gt; Bianca Gandolfo: Great,
anything else before we move on?

52
00:03:20.930 --> 00:03:24.000
Great, so today is day one.

53
00:03:24.000 --> 00:03:27.960
Like I was saying, yesterday was kind
of a pre-req day and today we will be

54
00:03:27.960 --> 00:03:34.010
introducing a lot of new things that
is gonna build on top of yesterday.

55
00:03:34.010 --> 00:03:38.920
Mostly, what we'll be working on today
is the recursion at the end of the day.

56
00:03:38.920 --> 00:03:41.520
But we'll start off a little bit slow,
like I was saying yesterday.

57
00:03:41.520 --> 00:03:45.500
We'll start off slow with some elementary
sorting, talking about time complexity,

58
00:03:45.500 --> 00:03:47.240
how do you calculate that.

59
00:03:47.240 --> 00:03:52.090
And then we'll do some recursive sorting
algorithms that are really fun, cool.

60
00:03:53.430 --> 00:03:59.810
Awesome, so you can come here
to slides.com/bgando/femasters,

61
00:03:59.810 --> 00:04:02.440
this is our syllabus.

62
00:04:02.440 --> 00:04:08.702
So you just scroll down to Sorting,
and you can follow me to the slides.

63
00:04:13.049 --> 00:04:15.533
&gt;&gt; Bianca Gandolfo: Great.

64
00:04:18.920 --> 00:04:20.454
&gt;&gt; Bianca Gandolfo: Let me
know when everyone's there.

65
00:04:30.252 --> 00:04:31.640
&gt;&gt; Bianca Gandolfo: Are we there?

66
00:04:31.640 --> 00:04:32.490
Thumbs?

67
00:04:32.490 --> 00:04:33.770
Awesome.

68
00:04:33.770 --> 00:04:38.240
So, the first thing I want to
talk about is speed of algorithm.

69
00:04:38.240 --> 00:04:40.451
So, we did a lot of different
things yesterday, and

70
00:04:40.451 --> 00:04:44.082
you all brought up
&gt;&gt; Bianca Gandolfo: The question is,

71
00:04:44.082 --> 00:04:48.600
what is the better way,
what is an optimized version of this?

72
00:04:48.600 --> 00:04:51.330
And I said, wait,
we don't know how to talk about that yet,

73
00:04:51.330 --> 00:04:55.710
we don't have the vocabulary and
method to calculate that quite yet.

74
00:04:55.710 --> 00:04:58.430
Some of us might, but
we haven't talked about it yet.

75
00:04:58.430 --> 00:05:02.460
Does anyone here use big
O notation previously?

76
00:05:03.510 --> 00:05:05.140
A couple of people, awesome.

77
00:05:05.140 --> 00:05:06.690
So that's what we're
gonna talk about today.

78
00:05:06.690 --> 00:05:09.470
There are other notations,
but we won't get into them,

79
00:05:09.470 --> 00:05:13.790
but I have some resources where
you can look into it after.

80
00:05:13.790 --> 00:05:20.810
Cool, so time complexity, or
what is the runtime of this algorithm?

81
00:05:20.810 --> 00:05:22.810
Is this algorithm fast, is it slow?

82
00:05:22.810 --> 00:05:25.220
How do we answer those questions?

83
00:05:25.220 --> 00:05:26.780
That's what we're gonna learn today.

84
00:05:26.780 --> 00:05:29.320
So there's a couple things,
there's space complexity.

85
00:05:30.770 --> 00:05:33.920
How much space is it gonna take up?

86
00:05:35.010 --> 00:05:37.290
How much memory is used then
we have time complexity.

87
00:05:37.290 --> 00:05:40.880
We can kind of ask these questions like,
how many comparisons are made?

88
00:05:40.880 --> 00:05:41.990
How many swaps are made?

89
00:05:41.990 --> 00:05:45.490
This is particularly related to our

90
00:05:45.490 --> 00:05:47.570
sorting algorithms that we're
going to get into later.

91
00:05:47.570 --> 00:05:53.650
There are other questions that you have to
ask as well, depending on the operation.

92
00:05:53.650 --> 00:05:57.080
Basically, it's like how many
operations do you have to do?

93
00:05:57.080 --> 00:05:59.790
More as your data grows, right.

94
00:06:02.450 --> 00:06:06.000
You know, we're posed with this problem as
computer scientists of how do we measure

95
00:06:06.000 --> 00:06:10.020
speed of an algorithm when there's so
many factors that make it different.

96
00:06:10.020 --> 00:06:13.870
We can't say, this algorithm is five,
you know, it runs in five seconds,

97
00:06:13.870 --> 00:06:16.040
when the data set is this big.

98
00:06:16.040 --> 00:06:19.480
There's different factors,
there's a computer, you know,

99
00:06:19.480 --> 00:06:22.500
there's like the compiler, there's
the language itself, and the environment.

100
00:06:22.500 --> 00:06:25.610
So all of these different
factors will change the actual

101
00:06:26.940 --> 00:06:29.080
time in which it is computed.

102
00:06:29.080 --> 00:06:33.860
And so that's why we have time complexity
notation, which is a relative speed.

103
00:06:34.940 --> 00:06:40.450
So as your data set grows, how much more
work does your algorithm have to do?

104
00:06:40.450 --> 00:06:44.150
How many more operations, and
that's gonna define the speed.

105
00:06:46.200 --> 00:06:47.310
Cool, any questions about that?

106
00:06:48.540 --> 00:06:51.070
Awesome, cool.

107
00:06:51.070 --> 00:06:52.530
So with respect to input size,

108
00:06:52.530 --> 00:06:54.780
and we're always gonna assume
the worst case scenario.

