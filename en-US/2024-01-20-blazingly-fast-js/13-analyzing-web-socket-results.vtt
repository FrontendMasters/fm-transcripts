WEBVTT

1
00:00:00.140 --> 00:00:03.737
So we have our little state map because
again, before we get the WebSockets passed

2
00:00:03.737 --> 00:00:06.830
in, we've used those we've listened
to those in this new paradigm.

3
00:00:06.830 --> 00:00:10.230
We no longer do that, so we kind of have
to make some basic changes to our program.

4
00:00:11.270 --> 00:00:18.130
Let's click this, export,
I can type on close.

5
00:00:18.130 --> 00:00:19.270
We're gonna have a web socket.

6
00:00:19.270 --> 00:00:20.827
I'm gonna call this thing a WS.

7
00:00:20.827 --> 00:00:25.266
Cuz right now we don't really have it
defined, and I'm gonna define WS as

8
00:00:25.266 --> 00:00:29.346
something with ascend that has
a string that returns void, right,

9
00:00:29.346 --> 00:00:31.127
I believe I have to do that.

10
00:00:31.127 --> 00:00:33.067
There we go.
So there we go.

11
00:00:33.067 --> 00:00:36.167
We're gonna keep our web sock
definition super simple at this point.

12
00:00:36.167 --> 00:00:37.863
Also, if you do these kind of things,

13
00:00:37.863 --> 00:00:41.794
sometimes it can make testing really easy
if you wish do that level of testing.

14
00:00:41.794 --> 00:00:44.660
I'd be a little skeptical if you're
doing that level of testing, but

15
00:00:44.660 --> 00:00:46.182
it can make things pretty dang easy.

16
00:00:46.182 --> 00:00:47.674
All right, awesome.

17
00:00:47.674 --> 00:00:50.234
So on close, thank you, Copilot.

18
00:00:50.234 --> 00:00:52.894
I'm gonna get the state.

19
00:00:54.344 --> 00:00:58.214
If this thing happens to exist,
we'll say, hey, this thing's been closed.

20
00:00:58.214 --> 00:01:00.179
Awesome, very, very easy.

21
00:01:00.179 --> 00:01:01.349
Let's see,
what's the other thing we need to do?

22
00:01:01.349 --> 00:01:02.299
We need to do on message.

23
00:01:02.299 --> 00:01:04.989
I believe I actually already have
an on message like function down here.

24
00:01:04.989 --> 00:01:07.379
So I'm gonna just bring that
on message function up here.

25
00:01:07.379 --> 00:01:08.579
We're gonna export it.

26
00:01:08.579 --> 00:01:10.922
We're gonna delete the inside and

27
00:01:10.922 --> 00:01:16.119
we're gonna have a web socket
that's a WS and a string message.

28
00:01:16.119 --> 00:01:18.049
Looks good, yeah, that looks good.

29
00:01:18.049 --> 00:01:20.854
And so we'll grab out the state.

30
00:01:20.854 --> 00:01:22.925
If there is no state,
so for whatever reason,

31
00:01:22.925 --> 00:01:26.006
we got a message from something in
which we're not keeping track of,

32
00:01:26.006 --> 00:01:29.124
which should never happen, but
if this did happen, I'll return.

33
00:01:29.124 --> 00:01:31.240
I mean, I could process,
got a board, we could dump,

34
00:01:31.240 --> 00:01:34.824
we could do something different, but we'll
just assume that this is good enough.

35
00:01:34.824 --> 00:01:37.520
There we go.
We have an on-message function that works

36
00:01:37.520 --> 00:01:42.196
based on a WebSocket, we have on clothes
based on WebSocket, you're probably going,

37
00:01:42.196 --> 00:01:46.114
hey, didn't we just fix a performance
problem by switching from array or

38
00:01:46.114 --> 00:01:47.211
from sets to array.

39
00:01:47.211 --> 00:01:48.351
Why are we using sets now?

40
00:01:48.351 --> 00:01:52.738
I would say this is probably a fine time
to use sets if we've made a good bargain,

41
00:01:52.738 --> 00:01:57.390
meaning that we have great performance win
on WebSockets for a small performance hit

42
00:01:57.390 --> 00:02:00.994
on having to do this lookup every
single message slash unclosed,

43
00:02:00.994 --> 00:02:02.634
find trade-off for me.

44
00:02:02.634 --> 00:02:04.674
I'd say that this is
a perfectly fine trade-off.

45
00:02:04.674 --> 00:02:06.736
All right, now that we've done that,
we're gonna have to go down here and

46
00:02:06.736 --> 00:02:07.304
round the fixes.

47
00:02:07.304 --> 00:02:09.954
First off, get out of here,
we don't need that.

48
00:02:09.954 --> 00:02:11.524
Next off, do we need any of this?

49
00:02:11.524 --> 00:02:12.934
No, we don't, we don't need that.

50
00:02:12.934 --> 00:02:20.041
We just simply need to go ws2state,
set websocket 1, 2 state 1.

51
00:02:20.041 --> 00:02:22.361
And then copilot will probably
do the other one for me.

52
00:02:22.361 --> 00:02:25.411
Set web socket 2 to state 2.

53
00:02:25.411 --> 00:02:28.031
Change these to something that
just has the send method, right?

54
00:02:28.031 --> 00:02:30.891
We're not being very prescriptive
here on the web socket anymore.

55
00:02:30.891 --> 00:02:31.611
Awesome.

56
00:02:31.611 --> 00:02:33.441
So this looks pretty good to me.

57
00:02:33.441 --> 00:02:36.451
We have all the mappings and
then we have to do one more thing,

58
00:02:36.451 --> 00:02:40.596
which is at the end of our game, we can't
forget to delete this things out, right.

59
00:02:40.596 --> 00:02:45.185
So I'm gonna delete out.

60
00:02:45.185 --> 00:02:47.943
There we go,
we'll delete out player one, player two,

61
00:02:47.943 --> 00:02:51.637
make sure our map isn't just
growing too big, awesome.

62
00:02:51.637 --> 00:02:55.527
And then finally, take our game runner,
turn that to that, and

63
00:02:55.527 --> 00:02:58.787
I'm pretty sure that is everything.

64
00:02:58.787 --> 00:03:00.598
Let's see, we have no more diagnostics.

65
00:03:00.598 --> 00:03:02.458
I think we're gonna do this first try.

66
00:03:02.458 --> 00:03:05.128
So there we go.
So we've made that pretty simple update.

67
00:03:05.128 --> 00:03:08.728
I've updated our actual server
to be using something like this.

68
00:03:08.728 --> 00:03:13.108
And we are now updating our actual game
to be using this different kind of look.

69
00:03:13.108 --> 00:03:17.808
So all I have to do here is obviously
import these two from game.

70
00:03:19.446 --> 00:03:24.126
Fantastic, feeling pretty
excited about this.

71
00:03:24.126 --> 00:03:27.217
If you can't keep up again, the point
is that I want to actually spend as

72
00:03:27.217 --> 00:03:30.770
little time on the code as possible, cuz I
think that this is the most boring part of

73
00:03:30.770 --> 00:03:32.856
the entire presentation, is the code.

74
00:03:32.856 --> 00:03:35.336
The exciting part is how did
we come to these conclusions?

75
00:03:35.336 --> 00:03:38.426
And again, if you forgot,
the conclusion really was memory.

76
00:03:38.426 --> 00:03:40.775
And I saw some in the performance and

77
00:03:40.775 --> 00:03:45.798
the gut intuition that JavaScript is
just never gonna be as fast as C+++.

78
00:03:45.798 --> 00:03:48.671
We can process this out
of band of JavaScript.

79
00:03:48.671 --> 00:03:49.991
So that's very exciting.

80
00:03:49.991 --> 00:03:54.923
All right, so now that we've done that,
I'll do a little, make sure that we don't,

81
00:03:54.923 --> 00:03:59.358
okay, I did accidentally have
that other server still running.

82
00:03:59.358 --> 00:04:01.808
Somewhere around there,
so we'll go npm run test.

83
00:04:02.958 --> 00:04:04.678
We'll make sure I haven't
broken the program.

84
00:04:04.678 --> 00:04:08.198
If I broke the program, that's genuinely
too bad because it's just like.

85
00:04:09.598 --> 00:04:11.765
Look at that, it's working, let's go.

86
00:04:11.765 --> 00:04:15.165
All right, so this should all work out
just fine, we shouldn't have any problems.

87
00:04:15.165 --> 00:04:19.064
I'll wait it out just to really make sure,
that way you all believe me.

88
00:04:20.275 --> 00:04:24.105
So the WS package, for those that don't
know, the WS package is fully JavaScript.

89
00:04:24.105 --> 00:04:27.469
It uses full internals of node and
everything,

90
00:04:27.469 --> 00:04:33.021
whereas UWeb sockets is gonna be fully
C++ and only having the JavaScript for

91
00:04:33.021 --> 00:04:36.915
handing out frames,
which to me is as good as it gets.

92
00:04:36.915 --> 00:04:37.905
I'm happy about that.

93
00:04:37.905 --> 00:04:40.137
All right, so
we know that our integration tests work.

94
00:04:40.137 --> 00:04:42.087
We know that our little tests work.

95
00:04:42.087 --> 00:04:43.687
We are now using WebSockets.

96
00:04:43.687 --> 00:04:45.467
We no longer have a bunch of promises.

97
00:04:45.467 --> 00:04:49.027
So let's see if this
UWebSocket runs better.

98
00:04:49.027 --> 00:04:52.481
So I'm gonna do the exact same
thing that I have been doing, but

99
00:04:52.481 --> 00:04:55.707
it might be a little bit more
fun to start off first with.

100
00:04:55.707 --> 00:04:59.307
Let's just check the memory charts and
see, do we make a difference there?

101
00:04:59.307 --> 00:05:01.133
Let's just I wanna just
kind of look a little bit,

102
00:05:01.133 --> 00:05:02.749
see if we've done anything there.

103
00:05:02.749 --> 00:05:07.659
So I'm gonna go tsc, we're gonna inspect,
and what did we run last time with?

104
00:05:07.659 --> 00:05:08.549
We ran with 2000.

105
00:05:08.549 --> 00:05:10.340
Let's keep on going with 2000.

106
00:05:10.340 --> 00:05:14.088
So we're gonna run this, awesome.

107
00:05:14.088 --> 00:05:21.722
And so I'm gonna start with a quick
performance grab, make sure we're all run.

108
00:05:21.722 --> 00:05:22.322
Okay, awesome.

109
00:05:22.322 --> 00:05:26.352
We're gonna grab this for ten seconds and
we're gonna look at this and just see if

110
00:05:26.352 --> 00:05:30.932
anything's changed on the performance
side, my guess is not a lot's changed.

111
00:05:30.932 --> 00:05:32.284
If we've done our job right,

112
00:05:32.284 --> 00:05:34.892
update should be taking a very
large portion of the time.

113
00:05:34.892 --> 00:05:36.362
We're gonna go over to memory.

114
00:05:36.362 --> 00:05:38.322
I'll start another recording.

115
00:05:38.322 --> 00:05:39.342
We'll come back here.

116
00:05:39.342 --> 00:05:42.571
We'll look at update is taking
an even larger chunk of time.

117
00:05:42.571 --> 00:05:43.671
So this is good.

118
00:05:43.671 --> 00:05:47.844
It looks like it's just update and run and
on message, which is doing that json

119
00:05:47.844 --> 00:05:52.251
decoding and pretty much everything
else is not taking a lot of much time.

120
00:05:52.251 --> 00:05:56.837
So we're now really taking our library and
just making it smaller and smaller and

121
00:05:56.837 --> 00:05:57.451
smaller.

122
00:05:57.451 --> 00:06:01.705
So if you had a server like this, the
amount of stuff you could put on it now.

123
00:06:02.865 --> 00:06:07.353
Analytics, any sort of extra logging for
debugging anything else you now have so

124
00:06:07.353 --> 00:06:12.039
much more room for because we made our one
program excessively better running than it

125
00:06:12.039 --> 00:06:13.325
was before.

126
00:06:13.325 --> 00:06:16.650
I'll let this keep running for
just a second longer because again,

127
00:06:16.650 --> 00:06:18.588
the longer you let it run, the better.

128
00:06:18.588 --> 00:06:27.222
Now remember from here to here
is Websocket or WS shall I say?

129
00:06:27.222 --> 00:06:32.152
&gt;&gt; I just wanna comment that I really
like your take about giving yourself more

130
00:06:32.152 --> 00:06:34.039
headroom for other things.

131
00:06:34.039 --> 00:06:38.714
For instance, on front-and-masters.com,
how fast it is we wanted to AB test

132
00:06:38.714 --> 00:06:42.637
something and that AB testing libraries,
extremely slow.

133
00:06:42.637 --> 00:06:48.071
So we were able to use it just kind of
targeted and I don't think it really

134
00:06:48.071 --> 00:06:53.959
impacted the user performance too much
because our site is so fast that like,

135
00:06:53.959 --> 00:06:59.377
okay, using this in one case,
fine, we were able to rip it out.

136
00:06:59.377 --> 00:07:04.840
Keep going but I feel like just having
an emphasis on performance gives you that

137
00:07:04.840 --> 00:07:10.456
headroom to add observability or logging
or testing or these kinds of things.

138
00:07:10.456 --> 00:07:13.453
&gt;&gt; People don't realize how
important those things are and

139
00:07:13.453 --> 00:07:17.586
if you pay yourself now, you pay yourself
later when you need to make a change.

140
00:07:17.586 --> 00:07:21.631
Cuz inevitably someone adds rammed,
someone adds low dash, someone adds all

141
00:07:21.631 --> 00:07:26.246
these extra things running, and then your
program inevitably gets slow again, right.

142
00:07:26.246 --> 00:07:30.686
There is no such thing as programs that
don't go through these cycles where

143
00:07:30.686 --> 00:07:34.986
everything's really great and
then overtime becomes really crappy and

144
00:07:34.986 --> 00:07:39.709
usually crappiness is not, we just need
to simply swap out just this library and

145
00:07:39.709 --> 00:07:41.137
things will be faster.

146
00:07:41.137 --> 00:07:45.712
And so it's really just having this
mentality of everything you do should be

147
00:07:45.712 --> 00:07:46.863
done really well.

148
00:07:46.863 --> 00:07:50.092
Do you really need to create all these
objects, do you really need to be doing

149
00:07:50.092 --> 00:07:52.715
all these things because if you
take that mentality through,

150
00:07:52.715 --> 00:07:55.049
you will always be programming
yourself pretty thin.

151
00:07:55.049 --> 00:07:58.070
And then as time goes on,
it will remain pretty thin and

152
00:07:58.070 --> 00:08:02.413
then you'll just keep on having that
headroom for an extended period of time.

153
00:08:02.413 --> 00:08:04.929
It's really nice to do, now look at it.

154
00:08:04.929 --> 00:08:07.233
We've literally taken
out the middle section.

155
00:08:07.233 --> 00:08:08.583
That entire thing is just gone.

156
00:08:08.583 --> 00:08:11.703
This is what it was from here to here,
was that?

157
00:08:11.703 --> 00:08:12.813
Now it's completely gone.

158
00:08:12.813 --> 00:08:15.863
We actually do feel like something
else better is happening.

159
00:08:15.863 --> 00:08:19.404
All memory is being managed
within C++ except for

160
00:08:19.404 --> 00:08:23.535
the array buffer that comes out,
which we just stringify.

161
00:08:23.535 --> 00:08:27.242
And so that is actually making a big,
big difference.

162
00:08:27.242 --> 00:08:31.057
And on the performance, you'll notice that
we just really don't see stuff other than

163
00:08:31.057 --> 00:08:34.361
fast buffer is array, there's just
not a lot that's happening anymore.

164
00:08:34.361 --> 00:08:39.240
We really only have just these three are
the last things that are doing anything on

165
00:08:39.240 --> 00:08:40.110
our program.

166
00:08:40.110 --> 00:08:45.471
So for fun,
let's do third optimization 500.

167
00:08:45.471 --> 00:08:49.887
Even though I don't think 500 is even
gonna be in our realm of looking at

168
00:08:49.887 --> 00:08:55.177
anymore, we've made a program so fast that
500 is just not even testing our server.

169
00:08:55.177 --> 00:08:57.632
And then we'll start off with 500.

170
00:08:57.632 --> 00:08:59.342
So here we go.

171
00:08:59.342 --> 00:09:03.100
We'll run a third optimization,
which contains optimization number two.

172
00:09:04.300 --> 00:09:04.970
So don't forget that.

173
00:09:06.510 --> 00:09:08.957
So let's just open up one more.

174
00:09:11.726 --> 00:09:16.405
All right, look how small that text is.

175
00:09:16.405 --> 00:09:19.817
Okay, so
this would be third optimization 500.

176
00:09:24.905 --> 00:09:25.959
That doesn't look great.

177
00:09:29.265 --> 00:09:30.836
That did not look great at all.

178
00:09:35.809 --> 00:09:41.661
Yeah, so, Weird.

179
00:09:41.661 --> 00:09:43.196
So for whatever reason,

180
00:09:43.196 --> 00:09:47.368
it looks like we're having a huge
regression and things being ran.

181
00:09:47.368 --> 00:09:53.098
So that doesn't, that seems confusing,
are you running the right thing?

182
00:09:53.098 --> 00:09:56.751
We should be running the right thing.

183
00:09:56.751 --> 00:09:59.485
Okay, we're going down.

184
00:09:59.485 --> 00:10:03.364
Regret sunsky skill issue,
this could be a skill issue.

185
00:10:03.364 --> 00:10:04.939
We're gonna keep on going though.

186
00:10:09.216 --> 00:10:11.158
Yeah, we're starting to slowly slide down.

187
00:10:11.158 --> 00:10:12.609
That's fine, we'll stop it there.

188
00:10:13.719 --> 00:10:15.649
We'll now go into 1,000.

189
00:10:15.649 --> 00:10:18.219
Again, not an exact science.

190
00:10:18.219 --> 00:10:20.535
Again, always measuring production.

191
00:10:22.280 --> 00:10:23.627
I swear this works.

192
00:10:27.618 --> 00:10:29.783
Okay, for whatever reason this
one's looking way better.

193
00:10:34.494 --> 00:10:37.898
False positive optimizations, can be false
positive optimizations very well could be?

194
00:10:42.725 --> 00:10:43.477
So let this run.

195
00:10:53.502 --> 00:10:56.051
Okay, fantastic.

196
00:11:07.420 --> 00:11:08.573
All right, fantastic.

197
00:11:08.573 --> 00:11:10.365
We did that one, we'll do one more.

198
00:11:10.365 --> 00:11:13.914
We'll do 2,000 now.

199
00:11:17.708 --> 00:11:20.006
And I honestly think we
could probably go up to,

200
00:11:20.006 --> 00:11:24.091
we'd probably see ourselves doing pretty
well into the 3,000s at this point.

201
00:11:33.306 --> 00:11:37.410
So one thing that gets really interesting
is as we get to this point we may not be

202
00:11:37.410 --> 00:11:41.220
giving our server enough load to
actually see, are we making changes?

203
00:11:41.220 --> 00:11:43.413
Are we actually testing it under load or

204
00:11:43.413 --> 00:11:46.278
are we just just measuring
it how it runs normally?

205
00:11:47.698 --> 00:11:48.823
It's still looking pretty good,

206
00:11:48.823 --> 00:11:50.698
it's below our target goal at
the original part of this.

207
00:11:52.048 --> 00:11:55.178
We started off with our boss
recorded at less than 25%.

208
00:11:55.178 --> 00:11:58.826
We're looking less than 25% right
now at a much higher amount.

209
00:11:58.826 --> 00:12:00.862
So pretty happy about that, and so

210
00:12:00.862 --> 00:12:04.245
it doesn't look like it's
made a huge huge difference.

211
00:12:04.245 --> 00:12:10.167
At this one at number two at 2,000
you'll notice that it was at 32.

212
00:12:10.167 --> 00:12:12.865
With our new change we're at 22, okay, so

213
00:12:12.865 --> 00:12:17.765
we're starting to really see benefits as
we're getting towards the higher end.

214
00:12:17.765 --> 00:12:20.675
As we get under load, we're starting to
see something that's a little bit better.

215
00:12:20.675 --> 00:12:22.285
So I'm happy about that.

216
00:12:22.285 --> 00:12:25.375
We're not really seeing much
happening in the lower amounts.

217
00:12:25.375 --> 00:12:27.205
So why is that?

218
00:12:27.205 --> 00:12:31.585
I can't really explain that,
is it local host?

219
00:12:31.585 --> 00:12:33.685
Is it that it really doesn't matter?

220
00:12:33.685 --> 00:12:37.447
I actually have no idea why it does these
things at lower volumes, but at higher

221
00:12:37.447 --> 00:12:41.608
volumes, as we get under pressure, we do
see large percentage changes cuz remember,

222
00:12:41.608 --> 00:12:44.572
33 to 23 is way more impressive
than 60 to 50, right?

223
00:12:44.572 --> 00:12:48.774
Cuz that change is significantly faster.

224
00:12:48.774 --> 00:12:51.171
That's like a what, practically almost,

225
00:12:51.171 --> 00:12:54.203
we're getting close to
a 50% speed up on this.

226
00:12:54.203 --> 00:12:57.830
So very happy about that, fantastic.

227
00:12:57.830 --> 00:12:59.425
C++ is still really good.

228
00:12:59.425 --> 00:13:03.120
Yeah, maybe it's the overhead of C++ in
the smaller amounts actually makes some

229
00:13:03.120 --> 00:13:07.365
level of difference, but as we get bigger,
it just scales better than the JavaScript.

230
00:13:07.365 --> 00:13:09.095
But we have made some good changes here.

231
00:13:09.095 --> 00:13:10.675
We're gonna take third optimization.

232
00:13:10.675 --> 00:13:12.686
We'll put first optimization on top and

233
00:13:12.686 --> 00:13:15.645
see now that we've really
stripped everything else away,

234
00:13:15.645 --> 00:13:19.687
are we gonna start seeing the update
function actually making a difference now?

235
00:13:20.927 --> 00:13:24.940
My guess it will probably
see a difference.

