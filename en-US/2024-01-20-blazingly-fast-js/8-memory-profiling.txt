[00:00:00]
>> So let's create a second optimization branch. And let's try to find another optimization, okay? So we're gonna do something a little bit different this time. I'm gonna go back over here. Again, we're just branched. We're in a clean state, so anyone can start with this one. And I'm gonna make sure you have your nice path.

[00:00:20]
Correctly done. So I'm just gonna call this one testing, right? And I'm gonna go inspect, I'm gonna launch that server and let's go backwards. Did I see it? No, okay, good. I just wanna make sure I didn't. I thought I saw a bunch of errors. I'm gonna just run 1,000 connections again, right?

[00:00:32]
That we are starting to get a nice good overload on our server at about 1,000. I'm gonna jump back over here. And instead of going on the Pro Performance tab. Let's jump over into the memory tab. And then we'll do the performance afterwards. So I'm gonna let this thing run for a while.

[00:00:47]
The longer you let the memory one run for the better. And by the way, you probably got hit here actually, I'm gonna stop this you probably got hit with this screen first. Don't do heap snapshot down to an allocation timeline. Let's first start with allocation sampling. So allocation sampling is a lot like how PerfTool works.

[00:01:03]
Imagine that as we allocate come in, every so much memory that's come through the system, we're gonna take a sample of it. Where did you come from? Where did you go? Where'd you come from? Cotton Eye Joe, right? Just grab that, put it in there, put it into a stack and go, okay, we have one object.

[00:01:18]
And then maybe thousands of more objects come in. It's come through, grabs another one. So you really want this to run for a while. The longer you can run it, the more rare events will also show up. The more statistically sound your memory kinda allocation scheme will look.

[00:01:33]
So I'm gonna let this run for about a minute longer.
>> They're just asking if you could detect major or minor GC in performance but that's kinda what you're gonna get into, right?
>> We're gonna look at just memory. We're not gonna look, I mean, we're gonna measure garbage collection.

[00:01:48]
The performance tool on node is not as good as it is in the browser, it just isn't as complete. We can throw a little trace GC and see how often these things are happening and we can actually disambiguate between the two and how long they're taking, but for now, we're just gonna do this.

[00:02:06]
This will give us a pretty good indication as to where memory's being spent.
>> So audio is good for the most part.
>> Yeah.
>> The only thing that's hurting us is that you do end of next step.
>> Okay, so don't back step. Can I walk off the side?

[00:02:26]
Okay, just checking. All right, I'll try to stand still. Firm. Ready? There we go. All right, I'm gonna stop this. So there you go. This is our memory graph. Look at what we see right here. So I'm just gonna kinda go through it much like the other graphs.

[00:02:41]
Every function that was involved along the way to the allocation is a part of the stack. At the tippy top, the flat areas, that is where the memory was allocated at. And so you've just kinda got to keep that in mind. So I can see right now, play games right here, we allocate a lot of memory in the play game region, but most of it is not play game, it's around these.

[00:03:04]
I can also see over here that a lot of these are on connection, socket, socket, duplex, right, start loop, right, right, handle upgrade, complete upgrade, socket, socket, socket. So I'm gonna call this region WebSocket, okay? So this is WebSocket creating JavaScript memory region over here. If I look at this.

[00:03:21]
I see, okay, play game, game, child set level, error, add chidings. I'm not sure what chidings are. I assume those are bindings for children in the penal logger. So this must be penal logger memory being created right here. Then we see these ones. We see tick runner, we see promise, promise, promise.

[00:03:39]
Okay, we definitely see some promises in here. We also see some adds. This kinda sounds like potentially some set stuff going on here. Create bullet is in here, because remember, we're still using sets. So we can see these things cuz we're back to the beginning, but this promise one is pretty interesting cuz this is a lot of memory right in here, right?

[00:03:57]
We are doing quite a bit of memory in this one region. And the reason why I'm zeroing in on that, let's go over here and let's take a sample from the performance. We'll just do 10 seconds. Just let it run. All right, fantastic. [BLANK AUDIO]

