WEBVTT

1
00:00:00.540 --> 00:00:05.901
Something I see right away
is that we're still creating

2
00:00:05.901 --> 00:00:10.805
arrays over and over again,
is adding to the end and

3
00:00:10.805 --> 00:00:15.040
shifting off the front, is that a problem?

4
00:00:15.040 --> 00:00:16.650
Is that gonna cause a bunch of problems?

5
00:00:16.650 --> 00:00:20.865
Likely that is gonna cause a problem,
cuz if V8 does something tricky,

6
00:00:20.865 --> 00:00:23.847
maybe it doesn't want to
reorder all the indices.

7
00:00:23.847 --> 00:00:26.830
Maybe it has some reasons when it
doesn't reorder the indices, and

8
00:00:26.830 --> 00:00:30.037
you're literally growing one direction,
maybe it's reallocating.

9
00:00:30.037 --> 00:00:33.204
We have no idea what's actually
happening underneath the hood, and so

10
00:00:33.204 --> 00:00:35.997
a linked list test here could be really,
really good.

11
00:00:35.997 --> 00:00:39.262
Should we create a linked list and
actually remove off the front old

12
00:00:39.262 --> 00:00:42.432
fashion computer science style
as opposed to using an array?

13
00:00:42.432 --> 00:00:44.087
There could be something
that's really good here,

14
00:00:44.087 --> 00:00:45.602
we can even use a singly linked list.

15
00:00:45.602 --> 00:00:48.085
So we're not doing a whole
bunch of link breaking,

16
00:00:48.085 --> 00:00:51.148
we're only doing a singular link
breaking every single time,

17
00:00:51.148 --> 00:00:55.092
which would just make it pretty fast,
we could totally do that.

18
00:00:55.092 --> 00:00:57.733
This are just all the thoughts you gotta
start thinking about when it comes to

19
00:00:57.733 --> 00:01:00.523
this level, because at this point,
there's no more free lunches.

20
00:01:00.523 --> 00:01:03.893
Everything is gonna be excessively
difficult to try to win.

21
00:01:03.893 --> 00:01:07.900
And so that's something I would most
certainly try is creating a linked list.

22
00:01:07.900 --> 00:01:12.348
The next thing, which is always pretty
disappointing, there's just C in general,

23
00:01:12.348 --> 00:01:14.483
which is this right here.

24
00:01:14.483 --> 00:01:18.443
So do we ever consider our logging?

25
00:01:20.231 --> 00:01:22.561
I don't know,
are you considering your logging?

26
00:01:22.561 --> 00:01:27.271
Should you have a build step in which some
servers just simply don't have logging?

27
00:01:27.271 --> 00:01:30.736
Some servers have logging, because
every single time we get a collision,

28
00:01:30.736 --> 00:01:31.951
we're creating memory.

29
00:01:31.951 --> 00:01:36.119
We're creating strings,
we're creating things all over the place,

30
00:01:36.119 --> 00:01:37.651
are they gonna be useful?

31
00:01:37.651 --> 00:01:38.521
Are they not useful?

32
00:01:38.521 --> 00:01:39.378
Are you mutating the thing?

33
00:01:39.378 --> 00:01:43.739
So if I just take out all the logging,
what happens now?

34
00:01:43.739 --> 00:01:45.899
And this isn't always a great
idea to take out logging.

35
00:01:45.899 --> 00:01:49.618
I'm not saying you should do that, but
you should potentially consider having

36
00:01:49.618 --> 00:01:52.799
a switch for when logging should and
should not exist.

37
00:01:52.799 --> 00:01:56.432
And so we can most certainly
take out this kind of stuff, and

38
00:01:56.432 --> 00:01:59.274
then see how does this
affect things overall.

39
00:02:02.681 --> 00:02:04.026
Really, it's very funny,

40
00:02:04.026 --> 00:02:07.064
I've seen logging make more
impact than almost anything else.

41
00:02:07.064 --> 00:02:10.000
Here, actually, I'm also gonna
just spring this up a little bit,

42
00:02:10.000 --> 00:02:11.455
let's go up to like 3,000.

43
00:02:11.455 --> 00:02:15.029
Let's just really try to generate
more memory at this point.

44
00:02:18.953 --> 00:02:22.154
&gt;&gt; Is the logger, in this case, the thing
that's writing to your temp directory?

45
00:02:22.154 --> 00:02:25.986
&gt;&gt; Yeah, it's the thing that's writing
to the temp directory, sort of, no, no.

46
00:02:25.986 --> 00:02:31.337
Well, the stuff that's writing the data
to the temp directory is not that.

47
00:02:31.337 --> 00:02:35.097
That is going to be the data writer
that's doing this extra kind of writing.

48
00:02:35.097 --> 00:02:37.927
This one that we're doing right now,
this is just the Pino logger.

49
00:02:37.927 --> 00:02:39.105
So this would be,

50
00:02:39.105 --> 00:02:44.135
I think pretty much every node.js
application in the universe uses Pino for

51
00:02:44.135 --> 00:02:48.783
logging or some variant of that logger,
Bunyan used to be the old one.

52
00:02:50.507 --> 00:02:52.683
So we're gonna let it run for
a little bit longer and hopefully,

53
00:02:52.683 --> 00:02:53.619
we've made a difference.

54
00:02:53.619 --> 00:02:56.908
Also, one thing that you may not
have noticed, when we go back here,

55
00:02:56.908 --> 00:03:01.206
you'll notice that there's always
a small flat spot on run right here.

56
00:03:01.206 --> 00:03:03.206
There's always a small flat spot on run.

57
00:03:03.206 --> 00:03:07.626
Well, then when we removed those arrays,
the flat spot went away.

58
00:03:07.626 --> 00:03:11.434
So we did actually take out the memory
that was being generated and run,

59
00:03:11.434 --> 00:03:16.536
which is shocking that 240,000 arrays
had very little impact into our system.

60
00:03:16.536 --> 00:03:21.330
And so now as you can see,
we have shrunk some things, because now,

61
00:03:21.330 --> 00:03:24.291
add player is becoming a larger section.

62
00:03:24.291 --> 00:03:28.763
This before add player was
this little teeny, tiniest,

63
00:03:28.763 --> 00:03:33.994
thin sliver, this teeniest,
tiniest, thin sliver right here.

64
00:03:34.994 --> 00:03:39.374
And now, after us removing the logger,
it's really, really thick.

65
00:03:39.374 --> 00:03:41.033
Which means proportionally,

66
00:03:41.033 --> 00:03:44.922
that little piece of memory which was
like 1% of the total memory we were

67
00:03:44.922 --> 00:03:48.698
generating is now 20% of the total
memory we're just generating.

68
00:03:48.698 --> 00:03:51.623
Unfortunately, this is one of those
unfortunate parts about flame graphs,

69
00:03:51.623 --> 00:03:52.478
you don't actually,

70
00:03:52.478 --> 00:03:55.484
or icicle charts, or however they
call the ones that are upside down.

71
00:03:55.484 --> 00:03:58.181
You don't actually know
the absolute difference here,

72
00:03:58.181 --> 00:04:00.553
you only see the relative difference.

73
00:04:00.553 --> 00:04:04.647
But the relative difference here is
that we went from just, honestly,

74
00:04:04.647 --> 00:04:09.233
the tiniest amount right here, all
the way to this, that's a big difference.

75
00:04:09.233 --> 00:04:12.333
We are now producing very little memory,
so that means fire.

76
00:04:12.333 --> 00:04:17.322
All that memory that was happening in
fire probably came down, honestly,

77
00:04:17.322 --> 00:04:18.996
I bet we could go in here.

78
00:04:18.996 --> 00:04:24.197
And I'll undo all these changes,
it probably was that line right there.

79
00:04:26.105 --> 00:04:31.313
Let's just take out that one line,
And let's see what happens.

80
00:04:35.714 --> 00:04:39.264
So I'm gonna give it a second to run, that
way we get all the pools kinda generated,

81
00:04:39.264 --> 00:04:41.518
so we don't get any false
positives in this memory.

82
00:04:41.518 --> 00:04:44.668
So now, once the pools have all
been generated, we're feeling good,

83
00:04:44.668 --> 00:04:47.887
we're feeling fast, we're feeling froggy,
we're feeling pooled.

84
00:04:51.424 --> 00:04:53.055
We'll let this thing record for a moment.

85
00:04:55.703 --> 00:04:59.108
By the way, this is something that I
genuinely do is that I'll start making

86
00:04:59.108 --> 00:05:02.675
guesses going, okay, I know this is
generating memory, but I have no idea how

87
00:05:02.675 --> 00:05:06.333
much memory it generates, cuz it's
behind no peg wall, it just exists.

88
00:05:06.333 --> 00:05:10.244
No one ever questions logging until you
question logging, and then you realize,

89
00:05:10.244 --> 00:05:12.673
holy cow, how did logging cost this much?

90
00:05:12.673 --> 00:05:16.284
I had no idea that it should cost this
much, and it can be quite surprising when

91
00:05:16.284 --> 00:05:20.356
you discover these little tidbits along
the way like, this is really expensive.

92
00:05:20.356 --> 00:05:24.059
My other one that I probably should
have considered removing, but I didn't,

93
00:05:24.059 --> 00:05:26.196
was this one right here.

94
00:05:26.196 --> 00:05:29.594
So every single time we have a collision,
which is a hundred times,

95
00:05:29.594 --> 00:05:32.397
150 times per game, and
we have thousands of games,

96
00:05:32.397 --> 00:05:35.996
we create these long form objects
that I don't know how long they live.

97
00:05:35.996 --> 00:05:39.240
So that one probably also could be
something that maybe you want to make it

98
00:05:39.240 --> 00:05:40.898
a bit more compiled conditionally.

99
00:05:44.293 --> 00:05:47.850
Okay, so there we go, so now,
we're back to here, so look at that.

100
00:05:47.850 --> 00:05:51.662
In fact, we actually never even
caught that add, that's funny.

101
00:05:54.240 --> 00:05:58.456
So we never actually ended
up catching that player add,

102
00:05:58.456 --> 00:06:00.618
that was this big last time.

103
00:06:00.618 --> 00:06:04.355
We never even sought on this graph, it
never even got a chance to be collected or

104
00:06:04.355 --> 00:06:05.326
sampled.

105
00:06:05.326 --> 00:06:09.000
So that's how big what we're
doing with logging is.

106
00:06:09.000 --> 00:06:12.465
So I remove those other couple lines and
apparently,

107
00:06:12.465 --> 00:06:17.013
it was just enough to cause it such
that it is a significant portion on.

108
00:06:17.013 --> 00:06:18.094
Let's go like this.

109
00:06:24.614 --> 00:06:27.621
Turn it back off, let's reproduce
that result really quickly.

110
00:06:29.831 --> 00:06:32.237
Always good practice,
reproduce your results,

111
00:06:32.237 --> 00:06:35.491
make sure there's not just
some kind of oopsy-daisy.

112
00:06:35.491 --> 00:06:40.380
So I'm curious if this will make
an actual frames per second or

113
00:06:40.380 --> 00:06:43.061
tick time win at this point.

114
00:06:43.061 --> 00:06:47.862
We're now pooling some objects,
we're now disabling logging in,

115
00:06:47.862 --> 00:06:49.774
say, certain instances.

116
00:06:49.774 --> 00:06:52.264
You could still imagine that if
you're running your own stuff,

117
00:06:52.264 --> 00:06:54.306
you can have logging on some
percentage of the time.

118
00:06:54.306 --> 00:06:57.601
Now, if you have an exceedingly rare
event, this would be really, really sad,

119
00:06:57.601 --> 00:07:00.567
because then you have to wait for
it to hit one of your logging instances.

120
00:07:00.567 --> 00:07:03.964
But often you're not chasing
such a rare event that it's

121
00:07:03.964 --> 00:07:08.424
causing the 0.0001% to crash,
cuz the reality is that node crashes

122
00:07:08.424 --> 00:07:11.428
way more frequently than
whatever that event is.

123
00:07:11.428 --> 00:07:14.692
[LAUGH] We've never had a problem
trying to chase that event.

124
00:07:16.505 --> 00:07:18.741
So we'll let it go for
a little bit longer.

125
00:07:22.792 --> 00:07:25.345
&gt;&gt; There's a question about
the frames per second,

126
00:07:25.345 --> 00:07:27.995
how do you suggest
that's being calculated?

127
00:07:27.995 --> 00:07:29.345
The easy and not so

128
00:07:29.345 --> 00:07:34.385
good approach being using the frame
time from the previous frame?

129
00:07:35.545 --> 00:07:36.875
&gt;&gt; So how we're doing the FPS?

130
00:07:36.875 --> 00:07:40.530
Yeah, the FPS is pretty straightforward
how we're doing, I mean,

131
00:07:40.530 --> 00:07:43.004
I would not write home about this one.

132
00:07:43.004 --> 00:07:46.750
It just simply takes the difference
between the now time or

133
00:07:46.750 --> 00:07:50.594
it just simply takes the next time,
next plus rate.

134
00:07:50.594 --> 00:07:55.466
So 16.666, so I always keep that extra
decimal amount, cuz you wanna keep that

135
00:07:55.466 --> 00:08:00.882
decimal amount going, because it goes
from 16.666 sleeping for 16 to 16.66 plus

136
00:08:00.882 --> 00:08:06.320
16.66 is gonna be 33333, a bunch of 3s,
which means the next leap is gonna be 17.

137
00:08:06.320 --> 00:08:10.061
And then the next one, a bunch of 3s and
bunch of 6s could equal a bunch of 9s or

138
00:08:10.061 --> 00:08:12.926
it equals 1, depending on
which way we're gonna go here.

139
00:08:12.926 --> 00:08:16.055
So we could actually sleep for
15, cuz it'll be 15.09s, and so

140
00:08:16.055 --> 00:08:18.665
it's good to kind of keep
track of these little bits.

141
00:08:18.665 --> 00:08:22.787
I've been bitten by nanoseconds before,
I had to write,

142
00:08:22.787 --> 00:08:27.665
kind of a little sync player for
a real time video player for Netflix.

143
00:08:27.665 --> 00:08:33.611
And as I shoved in enough data at some
point, me just ignoring milliseconds,

144
00:08:33.611 --> 00:08:39.018
it started causing tests to fail or
not milliseconds, nanoseconds.

145
00:08:39.018 --> 00:08:41.874
Once you shove through hundreds
of thousands of frames,

146
00:08:41.874 --> 00:08:45.989
all of a sudden nanos become milliseconds
and now, you're just completely off.

147
00:08:45.989 --> 00:08:49.559
And so it's always good to just keep track
of everything, so is this the best way?

148
00:08:49.559 --> 00:08:52.851
Probably not the best way,
but it's good enough, right?

149
00:08:52.851 --> 00:08:58.070
And if we accidentally go completely over,
I do this, probably also not a good way.

150
00:08:58.070 --> 00:09:02.268
This is probably causing different
results, I haven't measured this,

151
00:09:02.268 --> 00:09:03.785
I have no idea.

152
00:09:03.785 --> 00:09:04.911
And there we go, okay, so

153
00:09:04.911 --> 00:09:07.835
this time we got a completely
different result at this point.

154
00:09:07.835 --> 00:09:09.175
We didn't even measure anything going on.

155
00:09:09.175 --> 00:09:12.425
So I actually have no idea how
much memory you're using anymore.

156
00:09:12.425 --> 00:09:16.062
So let's try doing
a performance quick grab.

157
00:09:16.062 --> 00:09:19.244
So at this point, it looks like we're
using effectively no memory as far as I

158
00:09:19.244 --> 00:09:20.352
can tell, I have no idea.

159
00:09:21.722 --> 00:09:25.088
Again, those numbers are fake news
numbers, I don't I read whatever numbers

160
00:09:25.088 --> 00:09:28.562
are associated with them,
I just try to see what's happening.

161
00:09:28.562 --> 00:09:32.666
And still at this point at as fast as
we're going, update is now, again,

162
00:09:32.666 --> 00:09:34.135
our biggest bottleneck.

163
00:09:34.135 --> 00:09:36.588
So I'm doing 3,000 games, so

164
00:09:36.588 --> 00:09:41.694
we're completely bottlenecked by update,
which is rather shocking.

165
00:09:41.694 --> 00:09:45.382
The function in which made no difference
at all is now the function that is

166
00:09:45.382 --> 00:09:46.114
the slowest.

167
00:09:47.914 --> 00:09:49.934
So could we do a little bit better?

168
00:09:49.934 --> 00:09:51.924
Well, we potentially could.

