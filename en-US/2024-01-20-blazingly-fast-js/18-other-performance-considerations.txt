WEBVTT

1
00:00:00.100 --> 00:00:02.377
Now you gotta start playing the game of,
what am I trying to improve?

2
00:00:02.377 --> 00:00:04.350
Memory or update?

3
00:00:04.350 --> 00:00:06.350
I bet you the logging
made a big difference.

4
00:00:06.350 --> 00:00:10.093
We could actually kinda check that to see
if it did actually make a big difference.

5
00:00:10.093 --> 00:00:14.268
I'll go like this, get commit,
pull update and logging update.

6
00:00:14.268 --> 00:00:18.533
I'm gonna check out.

7
00:00:18.533 --> 00:00:19.636
There we go.
We can check out, how about this one?

8
00:00:19.636 --> 00:00:24.468
Git checkout to,
we've already kind of done that one.

9
00:00:24.468 --> 00:00:26.658
So I guess we'll do this
one really quickly.

10
00:00:26.658 --> 00:00:32.340
So we'll do a tsc, we'll erase this,
and I'm gonna go to-3000.

11
00:00:32.340 --> 00:00:35.007
So we're gonna actually try to push
through 3000 games on our third

12
00:00:35.007 --> 00:00:35.638
optimization.

13
00:00:35.638 --> 00:00:38.657
Now remember, our third optimization
contains second and third.

14
00:00:38.657 --> 00:00:41.427
No updates to update yet.

15
00:00:41.427 --> 00:00:43.732
And we really weren't seeing
a difference back then.

16
00:00:43.732 --> 00:00:45.339
So are we seeing a difference now?

17
00:00:47.083 --> 00:00:51.420
So I'll go here, and now that we've
made several changes to update,

18
00:00:51.420 --> 00:00:55.562
the best possible improved algorithm,
reducing logging.

19
00:00:55.562 --> 00:00:58.393
There's still one left which is
getting rid of a radar shift,

20
00:00:58.393 --> 00:00:59.894
which I think we could do.

21
00:00:59.894 --> 00:01:03.094
I haven't tried to do it live,
I haven't practiced at once.

22
00:01:03.094 --> 00:01:05.671
But I don't think it'd be too hard to
do live, I could write a quick link.

23
00:01:05.671 --> 00:01:06.847
I could write a linked list.

24
00:01:06.847 --> 00:01:08.005
I could do this.

25
00:01:14.989 --> 00:01:18.411
There's nothing better than
saying I can do this and

26
00:01:18.411 --> 00:01:22.465
then you write a linked list,
and you just totally suck at it.

27
00:01:24.592 --> 00:01:30.245
All right, so at 3,000, not doing
very great so far, our ratio is 43%.

28
00:01:30.245 --> 00:01:33.878
We've kind of, I bet you were probably
pretty underwater at this point.

29
00:01:33.878 --> 00:01:35.076
All right, so maybe 42.

30
00:01:35.076 --> 00:01:37.472
So it's higher.

31
00:01:37.472 --> 00:01:38.299
Let it keep on going.

32
00:01:42.780 --> 00:01:48.682
I'll give it,
we'll go to 6 million frames.

33
00:01:51.241 --> 00:01:55.048
By the way, this is legitimately something
that I do frequently, which is just,

34
00:01:55.048 --> 00:01:58.045
it comes down to exploring,
guessing, and looking at graphs.

35
00:01:58.045 --> 00:02:02.647
There's not gonna be a solid way unless
if you can rewrite the algorithm.

36
00:02:02.647 --> 00:02:04.857
Rethinking about the problem
is the best way.

37
00:02:04.857 --> 00:02:09.937
So that project specific one, which is
don't check all the bullets, just check

38
00:02:09.937 --> 00:02:15.108
the front ones, that is gonna be a huge
win because you're changing the problem.

39
00:02:15.108 --> 00:02:17.813
And that's where the big wins come,
is change the problems.

40
00:02:17.813 --> 00:02:21.728
I git check out blazingly fast.

41
00:02:21.728 --> 00:02:24.319
And we'll do this once more.

42
00:02:24.319 --> 00:02:29.259
This will be blazingly fast,
that is not how you do blazingly fast.

43
00:02:29.259 --> 00:02:31.383
Totally the wrong acronym there.

44
00:02:31.383 --> 00:02:33.204
So hopefully this one will do something.

45
00:02:33.204 --> 00:02:38.090
I'll be kind of sad if this
one doesn't do anything.

46
00:02:38.090 --> 00:02:41.522
I'll probably just weep
a little bit on stage.

47
00:02:41.522 --> 00:02:44.572
It could have done something,
we might, maybe, we'll see.

48
00:02:44.572 --> 00:02:47.012
We have plenty of time to watch
this thing get screwed up.

49
00:02:47.012 --> 00:02:51.196
Just import Assembly and
write it as Assembly.

50
00:02:51.196 --> 00:02:54.165
I mean, that's an option.

51
00:02:54.165 --> 00:02:58.316
I'm not that good to write it as assembly.

52
00:02:58.316 --> 00:03:00.024
So maybe there's a there there,

53
00:03:00.024 --> 00:03:03.807
maybe we're actually starting to
see something attach faster, right?

54
00:03:03.807 --> 00:03:06.707
We're sitting at 49 versus the current 32.

55
00:03:06.707 --> 00:03:09.456
My guess is that number will
go up next time I refresh it,

56
00:03:09.456 --> 00:03:11.043
which I'm really scared to do.

57
00:03:11.043 --> 00:03:12.585
We'll see 36.

58
00:03:12.585 --> 00:03:17.391
36, see I just felt it, I felt in my bones
that it was going up, just because all

59
00:03:17.391 --> 00:03:22.451
the games are running, how V8's handling
memory collections changing, right?

60
00:03:22.451 --> 00:03:25.358
How they handle it in the beginning is
probably a little bit different than once

61
00:03:25.358 --> 00:03:27.616
they start developing heuristics and
how long they can run.

62
00:03:27.616 --> 00:03:31.199
And so there's a lot of give and
take when it comes to these things.

63
00:03:31.199 --> 00:03:34.183
There we go.
So did we actually improve anything?

64
00:03:34.183 --> 00:03:36.540
At this point,
I don't think we improved anything.

65
00:03:36.540 --> 00:03:38.052
And so even though it looks like it might,

66
00:03:38.052 --> 00:03:40.227
it doesn't look like we
are actually improving anything.

67
00:03:40.227 --> 00:03:44.322
Again, this is where the problem
of local host testing comes along,

68
00:03:44.322 --> 00:03:47.512
which is we're not testing
it in a real environment.

69
00:03:47.512 --> 00:03:48.715
We're not testing with a real machine.

70
00:03:48.715 --> 00:03:51.020
We're not testing with two CPU cores.

71
00:03:51.020 --> 00:03:53.536
We're not getting all the good stuff
that you really want to get in

72
00:03:53.536 --> 00:03:54.418
production testing.

73
00:03:54.418 --> 00:03:58.041
These changes likely would result
in something a little bit better

74
00:03:58.041 --> 00:04:00.835
in production, but
as of right now, there we are.

75
00:04:00.835 --> 00:04:04.630
And so the last things we could try
to do is add in linked list changes.

76
00:04:04.630 --> 00:04:10.650
That's about it as far as run goes.

77
00:04:10.650 --> 00:04:12.627
We have onMessage, onClose.

78
00:04:12.627 --> 00:04:16.657
These things are using
sets to look up stuff.

79
00:04:16.657 --> 00:04:20.459
Is there a way that we can reuse this data
and create a pretty clever pull here?

80
00:04:20.459 --> 00:04:23.262
We could technically do something that's
very akin to the garbage collection,

81
00:04:23.262 --> 00:04:25.663
which would be, we could just test
it out to see if it actually works.

82
00:04:25.663 --> 00:04:27.168
You wouldn't even know if it works.

83
00:04:27.168 --> 00:04:29.201
But you could create an array in
which you're storing everything.

84
00:04:29.201 --> 00:04:33.360
And every time you get done with a state
and you wanna release a web socket,

85
00:04:33.360 --> 00:04:37.517
you could drop its index and add that
index to a free list, and then use that

86
00:04:37.517 --> 00:04:41.636
free list number to know where an empty
space's at with an unused state.

87
00:04:41.636 --> 00:04:44.276
And then on every single web
socket that comes in on open,

88
00:04:44.276 --> 00:04:46.320
you give it an index
into this larger array.

89
00:04:46.320 --> 00:04:49.401
So you're always using these spots really,
really quick.

90
00:04:49.401 --> 00:04:52.330
So to get a new index
requires an array.pop, but

91
00:04:52.330 --> 00:04:55.407
to look up the state just
requires an array access.

92
00:04:55.407 --> 00:04:56.727
Would that be better?

93
00:04:56.727 --> 00:04:58.192
Maybe, maybe not.

94
00:04:58.192 --> 00:04:59.557
It's very, very hard to tell.

95
00:04:59.557 --> 00:05:02.819
And so this is the fun part about
performance, is that it always ends like

96
00:05:02.819 --> 00:05:06.680
this, which is what's left to do unless
you can dramatically change the algorithm.

97
00:05:06.680 --> 00:05:09.555
Now at this point,
we have no algorithm left to change, and

98
00:05:09.555 --> 00:05:13.597
we're just trying to scrape around to see
what is and what isn't affecting stuff.

99
00:05:13.597 --> 00:05:16.688
Another thing we could really do
that would probably make somewhat

100
00:05:16.688 --> 00:05:20.273
of a difference, maybe it would make
difference in aggregate, is instead of

101
00:05:20.273 --> 00:05:23.819
writing out to disk every one second,
write out to disk every five seconds.

102
00:05:23.819 --> 00:05:26.793
Do we need one second resolution
on writing out all of our data?

103
00:05:26.793 --> 00:05:28.294
Probably not.

104
00:05:28.294 --> 00:05:29.670
We're just aggregating anyways.

105
00:05:29.670 --> 00:05:34.138
The amount of time that goes by doesn't
change how much data we're writing out.

106
00:05:34.138 --> 00:05:38.067
So we could have longer intervals between
writing if we really wanted to squeeze

107
00:05:38.067 --> 00:05:39.129
out every last item.

108
00:05:39.129 --> 00:05:43.471
And so this is just really the final part,
which is just,

109
00:05:43.471 --> 00:05:47.369
you got to just guess at
the very last part, right?

110
00:05:47.369 --> 00:05:50.201
And so, we already went
through all of these things.

111
00:05:50.201 --> 00:05:51.450
I just didn't do any of this.

112
00:05:51.450 --> 00:05:54.243
What about on message,
linked lists, stop using JSON.

113
00:05:54.243 --> 00:05:56.448
This would also be
another really good one,

114
00:05:56.448 --> 00:06:00.323
which is right now we're sending JSON
messages, which means every single on

115
00:06:00.323 --> 00:06:03.979
message call is decoding a block of
JSON that says fire from this player.

116
00:06:03.979 --> 00:06:05.277
Why not just send up a number?

117
00:06:05.277 --> 00:06:08.992
Why not just send up number one for fire?

118
00:06:08.992 --> 00:06:12.485
Like why send up something that
I have to take an array buffer,

119
00:06:12.485 --> 00:06:14.836
turn it into a string, take that string,

120
00:06:14.836 --> 00:06:18.005
turn it into an object by
crawling everything out of it.

121
00:06:18.005 --> 00:06:19.494
Yeah, json.parse is super fast.

122
00:06:19.494 --> 00:06:23.412
It has all these great optimizations
to it, still has to do it.

123
00:06:23.412 --> 00:06:27.958
It's really faster than parsing JSON,
not parsing JSON.

124
00:06:27.958 --> 00:06:31.007
So that's like the fastest
form of JSON is not JSON.

125
00:06:31.007 --> 00:06:32.265
And so this is another thing.

126
00:06:32.265 --> 00:06:35.846
Once you have a very set model, you can
explore using things like flat buffer.

127
00:06:35.846 --> 00:06:38.857
If you know your service
is never gonna change, or

128
00:06:38.857 --> 00:06:43.746
unlikely to change, using alternative
wire formats can yield really big wins.

129
00:06:43.746 --> 00:06:46.262
And I've definitely seen
this a lot in production.

130
00:06:46.262 --> 00:06:51.824
We recently had a service that,
it was completely pegged by JSON.

131
00:06:51.824 --> 00:06:53.226
It was doing a lot of stuff.

132
00:06:53.226 --> 00:06:54.905
It was spawning things.

133
00:06:54.905 --> 00:06:56.100
It was running games.

134
00:06:56.100 --> 00:06:57.370
It was doing all sorts of stuff.

135
00:06:57.370 --> 00:07:01.538
And the thing that was taking up the most
amount of time on the machine was

136
00:07:01.538 --> 00:07:02.242
just JSON.

137
00:07:02.242 --> 00:07:05.786
And so even by simply getting a good
zero allocation protobuf item,

138
00:07:05.786 --> 00:07:09.466
which protobufs are still eager parse,
you still have to parse them.

139
00:07:09.466 --> 00:07:12.463
The moment you get them,
you can't defer parsing,

140
00:07:12.463 --> 00:07:16.769
even that alone made such a big impact
that it was no longer the bottleneck.

141
00:07:16.769 --> 00:07:19.215
And so JSON can be very, very expensive.

142
00:07:19.215 --> 00:07:22.142
So changing interchange formats are huge.

143
00:07:22.142 --> 00:07:27.272
&gt;&gt; If you have a deeply nested object,
how much of an impact would it

144
00:07:27.272 --> 00:07:32.402
have on memory when you're creating
a constant or variable that

145
00:07:32.402 --> 00:07:39.243
just references that deeply nested versus
just using the path to that value instead?

146
00:07:39.243 --> 00:07:43.515
&gt;&gt; Well, I don't know what V8 does
does as far as CPU optimizations.

147
00:07:43.515 --> 00:07:46.123
If you have a hard-coded
path to an object,

148
00:07:46.123 --> 00:07:48.667
does it have some sort
of cool offset jump?

149
00:07:48.667 --> 00:07:51.729
Does it have some sort of jitted
opportunity to make that access

150
00:07:51.729 --> 00:07:54.459
really fast, or
is it looking it up at every single dot?

151
00:07:54.459 --> 00:07:55.623
I wouldn't know, but

152
00:07:55.623 --> 00:07:59.003
I often would just guess that
that's almost never your problem.

153
00:07:59.003 --> 00:08:03.502
Your problem often is that you're
just doing something too many times

154
00:08:03.502 --> 00:08:05.190
that's in bigger scope.

155
00:08:05.190 --> 00:08:09.245
Or you're creating memory that
you don't need to be creating.

156
00:08:09.245 --> 00:08:13.792
It's almost never something as simple as,
instead of using this,

157
00:08:13.792 --> 00:08:15.562
make a reference to that.

158
00:08:15.562 --> 00:08:16.801
If it was, I mean, that'd be fantastic.

159
00:08:16.801 --> 00:08:19.893
But if that was the case,
everything else we would do,

160
00:08:19.893 --> 00:08:22.255
would also be 10 times more expensive.

161
00:08:22.255 --> 00:08:26.830
Cuz if that's observable, then, I mean, a
radar push a radar pop has to be even more

162
00:08:26.830 --> 00:08:29.935
observable then, cuz you have to do so
many more things.

163
00:08:29.935 --> 00:08:33.536
But this has always been one
of the biggest wins I've seen,

164
00:08:33.536 --> 00:08:37.727
is parsed a format over the wire
starts making a real difference now.

165
00:08:37.727 --> 00:08:41.799
Obviously, if you're going
from the server to a client,

166
00:08:41.799 --> 00:08:44.300
JSON is probably your only choice.

167
00:08:44.300 --> 00:08:47.850
But if you don't have to use that and
you're in a place where you can change

168
00:08:47.850 --> 00:08:50.953
that, probably some better options
out there that you can try.

169
00:08:50.953 --> 00:08:55.150
And when I say don't use JSON,
I also don't mean use XML.

170
00:08:55.150 --> 00:08:56.337
So please don't take that out.

171
00:08:56.337 --> 00:08:59.972
That's not what I'm suggesting using,
okay?

172
00:08:59.972 --> 00:09:01.739
Conditional logging, we talked about that.

173
00:09:01.739 --> 00:09:02.912
Logging can be very heavy.

174
00:09:02.912 --> 00:09:05.944
I've seen logging become
the bottleneck multiple times.

175
00:09:05.944 --> 00:09:07.508
So careful about logging.

176
00:09:07.508 --> 00:09:08.405
Logging is great.

177
00:09:08.405 --> 00:09:09.411
Logging is fantastic.

178
00:09:09.411 --> 00:09:10.844
Logging can become quite annoying.

