WEBVTT

1
00:00:00.180 --> 00:00:03.330
Testing is awesome,
can also be kind of hard.

2
00:00:03.330 --> 00:00:05.616
Automation, especially for accessibility,

3
00:00:05.616 --> 00:00:08.320
is an important aspect of
building quality software.

4
00:00:08.320 --> 00:00:11.956
Like if you have a test suite with
any automated tests in it, or even if

5
00:00:11.956 --> 00:00:17.160
you don't, you have some opportunities to
let computers help test things for you.

6
00:00:17.160 --> 00:00:19.829
Things that can be
programmatically determined,

7
00:00:19.829 --> 00:00:22.343
computers can help you with that.

8
00:00:22.343 --> 00:00:25.963
There are some things that they can't
tell, they're not that great at and

9
00:00:25.963 --> 00:00:27.563
we still need human review.

10
00:00:27.563 --> 00:00:29.143
Like we still need manual testing.

11
00:00:30.193 --> 00:00:34.469
But if you could bake in a contract for
how something should work,

12
00:00:34.469 --> 00:00:38.900
your teammates, even you in the future,
you come back in January,

13
00:00:38.900 --> 00:00:42.973
like how did that work again,
or whenever after a long break.

14
00:00:42.973 --> 00:00:44.431
It would be more stable and

15
00:00:44.431 --> 00:00:48.888
less inclined to break without anyone
noticing if you have some test coverage.

16
00:00:50.028 --> 00:00:51.778
But it can be kind of hard.

17
00:00:51.778 --> 00:00:56.111
Sometimes, the tooling doesn't support
what you're trying to test, and maybe

18
00:00:56.111 --> 00:01:00.503
you're locked down on an old version of a
library that happened to me two weeks ago,

19
00:01:00.503 --> 00:01:03.235
I went to go update user event and
testing library.

20
00:01:03.235 --> 00:01:05.305
I'm like, la-di-da, here you go, team.

21
00:01:05.305 --> 00:01:08.395
And then I understood why people
aren't as eager to do that.

22
00:01:08.395 --> 00:01:12.755
It's because you have to make everything
work in all these other branches.

23
00:01:13.885 --> 00:01:16.938
You might not be able to go update
all the tests to make them work

24
00:01:16.938 --> 00:01:18.125
with this new upgrade.

25
00:01:18.125 --> 00:01:23.685
So, there's the things that go into
upgrading tooling that are challenging.

26
00:01:23.685 --> 00:01:25.255
You have to schedule them sometimes.

27
00:01:25.255 --> 00:01:27.488
So that's why this can be a bit hard, but

28
00:01:27.488 --> 00:01:30.525
there's a lot you can do with
some basic tools as well.

29
00:01:31.955 --> 00:01:36.095
There is a misconception that everything
in accessibility can be automated.

30
00:01:36.095 --> 00:01:41.105
I've heard executives want to cut their
team staff size, especially when it comes

31
00:01:41.105 --> 00:01:47.024
to training for accessibility because they
think that automation can solve it all.

32
00:01:47.024 --> 00:01:49.869
Sorry, I'm afraid that it can't.

33
00:01:49.869 --> 00:01:53.884
We need humans to review stuff
that humans are going to use.

34
00:01:53.884 --> 00:01:55.797
Kind of intuitive.

35
00:01:55.797 --> 00:02:00.433
So here are the things that we can
automate cuz we do want computers

36
00:02:00.433 --> 00:02:03.737
to help us plus we want
to make our jobs easier.

37
00:02:03.737 --> 00:02:08.547
So we can automate html and aria
validation like typescript is great for

38
00:02:08.547 --> 00:02:12.476
this like we were talking about
it can catch when you have do

39
00:02:12.476 --> 00:02:14.898
something wrong with your markup.

40
00:02:14.898 --> 00:02:19.990
Form labels, we can catch that, we can
catch color contrast most of the time,

41
00:02:19.990 --> 00:02:24.311
I do have in the manual column
contrast over images and gradients,

42
00:02:24.311 --> 00:02:25.793
a bit harder to check.

43
00:02:25.793 --> 00:02:28.893
Text over video, yeah good luck.

44
00:02:28.893 --> 00:02:32.843
That's very manual to test.

45
00:02:32.843 --> 00:02:36.519
Accessible names, so like icon buttons,
you know you have an icon button

46
00:02:36.519 --> 00:02:39.029
component, they have a prop for
you to pass text.

47
00:02:39.029 --> 00:02:42.849
Text in, like does it land in the right
place internally in the component?

48
00:02:44.119 --> 00:02:48.566
Focus management for keyboard stuff, those
are some of my favorite tests to write

49
00:02:48.566 --> 00:02:51.787
because you can assert did focus
move where you expected and

50
00:02:51.787 --> 00:02:55.769
the tools have gotten better for
that in the last few years.

51
00:02:55.769 --> 00:03:01.042
You can also test the document language in
a page level test like like using Cyprus.

52
00:03:01.042 --> 00:03:05.262
As for the manual stuff,
you can't really test focus order.

53
00:03:05.262 --> 00:03:11.662
If it's jumping around in a weird order,
what's the computer gonna say about that?

54
00:03:11.662 --> 00:03:13.252
Text alternative quality.

55
00:03:13.252 --> 00:03:19.889
So if you have the wrong alt text on
something, or yeah, it's just not right.

56
00:03:19.889 --> 00:03:22.692
The tooling can tell you
when all text is missing,

57
00:03:22.692 --> 00:03:25.175
it can't really tell you if it's not good.

58
00:03:25.175 --> 00:03:29.790
Screen reader testing, we can't automate
that, we can run things in the cloud with

59
00:03:29.790 --> 00:03:34.609
the system labs but as for assertions with
screen readers, we're not quite there yet.

60
00:03:36.009 --> 00:03:39.096
That'd be cool to see more of, I know
there's some experiments around that but

61
00:03:39.096 --> 00:03:39.984
nothing mainstream.

62
00:03:41.164 --> 00:03:44.296
Contrast, we talked about
error identification,

63
00:03:44.296 --> 00:03:47.864
if you have the wrong content
of your errors in validation.

64
00:03:49.214 --> 00:03:50.934
Computer can't really help you there.

65
00:03:50.934 --> 00:03:52.694
And then click events on divs.

66
00:03:52.694 --> 00:03:55.034
The computer doesn't know
what it doesn't know about.

67
00:03:55.034 --> 00:03:56.424
It's kind of like a blind person.

68
00:03:56.424 --> 00:03:56.924
It won't know.

69
00:03:58.449 --> 00:04:02.055
So as for estimates of how much
of what CAG we can automate,

70
00:04:02.055 --> 00:04:04.639
it's around 50% of issues by volume.

71
00:04:04.639 --> 00:04:07.796
Sometimes estimates are higher,
but I think it's yeah,

72
00:04:07.796 --> 00:04:09.479
it's not always consistent.

73
00:04:09.479 --> 00:04:10.458
So it's by volume,

74
00:04:10.458 --> 00:04:13.849
like the number of issues that you
could possibly have on a page.

75
00:04:13.849 --> 00:04:15.574
It's not my success criterion.

76
00:04:15.574 --> 00:04:19.683
And that's only from DQ,
that's their estimate.

77
00:04:19.683 --> 00:04:22.953
And I think I chose
the lower end of the number.

78
00:04:22.953 --> 00:04:26.224
But all of their rule descriptions for
XCOR I have linked so

79
00:04:26.224 --> 00:04:28.563
you can go see what they cover.

80
00:04:28.563 --> 00:04:33.327
And they are also very involved with the
standard side of accessibility rules for

81
00:04:33.327 --> 00:04:36.409
automation, the ACT Rules Group,
which stands for

82
00:04:36.409 --> 00:04:40.009
Accessibility Confirm Performance testing.

83
00:04:40.009 --> 00:04:43.595
So just trying to make this stuff
repeatable, more standard, so

84
00:04:43.595 --> 00:04:48.259
that different tools aren't so
wildly different in what they report.

85
00:04:48.259 --> 00:04:49.049
So that's pretty cool.

86
00:04:50.559 --> 00:04:53.459
But we definitely still
need some manual testing.

87
00:04:53.459 --> 00:04:57.664
And I have an article in here by
Eric Bailey on Smashing Magazine.

88
00:04:57.664 --> 00:05:01.897
He does a really eloquent job of
explaining why we still need manual

89
00:05:01.897 --> 00:05:03.794
testing, so check that out.

90
00:05:05.564 --> 00:05:09.828
So create your own coverage, I think
some of the best stuff you can do for

91
00:05:09.828 --> 00:05:15.024
automation is to write feature tests for
the components that you know a lot about.

92
00:05:15.024 --> 00:05:16.964
You know how that component should work.

93
00:05:16.964 --> 00:05:20.049
You've got the requirements specs.

94
00:05:20.049 --> 00:05:23.749
You've got insider knowledge
on how it was coded.

95
00:05:23.749 --> 00:05:27.649
So if you can write tests
that assert the outcomes,

96
00:05:27.649 --> 00:05:30.629
does my focus go to the right place.

97
00:05:30.629 --> 00:05:32.439
I'm not going to test
the internal logic of it.

98
00:05:32.439 --> 00:05:34.489
I'm going to test,
does it have the right outcome?

99
00:05:34.489 --> 00:05:36.579
Write inputs, create the right outputs.

100
00:05:37.709 --> 00:05:39.559
Keyboard tests are great for that.

101
00:05:39.559 --> 00:05:41.619
You can test that kind of thing.

102
00:05:41.619 --> 00:05:46.069
And they're fun to do with tools
like testing library and gest.

103
00:05:46.069 --> 00:05:49.549
It can be tricky to capture
exactly how the browser works.

104
00:05:49.549 --> 00:05:52.340
So make sure when you're
writing these tests,

105
00:05:52.340 --> 00:05:55.289
compare your tests with
how the browser works.

106
00:05:55.289 --> 00:05:57.540
Because if it's passing
the automated test, but

107
00:05:57.540 --> 00:06:01.026
it doesn't work as in the browser,
your test isn't effective.

108
00:06:01.026 --> 00:06:03.866
That would be what I
call a tautological test.

109
00:06:03.866 --> 00:06:05.996
It's kind of not testing anything useful.

110
00:06:05.996 --> 00:06:07.056
But it's really hard to tell.

111
00:06:07.056 --> 00:06:09.466
So you have to check it in real browser.

112
00:06:09.466 --> 00:06:13.376
Like, say I can capture
the test failure and

113
00:06:13.376 --> 00:06:17.984
do test-driven development style like TDD.

114
00:06:17.984 --> 00:06:21.770
I can capture the failure,
I think I go and fix it, I'm gonna go and

115
00:06:21.770 --> 00:06:26.184
check manually just to make sure,
like as part of my automated test process.

116
00:06:27.194 --> 00:06:29.803
So that when I check that code in,

117
00:06:29.803 --> 00:06:35.226
I know that it actually could
reproduce that bug and it's fixed now.

