WEBVTT

1
00:00:00.640 --> 00:00:02.690
Okay, now we're able to create our store.

2
00:00:04.420 --> 00:00:07.250
What we want to do is let's just
work on the YouTube loader for now.

3
00:00:07.250 --> 00:00:10.667
So the way this works is it's
going to take in that video URL,

4
00:00:10.667 --> 00:00:14.970
it's gonna use the loader.createFromUrl,
parsing the URL.

5
00:00:14.970 --> 00:00:16.530
You can add in some extra options here.

6
00:00:16.530 --> 00:00:19.220
And then we're gonna do
something called load and split.

7
00:00:19.220 --> 00:00:20.238
I'm going to talk about that in a second.

8
00:00:20.238 --> 00:00:26.902
So create YouTube, or what did I call it?

9
00:00:26.902 --> 00:00:27.750
Docs from YouTube video.

10
00:00:27.750 --> 00:00:28.400
Let's do that.

11
00:00:28.400 --> 00:00:32.360
Doc from YouTube video.

12
00:00:32.360 --> 00:00:33.460
Takes in a video.

13
00:00:36.190 --> 00:00:38.906
And then, yeah, I think this is gonna be,

14
00:00:38.906 --> 00:00:42.420
I think this needs to be async,
or does it?

15
00:00:42.420 --> 00:00:43.350
It actually doesn't.

16
00:00:43.350 --> 00:00:47.090
I put async on there, but we're not
doing any 08s in here, so we're good.

17
00:00:47.090 --> 00:00:49.610
So first, we'll make the loader,
which is a non-async thing.

18
00:00:49.610 --> 00:00:53.000
So we can say loader = YouTubeLoader.

19
00:00:53.000 --> 00:00:57.921
And then we can say,
yeah, .createsFromUrl,

20
00:00:57.921 --> 00:01:01.646
which is the video that we parsed in.

21
00:01:01.646 --> 00:01:03.384
We have some extra options here.

22
00:01:07.744 --> 00:01:10.120
We just wanna make sure it's in English,
obviously.

23
00:01:10.120 --> 00:01:13.320
And then I want to add the video
info to the metadata, right?

24
00:01:13.320 --> 00:01:16.790
So remember when we created the documents
on the search, you can add the metadata.

25
00:01:18.020 --> 00:01:22.194
I want to add the video information to
that metadata object so when I get because

26
00:01:22.194 --> 00:01:25.798
eventually what we're going to do
is when this QA system responds,

27
00:01:25.798 --> 00:01:28.150
I want it to respond back with the source.

28
00:01:28.150 --> 00:01:29.490
So I know where it got it from.

29
00:01:29.490 --> 00:01:31.450
It's proof.
It's like citing your work.

30
00:01:31.450 --> 00:01:34.510
I want this system to cite where
it got the information from.

31
00:01:34.510 --> 00:01:37.290
So having this video metadata is helpful.

32
00:01:37.290 --> 00:01:39.910
So I can see that like, yeah,
it came from this YouTube video.

33
00:01:39.910 --> 00:01:43.620
Here's the link, here's the title,
here's the ID, etc, etc.

34
00:01:43.620 --> 00:01:46.040
Otherwise, it sounds like,
how do I know that's accurate?

35
00:01:46.040 --> 00:01:46.910
Where's the source?

36
00:01:46.910 --> 00:01:48.210
Where'd you come up with this?

37
00:01:48.210 --> 00:01:49.050
This is the source.

38
00:01:49.050 --> 00:01:50.870
So the more metadata
here is the more helpful.

39
00:01:51.920 --> 00:01:57.820
And then we want to return
the loader loadAndSplit.

40
00:01:57.820 --> 00:01:59.440
So what does that mean?

41
00:01:59.440 --> 00:02:04.300
Okay, loadAndSplit, so
if you call a load on a loader and

42
00:02:04.300 --> 00:02:08.370
link chain basically,
it will go do the thing.

43
00:02:08.370 --> 00:02:11.993
So in the case of YouTube, it'll go to
YouTube, get the transcripts, load them

44
00:02:11.993 --> 00:02:16.370
up, convert them to those documents that
we have to do manually on the search side.

45
00:02:16.370 --> 00:02:20.200
And then return that,
that's what the loader is gonna do.

46
00:02:20.200 --> 00:02:27.740
The problem is that YouTube transcript is,
I don't know 1000s of tokens.

47
00:02:27.740 --> 00:02:32.189
So imagine if just one if
we made the whole YouTube

48
00:02:32.189 --> 00:02:37.190
transcript one entity,
one thing inside of an index.

49
00:02:38.290 --> 00:02:39.040
That wouldn't scale.

50
00:02:39.040 --> 00:02:41.180
I mean, that could be the whole database,
just that one thing.

51
00:02:41.180 --> 00:02:45.017
So we want to split up the transcript
into different chunks,

52
00:02:45.017 --> 00:02:47.360
right, for a lot of reasons.

53
00:02:47.360 --> 00:02:48.455
The big reason is,

54
00:02:48.455 --> 00:02:52.575
that whole YouTube transcript probably
won't fit in a prompt and GPT.

55
00:02:52.575 --> 00:02:55.945
And the difference between QA and
searches and search,

56
00:02:55.945 --> 00:03:00.044
we didn't have to do a prompt,
we just compared vectors together.

57
00:03:00.044 --> 00:03:05.066
We never actually made a call to open AI,
if you go look at the search beyond

58
00:03:05.066 --> 00:03:10.500
getting the embeds and stuff, but
we never did like a chat completion.

59
00:03:10.500 --> 00:03:12.180
Here we have to do a chat completion.

60
00:03:12.180 --> 00:03:14.670
The only difference is we're saying,
hey, use this information.

61
00:03:14.670 --> 00:03:19.432
Well, if the information is the entire
YouTube script, ChatGPT is like,

62
00:03:19.432 --> 00:03:21.330
I can't, that's too much.

63
00:03:21.330 --> 00:03:22.940
That's too many tokens.

64
00:03:22.940 --> 00:03:24.490
I ran out a token context.

65
00:03:24.490 --> 00:03:26.110
So we have to split it up.

66
00:03:26.110 --> 00:03:29.630
So we have to split that script
up on some part of chunking.

67
00:03:29.630 --> 00:03:32.964
That way when we go do the search,
we only pick the chunk

68
00:03:32.964 --> 00:03:37.920
that has the information needed based
off the query to answer that question.

69
00:03:37.920 --> 00:03:41.322
So it's like, you don't need this whole
transcript just to answer the part where

70
00:03:41.322 --> 00:03:43.910
like, it tells you how
to turn on your Xbox.

71
00:03:43.910 --> 00:03:46.210
All I needed was the part that
tells you how to turn on your Xbox.

72
00:03:46.210 --> 00:03:47.550
That's the one chunk that I needed.

73
00:03:47.550 --> 00:03:48.810
Okay, that's what I'm
gonna send to ChatGPT.

74
00:03:48.810 --> 00:03:51.478
I'm not gonna send a whole PDF just so

75
00:03:51.478 --> 00:03:55.450
GPT can answer the question
on how to turn on your Xbox.

76
00:03:55.450 --> 00:03:58.390
All right, so
I need to chunk it, split it up.

77
00:03:58.390 --> 00:04:00.060
So I'm not sending the whole thing.

78
00:04:00.060 --> 00:04:01.830
So avoid the context limit hit.

79
00:04:01.830 --> 00:04:03.050
Does that make sense?

80
00:04:04.680 --> 00:04:06.720
Okay, so same thing with a YouTube video.

81
00:04:06.720 --> 00:04:07.440
It's just too massive.

82
00:04:07.440 --> 00:04:08.406
So we need to split it.

83
00:04:08.406 --> 00:04:09.580
How you split it?

84
00:04:09.580 --> 00:04:14.409
That's the science is,
it depends on the data.

85
00:04:14.409 --> 00:04:17.122
You just you just got to figure out
the type of data and how you do that.

86
00:04:17.122 --> 00:04:21.620
The way that I did it here is
making a new CharacterTextSplitter.

87
00:04:23.390 --> 00:04:26.935
And for the separator I looked
at the transcript data and

88
00:04:26.935 --> 00:04:31.914
it's not like a story someone wrote so
there isn't like proper punctuation,

89
00:04:31.914 --> 00:04:35.660
it's always gonna be a period and
it ends the space.

90
00:04:35.660 --> 00:04:39.881
So I just decided to split it on a word or
like an empty space like this sounds like,

91
00:04:39.881 --> 00:04:42.320
all right,
split on an empty word basically.

92
00:04:43.840 --> 00:04:46.420
And then what is the chunk size?

93
00:04:46.420 --> 00:04:49.930
So the chunk size is like
how many tokens per chunk?

94
00:04:49.930 --> 00:04:52.713
I played around with this on
this transcript before and

95
00:04:52.713 --> 00:04:56.827
like 2500 seems to be like, big enough
that like there's enough context and

96
00:04:56.827 --> 00:05:00.760
a chunk but not so
small that there's a lot of these chunks.

97
00:05:00.760 --> 00:05:02.140
So I did that.

98
00:05:02.140 --> 00:05:06.630
And then overlap is,
how many tokens should these overlap?

99
00:05:06.630 --> 00:05:09.550
So, let's say I made three
chunks out of this whole thing.

100
00:05:09.550 --> 00:05:14.110
You're not just gonna cut it in three
pieces, you're gonna cut one into a third.

101
00:05:14.110 --> 00:05:16.957
And then like the last 200,
if I put 200 here,

102
00:05:16.957 --> 00:05:19.870
the last 200 of those tokens
at the end of that chunk

103
00:05:19.870 --> 00:05:23.980
are gonna be the first 200 tokens or
the big beginning of the next chunk.

104
00:05:23.980 --> 00:05:26.050
So there's some overlap there.

105
00:05:26.050 --> 00:05:28.320
And then that kind of
helps it search better.

106
00:05:28.320 --> 00:05:31.883
If those things just like cut
off that way, you might cut off

107
00:05:31.883 --> 00:05:36.600
something in the middle of the context
that's needed to answer the question.

108
00:05:36.600 --> 00:05:41.154
So like, imagine it got split right in the
middle of the sentence where it decides to

109
00:05:41.154 --> 00:05:43.590
like teach you how to turn off an Xbox.

110
00:05:43.590 --> 00:05:46.261
So if you said, okay,
how do I turn off an Xbox?

111
00:05:46.261 --> 00:05:50.485
Well, it doesn't actually know the full
way because you split it right on that

112
00:05:50.485 --> 00:05:54.273
part and it only knows part of it,
so it can't give you a right answer.

113
00:05:54.273 --> 00:05:55.639
But if you did a overlap,

114
00:05:55.639 --> 00:06:00.126
it might find that like, I need this chunk
and this chunk to answer this question

115
00:06:00.126 --> 00:06:03.730
because the beginning part
is at the end of this chunk.

116
00:06:03.730 --> 00:06:05.520
And the end part is
the beginning of this chunk.

117
00:06:05.520 --> 00:06:07.780
So combine them together and
then send that.

118
00:06:07.780 --> 00:06:11.876
So it's pretty complicated, but it's
basically we're trying to find a way to

119
00:06:11.876 --> 00:06:16.870
only send the information that's needed
to answer the question and nothing more.

120
00:06:16.870 --> 00:06:18.280
And it's just like a pseudoscience.

121
00:06:18.280 --> 00:06:20.598
So you can play around with these numbers,
but

122
00:06:20.598 --> 00:06:23.980
this is what I found that worked good for
this transcript.

123
00:06:23.980 --> 00:06:26.970
There's probably a better way.

124
00:06:26.970 --> 00:06:27.880
Okay, I guess 100 there.

125
00:06:27.880 --> 00:06:29.710
Let's do 100.

126
00:06:29.710 --> 00:06:32.760
Okay, so we have that.

127
00:06:32.760 --> 00:06:34.408
That's our docs from YouTube.

128
00:06:34.408 --> 00:06:36.100
The next thing, yes.

129
00:06:36.100 --> 00:06:40.130
&gt;&gt; How does our local code know what
chunk to send based on the prompt?

130
00:06:40.130 --> 00:06:43.573
Would that already require some
interpretation of the prompt like running

131
00:06:43.573 --> 00:06:44.750
through a model?

132
00:06:44.750 --> 00:06:46.404
&gt;&gt; You already know how to do this.

133
00:06:46.404 --> 00:06:49.609
This is what is the same process
that the semantic search did.

134
00:06:49.609 --> 00:06:51.836
We're gonna take those chunks,
convert them the vectors.

135
00:06:51.836 --> 00:06:55.030
We're gonna take the question
that someone's asking,

136
00:06:55.030 --> 00:06:59.419
convert that to a vector and we're gonna
find the chunks in the vector database

137
00:06:59.419 --> 00:07:03.768
that most likely sounds similar to
the question vector that you're asking.

138
00:07:03.768 --> 00:07:06.940
And those are the ones we're going
to return to the completion.

139
00:07:06.940 --> 00:07:08.430
So that's what this is for.

140
00:07:08.430 --> 00:07:10.473
That's why I said it's
very similar to searching,

141
00:07:10.473 --> 00:07:12.410
as in we turn everything to vectors.

142
00:07:12.410 --> 00:07:16.376
It's just instead of finding the search
results, we're finding the closest chunks,

143
00:07:16.376 --> 00:07:19.610
and only the chunks that are necessary
to answer this question.

144
00:07:19.610 --> 00:07:20.893
That's basically what we're doing.

145
00:07:25.582 --> 00:07:26.247
Okay, cool.

146
00:07:26.247 --> 00:07:28.890
So let's do the same thing,
but for the PDF.

147
00:07:28.890 --> 00:07:33.034
So we'll say docsFromPDF,

148
00:07:36.341 --> 00:07:41.859
And we'll say a loader is a new PDFLoader

149
00:07:41.859 --> 00:07:46.390
like this and it takes in a path.

150
00:07:46.390 --> 00:07:48.253
In this case, it's just xbox.pdf.

151
00:07:48.253 --> 00:07:50.060
That's on the root of this file.

152
00:07:50.060 --> 00:07:50.825
So I can just type that in.

153
00:07:54.821 --> 00:07:58.680
Okay, and then same thing, loadAndSplit.

154
00:07:58.680 --> 00:08:02.690
I think this one is, this one was
written with intent to be read.

155
00:08:02.690 --> 00:08:04.340
So the punctuation is a little different.

156
00:08:04.340 --> 00:08:07.976
So I can actually just like, I looked
at it and it's like, you can probably

157
00:08:07.976 --> 00:08:12.080
safely split on a period and a space,
which means the sentence is over.

158
00:08:12.080 --> 00:08:13.300
A new sentence is about to start.

159
00:08:13.300 --> 00:08:15.510
So you should never be splitting
in the middle of a sentence.

160
00:08:15.510 --> 00:08:18.846
Whereas like with a transcript,
there was really no good way to do

161
00:08:18.846 --> 00:08:22.381
that because [LAUGH] the punctuation
was just like all over the place.

162
00:08:22.381 --> 00:08:28.444
So like I said, it's, it's always
different depending on the data so

163
00:08:28.444 --> 00:08:33.916
and then loadAndSplit,
you got a new CharacterTextSplitter.

164
00:08:33.916 --> 00:08:39.209
We have a separator,
which I did a period like that and

165
00:08:39.209 --> 00:08:43.455
then chunk size I had 2500 and 200.

166
00:08:43.455 --> 00:08:44.601
So 2500 on this.

167
00:08:44.601 --> 00:08:46.862
It's a lot of data on this PDF actually.

168
00:08:46.862 --> 00:08:49.830
And then chunkOverlap, 200.

169
00:08:58.221 --> 00:09:02.685
Cool, now what we wanna do is
we wanna create our store and

170
00:09:02.685 --> 00:09:07.242
parse in all those docs,
because right now this is going to

171
00:09:07.242 --> 00:09:11.850
create a list of docs,
just like we did on the search.

172
00:09:11.850 --> 00:09:14.710
This is going to create a list of docs,
just like we did on the search.

173
00:09:14.710 --> 00:09:17.940
So, let's parse those in.

174
00:09:17.940 --> 00:09:19.960
And before that,
I'll kind of log them out.

175
00:09:19.960 --> 00:09:21.540
So you can kind of see
what they look like.

176
00:09:21.540 --> 00:09:22.400
I think it'll be interesting.

177
00:09:22.400 --> 00:09:23.769
So let's do that.

178
00:09:23.769 --> 00:09:26.719
So let's make a store loadStore,

179
00:09:26.719 --> 00:09:31.919
that's gonna be async because
we got to await these things.

180
00:09:31.919 --> 00:09:35.188
We can do them in parallel too but
it's not a big deal.

181
00:09:35.188 --> 00:09:39.006
So I'll say, how do I do it here,
videoDocs, pdfDocs.

182
00:09:39.006 --> 00:09:44.355
Okay, so
videoDocs = await docsFromYTVideo,

183
00:09:44.355 --> 00:09:47.360
I parse in the video there.

184
00:09:48.570 --> 00:09:52.819
And then pdfDocs is await

185
00:09:52.819 --> 00:09:57.477
docsFromPDF, like that.

186
00:09:57.477 --> 00:10:04.715
And I'm just going to return,
CreateStore with a new array,

187
00:10:04.715 --> 00:10:10.603
parse in those videoDocs, and
then parse in those pdfDocs.

188
00:10:15.608 --> 00:10:20.968
Order doesn't really matter cuz once they
get inside the store and index and put

189
00:10:20.968 --> 00:10:26.900
on that multidimensional plane, it doesn't
matter what order they are in this array.

