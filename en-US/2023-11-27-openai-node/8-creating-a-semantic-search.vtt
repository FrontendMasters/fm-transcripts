WEBVTT

1
00:00:00.000 --> 00:00:05.202
We left off talking about semantic search,
what it is,

2
00:00:05.202 --> 00:00:11.080
how embeddings and vectors work,
gave some examples on that.

3
00:00:11.080 --> 00:00:15.223
Like I said, this is not something
that you need to know, but

4
00:00:15.223 --> 00:00:19.784
it is definitely worth exploring
a little bit if you have the time.

5
00:00:19.784 --> 00:00:24.354
It's pretty cool how this math works and
seeing how it's basically

6
00:00:24.354 --> 00:00:28.939
the language behind systems like
these AI models understand data.

7
00:00:28.939 --> 00:00:32.404
It's cool for you to be able to
speak that language as well, so.

8
00:00:32.404 --> 00:00:36.167
But there's enough here for
us to continue to move forward, and

9
00:00:36.167 --> 00:00:39.730
now I want to actually create
a semantic search experience.

10
00:00:39.730 --> 00:00:40.875
So let's write some code.

11
00:00:40.875 --> 00:00:46.123
So what we're gonna make here is
a movie recommendation semantic search.

12
00:00:46.123 --> 00:00:50.428
So basically, there's gonna be a list of
movies in which this search engine is

13
00:00:50.428 --> 00:00:51.743
going to be indexed on.

14
00:00:51.743 --> 00:00:56.720
And you can type in the type of
movie that you want to watch,

15
00:00:56.720 --> 00:00:59.981
and it will recommend a movie for you.

16
00:00:59.981 --> 00:01:05.679
So, a regular search engine might require
you to type in a matching title or

17
00:01:05.679 --> 00:01:10.745
any other metadata associated
with that movie, like a director,

18
00:01:10.745 --> 00:01:14.831
an author, a category,
a year that it was released.

19
00:01:14.831 --> 00:01:18.038
So if you knew some of these
things you could find the movie or

20
00:01:18.038 --> 00:01:22.419
may be they were smart enough to have the
descriptions of the movies written out.

21
00:01:22.419 --> 00:01:26.750
So therefore if you type some word that
is in that body of text description,

22
00:01:26.750 --> 00:01:27.799
it might find it.

23
00:01:27.799 --> 00:01:29.924
It almost feels semantic.

24
00:01:29.924 --> 00:01:34.828
But what if you wanted to describe in your
own words the type of movie you wanted

25
00:01:34.828 --> 00:01:38.299
to watch, and
none of the descriptions in the movies or

26
00:01:38.299 --> 00:01:42.306
index had those words exactly,
but they had similar meaning?

27
00:01:42.306 --> 00:01:45.870
Okay, this is where semantics
search will come in so

28
00:01:45.870 --> 00:01:49.677
it can help us find things that
are similar in context and

29
00:01:49.677 --> 00:01:54.310
feeling verses just being lthe
string matches the string, right?

30
00:01:54.310 --> 00:01:58.775
So, Yeah, I mean I have a paragraph here

31
00:01:58.775 --> 00:02:02.345
describing how this will work in a
traditional search but here is an example.

32
00:02:02.345 --> 00:02:07.918
So, for instance, if we were looking for
a movie that was kinda Inception, right?

33
00:02:07.918 --> 00:02:11.814
If you had a traditional search, you can
type in Inception and it would just return

34
00:02:11.814 --> 00:02:15.558
all the titles of the movies that have
inception in them, literally the word.

35
00:02:15.558 --> 00:02:18.585
But with a semantic search,
we can type in inception.

36
00:02:18.585 --> 00:02:22.229
And it would understand the deeper
themes and vibes of inception.

37
00:02:22.229 --> 00:02:27.135
So it would know that dream,
manipulation, layered realities,

38
00:02:27.135 --> 00:02:31.427
a heist mind-bending plots,
it would know all that, and

39
00:02:31.427 --> 00:02:36.596
it could recommend movies that have
the same semantics as inception,

40
00:02:36.596 --> 00:02:38.899
and not just the title itself.

41
00:02:38.899 --> 00:02:40.696
Does that make sense?

42
00:02:40.696 --> 00:02:47.647
Okay, so you might get back some
results if you typed in inception.

43
00:02:47.647 --> 00:02:50.813
You might get back The Matrix because
it deals with alternate realities.

44
00:02:50.813 --> 00:02:52.226
You might get back Shutter Island.

45
00:02:52.226 --> 00:02:53.508
It's a mind-bending plot.

46
00:02:53.508 --> 00:02:55.235
You get it.

47
00:02:55.235 --> 00:03:01.391
So some of the benefit of this is that
it's just more in line with expectations

48
00:03:01.391 --> 00:03:06.896
of what someone is thinking about
when I type something in like that.

49
00:03:06.896 --> 00:03:13.122
It would suck to type in,
I wanna see a really funny horror movie.

50
00:03:13.122 --> 00:03:16.025
And then you just get back
really scary horror movies.

51
00:03:16.025 --> 00:03:17.400
[LAUGH] That's not what
you were looking for.

52
00:03:17.400 --> 00:03:19.546
So this help you understand that.

53
00:03:19.546 --> 00:03:23.121
It's great for discoverability because
now because everything is semantically

54
00:03:23.121 --> 00:03:25.462
related, it helps you
discover things a lot better.

55
00:03:25.462 --> 00:03:29.415
So semantic search is actually great for
a discover engine, in my opinion.

56
00:03:29.415 --> 00:03:30.837
It's one of the best use cases.

57
00:03:30.837 --> 00:03:32.831
Yeah, I just make sure user's happy.

58
00:03:32.831 --> 00:03:35.135
So let's get started with that.

59
00:03:35.135 --> 00:03:41.180
I'm gonna make a new file here,
we'll call it Search like this.

60
00:03:41.180 --> 00:03:47.291
We're gonna import our OpenAI
from the file that we created.

61
00:03:47.291 --> 00:03:51.417
If you didn't create the file,
then you just have to make a new open,

62
00:03:51.417 --> 00:03:54.630
OpenAI instance and
do the API key and all that stuff.

63
00:03:54.630 --> 00:03:56.939
So it should be good there.

64
00:03:56.939 --> 00:03:59.490
I don't have to do .EMV because
it's already done here.

65
00:03:59.490 --> 00:04:02.953
So we're good there.

66
00:04:02.953 --> 00:04:04.696
And then we need to install something.

67
00:04:04.696 --> 00:04:08.273
So I talked a little bit about LangChain,
we're actually gonna use it now.

68
00:04:08.273 --> 00:04:13.302
So we're gonna install this package called
LangChain, which, again, is like an SDK.

69
00:04:13.302 --> 00:04:15.185
That's like a wrapper for LLM.

70
00:04:15.185 --> 00:04:19.641
If you wanna build LLM into your
application, I would say today,

71
00:04:19.641 --> 00:04:24.108
LangChain is probably the most
sophisticated library for that.

72
00:04:24.108 --> 00:04:26.971
And they handle a lot of different things.

73
00:04:26.971 --> 00:04:32.182
Now I think a lot of people are finding
that they probably would do a lot of this

74
00:04:32.182 --> 00:04:37.406
stuff natively when it comes to like
interacting with the LMSs themselves.

75
00:04:37.406 --> 00:04:42.360
Because like I was saying earlier on the
break that I think l chain is helpful but

76
00:04:42.360 --> 00:04:47.011
then eventually you get to the point
where you have to learn how L chain does

77
00:04:47.011 --> 00:04:50.112
things and that mechanism and
how to learn it is.

78
00:04:50.112 --> 00:04:52.979
It's probably worth just learning how to
do it without LangChain at that point.

79
00:04:52.979 --> 00:04:54.227
It's very specific.

80
00:04:54.227 --> 00:04:58.273
But there are things that are very obvious
without a lot of documentation, and

81
00:04:58.273 --> 00:05:00.369
we're gonna use those obvious things.

82
00:05:00.369 --> 00:05:03.050
So, in this case, let's install LangChain.

83
00:05:06.527 --> 00:05:09.350
And they have a Python library.

84
00:05:09.350 --> 00:05:10.492
They have a JavaScript version.

85
00:05:10.492 --> 00:05:12.466
We're obviously using
the JavaScript version.

86
00:05:12.466 --> 00:05:15.798
I think the Python version might be
slightly ahead of the JavaScript version.

87
00:05:15.798 --> 00:05:20.766
So, there's typically newer things on that
version than a JavaScript version, but

88
00:05:20.766 --> 00:05:23.534
for the most part,
it's like feature parody.

89
00:05:23.534 --> 00:05:26.452
And the three things we want to
give is we wanna get document,

90
00:05:26.452 --> 00:05:28.869
memory vector, store,
and OpenAI embeddings.

91
00:05:28.869 --> 00:05:31.352
So, we've talked about two
of these things already.

92
00:05:31.352 --> 00:05:38.813
So, for a document, let's see,
that's from LangChain/, where is that?

93
00:05:38.813 --> 00:05:40.505
Document, I guess that makes sense.

94
00:05:43.253 --> 00:05:50.298
And then for the memory vectors,
it's not gonna auto-complete it for me.

95
00:05:50.298 --> 00:05:51.845
I thought it was.

96
00:05:51.845 --> 00:05:56.577
That's gonna be from LangChain,
the vector stores, and then, yeah.

97
00:05:56.577 --> 00:06:01.635
So for that, it's going to be
LangChain/vectorstores/memory.

98
00:06:01.635 --> 00:06:04.786
I don't know why it's doing that, and
then we can get the MemoryVectorStore.

99
00:06:04.786 --> 00:06:05.977
It's exactly what it sounds like.

100
00:06:05.977 --> 00:06:08.413
It's an in-memory vectorstore.

101
00:06:08.413 --> 00:06:11.881
Otherwise, we have to either
connect to something hosted.

102
00:06:11.881 --> 00:06:12.640
It's a database.

103
00:06:12.640 --> 00:06:16.273
You either gotta go find a hosted
one to connect to, download one, or

104
00:06:16.273 --> 00:06:17.723
use Docker and spin up one.

105
00:06:17.723 --> 00:06:20.162
We're not doing all that,
we're just gonna do it in memory.

106
00:06:20.162 --> 00:06:20.985
It's way easier.

107
00:06:20.985 --> 00:06:22.872
We don't need to persist
this across anything.

108
00:06:22.872 --> 00:06:26.790
But obviously, in production,
you would not do this in memory, right?

109
00:06:26.790 --> 00:06:28.657
And then OpenAI embeddings.

110
00:06:28.657 --> 00:06:32.764
So this is the thing that's gonna create
the embeddings for us using OpenAI.

111
00:06:32.764 --> 00:06:36.837
So up until this point, we've been
using OpenAI just to do completions,

112
00:06:36.837 --> 00:06:39.938
which is like give me an answer
to this question or chat.

113
00:06:39.938 --> 00:06:45.110
But OpenAI also has an embeddings
endpoint where you can

114
00:06:45.110 --> 00:06:50.072
send it data and
it will return the embeddings for it.

115
00:06:50.072 --> 00:06:51.942
So that's very convenient.

116
00:06:51.942 --> 00:06:53.630
It also costs money per token.

117
00:06:53.630 --> 00:06:56.258
So we will be doing the OpenAI embedding.

118
00:07:00.862 --> 00:07:03.316
And then from there you just
wanna copy this movie data.

119
00:07:03.316 --> 00:07:05.990
This is the data that we'll be indexing.

120
00:07:05.990 --> 00:07:08.357
So I have it all here for you to copy it.

121
00:07:08.357 --> 00:07:12.264
Okay, it's just literally
an array of movies.

122
00:07:12.264 --> 00:07:14.425
My mouse is, okay, calm down.

123
00:07:14.425 --> 00:07:15.454
There we go.

124
00:07:15.454 --> 00:07:16.056
There we go.

125
00:07:16.056 --> 00:07:17.404
So, we have our movies here.

126
00:07:17.404 --> 00:07:19.131
Like I said,
it's just an array of objects.

127
00:07:19.131 --> 00:07:22.231
It's just the idea, title,
description of some movies.

128
00:07:22.231 --> 00:07:23.613
Feel free to add some more movies here.

129
00:07:23.613 --> 00:07:24.440
Take away some movies.

130
00:07:24.440 --> 00:07:25.551
There's no right or wrong here.

131
00:07:25.551 --> 00:07:28.843
This is just some stuff saving you
some time from writing things, but

132
00:07:28.843 --> 00:07:30.219
that's an array of movies.

133
00:07:30.219 --> 00:07:31.291
You get the point.

134
00:07:35.165 --> 00:07:39.863
And then basically what we wanna do is
first we need to create a function that

135
00:07:39.863 --> 00:07:41.590
creates our vector store.

136
00:07:41.590 --> 00:07:45.164
We have to create it with
that index of movies.

137
00:07:45.164 --> 00:07:49.224
And there's some things to think
about to consider when doing that,

138
00:07:49.224 --> 00:07:51.536
and I'll talk about them a little bit.

139
00:07:51.536 --> 00:07:54.734
I'll get into more of it when I talk
about scaling it, but let's do that.

140
00:07:54.734 --> 00:08:00.222
So let's make a function
called createStore.

141
00:08:00.222 --> 00:08:07.100
And it's just going to return
the memory vector store from documents.

142
00:08:07.100 --> 00:08:10.558
So we'll just say,
MemoryVectorStore.fromDocuments, and

143
00:08:10.558 --> 00:08:12.034
there's different ways.

144
00:08:12.034 --> 00:08:15.221
There's from Text,
fromExistingIndex, fromDocuments.

145
00:08:15.221 --> 00:08:17.621
We're gonna say fromDocuments, and

146
00:08:17.621 --> 00:08:21.297
then it takes an array of
documents that you wanna create.

147
00:08:21.297 --> 00:08:23.328
So we have an array of movies here.

148
00:08:23.328 --> 00:08:27.051
What we need to do is we need to convert
these movies over to these LangChain

149
00:08:27.051 --> 00:08:27.721
documents.

150
00:08:27.721 --> 00:08:32.579
A LangChain document is just an object
in a specific format that all of

151
00:08:32.579 --> 00:08:35.611
LangChains vector stores are expecting.

152
00:08:35.611 --> 00:08:36.659
That's the sweet thing about LangChain.

153
00:08:36.659 --> 00:08:39.656
It does normalize how you
can interact with vector.

154
00:08:39.656 --> 00:08:42.196
It doesn't matter what store
you use as long as you use

155
00:08:42.196 --> 00:08:43.616
the LangChain version of it.

156
00:08:43.616 --> 00:08:46.400
They all take the same input,
and that input as a document.

157
00:08:46.400 --> 00:08:50.021
So that's the beautiful thing about that,
as you can change out your stores without

158
00:08:50.021 --> 00:08:53.035
having to really change your code as
long as you always use documents.

159
00:08:53.035 --> 00:08:56.463
So we need to convert these
objects into documents.

160
00:08:56.463 --> 00:08:58.189
So let's do that.

161
00:08:58.189 --> 00:09:03.136
So inside of here,
I'm just going to just say,

162
00:09:03.136 --> 00:09:06.857
movies.map, map over the movie.

163
00:09:06.857 --> 00:09:08.214
I'm gonna get one movie here.

164
00:09:08.214 --> 00:09:12.191
And then what we wanna do is for each
one movie, we wanna create a document.

165
00:09:12.191 --> 00:09:13.939
A document basically has
like two properties on it.

166
00:09:13.939 --> 00:09:15.258
One is the page content.

167
00:09:15.258 --> 00:09:17.288
So you can think of this,

168
00:09:17.288 --> 00:09:22.524
this is the content that I wanna
turn into a vector, basically.

169
00:09:22.524 --> 00:09:25.735
This is the stuff that I want
to turn into a vector and

170
00:09:25.735 --> 00:09:30.603
put inside of a multi-dimensional space so
people can do queries around it.

171
00:09:30.603 --> 00:09:35.419
So whatever about this movie,
you want to be indexed.

172
00:09:35.419 --> 00:09:38.404
This is what you wanna put
in page content, right?

173
00:09:38.404 --> 00:09:43.959
And then metadata is like all
the stuff associated with this entity.

174
00:09:43.959 --> 00:09:46.371
That way when you show the search results,

175
00:09:46.371 --> 00:09:48.920
you can point to this
metadata as the source.

176
00:09:48.920 --> 00:09:50.515
This is how I figured this out.

177
00:09:50.515 --> 00:09:53.720
This is helpful for like imagine if each
one of these movie titles had a link that

178
00:09:53.720 --> 00:09:55.433
you can click on that will take you there.

179
00:09:55.433 --> 00:09:56.610
So I can put the link in here.

180
00:09:56.610 --> 00:10:00.070
So when I return the search results, I can
show you the link to go to you can click

181
00:10:00.070 --> 00:10:03.284
on it, right things like that, or
any other things associated with it.

182
00:10:03.284 --> 00:10:08.080
So it's like it's like the structured
content of the non-structured content that

183
00:10:08.080 --> 00:10:09.573
will be indexed, right?

184
00:10:09.573 --> 00:10:12.536
So page content is usually non-structured.

185
00:10:12.536 --> 00:10:16.056
And metadata is usually
the structured one that's not indexed,

186
00:10:16.056 --> 00:10:18.878
that's helpful after you find the results,
okay?

187
00:10:18.878 --> 00:10:19.719
So let's do that.

188
00:10:19.719 --> 00:10:20.688
So we have one movie.

189
00:10:20.688 --> 00:10:21.484
Yes?

190
00:10:21.484 --> 00:10:24.673
&gt;&gt; Can the metadata be used
in your initial query?

191
00:10:24.673 --> 00:10:27.514
Say like, give me everything
that matches this metadata and

192
00:10:27.514 --> 00:10:29.078
then do semantic beyond that or.

193
00:10:29.078 --> 00:10:34.149
&gt;&gt; Yeah, so it depends on the memory or
on the vector store.

194
00:10:34.149 --> 00:10:36.727
Some vector stores allow you
to do what's called filtering.

195
00:10:36.727 --> 00:10:40.525
So you can filter the documents
based off the metadata and

196
00:10:40.525 --> 00:10:43.787
then do the semantic search
on the page content.

197
00:10:43.787 --> 00:10:44.711
So it's great for that.

198
00:10:44.711 --> 00:10:47.685
So you won't need the AI for
the metadata filter.

199
00:10:47.685 --> 00:10:49.750
Yeah, but yeah, that depends on the store.

200
00:10:49.750 --> 00:10:51.819
Good question.

201
00:10:51.819 --> 00:10:54.263
Yeah, that's actually what
people are starting to do now.

202
00:10:54.263 --> 00:10:59.279
I think, like Algolia AI.

203
00:10:59.279 --> 00:11:00.515
I think that's what they're doing now.

204
00:11:00.515 --> 00:11:03.138
Yeah, with their neural search,
which is a combination of that.

205
00:11:03.138 --> 00:11:09.684
It's a combination of keywords and AI at
the same time or something like that.

206
00:11:09.684 --> 00:11:11.521
I haven't tried it out.

207
00:11:11.521 --> 00:11:12.073
Okay cool.

208
00:11:12.073 --> 00:11:15.471
So we got that,
we wanna return a new document.

209
00:11:15.471 --> 00:11:17.540
We got some page content here.

210
00:11:17.540 --> 00:11:20.552
And I mean,
there's really no right or wrong way.

211
00:11:20.552 --> 00:11:21.760
It's just unstructured content.

212
00:11:21.760 --> 00:11:23.072
I want people to look at the title.

213
00:11:23.072 --> 00:11:29.167
So I'll say Title, and I'll put
the movie title in here like that.

214
00:11:29.167 --> 00:11:33.311
And then I'll make a new line and
I'll just throw the description in here.

215
00:11:37.605 --> 00:11:38.507
Like that.

216
00:11:38.507 --> 00:11:39.805
That's my page content.

217
00:11:39.805 --> 00:11:44.469
Leave whatever you want, just unstructured
content that you want people to be able to

218
00:11:44.469 --> 00:11:45.912
semantically search on.

219
00:11:45.912 --> 00:11:51.129
And then metadata, you just literally
store the whole movie in here if you want.

220
00:11:51.129 --> 00:11:56.381
So I'll just say I'll make one call
like source so here's the idea of it.

221
00:11:56.381 --> 00:11:57.157
Like that.

222
00:11:57.157 --> 00:11:59.803
And then I mean, you could really just put
the whole movie in here if you want it.

223
00:11:59.803 --> 00:12:04.234
There really is no wrong answer
of how you wanna do that.

224
00:12:04.234 --> 00:12:05.651
Let me go back to what I had there.

225
00:12:05.651 --> 00:12:07.805
I think yeah,
I just put like the title in here.

226
00:12:07.805 --> 00:12:09.598
That way I can quickly
show you what that is.

227
00:12:09.598 --> 00:12:11.231
If I was making a UI, it might be helpful.

228
00:12:11.231 --> 00:12:14.459
Just be like, yeah,
here's the title of it.

229
00:12:14.459 --> 00:12:15.684
Something like that.

230
00:12:15.684 --> 00:12:20.166
Okay, cool, any questions on that?

231
00:12:20.166 --> 00:12:23.765
And there are some implications
of indexing this and

232
00:12:23.765 --> 00:12:28.832
we'll talk about it in the QA part,
the document QA, but it's not always

233
00:12:28.832 --> 00:12:33.929
gonna be this simple as like I can just
make documents and throw it in here.

234
00:12:33.929 --> 00:12:35.761
Cuz there's like context limits, and

235
00:12:35.761 --> 00:12:38.047
sometimes you can't index
things that are big.

236
00:12:38.047 --> 00:12:38.786
Yes?

237
00:12:38.786 --> 00:12:42.868
&gt;&gt; Just like we converted the objects
into LangChain documents here,

238
00:12:42.868 --> 00:12:46.102
can we do the same with a CSV
file with numerical data?

239
00:12:46.102 --> 00:12:52.905
For example, movie data, movie runtime,
amount of views, and most time viewed.

240
00:12:52.905 --> 00:12:56.621
&gt;&gt; 100%, not only can you do that
because it doesn't care where you

241
00:12:56.621 --> 00:13:00.547
get the data from, langchain was smart
enough to just make that for you.

242
00:13:00.547 --> 00:13:03.902
So, if you go to their docs and
you go to Retrieval,

243
00:13:03.902 --> 00:13:08.987
you go to Document loaders, you go to
Integrations, you go to File Loaders.

244
00:13:08.987 --> 00:13:14.080
There's a CSV file loader here that
literally takes a path to a CSV file,

245
00:13:14.080 --> 00:13:18.440
loads it up, and creates a list
of documents out of it for you.

246
00:13:18.440 --> 00:13:21.569
So yeah, you can do it manually,
you can use their loader.

247
00:13:21.569 --> 00:13:24.963
This is why I said this is the part
of LangChain that I like cuz it's

248
00:13:24.963 --> 00:13:29.560
very obvious and it has absolutely nothing
to do with, it's not specific to anything.

249
00:13:29.560 --> 00:13:32.089
It just loads up a file and
makes this array.

250
00:13:32.089 --> 00:13:32.714
That's great.

251
00:13:32.714 --> 00:13:33.958
So I'll use that.

252
00:13:33.958 --> 00:13:38.059
And I like using their interface with the
vector stores because it works very well

253
00:13:38.059 --> 00:13:38.671
with this.

254
00:13:38.671 --> 00:13:41.456
Everything else it's a little
difficult in my opinion.

255
00:13:44.678 --> 00:13:46.203
Cool, any other questions?

256
00:13:48.337 --> 00:13:53.673
Okay, and then the last thing we have
to pass as a second argument from

257
00:13:53.673 --> 00:13:59.653
documents functions, we have to pass
in the embeddings function that we want

258
00:13:59.653 --> 00:14:05.087
the vector store to use to convert
all of these into embeddings for us.

259
00:14:05.087 --> 00:14:06.850
It's gonna do that for us, right?

260
00:14:06.850 --> 00:14:09.874
It's gonna make the API call to OpenAI for
us and

261
00:14:09.874 --> 00:14:12.904
convert all these
documents into embeddings.

262
00:14:12.904 --> 00:14:15.448
We just have to tell it.

263
00:14:15.448 --> 00:14:16.581
It's agnostic.

264
00:14:16.581 --> 00:14:19.698
It's not stuck on OpenAI's embedding API.

265
00:14:19.698 --> 00:14:22.650
It can use anything that
follows a certain structure.

266
00:14:22.650 --> 00:14:27.010
So we're gonna use the one that they allow
us to use, which is the OpenAI embedding.

267
00:14:27.010 --> 00:14:29.601
So we've seen new OpenAI
embeddings like that.

268
00:14:29.601 --> 00:14:34.029
This is expecting you to have your
API key and the environment variable.

269
00:14:34.029 --> 00:14:36.082
If you don't,
you need to pass in your API key here.

270
00:14:38.056 --> 00:14:39.424
Like that.

271
00:14:39.424 --> 00:14:42.099
But I have my environment variables so
we're good.

272
00:14:42.099 --> 00:14:44.053
So without this,
it cannot create embeddings.

273
00:14:47.114 --> 00:14:49.298
Cool, any questions on that?

274
00:14:49.298 --> 00:14:50.496
There are also issues with this.

275
00:14:50.496 --> 00:14:51.400
There's rate limiting.

276
00:14:51.400 --> 00:14:53.289
You can only create so
many bettings at one time.

277
00:14:53.289 --> 00:14:59.072
So there are a lot of issues associated
with this that are very nuanced.

278
00:14:59.072 --> 00:15:01.519
So we'll talk about that later

