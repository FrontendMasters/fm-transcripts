[00:00:00]
>> Yeah, so that's basically it. All this other stuff doesn't really matter. We already kind of covered some of the stuff, you can look at it. But let's just dive into making a document QA. Like I said, it's very similar to semantic search. It just goes a step further, which makes it a little harder in my opinion but It's really powerful.

[00:00:19]
I kinda like the document QA. So, let's write some code here. I'm just gonna make a new file, I'm just gonna call this QA.js. What we're gonna do here on this one, I wanted kinda just to make it cool and just show different use cases. So, we're gonna do QA on two things.

[00:00:41]
One is gonna be a YouTube video. If you haven't watched the podcast episode that Friendly Masters had with Brian, he's another instructor here, Brian Holt. He's also like a really good friend of mine, funny guy. They did a podcast and it was really cool. And we're gonna take that video and we're gonna do QA on it.

[00:00:57]
So we can ask it questions about anything in that podcast, anything that was talked about. We can ask you questions, which is really cool. So if you really wanna get to know, Brian, it's actually going to be a great exercise. So we'll do that, and then I also wanna show off that like, it can index other things too.

[00:01:11]
So in the repo, if you go to the GitHub, there is a Xbox PDF here. If you click on it, there should be a download button here. Click that because we're going to do QA on the Xbox PDF as well. I think PDF is cool because it's not structured.

[00:01:28]
It's not like a CSV, it's not like a JSON file, I mean, look at this. What is this, right, this is basically unstructured content. We're gonna do QA over this, we're gonna teach the AI this PDF, so you can ask it questions, and then we're gonna put them in the same index.

[00:01:44]
And then we're gonna leave it up to the AI to figure out if we're asking questions about the podcast or if we're asking questions about the Xbox. And if those two things overlap, we're gonna get some interesting results. [LAUGH] If the Xbox starts talking about Brian or Frontendmasters or Brian starts talking about Xboxes, I don't know where we're gonna get back, I don't know.

[00:02:05]
So, yeah, pretty cool, so yeah, just download that and then just drag it into your file or to your repo here. Okay, so I got that PDF, got my qa.js, let's get to work. So first thing first, I'm gonna allow us to type in a question from the command line.

[00:02:24]
That way we have to keep coming here and writing the code. So we can do that but first, let's bring in our imports. So the first thing we I don't know why I didn't put the imports here, but that's all right. We're just gonna import openAI, like we always have from the file that we created unless you didn't create the file, that's fine.

[00:02:43]
Then we pretty much need the same thing Search has. I'm just gonna go to Search, I'm just gonna grab all that. We need the document, the VectorStore, and the OpenAI embeddings, just we need all those. Yeah, I think that's mostly it I don't think we need anything else.

[00:03:02]
Wait no we do need one more, we need what is it? So, it's import from Lang chain is it, yeah, we need a tech splitter, I wanna say it's from there. I'm gonna need the character tech splitter from lane chain tech splitter. We'll talk about that in a minute, and then we're gonna import two loaders, one to handle the PDF and one to handle the YouTube video.

[00:03:29]
So I think it's like lane chain, document loaders, yeah, what is this it is this is important so we're FS and then web and YouTube okay starting with loaders FS and then PDF for that and this is a PDF loader And for the YouTube loader it's gonna be linkchain slash document loader, slash web, slash YouTube, like that.

[00:04:08]
Let me get rid of that CJ s on that area, and then YouTube loader. Cool, so we got that. These two things the PDF loader and the YouTube loader depend on some NPM packages that we have to install. So let's install those packages are going to be, I don't think I wrote them down, so luckily they are here.

[00:04:36]
They're basically just gonna be this PDF parse, YouTube transcripts, and YouTube IJS. So we'll download PDF parse. We got that pdf-parse, we have YouTube-transcripts And then YouTube i.js. YouTubei, or I don't know what they're doing there, but we wanna install those. We won't be using them directly, the loaders will be using this.

[00:05:28]
And this is probably the most used thing I use from linkhain is the document loaders, because they have so many of these to go load things up. They have one that will crawl a website, they have one that will take a podcast. They have one that will take a voice file and convert that to text and load that.

[00:05:45]
Like, there's so many of them, and it's not even the biggest one. There's something called Llama Index that's even bigger. This one's insane they have tons of loaders on here I just want to see the page where they show the loaders because it's quite massive you should just have a page where it just shows you all the ones that they had.

[00:06:11]
But they do the same ones just even more but it's only the only problem with this one is it's mostly in. Wait, they have TypeScript now. I was gonna say it's mostly just in Python. Wow, they have JavaScript now? This is insane, man, I can't wait to use this.

[00:06:29]
But now I'm gonna show you the Llama Hub, here we go, okay. So these are all the document loaders that they have. So if you want to teach your AI about something and it's somewhere else, yeah, they have it. So what do you want, you got something in asana?

[00:06:49]
Here you go, what about being searched, you got it. [LAUGH] Dad jokes, there's one for dad jokes. I mean, there's just a bunch of stuff in here that you can use Gmail, GitHub repos, Google drives. I mean, if there's something that you can feed AI is probably on here.

[00:07:11]
And it's all like a standard interface, kind of like the document loaders that we're using now in link chain, so this is great. Now that they have TypeScript support, I'm really pumped because there's some really cool stuff in here like OCR, like this right here is like computer vision that can like read things like that's powerful.

[00:07:30]
It's just have this thing visually look at this thing and get the information from it, and then turn that into data that I can then now search on or QA on. It's crazy to think about that, there's so many things you can do. Yeah, so you can out for a little bit, but this is really cool.

[00:07:48]
But like I said, lane chain right now, that's what these document loaders are. They're like a smaller subset of that, and they have some really good ones too. All right, so we got those, let's make some things. Yeah, so first thing we wanna is, let's do this. Let's get our question, so our question is gonna be either process.argv2.

[00:08:14]
If you don't know what that means, that just means if I'm on the terminal, let's say I run this file, node QA, okay, this would be argv0, this would be argv1. And then anything after this would be arg v2. So whatever I type here, so I wanna capture that.

[00:08:34]
That's what that is, right? You wanna put that in quotes because if you don't put that in quotes, it's gonna take each one of these words is a different argument. You've got to put the whole thing in quotes, so it's just one argument. So this is argv2, this is me just collecting whatever the hell you typed after the second thing, okay?

[00:08:52]
So that's what that is or if you don't put anything, just hi or whatever you want as a default, and then here's the YouTube video to that podcast. I'm just gonna copy that. Click on it, you can clearly see it is that YouTube video there, so we're good, and next thing we wanna do is create a function that creates a store.

[00:09:17]
This should be very familiar, we just did this, right, so let's do that. CreateStore, it takes in some docs that are already formatted from somewhere else. And we're just gonna make our memory vector store from docs. And we're gonna pass in the docs, and then we're gonna pass in a new OpenAI embeddings, literally what we did before.

