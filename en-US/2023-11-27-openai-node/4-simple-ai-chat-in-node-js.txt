[00:00:00]
>> We also need to, wait, no, it's built in now. I was gonna say we need to install readline, but it's actually built into Node now, so we can just import readline like this. So we can say import readline from 'node:readline'. Okay, if you're looking like, what the hell is this?

[00:00:20]
If you've never seen that before, this is optional. This is something new in Node. This is basically saying, hey, I know that Node has some internal package called readline. That's the one that I wanna import. And the reason this is great is because there might be a package you installed called readline.

[00:00:39]
In fact, there was one. They had to rename it because Node made one. So if there's an internal thing called readline and there's also a package you have installed called readline, which one is it gonna import? I don't know. So, yeah, to get around that confusion, you do that.

[00:00:55]
So now it will always import the one that's internal to Node and not some third-party one that you installed. So you can actually put this node prefix on every internal module that Node has to force it to use that one versus trying to figure out whether it's got to import the one that's installed with the same name or the internal one.

[00:01:13]
Because some crazy person decided to name their NPM package the same name as an internal node package. Could you imagine NPM package called FS? Who would do that? That's crazy. But people do it. So, all right, we got that. Readline is just a way that allows us to, I don't know, write text in our terminal and see text output.

[00:01:36]
That's basically it, we're gonna use that. We already initialized this. We're good to go. So now we just need to make a new readline interface. So the way you can do that is, I'm just gonna say readline = create, oops, readline.createInterface, like this. And you can say input.

[00:01:57]
And for the input, basically we're gonna use process.stdin and then stdout. This is just basically, How a terminal handles input and handles output. It's like a pipe through which it can receive text, in which it can output text. We're basically binding that to the inputs and outputs here.

[00:02:19]
So input is stdin. Why did it bring that in like that? I didn't do process, that's right. Process.that and then I'll put, If I can type, is the process.stdout, like that. So cool, now that we have our interface. We can start making some chat stuff. So from there, what we wanna do is, I'm just gonna create a helper function that wraps a call to the OpenAI API to make a new message.

[00:03:05]
That way, we don't have to write this every single time when you wanna make a new message. I'm just gonna create a wrapper around that because that's annoying to write all the time. [LAUGH] So newNessage, it takes a message, right? And then from here, we're just gonna say, response or results, whatever you wanna call it.

[00:03:27]
This is gonna be async = await openai.chat.completions.create, all right? Also, because we need to pass in the entire history for everything, we're gonna take the history as well. So when we create this, we'll say model. I'm still gonna use gpt-3. You can literally use whatever you want. And then I'm going to pass in the messages here.

[00:04:04]
The messages are going to be a brand new array of everything that came before, so the history plus your new messages that you pass in, like this. New messages go on the end of the array, not the beginning. You would not get the results you wanted if you did that.

[00:04:25]
All right, follow me so far? Okay, and then yeah, we just wanna go ahead and just return the message object itself. So that's what I'll do. I'll say return results.choices[0]message. So basically the same thing we did in the index file, nothing different here at this point. But the next thing we need to do is need to create a loop that runs constantly, so we can keep having the conversation.

[00:05:03]
Whereas before on our previous example, we'd ask the question, then it will stop, the process will stop. But we want it to keep going. So we can keep the memory alive and we can keep having a conversation. So that's basically what we need to do next. But before we do that, I'm just gonna create a function that formats the user input that someone types in.

[00:05:25]
So we'll say const formatMessage. It takes in user inputs, which is just a string, right? And then it's just gonna return a new object here that has role of user and then content of the userInput, Like that. So if you're looking at, what is going on here? If this looks new to you, this is just me doing a implicit return.

[00:06:00]
If your arrow function only has one line of code, you don't have to put the return statement. And then because I wanna return an object, I can wrap it in a parentheses, so therefore I return an object. If I didn't have those parentheses, it's thinking I'm making a function body and I get a syntax error.

[00:06:17]
But if I put it in parentheses, I'm saying return this object. So it's just a little shortcut. Cool, everybody following me there? All right, so next thing is we just wanna create the main chat function, which is gonna be the thing that houses our loop. And this is where we try to keep things going.

[00:06:39]
So the way that that's gonna work, if you scroll down, this is where we're gonna keep our history, and then we're gonna have this start function here that is recursive. And this is how we recreate a loop. We're just gonna use recursion as a mechanism for keeping things going, and that's how it's gonna work.

[00:06:59]
So if you've never done recursion before, if you've done it, like, wow, when am I ever gonna use it? You're gonna use it right now. This is that one time ever in your life that you're gonna use recursion and it actually is beneficial. And hopefully, it won't crash your computer.

[00:07:11]
Well, I guess recursion never really crashes your computer because it reaches a call stack limit, whereas while loop would. So cool, okay, so let's do that. So const chat, And then underneath it, I'm just gonna call it chat eventually, like that. And then let's create our history, which is just an empty array.

[00:07:32]
But for now ,let's prime the system with a system message. So I'll say role: 'system'. Remember, this is the origin story of the AI. So we always gotta start off with that, the origin story. So role and content, and then put whatever you want here. I'm just gonna keep what I always put, You are an AI assistant.

[00:07:57]
Answer questions or else. I don't know, whatever you want to put there [LAUGH]. You put whatever you want, that's the beauty of it. I wonder what that's, I don't know what's gonna happen there, but I kinda threatened it a little bit, so we'll see. I might get moderated.

[00:08:15]
All right, so that's the back story. Let me put a y there. And we'll make another function here called start, Inside of chat. And then underneath that, I'll just kick it off by calling start. That's the loop, right? And then in here, what we wanna do specifically is, we wanna go ahead and do our readline.question.

[00:08:38]
What this is gonna do is it's gonna prompt a question in the terminal in which you can type something in. So let's do that. So I'll say rl.question. I'll prefix the question with You. So when we see it in a terminal, we can see that this is our message, and then we'll see the log for the AI's message.

[00:08:56]
So I'll say You, takes a callback, that's gonna be async, and you get back the user Input here, Like that. And then from this, we want a way to exit out of this when we're done, so I'm just making a handler for that. So if you type in the word exit, it'll close.

[00:09:21]
That's basically it. So what I'll say is, if (userInput.toLowerCase=== 'exit'), or whatever word you wanna use to close out of this, then you can say rl.close, and then this just return out of this. So this will end the session effectively, just by typing the word exit. And then from here, what we need to do is we need to format that userInput because userInput is just a string.

[00:09:54]
And we know that in order to send a message, it needs to be an object that has a role and a constant property. And we have that function called formatMessage that does just that. It takes a userInput and it converts it to the appropriate thing. So let's do that.

[00:10:06]
So I'll say, message = formatMessage, takes in the userInput, right? We got that? And then from there, what I wanna do is I want to call the OpenAI API with the current history, so everything that's been said thus far plus this new message, right? Then I wanna update my history with the new message that I sent plus the response that I got back.

[00:10:41]
There's a million ways to do this, so I'm just doing it this way. So I'll say response = await, what did I call it? newMessage, await newMessage. It takes in the current history we have here. It takes in the new message we wanna send, like that. So we get our response.

[00:11:02]
And then we wanna update our history, so I'll say history.push. I wanna push in first the message that we created from the userInput, that needs to happen first. And then I want to push in the response that we got back from OpenAI. So I'm just updating our history with that so that way when this happens again, when we pass in this history, it's been updated with these messages.

[00:11:26]
Which works because history is outside of the start function. It's in a closure, so it never gets erased because we're doing this inner function here. So we got a closure there. And then from there, obviously, we want to log what the AI is saying. That's the whole point.

[00:11:42]
So let's do that. Console.log, I'm gonna add in some new lines here so we can better see it. If you didn't know, backtick in means new line. Backtick in JavaScript means escape this character, which means don't literally show this character, it represents something else. So then I'll say AI, and then here we can put the result.

[00:12:08]
I'm actually just gonna use backticks here. And the response here should just be response.content, like that, okay? And then we need to run this again, so we gotta call start again right underneath it. So that's the recursive loop. We gotta run this again because now we want this to run again so we can ask another question.

[00:12:30]
If we don't do this again, we won't get prompted to ask another question. So we need to do that. And then, obviously, the initial kickoff is down here. There's many different ways to do recursion. I know the official way of this pattern, but it's just, I call the inner recursive function.

[00:12:47]
I mean, we could have made chat recursive, too, but then we'd have this issue with a history closure. We have to put it up here somewhere, and then probably make it an object. It gets weird. So there we go. Okay, cool, and then lastly, you can just put a log at the bottom before you call chat just so we know that, hey, it's ready to go.

[00:13:13]
And you can hit exit when you're done. Otherwise you're just looking at a blank terminal, and you won't know if it's working or not. Okay, let's try to run it, maybe it works the first time, maybe it doesn't. So I'll say node chat.js. And you can see right here, it says Chatbot initialized.

[00:13:38]
Type 'exit' in the chat. That's a good sign. And then now you can see it's prompting me to add something. So let's test this out. Hi, my name is Scott. I hit Enter, and it says, Hello, Scott! It's nice to meet you. How can I assist you today?

[00:13:53]
You can see now it's prompting me again. And I'll just attest it. What is my name? Your name is Scott. Okay, it remembers, we're good now. So now we have an AI chat interface that remembers things, whereas before, that was not the case. So this is a quick little ChatGPT in your terminal if you wanted to do something..

[00:14:20]
I actually made something like this similarly, and I use it over ChatGPT, cuz I just prefer using the terminal than I did going to the Web. This is just better for me, in my opinion, so cool. And then if you wanna exit, you can just type exit and then you're out.

[00:14:37]
So yeah, obviously, ChatGPT will be a little more nuanced as far as its features and stuff. But the main part of being able to chat to it, I mean, this is essentially it, right? And I think I'm gonna add some new lines here, so it's, right, not next to it.

[00:14:49]
But yeah, that's basically, and then eventually, like I said, you will hit this point depending on what model you choose, of it just won't remember anymore and you'll have to handle that. So that's a constraint. And then, well, I'll talk about some more of the constraints in the next point, but just wanna make sure I handled any questions here about this interface.

[00:15:12]
I think first time I did this, I thought, wow, this is not that hard, [LAUGH] this makes sense. Because doing something like this before GPT came along, forget about it, this was not gonna happen. Can you imagine that company, Intercom, having something like this when they first came out?

[00:15:30]
It would be insane. It would be unheard of. But it was just really hard to do that back then, if not impossible. And now, anyone with an API key can do this in, I don't know, 47 lines of code. [LAUGH] It's kinda nuts. And you don't need to know anything about linear algebra or matrix math, what you don't want to know about.

[00:15:53]
So I thought that was pretty intense.
>> What is the token count for this chat so far, 4,000?
>> The token count for this chat? Well, I know they're asking the limit for this model, but I don't know the exact limit of the 3.5 Turbo model, but I think it's less than 6k for sure.

[00:16:15]
If you wanted to see how much you've spent so far, inside of newMessage, you can just console.log results.usage. And you can look at it that way and then do math on every single message and you'll see how much your tokens were. So if I did this, hello, that's how many tokens..

[00:16:42]
We're using the prompt, completion, stuff like that. And then I'm like, ok, make me some food. Yeah, and it can't, obviously, it doesn't know how to make food, but we can teach it that. So yeah, you can just do that, and then over time, you just collect this and do math, and you can figure out what your cost is over the span of a conversation.

[00:17:07]

>> The OpenAI dashboard will give you a pretty real-time breakdown of your spend, too.
>> There you go, OpenAI dashboard, very good for that. But you shouldn't treat this as, if you ever did, I don't know, smart contracts, you gotta think about the cost of gas and slippage.

[00:17:26]
It's not that mindset. That is the difference between a dollar or a few thousands of dollars. This is the difference between a penny and a fraction of a penny. So it's not something you should think about. None of this stuff gets expensive until you reach critical scale. And for this case, I wouldn't imagine someone spending more than maybe a few cents today, and that's what if they went nuts.

[00:17:54]
So should be good.

