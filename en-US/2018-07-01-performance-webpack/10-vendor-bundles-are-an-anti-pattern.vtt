WEBVTT

1
00:00:00.360 --> 00:00:03.380
&gt;&gt; Speaker 1: Can you talk about
the trade offs between using

2
00:00:03.380 --> 00:00:07.580
vendor bundles versus code splitting
entirely by the client's route?

3
00:00:08.640 --> 00:00:15.972
&gt;&gt; Sean Larkin: [LAUGH], yes, so 
vendor bundles are a big anti-pattern

4
00:00:15.972 --> 00:00:20.230
To me this is why in Web Pack
4 we got rid of commons chunk.

5
00:00:20.230 --> 00:00:24.084
Because so many people were,
and no offense to the person,

6
00:00:24.084 --> 00:00:27.180
who was it who asked me earlier,
or yesterday?

7
00:00:27.180 --> 00:00:31.900
I'm not painting you as this person, but
we had so many people who would obsess.

8
00:00:31.900 --> 00:00:37.094
Like, I can't synthetically get these
three modules to be in this one bundle,

9
00:00:37.094 --> 00:00:38.886
and by using common chunk.

10
00:00:38.886 --> 00:00:39.728
It caused so

11
00:00:39.728 --> 00:00:45.220
many people to froth at the mouth obsessed
about trying to optimize caching.

12
00:00:46.400 --> 00:00:51.153
But when we go back to my slides,

13
00:00:51.153 --> 00:00:55.036
what are the three costs?

14
00:00:55.036 --> 00:00:59.569
The number, the top three
costs of loading are actually

15
00:00:59.569 --> 00:01:04.489
the amount of JavaScript that
you have to parse, evaluate,

16
00:01:04.489 --> 00:01:08.460
and execute for
your initial download, right?

17
00:01:10.310 --> 00:01:11.460
By caching,

18
00:01:11.460 --> 00:01:15.160
you're only saving yourself the network
time it takes to get that file.

19
00:01:16.270 --> 00:01:18.870
In some browsers,
you might get byte code caching, but

20
00:01:18.870 --> 00:01:22.500
that's just parse cost,
that's not eval and execute.

21
00:01:22.500 --> 00:01:30.638
So you're doing yourself very little
favors by trying to optimize for caching.

22
00:01:30.638 --> 00:01:34.847
Versus trying to optimize for the smallest
amount of code that you actually need on

23
00:01:34.847 --> 00:01:37.170
your initial download of your page, right?

24
00:01:38.220 --> 00:01:42.690
So what you would find out is that
by trying to do a bunch of caching,

25
00:01:42.690 --> 00:01:44.540
you end up with these ginormous bundles.

26
00:01:44.540 --> 00:01:49.767
That you force entry points
to ship down the pipe,

27
00:01:49.767 --> 00:01:53.505
right, on your initial download.

28
00:01:53.505 --> 00:01:58.912
So I shouldn't discount caching as
an optimization, it is still valuable,

29
00:01:58.912 --> 00:02:02.834
but what I tend to say, and
maybe this is a little brash.

30
00:02:02.834 --> 00:02:07.340
But it's like, come talk to me
about caching when you get to 300

31
00:02:07.340 --> 00:02:11.020
kilobytes of code on
your initial download.

32
00:02:11.020 --> 00:02:13.650
And then we can take it a step further,
right?

33
00:02:13.650 --> 00:02:20.170
Because this is what's gonna
save you tens of seconds.

34
00:02:20.170 --> 00:02:22.991
Seven seconds on your load time,

35
00:02:22.991 --> 00:02:28.930
where caching is gonna maybe
save you 400 milliseconds.

36
00:02:28.930 --> 00:02:32.050
So, that's why we removed commons junk.

37
00:02:32.050 --> 00:02:36.250
That's why we do it by default now out of
the box for only asynchronous bundles.

