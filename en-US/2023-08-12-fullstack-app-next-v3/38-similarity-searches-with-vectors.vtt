WEBVTT

1
00:00:00.180 --> 00:00:02.290
Let's get started.

2
00:00:02.290 --> 00:00:04.300
So where's my GitHub?

3
00:00:04.300 --> 00:00:06.372
There we go.
Okay, so if we go into the AI one,

4
00:00:06.372 --> 00:00:09.927
I also don't have this one open because
there is a lot going on here and

5
00:00:09.927 --> 00:00:12.530
I want to make sure I get it
exactly the way I had it.

6
00:00:14.110 --> 00:00:18.310
So the first thing is if we go into our
AI, we have our function called QA.

7
00:00:18.310 --> 00:00:19.610
QA just needs to take two things.

8
00:00:19.610 --> 00:00:24.038
It needs to take the question that
you're asking and then all the entries.

9
00:00:24.038 --> 00:00:28.774
Cuz we have to index, we have to put all
the entries in the memory database cuz

10
00:00:28.774 --> 00:00:30.920
we're doing in memory database.

11
00:00:30.920 --> 00:00:34.795
If this was like a hosted database, we
won't have to take the entries every time,

12
00:00:34.795 --> 00:00:38.405
we'll just index them every time we
save them in our planet scale database.

13
00:00:38.405 --> 00:00:40.813
Every time they get saved
in the planet scale,

14
00:00:40.813 --> 00:00:43.420
also save it in the vector database.

15
00:00:43.420 --> 00:00:46.130
But we don't have a hosted vector
database, in memory database.

16
00:00:46.130 --> 00:00:48.920
So we have to create it every
single time we ask a question.

17
00:00:50.680 --> 00:00:53.016
So we'll take the entries, and
then basically what we wanna do,

18
00:00:53.016 --> 00:00:54.970
I'll just kind of give
an overview of everything, and

19
00:00:54.970 --> 00:00:58.260
then we'll talk about the specifics
of what's actually happening.

20
00:00:58.260 --> 00:01:02.020
We want to turn everything into
what's called a langchain document.

21
00:01:02.020 --> 00:01:05.960
Nothing fancy about it's just
an object that represents some string.

22
00:01:05.960 --> 00:01:09.257
And you can add metadata to it like
where it came from when it was created,

23
00:01:09.257 --> 00:01:10.700
whatever you want.

24
00:01:10.700 --> 00:01:15.187
This is helpful if you wanna have
the AI cite sources on where it learned

25
00:01:15.187 --> 00:01:17.110
information from.

26
00:01:17.110 --> 00:01:19.900
Because some, that's very beneficial.

27
00:01:19.900 --> 00:01:23.690
If you ask AI question and you say,
can you cite where you learned that from?

28
00:01:23.690 --> 00:01:26.610
So you can put that metadata
in your document so it can use

29
00:01:26.610 --> 00:01:30.851
sites to understand where it came from so
you know it's not just making up stuff.

30
00:01:30.851 --> 00:01:32.227
Or like where did you get that from?

31
00:01:32.227 --> 00:01:33.696
Really cool.

32
00:01:33.696 --> 00:01:36.649
So we'll take that, then what
we'll do is we'll create a model,

33
00:01:36.649 --> 00:01:38.770
from there we'll do this
thing called a chain.

34
00:01:38.770 --> 00:01:42.560
We'll talk about a chain in a minute,
chain inside of Lang chain,

35
00:01:42.560 --> 00:01:46.501
we'll create embeddings,
embeddings are just a group of vectors.

36
00:01:48.626 --> 00:01:52.410
And then we'll store those documents
in our memory vector database.

37
00:01:53.780 --> 00:01:57.337
We'll perform that similarity search
that I talked about where we take your

38
00:01:57.337 --> 00:02:00.670
question, turn it into a vector,
plot it, grab all the similar ones,

39
00:02:00.670 --> 00:02:02.244
come back with the similar ones.

40
00:02:02.244 --> 00:02:08.071
And then we'll do our a API call
to the AI and get back our result.

41
00:02:10.516 --> 00:02:12.660
Cool, so let's do that.

42
00:02:12.660 --> 00:02:15.680
So the first thing is let's take our
entries and turn them into docs.

43
00:02:15.680 --> 00:02:20.922
So we'll say docs = entries.map,

44
00:02:20.922 --> 00:02:24.479
and we get an entry here.

45
00:02:26.920 --> 00:02:32.800
And basically we wanna return a new
document that we can get from langchain.

46
00:02:32.800 --> 00:02:35.108
Let's see if it auto-completes it for
me, and

47
00:02:35.108 --> 00:02:37.660
I don't know why the autocomplete
pulls from Dist.

48
00:02:38.980 --> 00:02:40.740
Let's see if it pulls from anywhere else.

49
00:02:40.740 --> 00:02:44.595
It must be like lang chains,
the way they set their thing up, because

50
00:02:44.595 --> 00:02:49.131
the autocomplete never works for their
stuff but I'm pretty sure it comes from-

51
00:02:49.131 --> 00:02:53.780
&gt;&gt; /dist/document/chain/dist ASD.

52
00:02:53.780 --> 00:02:56.310
&gt;&gt; Yeah,
typically you don't wanna pull from dist.

53
00:02:56.310 --> 00:03:00.820
This is typically like, yeah,
that's just like their output folder.

54
00:03:00.820 --> 00:03:02.690
But there should be like another one,
right?

55
00:03:02.690 --> 00:03:04.670
So it probably is.

56
00:03:04.670 --> 00:03:05.720
Let's see.

57
00:03:05.720 --> 00:03:06.649
Where did I pull it from?

58
00:03:08.180 --> 00:03:09.300
Yeah, it's just /document, right?

59
00:03:09.300 --> 00:03:11.870
But I don't know why
the autocomplete doesn't see that.

60
00:03:11.870 --> 00:03:13.720
I think it's just something,
how they set their thing up.

61
00:03:13.720 --> 00:03:16.088
But yeah,
you typically don't pull from dist.

62
00:03:16.088 --> 00:03:17.380
Yeah.

63
00:03:20.136 --> 00:03:22.840
And then it has this green,
this is what throws me off.

64
00:03:22.840 --> 00:03:27.274
So usually when you see the green there,
to me that tells me that that's usually

65
00:03:27.274 --> 00:03:31.377
a type file, like a file with just types
in it and not a typescript file, so

66
00:03:31.377 --> 00:03:33.448
that's why it always throws me off.

67
00:03:33.448 --> 00:03:35.900
So I don't know why they have that there,
I don't know.

68
00:03:35.900 --> 00:03:41.247
Anyway that's just some
OG stuff I guess [LAUGH].

69
00:03:41.247 --> 00:03:46.694
So let me make a new document,
And then inside the document, you

70
00:03:46.694 --> 00:03:51.830
can put the page content, the page content
is just gonna be the entry.content.

71
00:03:51.830 --> 00:03:55.560
And then we can have the metadata,
which is just an object.

72
00:03:55.560 --> 00:03:58.722
And then I'll put like,
I want the ID of the entry in here, so

73
00:03:58.722 --> 00:04:00.280
we know where this came from.

74
00:04:02.010 --> 00:04:06.451
Maybe I want when this was created,
I'll get the entry.

75
00:04:08.648 --> 00:04:09.423
CreatedAt.

76
00:04:09.423 --> 00:04:12.201
And this is helpful if I asked a query on,
well,

77
00:04:12.201 --> 00:04:14.990
how did I feel two days
within the last two days?

78
00:04:14.990 --> 00:04:19.132
Well, now we can calculate that cuz
there's some metadata here on when this

79
00:04:19.132 --> 00:04:19.918
was created.

80
00:04:19.918 --> 00:04:22.644
So it's helpful to do that.

81
00:04:22.644 --> 00:04:23.614
You can put whatever you want.

82
00:04:23.614 --> 00:04:26.723
I mean, you can put the whole entry in
here if you want, it doesn't matter.

83
00:04:26.723 --> 00:04:28.354
I'm just gonna put those two things.

84
00:04:28.354 --> 00:04:29.928
So now, we have an array of documents.

85
00:04:34.207 --> 00:04:39.450
And from there, I mean, there's really no
right order or whatever we wanna do here.

86
00:04:39.450 --> 00:04:41.894
But I think from there, what we can do
is we can just load up the model and

87
00:04:41.894 --> 00:04:42.940
then create the chain.

88
00:04:42.940 --> 00:04:48.304
So for the model, because this is a QA

89
00:04:48.304 --> 00:04:54.187
model where we want it to be very strict,

90
00:04:54.187 --> 00:04:59.377
we can say, model = new, open AI,

91
00:04:59.377 --> 00:05:03.877
temperature, 0 model name,

92
00:05:03.877 --> 00:05:09.092
gpt- 3.5-turbo, like that.

93
00:05:14.184 --> 00:05:16.090
And then we're gonna create a chain.

94
00:05:16.090 --> 00:05:18.970
So a chain is basically,
it's exactly what it sounds like.

95
00:05:18.970 --> 00:05:23.760
It allows you to chain
multiple LLM calls together.

96
00:05:23.760 --> 00:05:26.226
You can string them together,
have the output of one,

97
00:05:26.226 --> 00:05:28.150
be the input of another one.

98
00:05:28.150 --> 00:05:29.060
That's basically what it is.

99
00:05:29.060 --> 00:05:31.062
Lang chain has many
different types of chains.

100
00:05:31.062 --> 00:05:34.792
They have like a chat chain,
an LLM chain, agent chain,

101
00:05:34.792 --> 00:05:39.000
different types of agent chains,
it's actually exhaustive.

102
00:05:39.000 --> 00:05:40.714
I don't think I've even
tried half of them yet.

103
00:05:40.714 --> 00:05:44.946
So what we're gonna do is use
the one that they have here

104
00:05:44.946 --> 00:05:48.903
called the low QA refine chain,
so let's do that.

105
00:05:48.903 --> 00:05:54.897
So we'll say, Chain = loadQA,

106
00:05:54.897 --> 00:05:59.619
it doesn't autocomplete for me.

107
00:05:59.619 --> 00:06:01.762
No, this one's from Langchain chains.

108
00:06:09.122 --> 00:06:11.110
Yeah, they just changed all their imports,

109
00:06:11.110 --> 00:06:14.820
used to just be able to import everything
from langchain until a week ago.

110
00:06:14.820 --> 00:06:16.970
So that's why I'm still
learning these imports.

111
00:06:17.990 --> 00:06:21.031
Load, Not QA chain.

112
00:06:21.031 --> 00:06:23.462
Load QA refine chain.

113
00:06:29.550 --> 00:06:31.665
We'll load the QA refine chain
we'll pass in the model.

114
00:06:36.848 --> 00:06:38.650
So what is QA refine chain?

115
00:06:38.650 --> 00:06:40.470
I think it's helpful
just to talk about that.

116
00:06:42.500 --> 00:06:50.070
So that one is,
I believe it is on index document QA.

117
00:06:51.700 --> 00:06:57.270
Here we go.
So the QA refine chain.

118
00:06:57.270 --> 00:06:59.430
They talk about it right here.

119
00:06:59.430 --> 00:07:02.296
So this chain iterates over
the inputs of documents one by one,

120
00:07:02.296 --> 00:07:05.230
updating an intermediate
answer with each iteration.

121
00:07:05.230 --> 00:07:09.060
It uses previous version of the answer
in the next document as context.

122
00:07:09.060 --> 00:07:12.034
It is suitable for QA tasks over
a large number of documents, so

123
00:07:12.034 --> 00:07:13.615
that's what we're using this.

124
00:07:16.474 --> 00:07:18.890
There's other ones too,
like MapReduce stuff.

125
00:07:18.890 --> 00:07:22.885
You can use stuff if it's just,
you don't have that many documents,

126
00:07:22.885 --> 00:07:25.400
you can just stuff them
all into one prompt.

127
00:07:25.400 --> 00:07:32.830
That's why it's called stuff, a MapReduce
is like- How do I describe this one?

128
00:07:32.830 --> 00:07:37.421
So, yeah, this one basically just,
it just like maps over it and

129
00:07:37.421 --> 00:07:40.680
tries to summarize stuff and
create smaller.

130
00:07:43.130 --> 00:07:44.730
It tries to do things in parallel.

131
00:07:44.730 --> 00:07:48.560
So what it'll do, it'll make multiple
calls to the AI in parallel.

132
00:07:48.560 --> 00:07:51.380
And then take all the results of all them.

133
00:07:51.380 --> 00:07:55.230
Combine those results and
ask another call to get the final result.

134
00:07:55.230 --> 00:07:59.949
So literally like maps over all of them
and then reduces it into one MapReduce.

135
00:08:02.038 --> 00:08:05.175
We're gonna refine documents,
I think that will get the best results for

136
00:08:05.175 --> 00:08:05.790
what we have.

137
00:08:05.790 --> 00:08:08.475
But as this app grows,
you might find you need something else.

138
00:08:12.904 --> 00:08:17.151
Okay, the next thing we're gonna do is
create the embeddings that we wanna use,

139
00:08:17.151 --> 00:08:19.600
and then we'll use a vector
store to get that.

140
00:08:19.600 --> 00:08:22.220
So we can say the embeddings.

141
00:08:22.220 --> 00:08:27.735
There's many embeddings model, we're
just gonna use the one that OpenAI has,

142
00:08:27.735 --> 00:08:32.697
so we can say new embeddings,
which I believe comes from /embeddings.

143
00:08:32.697 --> 00:08:38.680
Let's see, langchain/embeddings, yep.

144
00:08:38.680 --> 00:08:42.882
And we wanna get the OpenAIEmbeddings,
like so.

145
00:08:47.808 --> 00:08:51.230
We don't have to pass in any args here,
it's gonna read the environment variable.

146
00:08:51.230 --> 00:08:55.970
This is gonna return a function that
any chain can use to create embeddings.

147
00:08:55.970 --> 00:08:58.070
Remember, embeddings
are a group of vectors.

148
00:08:58.070 --> 00:09:01.460
So we need, it's basically saying this
is how I want you to create embeddings.

149
00:09:01.460 --> 00:09:07.270
In this case, it's going to make an API
call to open AI to create an embedding.

150
00:09:07.270 --> 00:09:10.016
Open AI has an embedding endpoint
where you can send it some text and

151
00:09:10.016 --> 00:09:11.449
I'll send you back some vectors.

152
00:09:12.920 --> 00:09:15.781
Because you don't have access to
Open AI's model on your machine, so

153
00:09:15.781 --> 00:09:18.700
you don't know what that is, so
you have to use theirs, host it.

154
00:09:18.700 --> 00:09:19.779
So that's what this is gonna do.

155
00:09:22.080 --> 00:09:23.880
So we have our embeddings.

156
00:09:23.880 --> 00:09:25.790
The next thing we wanna
do is create our store.

157
00:09:25.790 --> 00:09:28.370
This is our vector store,
which we can store everything.

158
00:09:28.370 --> 00:09:34.050
And this is just going to be inside of,
where's this one?

159
00:09:34.050 --> 00:09:35.510
Vector store's memory.

160
00:09:35.510 --> 00:09:38.969
So we'll do that, and
then we'll just do the from documents and

161
00:09:38.969 --> 00:09:41.030
parse in the docs and the embeddings.

162
00:09:41.030 --> 00:09:43.118
So let's import that.

163
00:09:47.322 --> 00:09:50.846
Langchain/vectorstore/memory.

164
00:09:52.420 --> 00:09:54.590
We'll bring in the memory vector store.

165
00:09:56.100 --> 00:10:01.260
We'll make a new memory vector store.from.

166
00:10:01.260 --> 00:10:03.340
I think you don't even
need the new actually.

167
00:10:03.340 --> 00:10:05.770
It's just memory vector store.from docs.

168
00:10:05.770 --> 00:10:11.256
We're gonna pass in our docs, and
then we're gonna pass in our embeddings.

169
00:10:18.262 --> 00:10:19.152
So we got that.

170
00:10:22.658 --> 00:10:23.240
Yes.

171
00:10:24.340 --> 00:10:25.569
&gt;&gt; And just to clarify,

172
00:10:25.569 --> 00:10:30.220
document is kind of the required data
type from LangChain to be able to.

173
00:10:30.220 --> 00:10:35.629
&gt;&gt; Yeah, if you want to be able to use
their stores that they abstract away,

174
00:10:35.629 --> 00:10:37.856
you would need the document.

175
00:10:37.856 --> 00:10:42.187
But if you talk to, for
instance langchain has wrappers for

176
00:10:42.187 --> 00:10:47.136
every popular vector database out there,
so first let me show you.

177
00:10:51.596 --> 00:10:52.480
Vector stores.

178
00:10:52.480 --> 00:10:53.833
So you can see they have,

179
00:10:53.833 --> 00:10:57.220
these are like some of the top
vector databases out there.

180
00:10:57.220 --> 00:11:01.251
So they had to create a standard format
and how you store things in those vector

181
00:11:01.251 --> 00:11:04.460
databases, documents is
that standard format.

182
00:11:04.460 --> 00:11:07.438
You can interact with these
databases outside of langchain,

183
00:11:07.438 --> 00:11:10.310
and then they might have their
own way in how you store text.

184
00:11:10.310 --> 00:11:12.970
It might not be a document,
but if using langchain,

185
00:11:12.970 --> 00:11:16.850
you might as well build an abstraction,
or use their abstraction to use it.

186
00:11:16.850 --> 00:11:19.232
So, but yeah.

187
00:11:19.232 --> 00:11:21.060
And there's many ways to make a document.

188
00:11:21.060 --> 00:11:25.024
They have document loaders
that can pull in a PDF file.

189
00:11:25.024 --> 00:11:26.055
Actually let me show you.

190
00:11:26.055 --> 00:11:31.233
Here's a file loader this can take
multiple files this can take CSVs,

191
00:11:31.233 --> 00:11:37.470
ePubs, docx, JSON files, PDF files,
a notion markdown, a text file.

192
00:11:37.470 --> 00:11:41.743
You can take in a website,
[LAUGH] you can take in a good book,

193
00:11:41.743 --> 00:11:43.893
a figma file, a GitHub repo.

194
00:11:43.893 --> 00:11:46.299
It doesn't matter,
it'll load all that in and

195
00:11:46.299 --> 00:11:49.681
create documents which would then
you can create embeddings for.

196
00:11:49.681 --> 00:11:54.445
And this is a small list compared to
the other stuff that's out there on

197
00:11:54.445 --> 00:11:55.427
llama index.

198
00:11:55.427 --> 00:11:57.053
If you've ever heard of that,

199
00:11:57.053 --> 00:12:01.440
that thing you can pull anything from
anywhere on that, it's absolutely insane.

200
00:12:01.440 --> 00:12:04.808
And that works with Langchain too.

201
00:12:04.808 --> 00:12:05.950
But that's getting off topic.

202
00:12:08.900 --> 00:12:10.220
Cool, so now we have the store.

203
00:12:10.220 --> 00:12:13.449
Now all we wanna do is perform our
similarity search here, so we can say

204
00:12:13.449 --> 00:12:17.540
story.similarity search and pass in our
question and get some relevant docs.

205
00:12:17.540 --> 00:12:18.510
So we'll say, cool.

206
00:12:18.510 --> 00:12:23.780
These are the relevant,
Docs, and we're gonna

207
00:12:23.780 --> 00:12:29.640
await the store.similarity search,
and pass in our, why did it do that?

208
00:12:29.640 --> 00:12:30.140
What?

209
00:12:32.178 --> 00:12:33.957
There we go.
Similarity search and

210
00:12:33.957 --> 00:12:35.549
then pass in the question.

211
00:12:38.079 --> 00:12:39.121
Lines are freaking out.

212
00:12:41.375 --> 00:12:42.965
I don't know why I forgot like that.

213
00:12:42.965 --> 00:12:43.987
What do you want?

214
00:12:45.694 --> 00:12:50.335
Does not exist on, it does?

215
00:12:50.335 --> 00:12:51.829
I use this all the time.

216
00:12:51.829 --> 00:12:54.676
You have to await this,
I'm sorry, that's a promise.

217
00:12:54.676 --> 00:12:55.899
There we go.

218
00:12:58.896 --> 00:13:00.710
Okay, so now we have our relevant docs.

219
00:13:00.710 --> 00:13:04.561
Now we're ready to make the call
to the AI cuz at this point,

220
00:13:04.561 --> 00:13:08.490
we know what entries you need
to answer this question.

221
00:13:08.490 --> 00:13:11.268
That's what this is,
based off the question you gave us,

222
00:13:11.268 --> 00:13:14.161
we know that these are the only
entries you need to answer that

223
00:13:14.161 --> 00:13:16.789
question because we already
put them in the database.

224
00:13:17.800 --> 00:13:21.235
And this right here takes your question,
puts in the database and

225
00:13:21.235 --> 00:13:23.540
comes back with the relevant docs.

226
00:13:23.540 --> 00:13:25.320
So now we're ready to make that call.

227
00:13:25.320 --> 00:13:27.865
And we can do that with any
chain if you just call call, and

228
00:13:27.865 --> 00:13:31.547
then we can pass in our input documents,
and then we can just pass in our question.

229
00:13:31.547 --> 00:13:32.526
So let's just do that.

230
00:13:32.526 --> 00:13:36.347
Res = await.

231
00:13:38.498 --> 00:13:44.730
Chain.call, relavantDocs,
it's gonna be relavantDocs.

232
00:13:44.730 --> 00:13:47.719
Or I think it's, I'm sorry, input_docs.

233
00:13:47.719 --> 00:13:50.819
Yeah, input_docs are gonna
be relavantDocs, and

234
00:13:50.819 --> 00:13:52.797
then question is just question.

235
00:13:55.727 --> 00:13:57.175
Input_documents, sorry.

236
00:13:57.175 --> 00:13:59.853
High school, where are you at?

237
00:13:59.853 --> 00:14:01.469
Where are you at?

238
00:14:07.008 --> 00:14:09.932
Now we have a response and
then response typically,

239
00:14:09.932 --> 00:14:13.263
I think it always has .output text or
something like that.

240
00:14:13.263 --> 00:14:18.192
Yeah, so
we could just say return response.output.

241
00:14:19.973 --> 00:14:23.300
Text, and that'll be our answer.

242
00:14:23.300 --> 00:14:27.400
So this is significantly different from
what we did with the first AI thing.

243
00:14:27.400 --> 00:14:28.780
This is way more advanced.

244
00:14:28.780 --> 00:14:32.620
In fact, this is a really good foundation
for building some pretty crazy stuff.

245
00:14:33.710 --> 00:14:38.216
I don't even know where to begin to give
you some examples of what you can do with

246
00:14:38.216 --> 00:14:41.510
this, but,
you can do pretty much anything with this.

247
00:14:41.510 --> 00:14:46.460
I have some code on my computer that I
give it a URL, it'll crawl that website,

248
00:14:46.460 --> 00:14:49.697
go to the sitemap,
find every URL on that website.

249
00:14:49.697 --> 00:14:54.057
Download every single page,
create embeddings for every single page,

250
00:14:54.057 --> 00:14:58.999
put in the database, and then now I can
ask questions about that website, right?

251
00:14:58.999 --> 00:15:02.400
I can then I can have it to ask
questions across many websites.

252
00:15:02.400 --> 00:15:05.115
Great for doing research,
great for learning,

253
00:15:05.115 --> 00:15:08.240
I can have it crawl next.js's
documentation in line.

254
00:15:08.240 --> 00:15:11.190
I can just like, yeah,
write me some code in nextjs's 13.

255
00:15:11.190 --> 00:15:14.912
And it knows how, cuz it knows
the whole website, so stuff like that.

256
00:15:14.912 --> 00:15:18.090
So, and that's still a small example
of all the things you can do.

