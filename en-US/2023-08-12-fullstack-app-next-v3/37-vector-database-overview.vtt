WEBVTT

1
00:00:00.000 --> 00:00:00.991
So let's do the AI part.

2
00:00:00.991 --> 00:00:02.030
This part is really cool.

3
00:00:02.030 --> 00:00:04.153
Don't worry if you can't
get the form down.

4
00:00:04.153 --> 00:00:05.970
It's just a regular form.

5
00:00:05.970 --> 00:00:06.651
You can get to it later.

6
00:00:06.651 --> 00:00:07.950
I also have the code on GitHub.

7
00:00:09.610 --> 00:00:12.903
Okay, AI stuff,
this one's gonna take some explaining.

8
00:00:12.903 --> 00:00:17.948
[LAUGH] Because it's way different
than what we did here, much different.

9
00:00:17.948 --> 00:00:19.401
But still pretty exciting.

10
00:00:19.401 --> 00:00:24.368
So I'm gonna make a new function in our
AI file, and I'm just gonna call it QA.

11
00:00:24.368 --> 00:00:26.683
It's an async function.

12
00:00:26.683 --> 00:00:28.080
Okay, let's talk about this.

13
00:00:29.280 --> 00:00:33.178
In order to do what we're trying to do,

14
00:00:33.178 --> 00:00:37.207
I have to explain to you how the AI works.

15
00:00:37.207 --> 00:00:42.065
So in-order for something like a LLM to be
able to answer a question based off some

16
00:00:42.065 --> 00:00:45.865
information, which is what we
wanted to do, we wanna give it.

17
00:00:45.865 --> 00:00:49.105
So think about how did
the the sentiment analysis,

18
00:00:49.105 --> 00:00:51.374
we had to give it the entry, right?

19
00:00:51.374 --> 00:00:54.124
If we didn't give it
the content of the entry,

20
00:00:54.124 --> 00:00:56.955
how would it have done
the sentiment analysis?

21
00:00:56.955 --> 00:01:01.605
Okay, so if we want to have it answer
a question across all of our entries,

22
00:01:01.605 --> 00:01:03.560
what do you think we need to do?

23
00:01:10.322 --> 00:01:12.800
&gt;&gt; You have to patch it and
feed it to OpenAI as well, or

24
00:01:12.800 --> 00:01:15.050
is there a different line chain module?

25
00:01:15.050 --> 00:01:17.104
&gt;&gt; Or feed what to OpenAI?

26
00:01:17.104 --> 00:01:18.420
&gt;&gt; Yeah, all the [CROSSTALK].

27
00:01:18.420 --> 00:01:19.290
&gt;&gt; All the entries?
&gt;&gt; Yeah.

28
00:01:19.290 --> 00:01:19.980
&gt;&gt; So, yeah, you do.

29
00:01:19.980 --> 00:01:21.650
You wanna feed all the entries.

30
00:01:21.650 --> 00:01:25.627
The only problem is,
there's one huge caveat,

31
00:01:25.627 --> 00:01:31.450
is that most LLMs have a context limit
on how many tokens you can feed it.

32
00:01:31.450 --> 00:01:36.227
A token, you can think of a token on
average is basically like four letters,

33
00:01:36.227 --> 00:01:38.180
every four letters is a token.

34
00:01:38.180 --> 00:01:39.255
And most LLMs, or

35
00:01:39.255 --> 00:01:43.504
actually every LLM has a token limit
on how many tokens you can feed it.

36
00:01:43.504 --> 00:01:46.166
And it depends on what model, GPT-3,

37
00:01:46.166 --> 00:01:49.390
every new one that comes
out has a bigger window.

38
00:01:49.390 --> 00:01:53.321
I think the biggest hosted big
one right now is probably.

39
00:01:53.321 --> 00:02:01.820
They just released one that has like a
over a 100k token limit, which is massive.

40
00:02:01.820 --> 00:02:06.262
I forgot what GPT 3.5 Turbo is,
but it's not big.

41
00:02:06.262 --> 00:02:07.990
And eventually you'll hit that limit.

42
00:02:07.990 --> 00:02:10.688
We might not hit it with our small
data set, but you will hit it.

43
00:02:10.688 --> 00:02:13.992
I mean, you can go to ChatGPT right now,
go copy a long blog post and

44
00:02:13.992 --> 00:02:17.730
paste it in GPT and ask it a question
about it, and it'll throw an error.

45
00:02:17.730 --> 00:02:19.457
They're like, I can't, this is too much.

46
00:02:19.457 --> 00:02:21.857
You passed my context window.

47
00:02:21.857 --> 00:02:24.530
So we got to find a way
to get around that.

48
00:02:25.690 --> 00:02:28.624
The best way to get around that is like,
well,

49
00:02:28.624 --> 00:02:32.177
do you always need everything
to answer this question?

50
00:02:32.177 --> 00:02:33.410
Maybe you don't.

51
00:02:33.410 --> 00:02:35.127
Maybe you don't need everything.

52
00:02:35.127 --> 00:02:36.810
That's one thing to think about.

53
00:02:36.810 --> 00:02:38.563
Maybe you only need
a specific set of things.

54
00:02:38.563 --> 00:02:42.681
If I have a history book that's
got 100,000 pages in it, and

55
00:02:42.681 --> 00:02:47.520
I'm asking a question about a specific
date and time, do I need to tell GPT about

56
00:02:47.520 --> 00:02:52.240
this entire history book or only the part
that references this date and time?

57
00:02:53.510 --> 00:02:54.151
That's a solution.

58
00:02:54.151 --> 00:02:58.850
Another solution is to
make multiple GPT calls,

59
00:02:58.850 --> 00:03:05.497
each call filling up the context
window until it is aware of all of it,

60
00:03:05.497 --> 00:03:10.670
and then you kinda like
summarize every single time.

61
00:03:11.820 --> 00:03:14.711
But basically, it's recursive,
you would feed it some context,

62
00:03:14.711 --> 00:03:16.850
ask the question that you want,
get that answer.

63
00:03:16.850 --> 00:03:18.855
Feed it some more context, you'd be like,

64
00:03:18.855 --> 00:03:21.410
is this an answer still valid
based on this new context?

65
00:03:21.410 --> 00:03:23.928
And you'll keep doing that until you're
done with all the data that you had, and

66
00:03:23.928 --> 00:03:25.422
then eventually you'll
get the final answer.

67
00:03:25.422 --> 00:03:26.679
That works too.

68
00:03:26.679 --> 00:03:27.632
There's a lot of ways.

69
00:03:27.632 --> 00:03:32.193
We're in the number one,
the first way, where we're just like,

70
00:03:32.193 --> 00:03:34.726
maybe you don't need all this data.

71
00:03:34.726 --> 00:03:41.168
We're only gonna send GPT the data
that it needs to answer your question.

72
00:03:41.168 --> 00:03:44.670
But we're gonna use AI to figure out what
data that we need to answer the question.

73
00:03:44.670 --> 00:03:46.272
Actually, we're gonna use something
called a vector database.

74
00:03:46.272 --> 00:03:47.760
Anybody ever heard of that?

75
00:03:49.810 --> 00:03:51.390
Okay, let's talk about that for a second.

76
00:03:51.390 --> 00:03:53.570
So what is a vector?

77
00:03:53.570 --> 00:03:54.665
Vectors are just numbers, really.

78
00:03:54.665 --> 00:03:59.247
If you've ever done matrix math or
anything like that,

79
00:03:59.247 --> 00:04:04.710
you could think of a vector as just
like an array of points, right?

80
00:04:04.710 --> 00:04:09.446
It's an array of numbers,
a number between 1 and 0, and

81
00:04:09.446 --> 00:04:13.908
it can have many different
numbers in that one vector.

82
00:04:13.908 --> 00:04:17.700
The amount of numbers in it is called,
how many dimensions it is, right?

83
00:04:17.700 --> 00:04:21.156
So in the case of OpenAI's capabilities,

84
00:04:21.156 --> 00:04:26.151
you can have vectors that
are over like 1500 dimensions.

85
00:04:26.151 --> 00:04:30.290
Too many to plot in physical space, right?

86
00:04:30.290 --> 00:04:34.122
You can't plot 1500 dimensions,
we don't even know what 4D looks like, yet

87
00:04:34.122 --> 00:04:34.953
alone 1500.

88
00:04:34.953 --> 00:04:38.320
So why is that important?

89
00:04:38.320 --> 00:04:43.199
Well, basically what's gonna happen is
we're gonna use AI to take the content, in

90
00:04:43.199 --> 00:04:48.302
this case, our entries, the text of that,
convert those into vectors or embeddings.

91
00:04:48.302 --> 00:04:50.290
An embedding is like
a collection of vectors.

92
00:04:51.370 --> 00:04:53.413
And basically we
are taking that string and

93
00:04:53.413 --> 00:04:56.031
turning it into a number
that represents that string.

94
00:04:56.031 --> 00:04:58.688
It represents the meaning of it,
the sentiment,

95
00:04:58.688 --> 00:05:02.371
everything about that string is
being converted to a number, okay?

96
00:05:02.371 --> 00:05:05.523
We're then gonna store
that number in a database,

97
00:05:05.523 --> 00:05:08.390
a special database called
a vector database.

98
00:05:08.390 --> 00:05:11.280
And then when you ask a question,
we're gonna do the same thing.

99
00:05:11.280 --> 00:05:13.912
We're gonna take that question,
we're gonna convert that to a number.

100
00:05:13.912 --> 00:05:16.595
We're gonna put that in
the vector database as well.

101
00:05:16.595 --> 00:05:20.597
And now, forget about 1500 dimensions,
just think about two dimensions.

102
00:05:20.597 --> 00:05:25.481
If I had two-dimensional points plotted on
a chart, okay, and they're just scattered

103
00:05:25.481 --> 00:05:29.579
all over the place, and then I get this
other one that comes in and I plot it,

104
00:05:29.579 --> 00:05:33.910
I can do math to figure out which
points are closer to this one, right?

105
00:05:33.910 --> 00:05:36.559
And I'm gonna grab the ones that
are closer, let's say the top five, and

106
00:05:36.559 --> 00:05:39.272
I'm gonna say, cool, these are the top
five points closer to this point.

107
00:05:39.272 --> 00:05:42.070
That's basically what we're gonna do.

108
00:05:42.070 --> 00:05:44.111
So we're gonna turn your
question into a vector.

109
00:05:44.111 --> 00:05:48.406
And then we're gonna see what vectors
are the closest to it in this space,

110
00:05:48.406 --> 00:05:52.701
which will be what entries are closest
to this in meaning and reasoning and

111
00:05:52.701 --> 00:05:55.149
whatever algorithm that AI is choosing.

112
00:05:55.149 --> 00:05:59.382
And we're gonna pull those out and we're
gonna feed that as context to ChatGPT,

113
00:05:59.382 --> 00:06:01.634
just like we fed this single entry itself.

114
00:06:05.310 --> 00:06:07.103
That sounds like a lot of work,
[LAUGH] very hard.

115
00:06:07.103 --> 00:06:11.141
And there's companies literally that
are raising billions of dollars to do

116
00:06:11.141 --> 00:06:11.781
just this.

117
00:06:11.781 --> 00:06:15.666
There's vector databases that are worth
billions of dollars now that just came out

118
00:06:15.666 --> 00:06:16.397
two years ago.

119
00:06:16.397 --> 00:06:19.730
Pinecone is one of the biggest
vector databases out there.

120
00:06:19.730 --> 00:06:20.290
It's amazing.

121
00:06:20.290 --> 00:06:22.130
We're just gonna do one in-memory.

122
00:06:22.130 --> 00:06:23.661
We're gonna do in-memory vector database.

123
00:06:23.661 --> 00:06:27.200
But a lot of databases are specialized for
this, some of them extended.

124
00:06:27.200 --> 00:06:30.601
So you can do vector database in Postgres,
Redis, Superbase.

125
00:06:30.601 --> 00:06:36.380
You can get a standalone vector database,
ChromaDB, Pinecone, Milvus, Weaviate.

126
00:06:36.380 --> 00:06:37.450
There's so many of them.

127
00:06:37.450 --> 00:06:42.100
We're just gonna do one, in-memory,
because we're just not gonna do that.

128
00:06:42.100 --> 00:06:44.640
I've messed around with all of them,
they're all just too much to set up and

129
00:06:44.640 --> 00:06:45.166
too annoying.

130
00:06:45.166 --> 00:06:48.450
So let's do one, in-memory.

131
00:06:48.450 --> 00:06:49.560
Okay, any questions on any of that?

132
00:06:49.560 --> 00:06:50.550
That was a lot.

133
00:06:52.840 --> 00:06:55.390
Actually, yeah?

134
00:06:55.390 --> 00:06:58.326
&gt;&gt; Are they similar to a KNN algorithm?

135
00:06:58.326 --> 00:07:02.397
&gt;&gt; KNN, I'm not familiar with
the KNN algorithm, so I can't tell.

136
00:07:02.397 --> 00:07:05.934
I think they might be describing
how the search on the algorithm or

137
00:07:05.934 --> 00:07:10.450
the search on the vector databases, and
there's different algorithms for that.

138
00:07:10.450 --> 00:07:14.532
One is cosine similarity,
which is what we're gonna do.

139
00:07:14.532 --> 00:07:17.333
I think KNN might be one
of those algorithms,

140
00:07:17.333 --> 00:07:22.048
in which you can search vectors on, but
I'm not a machine learning expert or

141
00:07:22.048 --> 00:07:25.604
mathematician, so
I don't really know, but could be.

142
00:07:25.604 --> 00:07:29.333
Yeah, if you go to OpenAI's website,

143
00:07:29.333 --> 00:07:34.871
if you go to their blog,
they actually have a really good,

144
00:07:38.934 --> 00:07:43.170
They have a really good
illustration of vectors.

145
00:07:43.170 --> 00:07:43.812
Let me see if I can find it.

146
00:07:43.812 --> 00:07:47.510
I think it's on this other one
where they talked about embeddings.

147
00:07:50.640 --> 00:07:54.007
&gt;&gt; Nearest neighbor algorithm,
is what they were referring to.

148
00:07:54.007 --> 00:07:55.020
&gt;&gt; Nearest neighbor.

149
00:07:55.020 --> 00:07:57.670
I think you could use
a nearest neighbor for that.

150
00:07:57.670 --> 00:08:02.057
I think the nearest neighbor gets more
complicated the more dimensions you have,

151
00:08:02.057 --> 00:08:03.590
though, so I don't know.

152
00:08:03.590 --> 00:08:06.032
It's actually not that
complicated once you look at it.

153
00:08:06.032 --> 00:08:08.300
Okay, so here's a 2D example of it.

154
00:08:08.300 --> 00:08:13.880
So imagine all of these
are journal entries, right?

155
00:08:13.880 --> 00:08:16.410
They're plotted based off meaning.

156
00:08:16.410 --> 00:08:19.800
The closer they are, the more they
relate in meaning or reasoning, right?

157
00:08:19.800 --> 00:08:26.490
So like canine companion, say,
that's very related to wolf, all right?

158
00:08:26.490 --> 00:08:28.751
Feline friends, say, meow,
those two are very related.

159
00:08:28.751 --> 00:08:31.850
And these are animals, so
they're kinda grouped together, right?

160
00:08:31.850 --> 00:08:37.037
So everything's kinda grouped together
by their meaning and relations.

161
00:08:37.037 --> 00:08:41.753
And then, basically, the question that you
ask gets turned into one of these two, and

162
00:08:41.753 --> 00:08:44.210
it too gets stuck on this graph.

163
00:08:44.210 --> 00:08:46.706
And then from there, we're just gonna
pick the ones that are closest to it.

164
00:08:46.706 --> 00:08:53.912
Take those out, feed it to GPT and
keep it already to the context window.

165
00:08:53.912 --> 00:08:55.567
And then we just ignore everything else,

166
00:08:55.567 --> 00:08:57.853
cuz you didn't need all of
that to answer this question.

167
00:08:57.853 --> 00:08:59.067
That makes sense?

168
00:08:59.067 --> 00:09:00.037
Okay, and I have like 3D one too.

169
00:09:00.037 --> 00:09:02.271
All right, here's what I wanted to show.

170
00:09:02.271 --> 00:09:04.244
Yeah, this one.
So you can kinda see how these things

171
00:09:04.244 --> 00:09:06.350
are plotted, right?

172
00:09:06.350 --> 00:09:07.559
This is just a 3D representation.

173
00:09:07.559 --> 00:09:10.684
There's only three dimensions,
but it goes higher than that.

174
00:09:10.684 --> 00:09:13.390
So you can see these things
are grouped together.

175
00:09:13.390 --> 00:09:15.980
Here's the text for them and
why they are grouped together.

176
00:09:15.980 --> 00:09:21.010
So these are like all animal stuff,
athletes, some film stuff, something

177
00:09:21.010 --> 00:09:26.210
about a village, and transportation,
and they're all grouped in that way.

178
00:09:26.210 --> 00:09:28.461
So when you ask a question,
we're just gonna throw yours in here too.

179
00:09:28.461 --> 00:09:30.850
Let's say that one's
gonna be a yellow dot.

180
00:09:30.850 --> 00:09:32.810
Which one of these dots are closer
to the yellow dot, take those.

181
00:09:36.750 --> 00:09:39.619
Yeah, it's kinda cool, yes?

182
00:09:39.619 --> 00:09:44.250
&gt;&gt; How deep have you gone into vectors and
matrices?

183
00:09:44.250 --> 00:09:47.530
Is it fairly superficial understanding?

184
00:09:47.530 --> 00:09:48.580
&gt;&gt; Yeah.

185
00:09:48.580 --> 00:09:51.987
&gt;&gt; [INAUDIBLE] or you are like, no,
keep keep learning what you can.

186
00:09:51.987 --> 00:09:54.592
&gt;&gt; Yeah, so
to be able to do what we're doing now,

187
00:09:54.592 --> 00:09:57.180
what I just told you is
all you need to know.

188
00:09:57.180 --> 00:10:01.302
You don't need to know any of this stuff
in order to be able to build applications

189
00:10:01.302 --> 00:10:02.236
with this stuff.

190
00:10:02.236 --> 00:10:05.060
&gt;&gt; But you don't, so as a boot camp
developer, like don't worry about it?

191
00:10:06.310 --> 00:10:09.687
&gt;&gt; No, you do not need to
worry about any of this stuff.

192
00:10:09.687 --> 00:10:12.833
The only reason I went deep on this is to,
one,

193
00:10:12.833 --> 00:10:16.730
part of my job is taking a lot
of these technical pitches.

194
00:10:16.730 --> 00:10:20.774
I'm usually talking to PhD scientists from
MIT who's like pitching me a company,

195
00:10:20.774 --> 00:10:22.925
and they talk very
deeply about this stuff.

196
00:10:22.925 --> 00:10:25.010
So I'm like, okay,
I need to go understand this.

197
00:10:25.010 --> 00:10:26.461
So that's one.
And then two,

198
00:10:26.461 --> 00:10:31.060
I've always just been interested
in math and stuff like that.

199
00:10:31.060 --> 00:10:33.488
I'm not a mathematician, if you know me,
you know I'm terrible at math.

200
00:10:33.488 --> 00:10:36.113
But it was always something
I was interested in, so

201
00:10:36.113 --> 00:10:38.060
I just never was excited about it.

202
00:10:38.060 --> 00:10:39.999
This actually got me excited to go learn.

203
00:10:39.999 --> 00:10:44.153
So I actually asked ChatGPT to build me a
math curriculum to teach me more about AI

204
00:10:44.153 --> 00:10:45.400
and machine learning.

205
00:10:45.400 --> 00:10:47.337
So then I just went and
followed that curriculum and-

206
00:10:47.337 --> 00:10:48.300
&gt;&gt; So cool.

207
00:10:48.300 --> 00:10:49.430
&gt;&gt; That's how I know a lot of stuff.

208
00:10:49.430 --> 00:10:52.600
But I would even say, I'm not good at it.

209
00:10:52.600 --> 00:10:55.167
I don't understand it as well
as the people who created it.

210
00:10:55.167 --> 00:10:57.117
I can have a conversation about it, but

211
00:10:57.117 --> 00:11:00.673
don't ask me to write an equation
about this stuff, cuz I don't know.

212
00:11:00.673 --> 00:11:01.549
I really don't know.

