[00:00:00]
>> Brian Holt: Resources are a little bit different paradigm, but I think you'll see some value in this. So the first thing I want to throw out there is, as of right now, Tome does not support resources or prompts. The next thing that we'll talk about either. So if you're using Tome, just sit back, crack a cold one, chill out.

[00:00:22]
You can just treat this like Netflix, basically. They are supported in cloud desktop though. Tools are basically like, hey, LLM, here's a brand new capability of a thing you can do. You have the ability to go fetch the weather or the ability to do something else. A resource is more like I'm going to provide you with additional context of what I want you to be able to do.

[00:00:50]
So frankly, so far these are way less used than tools. I think this was anthropic, just kind of guessing in the dark of what do we think that people could want from an MCP server. And so, they provided these other kind of things. But a resource, you can think of an LLM providing additional context to an LLM.

[00:01:11]
So it's you opting to give the LLM additional context. Whereas a tool is kind of the inverse where it's like an LLM going out and fetching either more context or more, something like that. But the volition lies with the user, with the resource, whereas the wanting to do so lies with the LLM with tools.

[00:01:30]
Does that kind of distinction make sense? Resources are not dynamic. That is one thing to know. It's basically a static thing. It's not that you can give it an additional give me a resource about this thing. It's just one thing. Now, that they're changing that. There's a thing called resource templates that do make them dynamic, that are supported in some clients.

[00:01:55]
We're just going to talk about resources or static resources. Yeah. You have a question?
>> Speaker 2: Yeah, I was just curious, how does this, is this basically a way of just giving it more context? And also, how does this differ from doing a Git interaction information tool? Like is it essentially the same idea, just kind of a more formalized approach?

[00:02:18]

>> Brian Holt: It's a good question. Let me answer the second question first, which is what's the difference between like giving it a tool that can go get the information? This is you, the user saying, I want you LLM to have this. So you are deciding to give the LLM more information.

[00:02:30]
The tool? Is the LLM deciding that it wants more information or wants more capability. So it will call the tool it's who's invoking the tool? You, the human are invoking the tool and giving it to the LLM. The tool is the LLM saying what I have is insufficient.

[00:02:46]
I'm gonna go do something about it. So the example that I'm about to give you is we have this MCP issue tracker project that I've shown you. We're going to go create a resource that gives it the entire schema of the database so that you can ask questions about the schema of the database.

[00:03:06]
Now you could definitely give it a tool that says, hey, here's how you could go get to the schema for the database. But in our particular case we can just say, no, I definitely wanna ask questions about this. Here's the resource. Now answer questions about this. If you're asking yourself like this doesn't really seem that useful, I'm going to say that I've never used these too much myself and I had to learn a lot about it to teach this course.

[00:03:26]
But I wanted to share. Yeah, go ahead.
>> Speaker 3: So it sounds like this is just basically a way to provide additional context. Is there any like mechanisms to do like vectorized, like retrieval, augmented generation with resources or is it just kind of eating up tokens?
>> Brian Holt: You could definitely do RAG for sure.

[00:03:45]
RAG is resource augmented. I can't remember what RAG stands for, but it's essentially like you can search a vector based database and get a bunch of context out of it. So I'm going to show you how to just dump SQLite schema and provide it to the LLM. But you could definitely do a whole vector search, is like, give me everything that's related to weather and then we're gonna feed that into the weather asking question thing.

[00:04:08]

>> Speaker 4: With something like the vector database, that would fit better into a resource than a tool. I guess.
>> Brian Holt: It just depends on what you're doing. There are two different things that are meant to accomplish different things. RAG would fit well into a tool. If you're saying, hey, I want to provide the LLM the capability of being able to go out and fetch information about some keyword.

[00:04:32]
Right, that would be a great tool use case. Whereas I would say a resource could be a good use case for something like here's all of the vector search databases that I have available to you. Here they are available to you. It's kind of like a push versus pull model.

[00:04:51]
Right here we're pushing into the LLM. Here's stuff that I want you to have. And the tools is like, hey, LLM, you can go pull this later if you want to. Again, I have not found much use for resources and neither has basically anyone else. They're kind of clunky, and I think they're going to get better.

[00:05:15]
I think they're going to figure out, especially with resource templates, the most annoying thing right now with resources is it's just static. You can provide one thing and that's it. That's all you can provide to it. With resource templates, eventually we're going to be able to say, here's this.

[00:05:30]
Like, I want to be able to provide you all of the databases for rag that have to do with animals, Right? Right now you just have to say, here's all of them. Because you have no ability to customize the response. There's no input parameter.

