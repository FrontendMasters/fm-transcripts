WEBVTT

1
00:00:00.340 --> 00:00:03.410
There's obviously a lot more you
can do with these JSON data types.

2
00:00:03.410 --> 00:00:07.534
I just wanted to introduce you to them
make you aware that they're out there.

3
00:00:07.534 --> 00:00:10.844
Kind of show you this really fun
way where you can have schema and

4
00:00:10.844 --> 00:00:14.110
schema less data living
next to each other.

5
00:00:14.110 --> 00:00:17.380
It's a really powerful
feature of Postgres.

6
00:00:17.380 --> 00:00:21.611
And it's made it a lot more popular since
they introduced it, because this fits now

7
00:00:21.611 --> 00:00:25.660
a lot of use cases that only
MongoDB could've fixed beforehand.

8
00:00:25.660 --> 00:00:30.889
Just like in MongoDB, performance and
cost is always a concern.

9
00:00:30.889 --> 00:00:34.314
So let's take a look at,
let's examine one particular query here.

10
00:00:34.314 --> 00:00:38.343
Select comment ID,

11
00:00:38.343 --> 00:00:42.609
user ID, and time and

12
00:00:42.609 --> 00:00:47.690
comment sorry left.

13
00:00:47.690 --> 00:00:53.632
Comment 20 from comments where board

14
00:00:53.632 --> 00:01:00.518
ID equals 39, Orders order by time,

15
00:01:02.183 --> 00:01:07.560
Descending limit 40.

16
00:01:07.560 --> 00:01:10.472
So as you can, this is something
that you might imagine that you'd

17
00:01:10.472 --> 00:01:12.350
be doing a lot for a message board, right?

18
00:01:12.350 --> 00:01:15.427
You might be querying that
message board database for,

19
00:01:15.427 --> 00:01:17.335
give me all the comments by board.

20
00:01:17.335 --> 00:01:20.470
If I thought if I visit the page for
Board Number 39, right?

21
00:01:20.470 --> 00:01:25.030
Which is the coffee board, you would
probably be querying the database

22
00:01:25.030 --> 00:01:29.061
to give you back all of the comments for
that particular board.

23
00:01:31.473 --> 00:01:34.049
Well, let's look at the performance
profile of this particular query that

24
00:01:34.049 --> 00:01:34.700
we've done here.

25
00:01:36.120 --> 00:01:40.864
So just like how MongoDB you can
do explain with SQL, you just put,

26
00:01:40.864 --> 00:01:44.954
explain in front of whatever
query you're about to run.

27
00:01:44.954 --> 00:01:49.100
And it'll tell you,
here's my plan to do that.

28
00:01:49.100 --> 00:01:49.954
So this cost,

29
00:01:49.954 --> 00:01:54.805
it's a relative number actually don't
even really know what it's measuring.

30
00:01:54.805 --> 00:01:58.284
But it's 65 is a lot [LAUGH]
I'll just tell you that much.

31
00:01:58.284 --> 00:02:01.835
It's not a good query,
when you're that high and

32
00:02:01.835 --> 00:02:06.500
the thing just like we were afraid
of seeing called scan MongoDB.

33
00:02:06.500 --> 00:02:10.240
The thing that we're afraid of
seeing in Postgres is this one here.

34
00:02:10.240 --> 00:02:15.424
Sequential scan,
you can see a lot of this cost here

35
00:02:15.424 --> 00:02:20.980
is coming from this particular
sequential scan here.

36
00:02:22.640 --> 00:02:25.836
This means it's looking at every single
comment in the database every single time

37
00:02:25.836 --> 00:02:27.340
that we run this query.

38
00:02:27.340 --> 00:02:30.067
Now imagine that you're
running a Reddit scale and

39
00:02:30.067 --> 00:02:32.359
you're running this a lot in production.

40
00:02:32.359 --> 00:02:36.003
You're gonna have an either
an astronomical bill or downtime or

41
00:02:36.003 --> 00:02:37.355
both more than likely.

42
00:02:37.355 --> 00:02:38.916
We can basically say ahead of time,

43
00:02:38.916 --> 00:02:42.030
this is a kind of query that
we're gonna be doing a lot.

44
00:02:42.030 --> 00:02:46.250
Please index this for us, right?

45
00:02:46.250 --> 00:02:51.394
So what I wanna do now
is I'm gonna say create

46
00:02:51.394 --> 00:02:55.860
index on comments board ID like that.

47
00:02:55.860 --> 00:02:59.813
So on the comments board or on
the comments table, index on the board ID

48
00:02:59.813 --> 00:03:03.237
because that's something I'd
be [INAUDIBLE] by quite a bit.

49
00:03:06.188 --> 00:03:11.655
Okay, again, don't just go run this in
production, this is a very hefty command.

50
00:03:11.655 --> 00:03:13.634
This only works because
I'm on my computer, and

51
00:03:13.634 --> 00:03:15.335
it's not doing anything else right now.

52
00:03:17.285 --> 00:03:22.676
Now, if I run this again, instead of
seeing sequential scan here on comments,

53
00:03:22.676 --> 00:03:25.340
what I'm seeing is bitmap index scan.

54
00:03:26.490 --> 00:03:28.921
This is the name of the index.

55
00:03:28.921 --> 00:03:32.186
And this went from being
65 cost to being 33 costs.

56
00:03:36.256 --> 00:03:38.040
Much better, right?

57
00:03:38.040 --> 00:03:44.235
Much, much better cuz this bitmap
index scan and bitmap heap scan,

58
00:03:44.235 --> 00:03:51.030
these are going to work significantly
faster than what we had before.

59
00:03:51.030 --> 00:03:53.942
So something else that we'd wanna do.

60
00:03:53.942 --> 00:03:59.411
Let's say we wanna make sure that all
users names have a unique username.

61
00:03:59.411 --> 00:04:04.417
We can do that with a unique
index just like we saw before.

62
00:04:04.417 --> 00:04:09.661
So we gonna you say, create unique index,
we can give it a name of the index, right?

63
00:04:09.661 --> 00:04:12.435
We'll just call this one
username index like that.

64
00:04:18.591 --> 00:04:24.755
On users username, like that, okay?

65
00:04:24.755 --> 00:04:30.122
So now, not only do we have an index
on usernames in the users index.

66
00:04:30.122 --> 00:04:34.743
But we can also be totally assured
that all of them are gonna be unique

67
00:04:34.743 --> 00:04:36.050
going on forward.

68
00:04:36.050 --> 00:04:38.700
This it will fail if there's
already a duplicate in there.

69
00:04:38.700 --> 00:04:44.694
So it's gonna make you all right,
go do duplicate this yourself and

70
00:04:44.694 --> 00:04:49.018
then once you're done we
can create this index.

71
00:04:49.018 --> 00:04:56.016
So, select star or select username from
users where user ID equals ten, right?

72
00:04:56.016 --> 00:05:00.842
So we got this one,
what happens if I tried to actually

73
00:05:00.842 --> 00:05:04.180
I'll just copy this from over here.

74
00:05:07.970 --> 00:05:09.230
This one right here.

75
00:05:09.230 --> 00:05:15.800
I know this Aaizikovj I know
that one exists in my database.

76
00:05:15.800 --> 00:05:18.191
So if I try and
run this with a duplicate username.

77
00:05:22.416 --> 00:05:28.895
Like this it's gonna say, duplicate
key value virus, unique constraints.

78
00:05:28.895 --> 00:05:31.912
I'm not gonna let you do this because you
promised me this is gonna be unique and

79
00:05:31.912 --> 00:05:32.745
this isn't unique.

80
00:05:35.135 --> 00:05:36.388
So that's another way of doing that.

81
00:05:36.388 --> 00:05:38.539
Postgres has a ton of
different types of indexes.

82
00:05:38.539 --> 00:05:41.195
I just showed you two of them.

83
00:05:41.195 --> 00:05:44.464
I left a link there in the course
notes for you to go, click on and

84
00:05:44.464 --> 00:05:46.584
see all the different types of indexes.

85
00:05:51.473 --> 00:05:54.090
Cool, and that's just kind of
like a whirlwind tour of indexes.

86
00:05:54.090 --> 00:05:56.210
I'm gonna be the same advice even for
MongoDB.

87
00:05:56.210 --> 00:06:00.186
In general, it's useful to see how
you're using your database and

88
00:06:00.186 --> 00:06:02.219
where the expensive queries are.

89
00:06:02.219 --> 00:06:04.190
And then go and create indexes for those.

90
00:06:04.190 --> 00:06:08.702
Usually you don't wanna go too much in
advance and prematurely optimizing.

91
00:06:08.702 --> 00:06:13.082
Because bad indexes and useless indexes
just slow down your computer or

92
00:06:13.082 --> 00:06:16.470
slow down your searches and
waste a lot of space.

93
00:06:16.470 --> 00:06:20.781
Yeah, indexes are not small, because it's
creating like a whole data structure to

94
00:06:20.781 --> 00:06:24.740
represent your table in a different way,
so that I can search it more easily.

