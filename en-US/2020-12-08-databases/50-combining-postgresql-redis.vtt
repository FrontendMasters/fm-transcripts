WEBVTT

1
00:00:00.760 --> 00:00:05.459
So we're going to kind of, I'm not gonna
do this, I actually thought about getting

2
00:00:05.459 --> 00:00:09.110
Postgres running again and
doing this with Postgres.

3
00:00:09.110 --> 00:00:12.602
We're just gonna kind of fake Postgres for
a moment, but

4
00:00:12.602 --> 00:00:16.331
this is how you would combine
Postgres together with Redis.

5
00:00:16.331 --> 00:00:20.300
So what I wanna do is I wanna do that
caching thing that we were talking

6
00:00:20.300 --> 00:00:21.285
about earlier.

7
00:00:21.285 --> 00:00:25.679
Let's pretend that we have a Postgres
query that takes a very long time

8
00:00:25.679 --> 00:00:27.160
to complete.

9
00:00:27.160 --> 00:00:29.350
And we wanna do a caching
strategy on top of that.

10
00:00:30.680 --> 00:00:33.060
So I have an rGet here,
we actually already did this one.

11
00:00:33.060 --> 00:00:34.260
Let's do one more line here.

12
00:00:34.260 --> 00:00:36.010
We're gonna do r with set.

13
00:00:38.540 --> 00:00:41.590
But the way that we're gonna do an XQuery
is you actually have to do it with

14
00:00:41.590 --> 00:00:42.090
an EX here.

15
00:00:42.090 --> 00:00:46.580
So this is gonna be setex like this.

16
00:00:46.580 --> 00:00:51.540
So this allows us to do
a set with an expiry, right.

17
00:00:51.540 --> 00:00:53.310
They just made it
a different function name.

18
00:00:55.690 --> 00:01:02.940
Okay, and what we're gonna do now is we're
gonna create a Function here called cache.

19
00:01:02.940 --> 00:01:06.034
This function is gonna take in some
sort of long running function and

20
00:01:06.034 --> 00:01:08.000
it's gonna create a cached version of it.

21
00:01:09.170 --> 00:01:10.658
So it's gonna take in a key,

22
00:01:10.658 --> 00:01:13.646
this is gonna be the key that
we're gonna store in Redis.

23
00:01:13.646 --> 00:01:19.214
It's gonna take in some sort of ttl,
how many seconds we want it to survive,

24
00:01:19.214 --> 00:01:23.491
and some sort of slow function
that we want to cache, oky.

25
00:01:23.491 --> 00:01:30.100
So here we're going to, this is a function
that will return another function.

26
00:01:30.100 --> 00:01:36.720
So we're going to return an async
function of some variety.

27
00:01:36.720 --> 00:01:41.482
We can even call this cached
over here rather, cachedFn,

28
00:01:41.482 --> 00:01:46.450
right, so that our stack traces
can look a little bit nicer.

29
00:01:46.450 --> 00:01:51.826
And this is gonna have some variety
of props that are gonna come into

30
00:01:51.826 --> 00:01:57.712
it that we're just going to pass on
to slow function when we call it.

31
00:01:57.712 --> 00:01:59.020
So it's a higher order function, right?

32
00:01:59.020 --> 00:01:59.520
It's a function that returns a function.

33
00:02:03.424 --> 00:02:11.808
So what we're gonna do
now is we're gonna say,

34
00:02:11.808 --> 00:02:19.994
const cachedResponse = await rGet(key).

35
00:02:19.994 --> 00:02:22.624
So the first thing we're gonna do is,

36
00:02:22.624 --> 00:02:25.922
do you have a cached
response already in Redis?

37
00:02:25.922 --> 00:02:28.810
If yes, return it, right?

38
00:02:28.810 --> 00:02:34.590
So you're gonna say if
cachedResponse here,

39
00:02:34.590 --> 00:02:39.330
success return, we can call it a day,

40
00:02:39.330 --> 00:02:43.640
return cachedResponse, right?

41
00:02:45.770 --> 00:02:50.301
If not, then we're gonna say
const result = await and

42
00:02:50.301 --> 00:02:53.165
we're gonna call slow function.

43
00:02:55.958 --> 00:02:59.094
And we're gonna just spread out
those props that we got here, right.

44
00:02:59.094 --> 00:03:02.140
So let's say this is
reading from the database.

45
00:03:02.140 --> 00:03:05.660
We're just going to be passing in
the prompts that we got in into the slow

46
00:03:05.660 --> 00:03:07.080
function here.

47
00:03:07.080 --> 00:03:08.779
In this case, it doesn't matter, but

48
00:03:08.779 --> 00:03:11.260
we're making a generic function
that we can use a bunch.

49
00:03:13.060 --> 00:03:19.108
We're gonna say await rSetx,
cuz we want to set it to our cache,

50
00:03:19.108 --> 00:03:26.530
so next time that we can hit it and
we're just gonna say key ttl result.

51
00:03:26.530 --> 00:03:29.140
So whatever came back from the database,
that's what we're gonna cache.

52
00:03:29.140 --> 00:03:32.364
And we're going to return result.

53
00:03:37.536 --> 00:03:38.480
So this is great.

54
00:03:38.480 --> 00:03:41.089
Now we have this generic cache
function that we can use anywhere that

55
00:03:41.089 --> 00:03:42.518
we want to cache some sort of result.

56
00:03:45.768 --> 00:03:50.040
So now we're just gonna make
an intentionally slow function.

57
00:03:50.040 --> 00:03:55.512
We're gonna call this async function

58
00:03:55.512 --> 00:04:02.011
verySlowAndEexpensivePostgresQL query,

59
00:04:02.011 --> 00:04:05.263
something like that.

60
00:04:06.660 --> 00:04:10.938
And you can imagine here, here you would
do a big ugly query for Postgres, right?

61
00:04:10.938 --> 00:04:17.776
We're just gonna return

62
00:04:17.776 --> 00:04:26.660
an artificially slow thing.

63
00:04:26.660 --> 00:04:31.744
So first think I'm gonna say, I'm gonna
say console.log('oh no a very expensive

64
00:04:31.744 --> 00:04:36.950
query No a very expensive query'),
just so we can know when it happens.

65
00:04:36.950 --> 00:04:40.925
We can even put this up here as well and

66
00:04:40.925 --> 00:04:45.685
say,right there, hooray, it is cached.

67
00:04:49.855 --> 00:04:54.824
Okay, and then here, we're gonna say

68
00:04:54.824 --> 00:05:00.402
const promise = new Promise (resolve).

69
00:05:06.056 --> 00:05:12.073
And then we're just
gonna say setTimeout and

70
00:05:12.073 --> 00:05:15.247
resolve with new Date,

71
00:05:20.406 --> 00:05:23.273
.toUTCString.

72
00:05:23.273 --> 00:05:27.784
So all it's gonna do is after five
seconds, it's gonna resolve with the date.

73
00:05:34.729 --> 00:05:36.769
And then down here, we'll make it last,
I don't know, ten seconds or

74
00:05:36.769 --> 00:05:37.421
something like that.

75
00:05:42.800 --> 00:05:45.250
Okay, and then down here,
we're gonna say return promise.

76
00:05:47.060 --> 00:05:52.037
So all this does right now, is it just
does a timeout and it'll resolve this

77
00:05:52.037 --> 00:05:57.900
promise after ten seconds, right, to kind
of simulate a long running Postgres query.

78
00:06:00.930 --> 00:06:02.960
So now here's the fun part.

79
00:06:02.960 --> 00:06:08.872
We can say const cachedFn = cache,

80
00:06:11.520 --> 00:06:15.262
('expensive_call') or
whatever you want to call it.

81
00:06:18.600 --> 00:06:21.662
Yeah, we'll stick with that.

82
00:06:21.662 --> 00:06:25.624
Let's say, we'll make this last for,

83
00:06:28.568 --> 00:06:33.007
This will be in seconds, make it last for
ten seconds or something like that.

84
00:06:38.028 --> 00:06:40.056
Let's make this one last five seconds.

85
00:06:40.056 --> 00:06:44.401
So this will get cached for
ten seconds and then the ttl,

86
00:06:44.401 --> 00:06:49.810
it'll expire, so very slow and
expensive function here.

87
00:06:49.810 --> 00:06:53.589
So now we have this cachedFn,
which will cache the response for

88
00:06:53.589 --> 00:06:57.816
this and then every 10 seconds,
it'll get you a fresh copy of that.

89
00:07:00.658 --> 00:07:04.274
Okay, let's make a new row in our
app here, it's gonna be app.get/,

90
00:07:04.274 --> 00:07:06.844
I don't know, get,
whatever you want to call it,

91
00:07:12.613 --> 00:07:15.587
async (req, res).

92
00:07:19.388 --> 00:07:25.912
And all it's gonna do here, it's gonna
say const data = await cachedFn.

93
00:07:29.818 --> 00:07:38.517
And say res.json, Data status: 'ok'.end.

94
00:07:43.983 --> 00:07:49.435
All right, so now we have this endpoint

95
00:07:49.435 --> 00:07:55.184
/get, That will call that endpoint.

96
00:07:55.184 --> 00:07:57.570
All right, so we need to stop and
start our server again.

97
00:07:59.140 --> 00:08:01.826
And we're just gonna go directly to /get.

98
00:08:01.826 --> 00:08:05.229
So notice this is gonna
take a second up here,

99
00:08:05.229 --> 00:08:09.570
cuz the first time it's
gonna get a cache miss.

100
00:08:09.570 --> 00:08:12.410
But now if I refresh it, it's really fast.

101
00:08:12.410 --> 00:08:16.879
And then after ten seconds we're
gonna get another long time before,

102
00:08:16.879 --> 00:08:20.070
there you go,
now it's taking a long time again.

103
00:08:22.282 --> 00:08:25.140
So you can see here, no,
a very expensive query.

104
00:08:25.140 --> 00:08:28.920
Hooray, it's cached and then down here
again, no, a very expensive query.

105
00:08:32.269 --> 00:08:35.570
Okay, so
now let's simulate thundering herd, right.

106
00:08:35.570 --> 00:08:40.994
So let's wait until this is gonna take a
long time, and now taking a bunch of time.

107
00:08:40.994 --> 00:08:42.373
And I'm gonna refresh a bunch of times,

108
00:08:42.373 --> 00:08:44.330
cuz I definitely wanna buy
that PlayStation 5, right?

109
00:08:45.960 --> 00:08:47.589
I'm not upset [LAUGH].

110
00:08:47.589 --> 00:08:53.360
But you can see here, I just thundering
herded all over this server, right.

111
00:08:53.360 --> 00:08:55.649
Kind of my point here is
you need to be aware and

112
00:08:55.649 --> 00:08:59.280
cautious of how you're doing
these kind of caching strategies.

113
00:08:59.280 --> 00:09:03.417
This caching strategy is probably fine for
something that's gonna be hit relatively

114
00:09:03.417 --> 00:09:06.990
infrequently, that your chances
of thundering herd are very low.

115
00:09:06.990 --> 00:09:08.314
It's probably okay.

116
00:09:08.314 --> 00:09:12.974
But if you're gonna be implementing
a black Friday flash sale,

117
00:09:12.974 --> 00:09:18.770
not that I'm speaking from experience
here, you don't want to do it this way.

118
00:09:20.210 --> 00:09:24.030
But again, yeah, this is one way you
can definitely do a caching strategy.

