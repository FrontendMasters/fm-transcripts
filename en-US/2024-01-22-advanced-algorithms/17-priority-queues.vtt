WEBVTT

1
00:00:00.209 --> 00:00:02.050
So we can make this faster and

2
00:00:02.050 --> 00:00:05.670
this is where we need to figure
out how to make it faster.

3
00:00:05.670 --> 00:00:09.010
I can see it behind everybody,
priority Q called it.

4
00:00:09.010 --> 00:00:12.494
Absolutely, we're gonna do a heap and
that is how we're gonna pull out things.

5
00:00:12.494 --> 00:00:14.722
So, does everybody here
know what a heap is?

6
00:00:14.722 --> 00:00:15.882
Min heap, max heap.

7
00:00:15.882 --> 00:00:20.034
We got one yes, two yes,
three yes, four yes, five.

8
00:00:20.034 --> 00:00:22.129
Was that peer pressure, yes,
or was that a real yes?

9
00:00:22.129 --> 00:00:23.982
&gt;&gt; No.

10
00:00:23.982 --> 00:00:27.046
&gt;&gt; Okay, I believe and then chat and
you probably all know it.

11
00:00:27.046 --> 00:00:28.970
But just in case you don't know it,

12
00:00:28.970 --> 00:00:31.544
a priority queue is
effectively a binary tree.

13
00:00:31.544 --> 00:00:34.305
It's like really not a tree,
but it is totally a tree.

14
00:00:34.305 --> 00:00:36.818
They're very, very cool.

15
00:00:36.818 --> 00:00:39.029
Where there's something
called a heap condition.

16
00:00:39.029 --> 00:00:42.973
A heap condition is either the min or
the max.

17
00:00:42.973 --> 00:00:46.534
Meaning that let's pretend this is A,
B and

18
00:00:46.534 --> 00:00:50.007
C are heap conditioned according to B or
A.

19
00:00:50.007 --> 00:00:55.208
Meaning that if we have the minimum, A is
the absolute minimum out of all elements,

20
00:00:55.208 --> 00:00:58.345
but B could be larger than C or
could be less than C.

21
00:00:58.345 --> 00:01:02.932
The heap condition only works up the tree,
meaning that B's children,

22
00:01:02.932 --> 00:01:05.876
we'll call it x and y,
are both larger than B.

23
00:01:05.876 --> 00:01:09.974
Now, they may also be smaller than C,
they may both be larger than C.

24
00:01:09.974 --> 00:01:13.428
The ordering does not matter this way or
across the level,

25
00:01:13.428 --> 00:01:15.414
it only matters going up or down.

26
00:01:15.414 --> 00:01:17.574
So that's a very important part of a heap.

27
00:01:17.574 --> 00:01:22.586
Some fun facts about a heap,
if you wanna visit the nodes, you always

28
00:01:22.586 --> 00:01:28.131
start at some place say A, to visit
this child, you have to do 2 your index.

29
00:01:28.131 --> 00:01:32.067
Index of the root node is 1,
so 2 index would be 2,

30
00:01:32.067 --> 00:01:37.177
which happens to be this,
2 index plus 1 would be your other side.

31
00:01:37.177 --> 00:01:41.649
That's because underneath it's actually
stored in an array which makes it so neat.

32
00:01:41.649 --> 00:01:44.097
So A would be here, then B, C.

33
00:01:44.097 --> 00:01:50.784
And so if we wanted to find X,
starting from i, it would be 2i.

34
00:01:50.784 --> 00:01:56.158
So since B is 2, we'd have to go
down to 4, so that'd be 1, 2, 3, 4.

35
00:01:56.158 --> 00:02:01.835
And it'd go right here, this is X, and
this is Y, because that's 2i plus 1.

36
00:02:01.835 --> 00:02:03.023
Pretty fun, and this keeps on going.

37
00:02:03.023 --> 00:02:04.342
So heaps are kind of cool.

38
00:02:04.342 --> 00:02:05.505
If you go into any position,

39
00:02:05.505 --> 00:02:08.465
you're actually jumping around inside
an array using some fancy math.

40
00:02:08.465 --> 00:02:11.486
Quick maths right here,
it's only 2's, 2's and pluses of 1's.

41
00:02:11.486 --> 00:02:13.260
That's the thing about
being a computer scientist.

42
00:02:13.260 --> 00:02:17.545
You never have to add more than one, and
you never have to multiply more than two.

43
00:02:17.545 --> 00:02:18.749
It's very, very nice.

44
00:02:18.749 --> 00:02:20.706
I absolutely love that.

45
00:02:20.706 --> 00:02:26.781
As a teacher once said, all answers
are 2 to the n or 2 to the n minus 1.

46
00:02:26.781 --> 00:02:28.009
That was 2 to the n right there.

47
00:02:28.009 --> 00:02:29.837
That were two to the n in r right there.

48
00:02:29.837 --> 00:02:36.389
All right, so we're going to use that
idea to now keep track of our edges but

49
00:02:36.389 --> 00:02:42.022
there is a cost to using a heap
when you add something to the heap.

50
00:02:42.022 --> 00:02:47.063
No matter where it is, you always add
it to the end of the underlying array,

51
00:02:47.063 --> 00:02:48.903
the length of the array, or

52
00:02:48.903 --> 00:02:54.362
the position within our array that is last
defined is the next position to add to.

53
00:02:54.362 --> 00:02:56.111
It's kind of one of
the optimizations of a heap.

54
00:02:56.111 --> 00:02:58.973
Then you have to heapify
up as it's called.

55
00:02:58.973 --> 00:03:02.523
Am I less than my parent,
if I am swap it up.

56
00:03:02.523 --> 00:03:07.193
Am I less than my parent,
If I am swap it up, if not you're done,

57
00:03:07.193 --> 00:03:09.538
heapified great you're dead.

58
00:03:09.538 --> 00:03:11.641
I don't know I like saying that phrase,
it's just super fun.

59
00:03:11.641 --> 00:03:15.888
All right, there we go, so that is a heap.

60
00:03:15.888 --> 00:03:19.032
Hopefully, everyone understands that and
so

61
00:03:19.032 --> 00:03:22.101
we are gonna be putting
our edges into a heap.

62
00:03:22.101 --> 00:03:26.647
That means we are gonna have to
potentially walk a binary tree that is

63
00:03:26.647 --> 00:03:28.980
perfectly balanced at all times.

64
00:03:28.980 --> 00:03:35.130
So what is the runtime of walking up
a tree that is perfectly balanced?

65
00:03:35.130 --> 00:03:36.880
&gt;&gt; Log h.

66
00:03:36.880 --> 00:03:38.723
&gt;&gt; h or log of n.

67
00:03:38.723 --> 00:03:41.029
Technically, h is log of n in this case.

68
00:03:41.029 --> 00:03:43.615
h equals log of n.

69
00:03:43.615 --> 00:03:46.408
So it always is gonna be that,
because it's perfectly balanced.

70
00:03:46.408 --> 00:03:51.392
So every single time you insert
into a heap, it is log of n.

71
00:03:51.392 --> 00:03:56.012
Every time you want to remove
the minimal element, it is log of n.

72
00:03:56.012 --> 00:03:57.083
So the exact same thing.

73
00:03:57.083 --> 00:04:02.292
So that means we go from
having to do this in E time to

74
00:04:02.292 --> 00:04:08.507
having to do a log N lookup, or
in this case, it'd be log E.

75
00:04:08.507 --> 00:04:11.272
E being N, because we're using edges.

76
00:04:11.272 --> 00:04:15.568
All right, which also means our add
to collection now gets changed.

77
00:04:15.568 --> 00:04:23.755
Our add to collection, every time you add
an edge to the collection, that is a log.

78
00:04:23.755 --> 00:04:26.964
We now actually have a log
situation going on here.

79
00:04:26.964 --> 00:04:32.314
Obviously, you can totally check for
visited, so you're not doing as many,

80
00:04:32.314 --> 00:04:36.134
but practically speaking,
we are E log E at this point.

81
00:04:36.134 --> 00:04:41.118
And so
now we have dynamically changed our run

82
00:04:41.118 --> 00:04:46.102
time of our algorithm from V.E to, whoops,

83
00:04:46.102 --> 00:04:49.920
that is totally wrong, to E log E.

84
00:04:49.920 --> 00:04:52.976
But we can still do even better than that.

85
00:04:52.976 --> 00:04:55.939
We can make it faster,
stronger, and more amazing.

86
00:04:55.939 --> 00:04:58.422
Are you ready for
the more amazing version of this?

87
00:04:58.422 --> 00:05:01.548
I'm gonna write that over here.

88
00:05:01.548 --> 00:05:03.848
You're probably thinking,
it can't get any better.

89
00:05:03.848 --> 00:05:06.174
Well, if he acts now, we can.

90
00:05:06.174 --> 00:05:09.721
Alright, so instead of doing this whole,
just dropped the idea of edges,

91
00:05:09.721 --> 00:05:11.541
you don't need to think about edges.

92
00:05:11.541 --> 00:05:13.064
You're thinking about this right now,

93
00:05:13.064 --> 00:05:15.491
this is actually one of my favorite
data structures of all time.

94
00:05:15.491 --> 00:05:19.232
It's a priority queue,
except for it's indexed,

95
00:05:19.232 --> 00:05:23.578
meaning we're literally gonna
use the PIQ data structure.

96
00:05:23.578 --> 00:05:25.236
If you don't know who PIQ is, great guy.

97
00:05:25.236 --> 00:05:29.733
So we're actually using the data
structure named after a very swell fella.

98
00:05:29.733 --> 00:05:32.489
So, the PIQ data structure,
a priority indexed queue.

99
00:05:32.489 --> 00:05:37.672
What we're gonna do here is that we're
going to initialize a priority queue,

100
00:05:37.672 --> 00:05:41.598
except the priority queue,
instead of having edges in it,

101
00:05:41.598 --> 00:05:45.540
is going to have vertices with
the minimum known distance.

102
00:05:45.540 --> 00:05:47.353
I know pretty exciting right?

103
00:05:47.353 --> 00:05:48.739
Which means we're going to do this.

104
00:05:48.739 --> 00:05:53.824
Let's just say again we start at E,
that means we're

105
00:05:53.824 --> 00:05:59.031
going to have a priority queue of A,
B, C, D, E and G.

106
00:05:59.031 --> 00:06:01.711
E will be zero,
we already know the distance right?

107
00:06:01.711 --> 00:06:03.516
We don't know any other distance.

108
00:06:03.516 --> 00:06:06.838
All of them are infinity.

109
00:06:06.838 --> 00:06:11.330
And since this is a pick, a priority
indexed queue, I can say, hey, get me C.

110
00:06:11.330 --> 00:06:12.890
O of 1, look up for C.

111
00:06:12.890 --> 00:06:17.396
Get out C, and I can say,
hey, is 3 less than infinity?

112
00:06:17.396 --> 00:06:19.959
It is, we'll put a 3 there, right?

113
00:06:19.959 --> 00:06:21.233
We've removed E, by the way.

114
00:06:21.233 --> 00:06:22.124
I forgot to do that step.

115
00:06:22.124 --> 00:06:24.805
We remove E,
now we're adding in its edges.

116
00:06:24.805 --> 00:06:26.471
And so we look up C, we do that,

117
00:06:26.471 --> 00:06:29.757
now we have to heapify it because
we've changed its weight.

118
00:06:29.757 --> 00:06:31.831
So we have to heapify
it within the heap and

119
00:06:31.831 --> 00:06:34.039
it's going to be moved
higher up to the top.

120
00:06:34.039 --> 00:06:39.686
So that's going to be a log V operation
because there's only V items in there.

121
00:06:39.686 --> 00:06:44.529
So log V, V is always smaller than E,

122
00:06:44.529 --> 00:06:48.916
other than this one single case.

123
00:06:48.916 --> 00:06:51.662
After that, it's always larger, right?

124
00:06:51.662 --> 00:06:56.042
You will always be able to
do the same size or larger.

125
00:06:56.042 --> 00:06:58.805
So just don't bring up the two node case,
okay?

126
00:06:58.805 --> 00:07:01.031
It's just unfair mathematics.

127
00:07:01.031 --> 00:07:03.570
All right, so we do that we can do with F.

128
00:07:03.570 --> 00:07:08.271
F turns into a 1, G turns into a 3, and

129
00:07:08.271 --> 00:07:15.264
now we've just done this with log V time,
E log V, right?

130
00:07:15.264 --> 00:07:19.712
And so we've properly made it
into an E log V algorithm.

131
00:07:19.712 --> 00:07:21.372
And just for the sake of completeness,

132
00:07:21.372 --> 00:07:23.545
I am gonna run through this
really really quickly.

133
00:07:23.545 --> 00:07:26.591
That means we take this,
we've now visited E,

134
00:07:26.591 --> 00:07:30.181
and we now are gonna pop off
the next item which will be F.

135
00:07:30.181 --> 00:07:35.078
So now, we'll have the line with
the priority queue right here.

136
00:07:35.078 --> 00:07:40.758
Then we'll update all the distances,
G becomes 2, D becomes 4.

137
00:07:40.758 --> 00:07:42.396
And then now we can pop off G.

138
00:07:42.396 --> 00:07:45.251
And you can kinda see this thing
go on from here on out, right?

139
00:07:45.251 --> 00:07:48.221
Everyone's following along,
everyone's tracking, same algorithm.

140
00:07:48.221 --> 00:07:52.877
We're now using nodes with their best
known distance as the way we pop things

141
00:07:52.877 --> 00:07:54.414
off the priority queue.

142
00:07:54.414 --> 00:07:56.222
Super, super cool, right?

143
00:07:56.222 --> 00:07:59.243
And we've now managed to get it all
the way down to E log V proper.

144
00:07:59.243 --> 00:08:00.986
And so I think that's a super cool.

145
00:08:00.986 --> 00:08:04.394
I didn't know about this
trick until not too long ago.

146
00:08:04.394 --> 00:08:06.653
I didn't realize you could
organize it by nodes and do that.

147
00:08:06.653 --> 00:08:08.318
I always thought it was E log E.

148
00:08:08.318 --> 00:08:11.602
So super cool, blew my mind when I
saw that, and I was just like, wow,

149
00:08:11.602 --> 00:08:12.516
that's awesome.

150
00:08:12.516 --> 00:08:13.939
All right, we need to go on.

151
00:08:13.939 --> 00:08:15.498
We need this to be even better.

152
00:08:15.498 --> 00:08:18.480
We're gonna now look at
Kruskal's algorithm.

153
00:08:18.480 --> 00:08:19.716
His algorithm is a little bit different.

