WEBVTT

1
00:00:00.210 --> 00:00:05.415
So vector-based databases, they let
you store and index high dimensional

2
00:00:05.415 --> 00:00:10.703
vector representing text data allowing for
efficient similarity search and

3
00:00:10.703 --> 00:00:16.880
retrieval of documents or phrases based
on their embedding representations.

4
00:00:16.880 --> 00:00:21.951
So, what, first before trying to
understand that concept let's go back and

5
00:00:21.951 --> 00:00:24.690
try to understand what's an embedding?

6
00:00:25.870 --> 00:00:30.936
It's a method of converting
text into numerical vectors,

7
00:00:30.936 --> 00:00:36.205
enabling efficient processing and
comparison of text data,

8
00:00:36.205 --> 00:00:41.476
learn through training neural
network models on large amount

9
00:00:41.476 --> 00:00:46.360
of text data is,
still weird to understand what they do.

10
00:00:47.420 --> 00:00:51.868
We will take a text,
a chunk of text, for example,

11
00:00:51.868 --> 00:00:57.041
my last ten minutes of speech,
and we can send that to open AI

12
00:00:57.041 --> 00:01:03.670
not to the CBT model to a different
API that is called embeddings.

13
00:01:03.670 --> 00:01:09.130
In return,
open AI will give us an array of numbers.

14
00:01:09.130 --> 00:01:14.526
The array of numbers, that's an embedding
represents the text and the semantic

15
00:01:14.526 --> 00:01:20.336
relationship of the text with other words,
it's difficult to understand actually.

16
00:01:20.336 --> 00:01:23.777
But the idea is that we store
that in a database, but

17
00:01:23.777 --> 00:01:28.550
it's not a normal database,
it's a vector-based database.

18
00:01:28.550 --> 00:01:33.570
So that vector-based database will
let us then make semantic search.

19
00:01:33.570 --> 00:01:37.639
So then when we have
the question from the user,

20
00:01:37.639 --> 00:01:44.580
we can find exactly which vector is more
semantically related to that question.

21
00:01:47.480 --> 00:01:50.910
The representation looks like
a dense vector of real numbers.

22
00:01:50.910 --> 00:01:55.920
It's actually an array of numbers,
a large array of numbers.

23
00:01:55.920 --> 00:02:00.917
And because it's number is also fast
to process for many algorithms, for

24
00:02:00.917 --> 00:02:05.832
example, a word embedding the word
cat may look like an array of 0.2,

25
00:02:05.832 --> 00:02:08.753
0.5 minute blah, blah, blah, blah.

26
00:02:08.753 --> 00:02:13.135
Typically we're talking about
really large numbers and

27
00:02:13.135 --> 00:02:16.877
infinite numbers when
you're looking at them,

28
00:02:16.877 --> 00:02:21.180
so that's why we needed
an especial database for that.

29
00:02:21.180 --> 00:02:26.250
So the method to work with this
is known as a split and embed.

30
00:02:26.250 --> 00:02:30.750
So we're going to split our
document in slices in chunks.

31
00:02:30.750 --> 00:02:35.435
By any character length, you pick one,
1000 characters 1500 even in fact,

32
00:02:35.435 --> 00:02:39.770
you can play with different numbers and
see which one works better.

33
00:02:39.770 --> 00:02:41.887
It doesn't need to be a semantic cut so

34
00:02:41.887 --> 00:02:46.550
you can cut anywhere well here from
here to here, that's a slice, okay.

35
00:02:46.550 --> 00:02:49.844
It can be a PDF, videos caption,
frequently asked questions,

36
00:02:49.844 --> 00:02:52.109
wherever document lash document you have.

37
00:02:52.109 --> 00:02:57.066
It can be even also like
an output from classic database

38
00:02:57.066 --> 00:03:01.700
with all your customers,
with all your products,

39
00:03:01.700 --> 00:03:06.681
with prices, so
you have cut it in slices, in chunks.

40
00:03:06.681 --> 00:03:11.180
Sometimes you even overlap a little bit,
like 10% of the slice of the next

41
00:03:11.180 --> 00:03:14.570
slice also contains the last
10% of the previous one.

42
00:03:16.130 --> 00:03:20.580
We convert each slice into
its embedded representation.

43
00:03:20.580 --> 00:03:23.760
How we pay Open AI for that?

44
00:03:23.760 --> 00:03:27.320
We make a request, you do that once only.

45
00:03:27.320 --> 00:03:29.823
We make a request to the open API for
embeddings,

46
00:03:29.823 --> 00:03:33.470
that's a different API from
the ones that we have been using.

47
00:03:33.470 --> 00:03:37.934
And in return GPT will give
us the vector representation,

48
00:03:37.934 --> 00:03:40.220
the embedding of that chunk.

49
00:03:41.320 --> 00:03:45.749
We then with that we store
the embeddings in a vector database that

50
00:03:45.749 --> 00:03:50.350
you need to install, you need to use,
or you can use from the cloud.

51
00:03:51.470 --> 00:03:56.136
There are a lot of cloud based solutions
that will solve you that problem.

52
00:03:56.136 --> 00:04:00.488
And it's just numbers, it's numbers, okay?

53
00:04:00.488 --> 00:04:04.125
So, we do that when we want
to create our database.

54
00:04:04.125 --> 00:04:05.915
But then, the user is asking questions.

55
00:04:05.915 --> 00:04:11.035
So, when we need a prompt, and we need
the prompt to answer the question from

56
00:04:11.035 --> 00:04:15.929
our data, we search in the vector
database based on what the user needs.

57
00:04:17.030 --> 00:04:22.093
The database will return the slice,
the chunk of the information that is

58
00:04:22.093 --> 00:04:27.250
closer semantically to the query,
and that's the power of embeddings.

59
00:04:29.460 --> 00:04:36.010
Then we checked that chunk of information,
that slice, as the context of the prompt.

60
00:04:36.010 --> 00:04:39.709
We go back to the idea of
filing the context, right,

61
00:04:39.709 --> 00:04:44.672
prompt engineering we are injecting
that slice of information that is

62
00:04:44.672 --> 00:04:48.220
semantically close to
the query into the prompt.

63
00:04:49.420 --> 00:04:54.067
This is how it looks like in a diagram,
so we have a use of prompt,

64
00:04:54.067 --> 00:04:58.940
we have our app,
it's a server-side app, for example.

65
00:04:58.940 --> 00:05:02.860
We have a vector database in our server or
in the Cloud, and

66
00:05:02.860 --> 00:05:04.860
then we have the Open AI APIs.

67
00:05:06.460 --> 00:05:07.850
So this is how it works.

68
00:05:07.850 --> 00:05:10.990
We receive the users prompt,
it's a query, it's a question.

69
00:05:12.690 --> 00:05:19.780
Then our app, we'll take the prompt and
talk to the Open AI embeddings API.

70
00:05:19.780 --> 00:05:21.810
I have this question from the user.

71
00:05:21.810 --> 00:05:26.020
The question is,
what's the price of the Open AI?

72
00:05:26.020 --> 00:05:27.790
So what's the price of a token?

73
00:05:27.790 --> 00:05:31.040
That's something that I said at
the beginning of the course.

74
00:05:31.040 --> 00:05:33.580
So Open AI doesn't know about that.

75
00:05:33.580 --> 00:05:38.450
But it receives a string, and it returns
me the embedding of that question.

76
00:05:39.460 --> 00:05:43.130
Numbers, statistical
numbers are just numbers.

77
00:05:43.130 --> 00:05:47.850
We then go with those embeddings to
our vector database and say, hey,

78
00:05:47.850 --> 00:05:50.170
I have this embedding.

79
00:05:50.170 --> 00:05:56.290
Find me the chunk that is semantically
closer to that embedding.

80
00:05:56.290 --> 00:06:01.242
And your vector database will give you
the slice of relevant information,

81
00:06:01.242 --> 00:06:07.800
the chunk of strings, the 1000 characters,
where I was talking about the price.

82
00:06:07.800 --> 00:06:13.587
And then with that, you will add that
as a context of the use of prompt and

83
00:06:13.587 --> 00:06:16.961
I'm making a final query
to the GPT API and

84
00:06:16.961 --> 00:06:21.322
that will give me the output
that I essentially user.

85
00:06:21.322 --> 00:06:26.391
That's the process today to create
a chatbot that will answer questions

86
00:06:26.391 --> 00:06:31.126
about a lot of things that you have
in your system to documentation,

87
00:06:31.126 --> 00:06:35.860
for example, if you have a documentation
of your API or if your app,

88
00:06:35.860 --> 00:06:39.290
you have a big manual
of how something works.

89
00:06:39.290 --> 00:06:42.110
It can be documentation about
a product that you are selling.

90
00:06:42.110 --> 00:06:44.990
I'm selling laptops and I have a manual.

91
00:06:44.990 --> 00:06:48.280
Well, how can I make a chatbot that
can answer questions about the manual?

92
00:06:48.280 --> 00:06:53.253
Well, you split the manual in chunks,
you create the embeddings of those of each

93
00:06:53.253 --> 00:06:57.716
chunk, you store that in a vector
database and when there is a question,

94
00:06:57.716 --> 00:06:59.860
you do that process.

95
00:06:59.860 --> 00:07:02.320
That's how embedding works.

96
00:07:02.320 --> 00:07:05.668
It's a lot of work, yeah, I know that for

97
00:07:05.668 --> 00:07:10.500
you as developer are expecting
something simpler.

98
00:07:10.500 --> 00:07:14.611
Even a lot of people is expecting
actually fine-tuning Chat GPT, but

99
00:07:14.611 --> 00:07:20.480
that's not possible with that model as of
today, and I don't think it's the idea.

100
00:07:20.480 --> 00:07:26.310
So you can still fine-tune, and
you pay for that as well on Open AI.

101
00:07:26.310 --> 00:07:29.804
Previous models not just CBT but for

102
00:07:29.804 --> 00:07:35.176
church CBT it's everything
has to do with the prompt.

