WEBVTT

1
00:00:00.129 --> 00:00:01.423
So if you ask me,

2
00:00:01.423 --> 00:00:07.068
I think this is kind of magic that you
can give more context to the prompt.

3
00:00:07.068 --> 00:00:09.543
And that's how you do that.

4
00:00:09.543 --> 00:00:14.096
So if you want to create a chat
in your own website that answers

5
00:00:14.096 --> 00:00:17.952
questions from your
frequently asked questions.

6
00:00:17.952 --> 00:00:25.559
Well, you need to pass to GPT,
you are frequently asked question.

7
00:00:25.559 --> 00:00:27.964
And then the user question.

8
00:00:27.964 --> 00:00:31.062
Doesn't make sense and
you need to explain,

9
00:00:31.062 --> 00:00:34.413
you will answer only from
this set of questions.

10
00:00:34.413 --> 00:00:36.953
Things like that, that's how it's done.

11
00:00:36.953 --> 00:00:39.225
But is there any other way?

12
00:00:39.225 --> 00:00:44.215
So because we cannot fine tune
LLMs such as such, chatGPT.

13
00:00:44.215 --> 00:00:47.302
We need to go back to the prompt.

14
00:00:47.302 --> 00:00:53.946
But if you wanna connect GPT to our data,
our databases or

15
00:00:53.946 --> 00:00:59.768
our PDF files,
The magic happens in the context.

16
00:00:59.768 --> 00:01:04.698
And we know that we need to
pass a lot of information In

17
00:01:04.698 --> 00:01:07.622
this chat format that we have.

18
00:01:07.622 --> 00:01:11.582
Typically we pass that in the system
message remember that we have

19
00:01:11.582 --> 00:01:15.902
a dialogue and we can pass a system you
are this and that well there you can

20
00:01:15.902 --> 00:01:19.790
add all the information or
the context that you want to provide.

21
00:01:19.790 --> 00:01:23.066
The problem is that sometimes
the context is too large.

22
00:01:23.066 --> 00:01:29.644
GPT doesn't have memory so we have
to inject the prompt on every call,

23
00:01:29.644 --> 00:01:34.896
which is costly first and
seems like a problem, right?

24
00:01:34.896 --> 00:01:40.628
So for large databases and
documents there is a design pattern.

25
00:01:40.628 --> 00:01:48.277
To split the data and do a search
outside of the model before the prompt.

26
00:01:48.277 --> 00:01:53.254
Let me explain how that works, for
example we can connect GPT with

27
00:01:53.254 --> 00:01:57.972
our own data for a chatbot that
can answer questions locally.

28
00:01:57.972 --> 00:02:03.884
To search transform
summarize our own data.

29
00:02:03.884 --> 00:02:08.902
Or something that is kind
of a final use case that we

30
00:02:08.902 --> 00:02:15.484
see lately a lot is chat with,
chat with a PDF, chat with a video.

31
00:02:15.484 --> 00:02:19.175
So you can chat with these videos
you're watching right now.

32
00:02:19.175 --> 00:02:23.526
In this case We use the caption,
we need to use text for now,

33
00:02:23.526 --> 00:02:26.151
the captions of my voice speaking.

34
00:02:26.151 --> 00:02:29.881
And we can put this into this process
that I will explain in a minute.

35
00:02:29.881 --> 00:02:34.268
And then you can chat with I
know some kind of myself in

36
00:02:34.268 --> 00:02:38.178
the metaverse of GPT,
at least in this video.

37
00:02:38.178 --> 00:02:42.158
So how does it work?

38
00:02:42.158 --> 00:02:47.150
The idea is that if you have an idea of
what you're looking for you first search.

39
00:02:47.150 --> 00:02:48.346
So for example,

40
00:02:48.346 --> 00:02:54.079
someone is asking about how to make from
this video how to make a ChatGPT plugin.

41
00:02:54.079 --> 00:02:57.619
Okay, so you know,
that has to do with ChatGPT plugin.

42
00:02:57.619 --> 00:03:01.586
And I haven't mentioned
ChaGPT in the last hour, so

43
00:03:01.586 --> 00:03:04.303
we know that it's not in that park.

44
00:03:04.303 --> 00:03:07.857
But there is a part of the video
where we mentioned that.

45
00:03:07.857 --> 00:03:12.178
So we search that we
can search in a normal

46
00:03:12.178 --> 00:03:16.379
database in files or data collection.

47
00:03:16.379 --> 00:03:20.713
And then you pass
the result just the piece,

48
00:03:20.713 --> 00:03:27.167
the chunk of text of that part of
the video to ChatGPT as a context.

49
00:03:27.167 --> 00:03:29.962
I know it's a silly.

50
00:03:29.962 --> 00:03:34.723
But sometimes it's easy when
not simple to understand where

51
00:03:34.723 --> 00:03:39.120
in the whole document,
we have the answer for the user.

52
00:03:39.120 --> 00:03:42.907
It's difficult just by
searching by keyword.

53
00:03:42.907 --> 00:03:44.397
It's not so simple.

54
00:03:44.397 --> 00:03:49.020
For example, if you asked me about GPT,
I mentioned GPT over the whole video

55
00:03:49.020 --> 00:03:52.722
1000 times, so
then you will pass the whole video text?

56
00:03:52.722 --> 00:03:56.542
No, we have another solution for that.

57
00:03:56.542 --> 00:03:59.143
And that solution is called embeddings.

58
00:03:59.143 --> 00:04:02.416
And we use a different
kind of database for that.

59
00:04:02.416 --> 00:04:05.745
That open AI is not helping
you with that part.

60
00:04:05.745 --> 00:04:08.643
So, because this is an open AI and
ChatGPT course.

61
00:04:08.643 --> 00:04:12.686
I will give you some hints on
where to look for these APIs, but

62
00:04:12.686 --> 00:04:14.599
we won't cover that today.

