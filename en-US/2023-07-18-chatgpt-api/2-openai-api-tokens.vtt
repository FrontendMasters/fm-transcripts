WEBVTT

1
00:00:00.000 --> 00:00:01.711
ChatGPT works in this way.

2
00:00:01.711 --> 00:00:04.701
ChatGPT is in the middle,
is that logo we have there.

3
00:00:04.701 --> 00:00:09.932
ChatGPT or any GPT model,
actually, receives a prompt,

4
00:00:09.932 --> 00:00:14.323
and it gives a result,
that's kind of the idea.

5
00:00:14.323 --> 00:00:19.318
And in this case,
ChatGPT as an app is using a GPT model

6
00:00:19.318 --> 00:00:22.538
that looks like a black box there.

7
00:00:22.538 --> 00:00:26.553
And the color is not random
because it's actually a black box,

8
00:00:26.553 --> 00:00:28.609
we don't know what's inside.

9
00:00:28.609 --> 00:00:30.550
We don't know how it works.

10
00:00:30.550 --> 00:00:33.825
We will see this in action
in a couple of minutes.

11
00:00:33.825 --> 00:00:38.235
But we treat that piece of software,
let's say it's a software,

12
00:00:38.235 --> 00:00:42.663
as something that we don't
actually understand what's inside.

13
00:00:42.663 --> 00:00:46.044
The only thing we know is
that we put a prompt and

14
00:00:46.044 --> 00:00:49.011
we receive something in return, okay?

15
00:00:49.011 --> 00:00:50.365
What's a prompt?

16
00:00:50.365 --> 00:00:52.670
A string, just text.

17
00:00:52.670 --> 00:00:54.214
What's the result?

18
00:00:54.214 --> 00:00:56.900
A string, another text.

19
00:00:56.900 --> 00:01:00.213
That's why it's known as
a large language model.

20
00:01:00.213 --> 00:01:03.037
So that's the basic thing.

21
00:01:03.037 --> 00:01:05.596
And maybe if you're a developer,

22
00:01:05.596 --> 00:01:11.254
you're expecting this to be different
later during the day in this course.

23
00:01:11.254 --> 00:01:15.667
You're expecting me to show you an API
where you can actually get into

24
00:01:15.667 --> 00:01:19.717
that black box to make things
differently or things like that.

25
00:01:19.717 --> 00:01:23.385
And that doesn't exist,
actually, that doesn't exist.

26
00:01:23.385 --> 00:01:28.171
So I got that as a surprise when I was
trying to understand how this work.

27
00:01:28.171 --> 00:01:30.981
So GPT,
we have different versions of GPT, and

28
00:01:30.981 --> 00:01:33.521
there will be more versions in the future.

29
00:01:33.521 --> 00:01:36.215
That's the only thing that you pick,
the version.

30
00:01:36.215 --> 00:01:40.088
And there are some settings as well,
but we don't have an API for

31
00:01:40.088 --> 00:01:42.550
do something different with the model.

32
00:01:42.550 --> 00:01:46.135
It's always a prompt and
a result, that's all.

33
00:01:46.135 --> 00:01:48.373
So we need to deal with that.

34
00:01:48.373 --> 00:01:50.878
That's why there is something
known as prompt engineering.

35
00:01:50.878 --> 00:01:54.092
Because the only input we
have there is the prompt.

36
00:01:54.092 --> 00:01:58.601
So we need to get experts
integrating that prompt.

37
00:01:58.601 --> 00:02:05.194
Well, when we are setting a prompt or
we are sending a prompt to ChatGPT or

38
00:02:05.194 --> 00:02:11.139
to any API that is GPT-enabled,
and we're getting the result,

39
00:02:11.139 --> 00:02:17.003
we are measuring those strings
with something known as tokens.

40
00:02:17.003 --> 00:02:22.476
Tokens will be the most important unit for
us from now on, why?

41
00:02:22.476 --> 00:02:25.613
Because that's what we are paying for.

42
00:02:25.613 --> 00:02:29.901
A token is a sequence of characters,
or, let's say,

43
00:02:29.901 --> 00:02:34.844
subwords that the model uses as
the basic unit of processing and

44
00:02:34.844 --> 00:02:38.035
understanding natural language text.

45
00:02:38.035 --> 00:02:42.363
So we are not going to be
charged in our credit card,

46
00:02:42.363 --> 00:02:46.100
we will get into that
in a couple of minutes.

47
00:02:46.100 --> 00:02:50.233
We are not going to get charged by
the character or by the word or

48
00:02:50.233 --> 00:02:54.299
by the paragraph,
we're going to get charged by the token.

49
00:02:54.299 --> 00:02:57.292
So that's how we work.

50
00:02:57.292 --> 00:03:02.651
So during the month, OpenAI will
count how many tokens we've used.

51
00:03:02.651 --> 00:03:08.926
And you will use tokens when we prompt and
when we receive the output, okay?

52
00:03:08.926 --> 00:03:13.054
Yeah, you're actually in charge
of the prompt, not of the output.

53
00:03:13.054 --> 00:03:17.484
But what you can do is you select
the maximum amount of token that you

54
00:03:17.484 --> 00:03:19.951
are willing to pay for every prompt.

55
00:03:19.951 --> 00:03:26.843
So you will say, hey, I'm going to pay for
only ten tokens, not more than that.

56
00:03:26.843 --> 00:03:31.653
So we can narrow the output
using that maximum tokens

57
00:03:31.653 --> 00:03:36.148
property that we will see
where it is in a minute.

58
00:03:36.148 --> 00:03:41.658
And just to give you an idea of
what a token is, in English,

59
00:03:41.658 --> 00:03:47.629
it's roughly 4.5, so between 3 and
6 letters per token.

60
00:03:47.629 --> 00:03:54.065
So one token, let's say it's four letters,
but that's different per language.

61
00:03:54.065 --> 00:03:57.734
And also that's different when
you are applying source code.

62
00:03:57.734 --> 00:04:02.887
So because ChatGPT or
GPT can also read and write source code.

63
00:04:02.887 --> 00:04:05.402
So in that case, it's not per character.

64
00:04:05.402 --> 00:04:09.072
For example, when you open curly braces,
that might be just one token.

65
00:04:09.072 --> 00:04:12.022
So it's not counting really characters.

66
00:04:12.022 --> 00:04:15.658
And when you're writing in different
languages, Chinese, Korean,

67
00:04:15.658 --> 00:04:18.394
it's not like four characters
will give you a token.

68
00:04:18.394 --> 00:04:22.463
So it's a different way
of understanding that.

69
00:04:22.463 --> 00:04:27.333
At this point, you might be thinking,
how do I know how this works?

70
00:04:27.333 --> 00:04:33.375
Well, we do have in
OpenAI a tokenizer tool.

71
00:04:33.375 --> 00:04:40.485
It's platform.openai.com/tokenizer,
where you can write some text.

72
00:04:40.485 --> 00:04:47.515
And you can see how many tokens
this particular text will get.

73
00:04:47.515 --> 00:04:51.440
In this case,
it's going to be three tokens, but

74
00:04:51.440 --> 00:04:56.122
I can just copy any text and
see how many tokens it will take.

75
00:04:56.122 --> 00:04:57.532
You will see that it's
not always the same.

76
00:04:57.532 --> 00:05:00.871
For example, here I have one comma,

77
00:05:00.871 --> 00:05:06.171
the comma is taking one token we have for
the comma, okay?

78
00:05:06.171 --> 00:05:11.813
But at least with this you can estimate
based on the prompts that you will use and

79
00:05:11.813 --> 00:05:14.480
the results that you are expecting.

80
00:05:14.480 --> 00:05:19.687
You will try to understand roughly or to
estimate roughly how this is gonna work.

81
00:05:19.687 --> 00:05:22.567
By the way, here we see GPT-3.

82
00:05:22.567 --> 00:05:26.907
GPT, we know what that is,
it's the LLM model.

83
00:05:26.907 --> 00:05:27.856
What about Codex?

84
00:05:27.856 --> 00:05:32.050
Codex is a different model that OpenAI,
the company,

85
00:05:32.050 --> 00:05:34.797
is going to deprecate pretty soon.

86
00:05:34.797 --> 00:05:37.788
And Codex was actually optimized for
source code.

87
00:05:37.788 --> 00:05:41.471
But because now GPT is pretty
good at source code as well,

88
00:05:41.471 --> 00:05:43.407
they are deprecating Codex.

89
00:05:43.407 --> 00:05:45.693
It was a different model, so

90
00:05:45.693 --> 00:05:50.562
different models will calculate
tokens in a different way.

91
00:05:50.562 --> 00:05:52.309
So that's about tokens.

92
00:05:52.309 --> 00:05:55.278
Well, what about the price of tokens?

93
00:05:55.278 --> 00:05:57.886
Well, of course, pricing might change.

94
00:05:57.886 --> 00:06:02.614
So I'm just giving you the rough
price as we are shooting this video.

95
00:06:02.614 --> 00:06:07.767
There is a pricing website at OpenAI
where you can get the exact pricing.

96
00:06:07.767 --> 00:06:13.614
But just to give you an idea,
ChatGPT, or GPT 3.5,

97
00:06:13.614 --> 00:06:19.336
that's actually the version
that ChatGPT is using,

98
00:06:19.336 --> 00:06:24.440
cost around US$2 per million tokens, okay?

99
00:06:24.440 --> 00:06:28.035
Yeah, you won't pay per million token,
you will pay by the token.

100
00:06:28.035 --> 00:06:33.929
So if it's $0.01 cent, you will be charged
$0.01, but that's actually the price.

101
00:06:33.929 --> 00:06:40.460
So GPT4, that is the latest
version of the model available,

102
00:06:40.460 --> 00:06:46.614
that you may have heard that
it's actually much better for

103
00:06:46.614 --> 00:06:52.516
some special tasks,
such as coding and complex tasks,

104
00:06:52.516 --> 00:06:58.816
is actually 30 to 60 times
more expensive than 3.5.

105
00:06:58.816 --> 00:07:04.016
So that power comes with
more processing power used,

106
00:07:04.016 --> 00:07:07.722
so that's why it's more expensive.

107
00:07:07.722 --> 00:07:11.357
The advantage is that it
has a higher token window.

108
00:07:11.357 --> 00:07:11.967
Is it okay?

109
00:07:11.967 --> 00:07:12.574
What's that?

110
00:07:12.574 --> 00:07:14.846
What's a token window?

111
00:07:14.846 --> 00:07:19.569
So now we know what a token is, and
we know that we will prompt a model and

112
00:07:19.569 --> 00:07:23.593
the model will respond with a string,
okay, we know that.

113
00:07:23.593 --> 00:07:26.956
And we know that that's expressing tokens.

114
00:07:26.956 --> 00:07:32.956
What we don't know as of right
now is that models have a limit

115
00:07:32.956 --> 00:07:39.320
of how many tokens you can input,
you can prompt, or receive.

116
00:07:39.320 --> 00:07:44.254
And GPT 4, it has a higher token window.

117
00:07:44.254 --> 00:07:51.133
If I wanna send GPT a book because
I want GPT to summarize the book,

118
00:07:51.133 --> 00:07:57.404
I need to calculate how many
tokens that book will contain.

119
00:07:57.404 --> 00:08:05.264
And GPT 3 can maybe read one
page per request, only one page.

120
00:08:05.264 --> 00:08:11.981
But ChatGPT 4 can read 60 pages,
80 pages of that same book.

121
00:08:11.981 --> 00:08:15.577
Of course, I will pay more, not just
because the token is more expensive,

122
00:08:15.577 --> 00:08:17.991
but because, of course,
I'm paying per token.

123
00:08:17.991 --> 00:08:23.237
But having that higher
token window means that

124
00:08:23.237 --> 00:08:28.078
I can give more context
to that LLM black box

125
00:08:28.078 --> 00:08:32.935
to get better answers, that's the idea.

126
00:08:32.935 --> 00:08:36.787
Also, GPT 4 will have in the near future,

127
00:08:36.787 --> 00:08:42.570
it's not today available to every user,
image and prompting.

128
00:08:42.570 --> 00:08:47.714
That is the idea of taking a picture and
ask questions about the picture.

129
00:08:47.714 --> 00:08:53.231
So I can take a picture of the room here,
and I can get an answer of, okay,

130
00:08:53.231 --> 00:08:59.401
how many chairs do I have here in this
room, or ask questions about that picture.

131
00:08:59.401 --> 00:09:02.823
That API was demoed by the CEO,

132
00:09:02.823 --> 00:09:07.435
but it's not yet available to everyone.

133
00:09:07.435 --> 00:09:11.701
When that happens,
it will have its own pricing system.

134
00:09:11.701 --> 00:09:17.089
Also, there are other models available
on OpenAI that we won't use today.

135
00:09:17.089 --> 00:09:21.280
But have in mind, it's not everything
ChatGPT, there are other models,

136
00:09:21.280 --> 00:09:23.488
the most common one is called DaVinci.

137
00:09:23.488 --> 00:09:27.217
Those models are not optimized for
chat, for

138
00:09:27.217 --> 00:09:30.858
a conversation between a human and
the LLM.

139
00:09:30.858 --> 00:09:36.105
It was more about completion,
so you were actually saying I'm

140
00:09:36.105 --> 00:09:41.253
a web developer, and
because of that my primary language is,

141
00:09:41.253 --> 00:09:46.305
and the model will give you JavaScript,
probably, right?

142
00:09:46.305 --> 00:09:50.595
But it's not about answering questions,
it's more completion,

143
00:09:50.595 --> 00:09:53.162
it's like the grandfather of ChatGPT.

144
00:09:53.162 --> 00:09:55.712
Those models are still there and
you can still use them.

145
00:09:55.712 --> 00:10:00.959
And sometimes they are cheaper than
ChatGPT if you wanna use them.

146
00:10:00.959 --> 00:10:05.734
But they are for
more precise specific situations.

147
00:10:05.734 --> 00:10:09.985
And we know that LLMs can be used for
anything, so

148
00:10:09.985 --> 00:10:13.208
most people are just using ChatGPT.

149
00:10:13.208 --> 00:10:18.798
Also we have image models, and later
today we will use one, DALL-E, actually.

150
00:10:18.798 --> 00:10:23.161
So you can actually send a prompt,
that's not an LLM, it's a different model.

151
00:10:23.161 --> 00:10:25.133
You will send a prompt like,

152
00:10:25.133 --> 00:10:30.976
I want a web developer that is actually
thinking about an artificial intelligence.

153
00:10:30.976 --> 00:10:35.673
And you will get an image that
was created based on your prompt.

154
00:10:35.673 --> 00:10:38.142
And for everything we have an API.

155
00:10:38.142 --> 00:10:42.799
And we will use that API from our web app.

156
00:10:42.799 --> 00:10:45.273
And finally, there is audio models.

157
00:10:45.273 --> 00:10:49.564
We have that audio model
from OpenAI open source.

158
00:10:49.564 --> 00:10:54.061
But if you don't wanna download and
run that directly in your computer,

159
00:10:54.061 --> 00:10:55.620
you can use the service.

160
00:10:55.620 --> 00:10:59.551
In that case, the audio service
they have is for transcription.

161
00:10:59.551 --> 00:11:02.775
So we can get the audio of
what I'm speaking right now.

162
00:11:02.775 --> 00:11:07.998
We can get really quickly, like three
hours of audio, you can get the text

163
00:11:07.998 --> 00:11:13.829
transcript that works pretty well in
around five seconds, that's how quickly.

164
00:11:13.829 --> 00:11:16.321
So three hours in five seconds.

165
00:11:16.321 --> 00:11:21.160
So those are the models that
we have today on OpenAI.

166
00:11:21.160 --> 00:11:24.332
What about how to create
an account on OpenAI?

167
00:11:24.332 --> 00:11:28.069
First, it's not the same as
having an account on ChatGPT.

168
00:11:28.069 --> 00:11:31.280
So you need to go and
create a different account.

169
00:11:31.280 --> 00:11:35.145
You go to platform.openai.com.

170
00:11:35.145 --> 00:11:38.064
It's free to sign in,
there is only one restriction,

171
00:11:38.064 --> 00:11:40.609
is that you need to
validate your phone number.

172
00:11:40.609 --> 00:11:44.049
So you need a valid phone
number with an SMS, and

173
00:11:44.049 --> 00:11:47.925
that phone number shouldn't
be a VoIP phone number.

174
00:11:47.925 --> 00:11:53.010
So it's not gonna work if you try a VoIP
like an online number such as Skype or

175
00:11:53.010 --> 00:11:57.802
things like that, it's not gonna work,
it should be a real SIM card.

176
00:11:57.802 --> 00:12:01.690
And you will get, if this is
the first time you will try this, and

177
00:12:01.690 --> 00:12:06.010
you can do that right now, you can
pause the video and do that right now.

178
00:12:06.010 --> 00:12:13.140
If you sign in, you can get free credits,
today it's $5 that will last 3 months.

179
00:12:13.140 --> 00:12:19.030
And in that case,
you can start playing with the API and

180
00:12:19.030 --> 00:12:26.349
do all the exercises that we will
be using today, not paying a dime.

181
00:12:26.349 --> 00:12:32.738
So $5 will be good enough for everything
that we will be doing today and more.

182
00:12:32.738 --> 00:12:37.362
If you are thinking I will
create different accounts so

183
00:12:37.362 --> 00:12:39.311
I can get more than $5.

184
00:12:39.311 --> 00:12:42.346
Those $5 is per phone number, okay?

185
00:12:42.346 --> 00:12:45.711
That's why they're not
accepting VoIP numbers.

186
00:12:45.711 --> 00:12:47.948
There will be rate limits as well.

187
00:12:47.948 --> 00:12:51.324
This is in case you are getting
really professional or

188
00:12:51.324 --> 00:12:55.008
your service is going viral,
there are some rate limits.

189
00:12:55.008 --> 00:13:03.527
So you cannot get into one particular
API more than 500 times per minute.

190
00:13:03.527 --> 00:13:08.334
For example, GPT 3.5, so that's ChatGPT,

191
00:13:08.334 --> 00:13:14.330
the cheaper version,
it's 3500 requests per minute.

192
00:13:14.330 --> 00:13:16.723
It's actually pretty good,
for a start, at least.

193
00:13:16.723 --> 00:13:20.714
It depends on what you're doing, have in
mind that you have that limit per account.

194
00:13:20.714 --> 00:13:27.192
And GPT 4, it's only 200 requests
per minute, so it's more expensive,

195
00:13:27.192 --> 00:13:32.905
it's much better, but
also it's much limited, today, at least.

196
00:13:34.371 --> 00:13:38.991
So this is important for those of you
that are working for a company or

197
00:13:38.991 --> 00:13:41.435
creating products for companies.

198
00:13:41.435 --> 00:13:44.555
When you're using the OpenAI API,

199
00:13:44.555 --> 00:13:49.755
all the interaction that you're
having will not be used for

200
00:13:49.755 --> 00:13:54.127
training or
improving models at OpenAI company.

201
00:13:54.127 --> 00:13:56.712
That's not the case for ChatGPT.

202
00:13:56.712 --> 00:14:02.288
When you're using ChatGPT, even if
you're paying for the plus service,

203
00:14:02.288 --> 00:14:07.077
the data that you are submitting
may be used later for training.

204
00:14:07.077 --> 00:14:12.465
When you're using the API, that's not
the case, it's part of the contract, okay?

205
00:14:12.465 --> 00:14:17.165
So legally,
everything that you say there is not

206
00:14:17.165 --> 00:14:21.873
going to be stored or
used to train other models.

207
00:14:21.873 --> 00:14:28.517
So this is important, and if you're
a ChatGPT user, you probably know this.

208
00:14:28.517 --> 00:14:32.493
OpenAI GPT, both 3.5 and 4,

209
00:14:32.493 --> 00:14:38.041
the training data is actually up to 2021.

210
00:14:38.041 --> 00:14:42.928
So they might not have
knowledge of current events,

211
00:14:42.928 --> 00:14:46.260
so you shouldn't rely on OpenAI for

212
00:14:46.260 --> 00:14:51.049
events in the past two years,
so have in mind that.

213
00:14:51.049 --> 00:14:54.760
That was the basic of OpenAI and
understanding how that works.

214
00:14:54.760 --> 00:14:59.661
So at this point, the next step for
you is to go and get an account,

215
00:14:59.661 --> 00:15:04.227
because without an account,
you won't be able to use this.

