WEBVTT

1
00:00:00.000 --> 00:00:04.690
There is one particular plugin
that was created by ChatGPT

2
00:00:04.690 --> 00:00:06.899
that is a browsing plugin.

3
00:00:06.899 --> 00:00:09.330
So it can browse the web.

4
00:00:09.330 --> 00:00:12.470
That is similar to how
Bing Chat works today.

5
00:00:12.470 --> 00:00:16.288
That you can search something,
and it will go and

6
00:00:16.288 --> 00:00:20.588
make a search, and it will go and
browse your website.

7
00:00:20.588 --> 00:00:24.096
It will honor robots.txt,
that old file from,

8
00:00:24.096 --> 00:00:27.271
if you're a web developer, you know that.

9
00:00:27.271 --> 00:00:30.861
Basically, you can actually say,
hey, OpenAI,

10
00:00:30.861 --> 00:00:34.466
I don't want you to take my content for
your users.

11
00:00:34.466 --> 00:00:39.813
So you can actually, it will honor that
declaration if you deny access to the bot.

12
00:00:39.813 --> 00:00:46.117
And the keyword to deny that based
on the User Agent is ChatGPT-User.

13
00:00:46.117 --> 00:00:50.695
So you can say, now, I don't want
user from Chat-GPT in my website.

14
00:00:50.695 --> 00:00:55.358
One of the problems here is that maybe
what happens if you have then a lot of

15
00:00:55.358 --> 00:00:58.045
users on ChatGPT browsing your website?

16
00:00:58.045 --> 00:01:01.637
First, they're not actually
seeing your banners, your ads.

17
00:01:01.637 --> 00:01:05.057
They're not seeing your promotions,
they're not seeing your login screen,

18
00:01:05.057 --> 00:01:06.494
they're just taking your data.

19
00:01:06.494 --> 00:01:11.540
So that's why some companies are saying,
hey, maybe I'm going to filter this.

20
00:01:11.540 --> 00:01:16.570
And also, actually, the plugin says that

21
00:01:16.570 --> 00:01:22.729
it's going to be nice with domains,
with origins.

22
00:01:22.729 --> 00:01:28.000
Meaning that they're not going to send
you a million requests to your server.

23
00:01:28.000 --> 00:01:34.086
So they will try to be good citizens
of the Web, that's what they're saying.

24
00:01:34.086 --> 00:01:37.841
And the next question is,
that's a User Agent.

25
00:01:37.841 --> 00:01:41.517
Can you deliver something different for
ChatGPT?

26
00:01:41.517 --> 00:01:46.045
Technically you can, server-side,
you can read the user agent,

27
00:01:46.045 --> 00:01:47.718
so the browser's name.

28
00:01:47.718 --> 00:01:53.115
And deliver something different,
better, different, worse, I don't know.

29
00:01:53.115 --> 00:01:54.000
Is it possible?

30
00:01:54.000 --> 00:01:57.251
It is, you shouldn't be doing that.

31
00:01:57.251 --> 00:02:01.141
So, technically, that browser,

32
00:02:01.141 --> 00:02:05.426
it's capable of reading any website.

33
00:02:07.971 --> 00:02:11.934
That leads to another question,
it's about security.

34
00:02:14.020 --> 00:02:17.752
There are, for example, ideas, papers, and

35
00:02:17.752 --> 00:02:22.709
even real things around something
known as prompt injection.

36
00:02:22.709 --> 00:02:25.792
So a prompt injection is a way, because,

37
00:02:25.792 --> 00:02:31.618
remember I mentioned that the plugin is
just injecting content in the prompt?

38
00:02:31.618 --> 00:02:35.922
So what if the plugin is injecting
something that changes the prompt

39
00:02:35.922 --> 00:02:36.836
completely?

40
00:02:36.836 --> 00:02:42.182
As, for example, SQL injection that
is changing the whole SQL query.

41
00:02:42.182 --> 00:02:44.404
Well, something similar happens here.

42
00:02:44.404 --> 00:02:48.918
And sometimes, for example,
you can inject words such as

43
00:02:48.918 --> 00:02:53.076
forget about everything
that was requested before.

44
00:02:53.076 --> 00:02:57.053
Now listen to me, colon, and
you give another instruction.

45
00:02:57.053 --> 00:03:01.772
If you know that that string
is going to be injected in

46
00:03:01.772 --> 00:03:06.724
a larger prompt,
you might be injecting that prompt.

47
00:03:06.724 --> 00:03:12.240
And there is a researcher here,
that we can check,

48
00:03:12.240 --> 00:03:17.259
with more information
about that technique.

49
00:03:17.259 --> 00:03:22.900
In fact, he has a demo here
on how he made Bing Chat,

50
00:03:22.900 --> 00:03:30.276
that is based on GPT, on the same ChatGPT,
to speak like a pirate.

51
00:03:30.276 --> 00:03:35.513
So you get into the website,
you ask questions,

52
00:03:35.513 --> 00:03:39.859
and without saying nothing different,

53
00:03:39.859 --> 00:03:45.114
the GPT model will speak like a pirate,
and why?

54
00:03:45.114 --> 00:03:51.082
Because he injected a prompt
within the contents of the HTML.

55
00:03:51.082 --> 00:03:56.223
And in this case, Bing is reading
the source code of your HTML,

56
00:03:56.223 --> 00:04:00.302
the content, and
he managed to inject the model.

57
00:04:00.302 --> 00:04:05.005
This is just, yeah, it can be funny,
but also you can inject instruction.

58
00:04:05.005 --> 00:04:11.253
For example, you can inject, you can make
the AI work for you if you're a bad actor.

59
00:04:11.253 --> 00:04:15.338
Such as, the AI can ask you for
your credit card.

60
00:04:15.338 --> 00:04:21.891
And you see, it's not the website,
it's Bing asking me for my credit card.

61
00:04:21.891 --> 00:04:24.186
Okay, I will give the credit card.

62
00:04:24.186 --> 00:04:29.234
So, this is an ongoing research,
if you want.

63
00:04:29.234 --> 00:04:34.093
But it's possible then
to inject text into your

64
00:04:34.093 --> 00:04:39.442
websites that will change
how models are reacting.

65
00:04:39.442 --> 00:04:43.705
Because everything is just
about prompt injection.

66
00:04:43.705 --> 00:04:46.643
So prompt is key in here.

67
00:04:48.598 --> 00:04:53.488
Okay, so we need to be very
careful with our own calls.

68
00:04:53.488 --> 00:04:57.558
If we integrate GPT data into our system,

69
00:04:57.558 --> 00:05:01.175
run actions based on GPT responses.

70
00:05:01.175 --> 00:05:06.559
So I'm not sure if any of you have
heard about something known as AutoGPT.

71
00:05:06.559 --> 00:05:11.797
AutoGPT is a tool that
is used in OpenAI that

72
00:05:11.797 --> 00:05:16.753
actually iterates over GPT many times.

73
00:05:16.753 --> 00:05:21.307
And one of the things that it can do is
take actions on your operating system, or

74
00:05:21.307 --> 00:05:23.034
take actions in your system.

75
00:05:23.034 --> 00:05:27.382
It can open apps, close apps, use apps,

76
00:05:27.382 --> 00:05:31.744
it can do stuff based
on what GPT is doing.

77
00:05:31.744 --> 00:05:38.619
Well, if someone can inject a prompt, they
can ask for stealing your information.

78
00:05:38.619 --> 00:05:43.168
And then a tool will get the folder
on your computer, make a SIP,

79
00:05:43.168 --> 00:05:46.464
and send that folder over
email to a bad actor.

80
00:05:46.464 --> 00:05:52.436
So you need to be very careful
with prompt injection, right?

81
00:05:52.436 --> 00:05:58.373
So if you iterate responses with GPT,
call GPT many times,

82
00:05:58.373 --> 00:06:03.259
have in mind that some
security risks are there.

83
00:06:03.259 --> 00:06:08.283
So you should always validate the format
and the intention before acting.

84
00:06:08.283 --> 00:06:14.644
In fact, you can use GPT, again,
to check if an action is valid or

85
00:06:14.644 --> 00:06:19.169
invalid, or if it was changed,
for example.

