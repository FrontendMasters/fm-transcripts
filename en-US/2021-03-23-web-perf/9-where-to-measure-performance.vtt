WEBVTT

1
00:00:00.565 --> 00:00:05.360
What this was, was lab data,
it was our own private measurement.

2
00:00:05.360 --> 00:00:10.176
And so this brings up an important
point about where should we measure

3
00:00:10.176 --> 00:00:11.596
performance from?

4
00:00:11.596 --> 00:00:16.480
So let's think for a minute about how a
website works, how web application works.

5
00:00:16.480 --> 00:00:19.661
You have your servers,
and you have your users.

6
00:00:19.661 --> 00:00:24.396
And there's a whole bunch of magic
network things that happen in between.

7
00:00:24.396 --> 00:00:29.060
Fundamentally, what your servers need
to do is produce some documents,

8
00:00:29.060 --> 00:00:33.871
some JavaScript, some CSS, some images,
and send those across the wire to

9
00:00:33.871 --> 00:00:37.880
your users, who will run it in
their browser and render a page.

10
00:00:39.430 --> 00:00:44.290
So how do we measure how
fast this is happening?

11
00:00:44.290 --> 00:00:48.995
Well, what we just did, was lab data,
is we connected directly to

12
00:00:48.995 --> 00:00:53.374
our server from our dev machine,
from our local dev machine.

13
00:00:53.374 --> 00:00:58.275
And we measured how well does this
perform for us using our laptop.

14
00:00:58.275 --> 00:01:05.350
Not really for the user, not really for
anything else, just how we see our data.

15
00:01:05.350 --> 00:01:09.090
If this is something that we're running
locally, like if we're running the site on

16
00:01:09.090 --> 00:01:11.408
our machine and
we're testing it from our machine,

17
00:01:11.408 --> 00:01:14.720
then we've taken the network
out of the equation entirely.

18
00:01:14.720 --> 00:01:19.000
We've not tested anything about
how a real network performs.

19
00:01:19.000 --> 00:01:22.944
We're just testing how fast our loopback
interface in our own machines can run,

20
00:01:22.944 --> 00:01:25.040
which is generally really, really fast.

21
00:01:26.800 --> 00:01:28.470
So these are tools like Lighthouse.

22
00:01:29.720 --> 00:01:32.340
Well, there's another way
you can capture data.

23
00:01:32.340 --> 00:01:37.273
We can capture things synthetically,
which is there's a robot somewhere out

24
00:01:37.273 --> 00:01:42.770
in the network that will periodically
load your page and tell you how it works.

25
00:01:42.770 --> 00:01:46.120
In this case,
we're testing some of the network.

26
00:01:46.120 --> 00:01:51.358
There's a test server, it'll run
a window of Chrome, and it'll give you

27
00:01:51.358 --> 00:01:57.194
some performance metrics about how their
instance of Chrome in that server ran it.

28
00:01:57.194 --> 00:01:58.480
And this is pretty good.

29
00:01:58.480 --> 00:02:01.633
There's a lot of tools out there on
the marketplace that will do this.

30
00:02:01.633 --> 00:02:06.400
There's things like New relic ,and
Pingdom, and those sorts of things.

31
00:02:06.400 --> 00:02:08.203
You can buy a service
that will do this for

32
00:02:08.203 --> 00:02:10.710
you and periodically tell
you about your performance.

33
00:02:12.370 --> 00:02:16.010
Well, the third way that we could
do this is called field data.

34
00:02:16.010 --> 00:02:20.845
Because even synthetic data isn't
what our users saw, it's what a test

35
00:02:20.845 --> 00:02:25.852
machine that's running on very stable
hardware on a stable network sees.

36
00:02:25.852 --> 00:02:29.636
It'll be best if we could
actually capture information from

37
00:02:29.636 --> 00:02:34.603
the people who actually use the site,
on the networks that they use it from, and

38
00:02:34.603 --> 00:02:37.440
see how the real users
experienced the site.

39
00:02:38.710 --> 00:02:42.831
So if we could gather an experience
report, if we could capture

40
00:02:42.831 --> 00:02:47.653
that lighthouse report from every user
every time they load the page, and

41
00:02:47.653 --> 00:02:51.023
send it back somewhere so
that we could analyze it.

42
00:02:51.023 --> 00:02:55.783
Well, this is what's called a run tool,
a real user monitoring tool.

43
00:02:55.783 --> 00:02:59.585
And it's a tool like the one I
work on called request metrics.

44
00:02:59.585 --> 00:03:02.417
And there's a lot of good
things about doing it this way,

45
00:03:02.417 --> 00:03:04.295
as in it's much more accurate.

46
00:03:04.295 --> 00:03:07.685
It's showing you what the real user sees.

47
00:03:07.685 --> 00:03:09.129
But it's also really noisy,

48
00:03:09.129 --> 00:03:13.440
because a lot of users run on really
terrible networks and terrible computers.

49
00:03:13.440 --> 00:03:18.368
And you don't necessarily care
what all of your users experience.

50
00:03:18.368 --> 00:03:21.972
As in, let's say if you're running
a jobs board in India, and

51
00:03:21.972 --> 00:03:26.350
you all of a sudden get a whole bunch
of traffic from outer Mongolia.

52
00:03:26.350 --> 00:03:30.702
Well, you might not care what the people
from outer Mongolia care, what they see,

53
00:03:30.702 --> 00:03:33.514
like it doesn't matter what
their performance was.

54
00:03:33.514 --> 00:03:37.385
They're not your audience, they're not
the people who are most interested in your

55
00:03:37.385 --> 00:03:38.814
site, they're likely bots.

