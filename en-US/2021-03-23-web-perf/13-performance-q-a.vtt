WEBVTT

1
00:00:00.190 --> 00:00:01.683
Quick recap.

2
00:00:01.683 --> 00:00:05.941
The what we talked about here in part
one is the psychology of performance,

3
00:00:05.941 --> 00:00:10.930
how you perceive performance and
the different ways that can be affected.

4
00:00:10.930 --> 00:00:14.925
We talked about measuring performance
in the lab synthetically and

5
00:00:14.925 --> 00:00:17.526
in the field and
we looked at those numbers.

6
00:00:17.526 --> 00:00:21.370
And then we briefly talked about how you
interpret that field performance data.

7
00:00:22.810 --> 00:00:27.457
Now, before we go here on a break,
I wanna open it up for questions and

8
00:00:27.457 --> 00:00:29.475
try and fill as many as we can.

9
00:00:29.475 --> 00:00:33.300
There's some questions about blink and
chromium.

10
00:00:33.300 --> 00:00:35.920
They're kind of synonyms but
not technically.

11
00:00:35.920 --> 00:00:38.244
Chromium is the overall project.

12
00:00:38.244 --> 00:00:40.783
Blink is the rendering engine in it.

13
00:00:40.783 --> 00:00:45.033
It's technically blink is
where the web vitals thing,

14
00:00:45.033 --> 00:00:50.880
the web vitals concepts are baked in,
but it's essentially chromium.

15
00:00:50.880 --> 00:00:57.643
So any chromium based browser uses
blink and would have this data.

16
00:00:57.643 --> 00:01:03.145
&gt;&gt; I'm curious, you were saying we
should open up the tools in a separate

17
00:01:03.145 --> 00:01:09.411
window photo I have done before, but I
know what tests a lot of different sizes.

18
00:01:09.411 --> 00:01:13.284
So if I have my browser set,
say, I'm testing a large screen,

19
00:01:13.284 --> 00:01:17.466
the smaller screen is that applying
to lighthouse want to run that?

20
00:01:17.466 --> 00:01:18.454
&gt;&gt; Yes, absolutely.

21
00:01:18.454 --> 00:01:21.018
So, when you separate
into the other screen,

22
00:01:21.018 --> 00:01:26.140
it allows you to test your performances,
the performance is on that screen size.

23
00:01:26.140 --> 00:01:30.051
So I have my Chrome window
set here to 1150 by 720,

24
00:01:30.051 --> 00:01:35.355
which is just a common resolution that
a lot of laptops and tablets would use.

25
00:01:35.355 --> 00:01:39.630
If I wanted to test what the performance
was on a super big screen,

26
00:01:39.630 --> 00:01:43.540
I would need to make Chrome like
as big as I want to test it on.

27
00:01:44.550 --> 00:01:48.647
Technically, you can do that for applying
to mobile as well if you made it really

28
00:01:48.647 --> 00:01:52.948
small, but a better way to do that is when
you're running your lighthouse report.

29
00:01:52.948 --> 00:01:57.658
Just select that you wanna emulate
a mobile device as automatically

30
00:01:57.658 --> 00:02:01.386
gonna put it inside of a small
window when it renders.

31
00:02:01.386 --> 00:02:05.675
So they'll use one of
the chrome mobile emulation

32
00:02:05.675 --> 00:02:09.155
techniques before it runs lighthouse.

33
00:02:09.155 --> 00:02:13.338
I've just seen lots of people
leave their DevTools attached and

34
00:02:13.338 --> 00:02:18.760
then have just 50 pixels of the screen at
the top and run their lighthouse report,

35
00:02:18.760 --> 00:02:22.345
and it comes up and
says everything is awesome, yeah.

36
00:02:22.345 --> 00:02:26.999
Because browser rendered a hundred pixels,
it didn't take anything to do it.

37
00:02:26.999 --> 00:02:29.160
It's not a real performance snapshot.

38
00:02:30.750 --> 00:02:31.865
How do we get field data?

39
00:02:31.865 --> 00:02:36.379
All right, so the field data that we
captured is part of this exercise was

40
00:02:36.379 --> 00:02:41.337
the data that came from the Chrome user
experience report, which is cool data,

41
00:02:41.337 --> 00:02:43.260
but it's flawed, right?

42
00:02:43.260 --> 00:02:48.444
It is aggregated to the month,
we don't get detailed data.

43
00:02:48.444 --> 00:02:52.797
What we're gonna do here,
in part two is we're gonna build a small

44
00:02:52.797 --> 00:02:57.490
performance agents that's gonna
pull data from your real users.

45
00:02:57.490 --> 00:03:01.887
And so we'll have a data point for
every single user who loads your page,

46
00:03:01.887 --> 00:03:06.665
and that's gonna be how you can use it for
both public sites and private sites.

47
00:03:06.665 --> 00:03:11.192
You'll be able to pull data from anywhere
that your users access your site from, and

48
00:03:11.192 --> 00:03:13.182
then figure out how to aggregate it.

49
00:03:13.182 --> 00:03:15.040
We're gonna talk about
that a lot in part two.

50
00:03:17.150 --> 00:03:20.345
Lighthouse says that it cannot generate
correctly due to Chrome extensions.

51
00:03:20.345 --> 00:03:21.361
Yes.

52
00:03:21.361 --> 00:03:26.495
Chrome extensions absolutely affect the
performance of the page in all browsers.

53
00:03:26.495 --> 00:03:31.239
And if you put extensions in your
browser that's essentially a bit of code

54
00:03:31.239 --> 00:03:34.400
that's injecting itself into the loop.

55
00:03:34.400 --> 00:03:38.143
Extensions can read the entire
structure of every page.

56
00:03:38.143 --> 00:03:41.870
They can monitor what you
type into the browser.

57
00:03:41.870 --> 00:03:45.912
They have a alarming amount of access and
so

58
00:03:45.912 --> 00:03:51.429
you should be very wary of
the extensions you put in place.

59
00:03:51.429 --> 00:03:55.757
And then when you run a lighthouse report,
you should disable your

60
00:03:55.757 --> 00:04:01.490
extensions if possible, or run the ones
that are most likely for your users.

61
00:04:01.490 --> 00:04:05.746
What you might notice is my Chrome right
now I only have one extension running

62
00:04:05.746 --> 00:04:10.615
right now, which is my password manager, I
disabled all the other ones for right now.

63
00:04:10.615 --> 00:04:15.940
Especially if you have things like micro
block or ad blockers or stuff like that.

64
00:04:15.940 --> 00:04:20.504
Turn those all off before you do
performance testing, because you

65
00:04:20.504 --> 00:04:25.489
wanna see how those blocked things
affect the performance of your page.

66
00:04:25.489 --> 00:04:31.016
Why are there differences in the results
between the report metrics or

67
00:04:31.016 --> 00:04:36.080
between the lighthouse metrics and
the web devs that thing.

68
00:04:36.080 --> 00:04:42.840
Those are difference is in well,
I'm not sure I understand the question.

69
00:04:42.840 --> 00:04:47.499
You might be asking why does one
does lighthouse say this is orange,

70
00:04:47.499 --> 00:04:51.610
it needs improvement, but
web dev says it's worse.

71
00:04:51.610 --> 00:04:56.290
Well, they change what the ratios are,
what the recommendations were good, okay,

72
00:04:56.290 --> 00:04:57.331
bad are over time.

73
00:04:57.331 --> 00:05:02.114
And they're not always in lock step, it's
different teams were making those changes.

74
00:05:02.114 --> 00:05:06.360
If you're asking about why does
crux data not match lighthouse,

75
00:05:06.360 --> 00:05:08.687
that's lab versus field, right?

76
00:05:08.687 --> 00:05:13.338
The lab data is lighthouse,
lab data is what lighthouse is measuring,

77
00:05:13.338 --> 00:05:15.906
and it's what your machine rendered.

78
00:05:15.906 --> 00:05:20.466
Whereas the crux data is what real
users on the Internet who visited that

79
00:05:20.466 --> 00:05:21.760
site experienced.

