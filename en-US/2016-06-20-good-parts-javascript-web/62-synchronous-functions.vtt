WEBVTT

1
00:00:00.025 --> 00:00:03.825
[MUSIC]

2
00:00:03.825 --> 00:00:05.520
&gt;&gt; Douglas Crockford: It's time now for
a Asynchronicity.

3
00:00:07.340 --> 00:00:09.540
So there are two kinds of
functions in the world,

4
00:00:09.540 --> 00:00:13.490
there are Synchronous functions and
Asynchronous functions.

5
00:00:13.490 --> 00:00:16.460
So let's first look at
Synchronous functions.

6
00:00:16.460 --> 00:00:19.410
A Synchronous function is
a function that does not return

7
00:00:19.410 --> 00:00:22.440
until the work is completed or has failed.

8
00:00:22.440 --> 00:00:25.562
So all of the functions that we wrote for
the last couple of days have been

9
00:00:25.562 --> 00:00:28.023
synchronous functions
because that's how they work.

10
00:00:28.023 --> 00:00:32.271
And that's a very useful thing to
have in a function because it means,

11
00:00:32.271 --> 00:00:35.369
it's easy to reason about
its behavior over time.

12
00:00:35.369 --> 00:00:41.285
When asynchronous function calls
another synchronous function.

13
00:00:41.285 --> 00:00:43.245
The caller is suspended in time and

14
00:00:44.505 --> 00:00:48.575
nothing advances until
the the callee returns.

15
00:00:49.835 --> 00:00:54.320
If the caller is looking at a clock at
the moment that they make the call.

16
00:00:54.320 --> 00:00:58.200
Their experience will be,
that the hands jump forward quickly.

17
00:00:58.200 --> 00:01:00.790
But otherwise, they're not aware
that this stuff has happened,

18
00:01:00.790 --> 00:01:04.190
except that the thing that they asked for
has magically been completed.

19
00:01:05.350 --> 00:01:08.090
And that makes it easy for
us to reason about things,

20
00:01:08.090 --> 00:01:10.800
unless we need to make multiple
things happen at the same time.

21
00:01:12.180 --> 00:01:16.250
You can't make multiple things happen at
the same time if you're suspended in time.

22
00:01:16.250 --> 00:01:19.413
So, the way that Topham mitigated
is by use of the threads,

23
00:01:19.413 --> 00:01:23.466
that thread allows to have multiple
threads of execution happening through

24
00:01:23.466 --> 00:01:25.195
a memory space at the same time.

25
00:01:25.195 --> 00:01:28.540
So that's lots of things and
happen at the same time.

26
00:01:28.540 --> 00:01:31.590
Unfortunately, races come
with some problems including,

27
00:01:33.270 --> 00:01:35.990
threads come with problems
including races, deadlocks and

28
00:01:35.990 --> 00:01:39.600
other reliability problems and performance
problems, and will look more at these.

29
00:01:41.170 --> 00:01:45.880
So the threading model,
like all models comes with pros and cons.

30
00:01:45.880 --> 00:01:49.970
And the first pro is a really important,
really significant one.

31
00:01:49.970 --> 00:01:51.860
No rethinking is necessary.

32
00:01:51.860 --> 00:01:56.420
You can take any existing piece of code,
put it in a thread and

33
00:01:56.420 --> 00:01:58.040
it'll just work that way.

34
00:01:58.040 --> 00:01:59.560
You don't have to make any changes to it,

35
00:01:59.560 --> 00:02:01.479
in order to introduce it
to a threaded environment.

36
00:02:02.500 --> 00:02:06.040
Now that doesn't necessarily mean
that you'll never need to change it,

37
00:02:06.040 --> 00:02:10.200
but the starting up phase is really easy.

38
00:02:10.200 --> 00:02:13.070
The next pro is that
blocking programs are okay.

39
00:02:13.070 --> 00:02:17.070
It's okay for programs to block and
in fact, that is what threads are for.

40
00:02:17.070 --> 00:02:19.800
Threads exist, so that things can stop.

41
00:02:19.800 --> 00:02:22.900
And have other things
happening while it stopped.

42
00:02:22.900 --> 00:02:25.820
Execution will continue as long
as any thread is not blocked.

43
00:02:25.820 --> 00:02:27.970
But there are some cons.

44
00:02:27.970 --> 00:02:32.070
The first con is that there is
stuck memory allocated per thread.

45
00:02:32.070 --> 00:02:34.810
This used to be a significant problem.

46
00:02:34.810 --> 00:02:35.810
It's not any more.

47
00:02:35.810 --> 00:02:38.460
Moore's Law continued to
ramp on memory capacity, and

48
00:02:38.460 --> 00:02:42.320
so thread stacks are now in the noise.

49
00:02:42.320 --> 00:02:44.720
We don't care about them anymore.

50
00:02:44.720 --> 00:02:48.715
A more important con is that if two
threads use the same memory at the same

51
00:02:48.715 --> 00:02:50.123
time, a race may occur.

52
00:02:50.123 --> 00:02:53.150
And the fact, this is a big problem.

53
00:02:53.150 --> 00:02:55.470
So a lot of people been asking,

54
00:02:55.470 --> 00:02:59.240
when are we going get threads in
JavaScript and the answer is never.

55
00:02:59.240 --> 00:03:01.530
And let me illustrate why.

56
00:03:01.530 --> 00:03:05.824
So here we have two programs which
will each run in its own thread and

57
00:03:05.824 --> 00:03:08.747
we were run them,
possibly at the same time.

58
00:03:08.747 --> 00:03:15.830
And there are a number of possible
consequences of this program.

59
00:03:15.830 --> 00:03:18.092
One is, an array containing A and B.

60
00:03:18.092 --> 00:03:21.610
And the other is,
an array containing B and A.

61
00:03:21.610 --> 00:03:24.540
Because we can control in what
order these two threads run,

62
00:03:24.540 --> 00:03:25.780
these are two possible outcomes.

63
00:03:26.810 --> 00:03:31.530
But that's not the race I'm worried about,
the race I'm worried about is this one.

64
00:03:31.530 --> 00:03:36.360
Another possible outcome of this program
is an array containing only a or

65
00:03:36.360 --> 00:03:37.780
an array containing only b.

66
00:03:38.910 --> 00:03:41.800
And this is not due to anything,

67
00:03:41.800 --> 00:03:44.770
except what's happening in these two
statements, and you can look at these for

68
00:03:44.770 --> 00:03:48.040
a long time and
try to figure out did half of my data go.

69
00:03:49.070 --> 00:03:50.400
How did this fail?

70
00:03:50.400 --> 00:03:54.020
It's really hard to reason about
programs that race in threads.

71
00:03:54.020 --> 00:03:56.770
So let's zoom in on this and
look at what's going on.

72
00:03:56.770 --> 00:03:58.550
So that's the first statement.

73
00:03:58.550 --> 00:04:00.560
One of the things that
makes jobs descriptive and

74
00:04:00.560 --> 00:04:04.080
expressively powerful language is
that one statement can do the work of

75
00:04:04.080 --> 00:04:05.830
many statements and that's the case,

76
00:04:05.830 --> 00:04:10.220
in this one, that one statement on the
top, does what the four green lines do.

77
00:04:11.870 --> 00:04:17.050
It'll get the current length that
we'll assign to the part of the array.

78
00:04:17.050 --> 00:04:21.700
If the length of the array has increased,
then we'll make that change.

79
00:04:22.910 --> 00:04:26.970
And if we look at the second thread,
it also expands into stuff like that.

80
00:04:26.970 --> 00:04:33.440
And we cannot control how these might
be ordered in actual execution.

81
00:04:33.440 --> 00:04:37.650
So one possible ordering could be

82
00:04:37.650 --> 00:04:42.460
both capture the length at the same time,
and both will be using that

83
00:04:42.460 --> 00:04:46.870
to store into the rain both will be using
it to change the length of the arrays.

84
00:04:46.870 --> 00:04:50.700
And as a result, which ever one run
second is probably going to win.

85
00:04:51.940 --> 00:04:53.087
So that's where half of our data went.

86
00:04:53.087 --> 00:04:55.320
And this stuff is really
hard to reason about.

87
00:04:55.320 --> 00:05:00.140
For one thing, you can't see it in the
original code but it's worse than this,

88
00:05:00.140 --> 00:05:03.710
because each of these statements could
expand into multiple machine language

89
00:05:03.710 --> 00:05:04.280
statements.

90
00:05:04.280 --> 00:05:07.160
And you don't know how
those are gonna interleave.

91
00:05:07.160 --> 00:05:10.610
And each of those could expand at the low
level into micro instructions and

92
00:05:10.610 --> 00:05:14.070
you can't control how those will
interleave and it may be that

93
00:05:14.070 --> 00:05:18.690
the real time behavior of this threaded
code changes according to loading.

94
00:05:20.270 --> 00:05:22.390
So might be working fine
during development, but

95
00:05:22.390 --> 00:05:24.550
then fail when we put in production.

96
00:05:24.550 --> 00:05:27.515
Or it's working fine most of the year,
but it fails at Christmas.

97
00:05:27.515 --> 00:05:32.390
As things change, things that wouldn't
appear to affect the behavior of

98
00:05:32.390 --> 00:05:37.200
the program can actually radically
affect the behavior of the program.

99
00:05:37.200 --> 00:05:41.577
So it's impossible to have
application integrity,

100
00:05:41.577 --> 00:05:44.990
when we're subject to race conditions.

101
00:05:47.270 --> 00:05:49.950
So that we mitigate that
with mutual exclusion.

102
00:05:49.950 --> 00:05:52.820
Mutual exclusion allows only one

103
00:05:52.820 --> 00:05:56.230
thread to be running in a critical
section of memory at a time,

104
00:05:56.230 --> 00:06:00.340
and there's a long history of this stuff,
starting with Dykstra semaphores.

105
00:06:00.340 --> 00:06:02.890
Or as an horse monitors
the editor rendezvousing,

106
00:06:02.890 --> 00:06:07.400
now we caught synchronization but
these are all transforms on the same idea.

107
00:06:07.400 --> 00:06:09.300
This used to be operating system stuff.

108
00:06:10.470 --> 00:06:14.320
Used to be only operating systems were
concerned with mutual exclusion and

109
00:06:14.320 --> 00:06:18.640
running multiple things at the same time,
but this has all leaked into applications,

110
00:06:18.640 --> 00:06:21.060
because of networking and
because of the multi-core problem.

111
00:06:22.290 --> 00:06:25.899
The concern with networking is that,
&gt;&gt; Douglas Crockford: We want

112
00:06:25.899 --> 00:06:31.440
to be able to have stuff happening
while slow things are happening.

113
00:06:31.440 --> 00:06:34.800
And one of the slowest things we
can do is go out to the network,

114
00:06:34.800 --> 00:06:37.250
cuz that has a large latencies, and

115
00:06:38.290 --> 00:06:43.100
In some cases are noble latencies, and so
you can be stopped for a long time and

116
00:06:43.100 --> 00:06:46.610
generally, you can't afford to have
systems be suspended for that long.

117
00:06:46.610 --> 00:06:48.790
So you need threads in order
to allow them to continue.

118
00:06:50.030 --> 00:06:51.470
Then there is the multi-core problem,

119
00:06:51.470 --> 00:06:55.840
CPU designers have lost the ability
to make CPU's go faster.

120
00:06:55.840 --> 00:06:58.760
So instead,
they're giving us more of them.

121
00:06:58.760 --> 00:07:01.923
And we don't know how to use them,
unless if you have a problem that's

122
00:07:01.923 --> 00:07:04.724
embarrassingly parallel,
then we can take advantage of it.

123
00:07:04.724 --> 00:07:07.778
But most of what we do is
embarrassingly serial and

124
00:07:07.778 --> 00:07:12.433
we don't know how to take multiple cores
and put them in our applications and

125
00:07:12.433 --> 00:07:14.630
get a significant benefit from it.

126
00:07:17.780 --> 00:07:18.620
So that's where we are.

127
00:07:19.950 --> 00:07:21.780
So with mutual exclusion,

128
00:07:22.780 --> 00:07:25.990
only one thread can be executing in
a critical section at a time and

129
00:07:25.990 --> 00:07:30.090
all other threads waiting to execute in
the critical section will be blocked.

130
00:07:30.090 --> 00:07:31.340
If the threads don't interact,

131
00:07:31.340 --> 00:07:34.540
then the programs can run at
full speed across all the cores.

132
00:07:34.540 --> 00:07:39.690
But if they do interact, then races will
occur unless mutual exclusion is employed.

133
00:07:39.690 --> 00:07:42.200
Unfortunately, mutual exclusion
comes with its own dark side.

134
00:07:42.200 --> 00:07:45.180
And that is deadlock.

135
00:07:45.180 --> 00:07:48.860
Here we have two threads,
Alphonse and Gaston.

136
00:07:48.860 --> 00:07:50.260
They are both program to wait for

137
00:07:50.260 --> 00:07:53.560
the other to stand up,
before they can stand up.

138
00:07:53.560 --> 00:07:54.230
This is deadlock.

139
00:07:54.230 --> 00:07:57.510
It turns out computer
systems do this all the time.

140
00:07:57.510 --> 00:07:58.274
Here's another example.

141
00:07:58.274 --> 00:08:01.510
This is a real world
example from Sao Paulo.

142
00:08:01.510 --> 00:08:05.205
You can think of,
apparently they do this all the time.

143
00:08:05.205 --> 00:08:08.070
&gt;&gt; Speaker 2: [LAUGH]
&gt;&gt; Douglas Crockford: You can think of

144
00:08:08.070 --> 00:08:11.510
each of these cars as being a thread,
which is ready to run.

145
00:08:11.510 --> 00:08:14.775
It's just waiting for the thread that's
blocking it to get out of the way.

146
00:08:14.775 --> 00:08:18.030
&gt;&gt; Speaker 2: [LAUGH]
&gt;&gt; Douglas Crockford: So deadlock,

147
00:08:18.030 --> 00:08:18.840
it's a serious thing.

