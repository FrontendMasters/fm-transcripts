WEBVTT

1
00:00:00.010 --> 00:00:04.865
&gt;&gt; Eric: The first alternative that we
could potentially use to log pooling is

2
00:00:04.865 --> 00:00:06.799
the Server-Sent Events.

3
00:00:06.799 --> 00:00:12.040
This is the server-push technology,

4
00:00:12.040 --> 00:00:16.100
so it's based on HTTP2.

5
00:00:16.100 --> 00:00:20.504
And the way it works is when you
establish the connection with the server,

6
00:00:20.504 --> 00:00:24.979
the duplex communication is used only
when you do the initial connection,

7
00:00:24.979 --> 00:00:28.251
just the initial three-way handshake.

8
00:00:28.251 --> 00:00:32.180
But the rest of the connection is
basically the server pushes the data to

9
00:00:32.180 --> 00:00:33.541
the client.

10
00:00:33.541 --> 00:00:38.800
So, in case of the Server-Sent Events,
the duplex Santana is that used,

11
00:00:38.800 --> 00:00:43.733
we only use the receive only mode,
and whether that drain the energy.

12
00:00:43.733 --> 00:00:48.481
Although, we still have an issue with
the reconnection where we need to do

13
00:00:48.481 --> 00:00:50.101
the freeway handshake.

14
00:00:50.101 --> 00:00:53.752
But the huge difference with the
Server-Sent Events that the reconnection

15
00:00:53.752 --> 00:00:55.814
is implemented on protocol level.

16
00:00:55.814 --> 00:00:59.801
So you don't need to handle
that on infrastructure wise, so

17
00:00:59.801 --> 00:01:03.489
you can always resume from
the place where you started.

18
00:01:03.489 --> 00:01:07.715
And the huge benefit business-wise for
using Server-Sent Events,

19
00:01:07.715 --> 00:01:09.966
it's very easy to scale.

20
00:01:09.966 --> 00:01:15.614
So for instance if we have multiple
instances of the server and

21
00:01:15.614 --> 00:01:22.797
one instance is died, we can just forward
the request to a separate instance.

22
00:01:22.797 --> 00:01:26.370
And because we can always resume
from the previous place using

23
00:01:26.370 --> 00:01:31.832
the Server-Sent Events, so it doesn't
matter for us which instance will respond.

24
00:01:31.832 --> 00:01:35.486
So since the Server-Sent Events
is HTTP2-based,

25
00:01:35.486 --> 00:01:38.944
it also utilizes the TCP
socket differently.

26
00:01:38.944 --> 00:01:44.541
We gonna talk about HTTP2
protocol just in a few moments,

27
00:01:44.541 --> 00:01:50.724
but the huge benefit of HTTP2
it has the multiplexing feature.

28
00:01:50.724 --> 00:01:58.775
The multiplexing allows us to open 200
requests within one single TCP socket.

29
00:01:58.775 --> 00:02:03.567
So this means while in order to
be one to fetch five resources,

30
00:02:03.567 --> 00:02:09.335
we have to open five TCP connection,
which is much less efficient.

31
00:02:09.335 --> 00:02:13.583
So the Server-Sent Events is generally
much faster than long polling because it

32
00:02:13.583 --> 00:02:16.125
also doesn't send any channel data.

33
00:02:16.125 --> 00:02:19.241
So we don't send any
unnecessary headers and

34
00:02:19.241 --> 00:02:22.939
receive only the data that
relates to the content.

35
00:02:22.939 --> 00:02:25.994
And the summary for
that is there are definitely pros for

36
00:02:25.994 --> 00:02:30.089
Server-Sent Events because
the connections can handled thematically,

37
00:02:30.089 --> 00:02:33.959
it's very better, efficient from
the mobile device perspective.

38
00:02:33.959 --> 00:02:38.107
And it doesn't send the overhead data and
the horizontal scaling of your

39
00:02:38.107 --> 00:02:43.099
infrastructure is much easier when
you use the Server-Sent Events.

40
00:02:43.099 --> 00:02:46.449
The cons though,
you can't push the data to a server and

41
00:02:46.449 --> 00:02:50.129
only the string data is
supported by detraining this.

42
00:02:50.129 --> 00:02:56.739
So you will need to parse the text
payload that you send from the server.

43
00:02:56.739 --> 00:03:00.717
And when you need to use it,
that's good for both desktop and

44
00:03:00.717 --> 00:03:05.319
mobile applications, and
it also provides a very good performance.

45
00:03:05.319 --> 00:03:08.191
So the performance comparable to
the web sockets that we're going to

46
00:03:08.191 --> 00:03:10.269
discuss on the next slide.

47
00:03:10.269 --> 00:03:16.209
And it's very good for streaming the large
text data, if you have this case.

48
00:03:16.209 --> 00:03:22.266
And the reason why you'd avoid this, is if
you are building very simple desktop app,

49
00:03:22.266 --> 00:03:25.056
so then you'll be fine with long poll.

50
00:03:25.056 --> 00:03:29.626
You don't need to really overcomplicate
the architecture of your app.

