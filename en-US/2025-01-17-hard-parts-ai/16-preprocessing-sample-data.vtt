WEBVTT

1
00:00:00.462 --> 00:00:02.893
&gt;&gt; Will Sentance: Okay, any questions?

2
00:00:02.893 --> 00:00:04.434
&gt;&gt; Maria: Yeah, I had a question.

3
00:00:04.434 --> 00:00:09.064
What if we flipped the original
smile upside down to make it

4
00:00:09.064 --> 00:00:11.054
an upside-down smile?

5
00:00:11.054 --> 00:00:12.377
Would it still-
&gt;&gt; Will Sentance: And just be clear,

6
00:00:12.377 --> 00:00:13.880
Maria's not asking here.

7
00:00:13.880 --> 00:00:17.343
What if we switch the smile
upside down and made it a frown,

8
00:00:17.343 --> 00:00:19.263
like switch that frown upside.

9
00:00:19.263 --> 00:00:24.465
I get that Maria's note
making a refrigerator magnet,

10
00:00:24.465 --> 00:00:28.124
but instead is referring to, hold on.

11
00:00:28.124 --> 00:00:35.355
What if we are training image sample has
an image, which could totally happen.

12
00:00:35.355 --> 00:00:38.979
Someone's uploaded it when they wanna
identify a smile or not, the wrong way up.

13
00:00:38.979 --> 00:00:41.634
As in, when we use it,
when we want to infer for a new image,

14
00:00:41.634 --> 00:00:45.355
someone's provided an image that's upside
down, and we wanna be able to spot it so

15
00:00:45.355 --> 00:00:46.860
smart it's just an upside down.

16
00:00:46.860 --> 00:00:50.612
The heads, the whole way upside down,
almost the photos upside down.

17
00:00:50.612 --> 00:00:54.223
We're gonna see in a moment,

18
00:00:54.223 --> 00:00:58.418
we need to pre-process our data.

19
00:00:58.418 --> 00:01:03.053
We do not want to have multipliers be

20
00:01:03.053 --> 00:01:08.002
learned for the rotation of the head.

21
00:01:08.002 --> 00:01:13.664
We want to learn the right multipliers
that capture for the same orientation,

22
00:01:13.664 --> 00:01:17.798
the features of the smile,
not the rotation of the head.

23
00:01:17.798 --> 00:01:22.853
So we would preliminary, perhaps, have
a totally separate model that actually

24
00:01:22.853 --> 00:01:27.854
works out the right rotation of the head
and says, that head is off by this side.

25
00:01:27.854 --> 00:01:31.371
Before you input it into
this model creation,

26
00:01:31.371 --> 00:01:35.345
rotate it to be facing,
we'll see this in a second.

27
00:01:35.345 --> 00:01:38.356
One doesn't wanna learn or
figure out multipliers for

28
00:01:38.356 --> 00:01:40.713
a bunch of different orientations ahead,

29
00:01:40.713 --> 00:01:45.179
because then you're not actually capturing
the characteristics of the smile.

30
00:01:45.179 --> 00:01:48.514
You're capturing the characteristics
of the head rotation.

31
00:01:48.514 --> 00:01:52.148
And that's not as useful, or
if it is, do that bit first and

32
00:01:52.148 --> 00:01:57.409
then capture the characteristics of the
smile, have multiple models working on it.

33
00:01:57.409 --> 00:02:01.358
Great question from Maria,
you had another one as well.

34
00:02:01.358 --> 00:02:05.779
&gt;&gt; Maria: I think I just was looking
at a different type of smiles, so

35
00:02:05.779 --> 00:02:09.128
it would be kind of like
an open mouth smile.

36
00:02:09.128 --> 00:02:12.054
&gt;&gt; Will Sentance: And I think in that
sense, we could always add many more here.

37
00:02:12.054 --> 00:02:15.776
And the labels you give them will
determine what the prediction is for

38
00:02:15.776 --> 00:02:19.449
the population, there's no truth
to the small characteristics.

39
00:02:19.449 --> 00:02:25.235
The only truth is in the sample,
did this set of pixels get labeled 0,

40
00:02:25.235 --> 00:02:30.841
this set 0, this set a 100 percent,
this set a 100 percent?

41
00:02:30.841 --> 00:02:34.014
Okay, Ben, question?

42
00:02:34.014 --> 00:02:38.237
&gt;&gt; Ben: I don't know if this is really
appropriate, but in your training data,

43
00:02:38.237 --> 00:02:42.543
would you put in things that you
don't have 100 or 0% confidence on?

44
00:02:42.543 --> 00:02:46.948
&gt;&gt; Will Sentance: You could do, I think in
this case, the classification is binary,

45
00:02:46.948 --> 00:02:51.139
it's just, and
I'd almost say it's really 1, 0, 1, 0.

46
00:02:51.139 --> 00:02:56.972
And we're building confidence
here of the 1, 0 sort of binary.

47
00:02:56.972 --> 00:03:00.590
&gt;&gt; Ben: I can't really
think of an example.

48
00:03:00.590 --> 00:03:04.838
&gt;&gt; Will Sentance: There's
a little bit of a smile [LAUGH],

49
00:03:04.838 --> 00:03:12.062
you're trusting the model to
capture the subtleties in between.

50
00:03:12.062 --> 00:03:17.186
With a large enough sample,
you're finding those

51
00:03:17.186 --> 00:03:22.310
in-betweens via
the in-betweens in the sample,

52
00:03:22.310 --> 00:03:27.688
as in, that is labeled a smile,
that's not that is.

53
00:03:27.688 --> 00:03:30.395
But actually the difference
between them is only subtle, and

54
00:03:30.395 --> 00:03:33.946
you can't even quite pin down what it is
that meant that that one got labeled not.

55
00:03:33.946 --> 00:03:40.575
But that is capturing the in-between via
if you had ten pictures you label a smile.

56
00:03:40.575 --> 00:03:44.109
And they have a range
of characteristics and

57
00:03:44.109 --> 00:03:49.280
ten that you label not and
they have a range of characteristics.

58
00:03:49.280 --> 00:03:54.383
You're capturing in that the diversity and
also the boundaries,

59
00:03:54.383 --> 00:03:59.317
at the point at which that one
didn't get classified as a smile.

60
00:03:59.317 --> 00:04:02.197
We didn't get labeled as a smile, and

61
00:04:02.197 --> 00:04:07.159
the in-between will be captured
quite well by the multipliers.

62
00:04:07.159 --> 00:04:10.352
So when it's applied to a new smile,

63
00:04:10.352 --> 00:04:15.713
the 89% represents some of
that kind of in-betweenness.

64
00:04:15.713 --> 00:04:22.879
So it's quite nice that it's not a binary
output because we don't want to have that.

65
00:04:22.879 --> 00:04:25.944
And that's another thing
about the sigmoid function,

66
00:04:25.944 --> 00:04:28.104
is it can never reach 100% or 0%.

67
00:04:28.104 --> 00:04:31.837
We don't want to have absolute certainty,
smile or not.

