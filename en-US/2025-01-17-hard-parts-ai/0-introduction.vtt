WEBVTT

1
00:00:00.000 --> 00:00:01.545
&gt;&gt; Will Sentance: We are live.

2
00:00:01.545 --> 00:00:06.107
Hello and welcome to artificial
intelligence and machine learning for

3
00:00:06.107 --> 00:00:11.059
software engineers, prediction and
neural networks on Frontend Masters.

4
00:00:11.059 --> 00:00:13.482
Let's have an enormous thank
you to Frontend Masters.

5
00:00:13.482 --> 00:00:15.618
&gt;&gt; [APPLAUSE]
&gt;&gt; Will Sentance: As you can hear,

6
00:00:15.618 --> 00:00:18.628
we have hundreds of people
here in the room, but

7
00:00:18.628 --> 00:00:22.789
we're gonna select just seven
of them to introduce themselves.

8
00:00:22.789 --> 00:00:26.197
Here we go, machine learning, artificial
intelligence, and neural networks.

9
00:00:26.197 --> 00:00:30.687
I'm just delighted to be able
to share this with everybody,

10
00:00:30.687 --> 00:00:36.778
because prediction in software engineering
changes what we can build with code.

11
00:00:36.778 --> 00:00:40.142
We're gonna be able to do things
like predicting fraud, okay?

12
00:00:40.142 --> 00:00:43.349
Maybe we've heard of this before,
maybe a fraud detection model.

13
00:00:43.349 --> 00:00:45.094
We're gonna build one.

14
00:00:45.094 --> 00:00:50.129
We're gonna build a DoorDash refund
predictor that's gonna allow us to

15
00:00:50.129 --> 00:00:55.493
automatically give a refund, improve
the product experience on DoorDash,

16
00:00:55.493 --> 00:00:58.558
or Uber Eats, or other delivery services.

17
00:00:58.558 --> 00:01:04.401
But predicting fraud, it's gonna extend
to predicting the content of images.

18
00:01:04.401 --> 00:01:09.248
It's gonna turn out to be no fundamental
difference to predicting fraud.

19
00:01:09.248 --> 00:01:15.570
We're then gonna discover you can extend
that to predicting responses to questions.

20
00:01:15.570 --> 00:01:19.176
All of this prediction,
this ability to see the future,

21
00:01:19.176 --> 00:01:23.698
I never said that phrase before,
that may be a bad way of describing it.

22
00:01:23.698 --> 00:01:28.841
Is gonna enable not only bridge and fraud,
image content, responses to questions.

23
00:01:28.841 --> 00:01:34.379
But also emergent phenomena,
and maybe even intelligence,

24
00:01:34.379 --> 00:01:40.246
if all we think there is in
the universe is distributions of data.

25
00:01:40.246 --> 00:01:44.702
We'll see what all of this means for
these terms, will all come out.

26
00:01:44.702 --> 00:01:49.406
But at the core of all this
grand set of goals is one thing,

27
00:01:49.406 --> 00:01:55.401
the ability to develop rules to match
patterns in known data, a sample.

28
00:01:55.401 --> 00:01:59.293
Again, see all these terms
in the coming slides.

29
00:01:59.293 --> 00:02:05.049
And then generalize to a population,
from a sample to a population,

30
00:02:05.049 --> 00:02:11.810
where we have unknown data that we want
to, instead of know, we want to predict.

31
00:02:11.810 --> 00:02:20.328
These transformative things are gonna be
powered by enormous amount of compute.

32
00:02:20.328 --> 00:02:26.808
That is the processing power that it
takes to do the work of prediction or

33
00:02:26.808 --> 00:02:34.377
to do the work of generating the tools to
do prediction, is remarkably heavy lift.

34
00:02:34.377 --> 00:02:38.789
This is why Nvidia is worth,
how much today?

35
00:02:38.789 --> 00:02:40.821
Is it in the billions?

36
00:02:40.821 --> 00:02:46.169
Well, I guess definitionally it's in
the millions, I guess, definitionally.

37
00:02:46.169 --> 00:02:47.413
But is it in the billions?

38
00:02:47.413 --> 00:02:50.409
Is it in the trillions?

39
00:02:50.409 --> 00:02:51.360
&gt;&gt; Speaker 2: Yes.
&gt;&gt; Will Sentance: Uh-huh,

40
00:02:51.360 --> 00:02:52.955
how many [LAUGH] trillions?

41
00:02:52.955 --> 00:02:54.021
&gt;&gt; Speaker 3: 3.5.

42
00:02:54.021 --> 00:02:57.257
&gt;&gt; Will Sentance: Three and
half trillion dollars,

43
00:02:57.257 --> 00:03:00.947
all because of the demand for compute.

44
00:03:00.947 --> 00:03:04.731
It also requires a deep
understanding of the data and

45
00:03:04.731 --> 00:03:08.860
exploratory introspection
into the nature of the data.

46
00:03:08.860 --> 00:03:12.441
And phenomenal creative scientific
research, two of the Nobel Prize winners

47
00:03:12.441 --> 00:03:16.418
this year, two of the Nobel Prizes, sorry,
more than two of the Nobel Prize winners.

48
00:03:16.418 --> 00:03:21.867
Two of the Nobel Prizes this
year were from breakthroughs

49
00:03:21.867 --> 00:03:26.874
in scientific research that
backs up all this work.

50
00:03:26.874 --> 00:03:31.061
One by Geoffrey Hinton, who also
popularized an algorithm that we'll

51
00:03:31.061 --> 00:03:35.316
work with today, or at least work towards,
known as backpropagation,

52
00:03:35.316 --> 00:03:37.917
a key part of building
out neural networks.

53
00:03:37.917 --> 00:03:41.606
Enormous amount of scientific research
has gone into all this work, or

54
00:03:41.606 --> 00:03:45.668
to find the best fit rules, known as
models, to capture the patterns in data.

55
00:03:45.668 --> 00:03:48.330
Software engineers, all of us,

56
00:03:48.330 --> 00:03:54.425
are at the heart of turning these machine
learning AI models into products.

57
00:03:54.425 --> 00:03:58.507
Things you can use, things that can,
quote, change the world.

58
00:03:58.507 --> 00:04:01.922
In collaboration with machine learning
engineers and data scientists.

