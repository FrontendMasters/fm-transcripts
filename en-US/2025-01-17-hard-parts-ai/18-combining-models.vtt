WEBVTT

1
00:00:00.044 --> 00:00:04.376
We can actually also combine up

2
00:00:04.376 --> 00:00:09.208
models to use our smile detector to

3
00:00:09.208 --> 00:00:13.884
maybe even generate new smiles.

4
00:00:13.884 --> 00:00:19.702
We create a new model, so
we're gonna take our existing,

5
00:00:19.702 --> 00:00:22.922
I don't know if I can draw this.

6
00:00:22.922 --> 00:00:24.181
We're out of space, unfortunately.

7
00:00:24.181 --> 00:00:28.685
I feel bad to mess with them.

8
00:00:28.685 --> 00:00:29.853
I will squeeze in here.

9
00:00:29.853 --> 00:00:34.047
This is our smile detector.

10
00:00:34.047 --> 00:00:40.039
Takes in an image, and
if it's random data,

11
00:00:40.039 --> 00:00:46.356
there you go, it comes out and
says, no smile.

12
00:00:46.356 --> 00:00:50.071
Hopefully that's no smile,
looks about no smile.

13
00:00:50.071 --> 00:00:51.280
Says, no smile.

14
00:00:51.280 --> 00:00:56.648
We can build a new model that generates

15
00:00:56.648 --> 00:01:02.521
random squiggles like this, squiggle,

16
00:01:02.521 --> 00:01:08.076
didn't think you see that, creator.

17
00:01:08.076 --> 00:01:14.008
Its first effort went past
this model says, no smile.

18
00:01:14.008 --> 00:01:18.665
So it goes, let me, and
this is a high level explanation,

19
00:01:18.665 --> 00:01:20.671
let me try new squiggle.

20
00:01:20.671 --> 00:01:26.026
And so it's getting better,
this time it was getting up to,

21
00:01:26.026 --> 00:01:30.757
the first time 7% next time it got to 13%,
okay.

22
00:01:30.757 --> 00:01:38.294
After many tries, it gets to generating
squiggles at a 90% conversion.

23
00:01:38.294 --> 00:01:43.182
Well, now it's a smile generator
within the category of images

24
00:01:43.182 --> 00:01:47.448
labeled smile and
against a high-level explanation.

25
00:01:47.448 --> 00:01:52.478
But at its core, this is what a generative
adversarial network is doing.

26
00:01:52.478 --> 00:02:00.058
It's got one model that's trying to catch
out bad squiggles as not a smile and

27
00:02:00.058 --> 00:02:05.072
one that's trying to
generate squiggles that will

28
00:02:05.072 --> 00:02:12.315
convince this at a 90% confidence
that what it's produced is a smile.

29
00:02:12.315 --> 00:02:16.028
And once it's done so,
it's a smile generator.

30
00:02:16.028 --> 00:02:19.831
And while we've moved beyond, very,
very recently, the last two or

31
00:02:19.831 --> 00:02:23.571
three years, generative adversarial
networks is the central way in

32
00:02:23.571 --> 00:02:27.330
which generation is done towards
what's called diffusion models.

33
00:02:27.330 --> 00:02:32.168
At their core,
it's still combining models up that allows

34
00:02:32.168 --> 00:02:36.629
us to achieve these remarkable
generative outcomes.

35
00:02:36.629 --> 00:02:39.571
Same thing with text-conditional
image generation.

36
00:02:39.571 --> 00:02:45.002
We have models that associate
text with images and pixels and

37
00:02:45.002 --> 00:02:50.227
enable us to actually define
the content of image we want.

38
00:02:50.227 --> 00:02:52.589
And then to combine that model up,

39
00:02:52.589 --> 00:02:57.404
which is capturing the meaning of
that text, with image generation.

40
00:02:57.404 --> 00:03:01.595
Which again, was sometimes
done by adversarial networks,

41
00:03:01.595 --> 00:03:04.149
now typically, diffusion models.

