WEBVTT

1
00:00:00.000 --> 00:00:04.527
&gt;&gt; Will Sentance: You've seen the core
principles of machine learning and

2
00:00:04.527 --> 00:00:06.042
neural networks.

3
00:00:06.042 --> 00:00:11.882
We've had probability and
at the core making predictions

4
00:00:11.882 --> 00:00:16.648
about our larger population of,
in this case,

5
00:00:16.648 --> 00:00:22.845
three by four images in the previous case,
refund requests,

6
00:00:22.845 --> 00:00:29.901
making prediction using a model
that converted our background data.

7
00:00:29.901 --> 00:00:34.427
In this case,
pixels into the associated data.

8
00:00:34.427 --> 00:00:37.934
The label smile yes, smile no, smile no,

9
00:00:37.934 --> 00:00:42.523
smile yes, the tool we use
towards the neural network.

10
00:00:42.523 --> 00:00:50.161
It's generalizing that pattern we found
in the sample that these 12 pixels 100%.

11
00:00:50.161 --> 00:00:55.077
These 12 pixels 0% these
12 0% these 12 100%

12
00:00:55.077 --> 00:00:59.099
to the population these
12 pixels who knows?

13
00:00:59.099 --> 00:01:00.843
We'll get 100 percentage fromit.

14
00:01:00.843 --> 00:01:06.876
That presumably would be, helpfully, yes,
it would be quite a -1, wouldn't it?

15
00:01:06.876 --> 00:01:09.450
If anyone's tried this one,
it will be quite a -1.

16
00:01:09.450 --> 00:01:14.949
It will come out at probably,
I don't know, three or 4%, hopefully.

17
00:01:14.949 --> 00:01:19.016
We can apply, someone try,
we can apply the model, the converter,

18
00:01:19.016 --> 00:01:20.716
to our broader population.

19
00:01:20.716 --> 00:01:25.033
And as long as the sample is reflective
of the population as a whole,

20
00:01:25.033 --> 00:01:29.605
which if it's a decent sized sample,
we can feel confident it will be.

21
00:01:29.605 --> 00:01:34.770
Then we're able to make decent predictions
converting just like we did here,

22
00:01:34.770 --> 00:01:40.105
where we wanted to get as many of these
converted to the actual label as possible.

23
00:01:40.105 --> 00:01:45.647
So, 2 we're able to convert
this new 12 pixels values and

24
00:01:45.647 --> 00:01:50.005
get a good decision,
1 or -1, small or not.

25
00:01:50.005 --> 00:01:50.971
How do we do it?

26
00:01:50.971 --> 00:01:55.885
Via the neural network converter,
the neural network model that

27
00:01:55.885 --> 00:02:00.453
gives layers of multipliers,
layers of multipliers.

28
00:02:00.453 --> 00:02:06.435
Weights known as the parameters of
the model that capture the association

29
00:02:06.435 --> 00:02:12.623
between the input values of features
of pixels and their label small or not.

30
00:02:12.623 --> 00:02:18.598
The class, the label small or not, we then
used the training approach of gradient

31
00:02:18.598 --> 00:02:24.420
descent to tweak from the 0s initially,
which gave us a terrible conversion.

32
00:02:24.420 --> 00:02:29.494
Steadily closer and closer, until we
were converting our whole sample with

33
00:02:29.494 --> 00:02:34.424
an accuracy of 93% and an error of
only 37% using gradient descent.

34
00:02:34.424 --> 00:02:36.991
Then we refine our model, we could add,

35
00:02:36.991 --> 00:02:41.380
we could improve our learning rate,
jump faster, but it's a risk.

36
00:02:41.380 --> 00:02:45.028
We added an activation function,
in this case sigmoid,

37
00:02:45.028 --> 00:02:49.664
that not only made things easier
to interpret, 100% it's a smile,

38
00:02:49.664 --> 00:02:54.078
0% it's not, and somewhere in between,
more or less confident.

39
00:02:54.078 --> 00:02:57.421
But also ensured we actually
found a set of multipliers

40
00:02:57.421 --> 00:03:00.192
that did a decent conversion for
our sample.

41
00:03:00.192 --> 00:03:07.482
And then finally, integrating all
of that into a model pipeline.

42
00:03:07.482 --> 00:03:13.398
That's the fancy word for the process by
which we take all of that training data,

43
00:03:13.398 --> 00:03:16.704
develop our set of multipliers, our model,

44
00:03:16.704 --> 00:03:20.457
then, make it available to be used for
inferring.

45
00:03:20.457 --> 00:03:23.825
Making a bet,
making a prediction about a new image.

46
00:03:23.825 --> 00:03:26.730
And then, by the way,
if we look at that, and

47
00:03:26.730 --> 00:03:30.782
over time, realize it's not doing
a very good job refining and

48
00:03:30.782 --> 00:03:34.470
maybe retraining our model,
designing the API to do so.

49
00:03:34.470 --> 00:03:38.266
And isn't that a gorgeous little
pet dog in the corner there,

50
00:03:38.266 --> 00:03:41.267
designed by our wonderful
illustrator Kieran.

51
00:03:41.267 --> 00:03:45.106
So extending these principles
to an unfathomable scale,

52
00:03:45.106 --> 00:03:49.099
which is where we move into large
language models, all AI and

53
00:03:49.099 --> 00:03:53.094
ML models you develop and
deploy build on these principles,

54
00:03:53.094 --> 00:03:57.903
much of the power, though, comes from
the vast scale of training data.

55
00:03:57.903 --> 00:03:59.541
We had a sample of four, but

56
00:03:59.541 --> 00:04:02.907
we were able to follow every
single one of these pixels.

57
00:04:02.907 --> 00:04:08.351
In practice, it's beyond comprehension,
but it's just an extension

58
00:04:08.351 --> 00:04:13.702
of just like programming is just save
data, do stuff to it, but my God,

59
00:04:13.702 --> 00:04:18.899
there's a lot of data you can save and
a lot of stuff you can do with it.

60
00:04:18.899 --> 00:04:22.175
Same here, it's only ever take sample,
identify pattern,

61
00:04:22.175 --> 00:04:26.396
to convert within the sample and apply to
population where in the population you

62
00:04:26.396 --> 00:04:30.189
don't have all the data, so
you don't know if there's a smile or not.

63
00:04:30.189 --> 00:04:34.125
If you worked out how to convert it in
the sample effectively where you did know,

64
00:04:34.125 --> 00:04:35.787
you can use it in the population.

65
00:04:35.787 --> 00:04:40.403
But throughout, remember, it all depends
on our ability to generalize from a sample

66
00:04:40.403 --> 00:04:44.652
to the population by building a model
that converts or captures the patterns.

67
00:04:44.652 --> 00:04:47.522
These patterns of pixels
associated with smile,

68
00:04:47.522 --> 00:04:51.019
these with not these with not
these with smile in the sample.

69
00:04:51.019 --> 00:04:54.137
And assuming that reflects
the population as a whole,

70
00:04:54.137 --> 00:04:56.860
we can make predictions
about our population.

71
00:04:56.860 --> 00:05:01.784
It just happens that population
in large language models,

72
00:05:01.784 --> 00:05:06.707
as we'll see here,
is something akin to all possible use of

73
00:05:06.707 --> 00:05:11.531
human language,
not just three by four images with 0s and

74
00:05:11.531 --> 00:05:16.168
1s, and that has some pretty
profound consequences.

