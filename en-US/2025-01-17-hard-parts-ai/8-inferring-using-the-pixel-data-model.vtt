WEBVTT

1
00:00:00.000 --> 00:00:00.862
&gt;&gt; Will Sentance: Let's use it.

2
00:00:00.862 --> 00:00:05.460
Assuming the sample reflects
the population and think about that for

3
00:00:05.460 --> 00:00:06.180
a second.

4
00:00:06.180 --> 00:00:09.995
We're saying that we can't
define a smile except for

5
00:00:09.995 --> 00:00:13.907
by giving a label saying this
is a smile and this is not.

6
00:00:13.907 --> 00:00:18.361
Now, in a very small sample, you might be,
well, that's not very sort of true.

7
00:00:18.361 --> 00:00:20.366
It's not capturing the essence of a smile.

8
00:00:20.366 --> 00:00:23.788
In a larger sample, one would hope
that you've labeled enough that

9
00:00:23.788 --> 00:00:26.563
you are capturing in some
sense the essence of a smile.

10
00:00:26.563 --> 00:00:30.333
But that's vital because that sample
better be reflective of the overall

11
00:00:30.333 --> 00:00:31.076
population.

12
00:00:31.076 --> 00:00:35.667
And the population is all possible images,
4,096 of them, smile or not.

13
00:00:35.667 --> 00:00:39.865
But also in some senses,
hopefully the essence of a smile.

14
00:00:39.865 --> 00:00:44.162
Some labels smile or
not that there is an underlying I'm sorry.

15
00:00:44.162 --> 00:00:47.727
Again, getting a little bit sort of
philosophical in the sense of what is

16
00:00:47.727 --> 00:00:48.959
a data, what is a smile?

17
00:00:48.959 --> 00:00:54.900
Well, it is a collection of [LAUGH] we've
all agreed enough of us have agreed.

18
00:00:54.900 --> 00:00:56.290
That's roughly what a smile looks like.

19
00:00:56.290 --> 00:00:59.873
There is no perfect definition of a smile.

20
00:00:59.873 --> 00:01:04.295
It is only a sample of labeled that we've
agreed that's a smile and that's not.

21
00:01:04.295 --> 00:01:07.305
That is why, by the way,
we mentioned scale AI.

22
00:01:07.305 --> 00:01:11.571
There's also an amazing research
project out of many universities, but

23
00:01:11.571 --> 00:01:15.833
I know about it out of Oxford, that is
about ensuring that the people doing

24
00:01:15.833 --> 00:01:20.126
the labelling of what is increasingly
becoming the truth of our society.

25
00:01:20.126 --> 00:01:23.233
That is judgments on, from models,

26
00:01:23.233 --> 00:01:28.446
the labelers are also representative
of a range of cultures,

27
00:01:28.446 --> 00:01:32.771
experiences, and
definitions of what a smile is.

28
00:01:32.771 --> 00:01:35.783
It's a really phenomenal project
led by some researchers at

29
00:01:35.783 --> 00:01:38.449
Oxford Internet Institute or
at least among others.

30
00:01:38.449 --> 00:01:42.589
But if really very important because it's
literally, that's what's determining.

31
00:01:42.589 --> 00:01:48.127
It's only the definition of the smile as
so far as the sample says 1 and minus 1.

32
00:01:48.127 --> 00:01:50.340
Therefore, okay, so let's go in.

33
00:01:50.340 --> 00:01:54.733
We can use this converter on new images of
population that don't have a label 1 or

34
00:01:54.733 --> 00:01:57.978
minus 1 and run the converter
on it to predict their label.

35
00:01:57.978 --> 00:02:02.331
Running the converter people,
remember this term, inference.

36
00:02:02.331 --> 00:02:06.527
Training is coming up with
the multipliers to do the conversion.

37
00:02:06.527 --> 00:02:11.137
Inference, using those multipliers
on a new set of numbers.

38
00:02:11.137 --> 00:02:12.187
Folk, let's do it.

39
00:02:14.376 --> 00:02:17.677
&gt;&gt; Will Sentance: I think I only say folk
in this room I don't know I've sort of

40
00:02:17.677 --> 00:02:19.075
stopped saying anyway.

41
00:02:19.075 --> 00:02:22.317
So we don't know if it's a smile or not.

42
00:02:22.317 --> 00:02:25.165
Smile, question mark.

43
00:02:25.165 --> 00:02:28.282
Let's apply our multipliers, people.

44
00:02:28.282 --> 00:02:30.044
Let's apply them, let's apply them,
let's apply them.

45
00:02:30.044 --> 00:02:34.095
So multiplied by 0.

46
00:02:34.095 --> 00:02:35.499
I'm gonna put it here just so

47
00:02:35.499 --> 00:02:38.962
we get really clear that we're taking
just those set of multipliers.

48
00:02:38.962 --> 00:02:41.554
I know it's a bit,
do I have to write out again?

49
00:02:41.554 --> 00:02:45.521
But, just so
we know we're using these now and

50
00:02:45.521 --> 00:02:49.400
then we're gonna multiply and
then sum all.

51
00:02:54.756 --> 00:02:57.300
&gt;&gt; Will Sentance: No, Maria, you're up.

52
00:02:57.300 --> 00:02:58.018
You've already done it.

53
00:02:58.018 --> 00:02:59.204
Sorry Kayla, you're up.

54
00:02:59.204 --> 00:03:01.368
Give me everyone together, 0 plus.

55
00:03:01.368 --> 00:03:02.469
&gt;&gt; Ben: 0.
&gt;&gt; Will Sentance: Plus.

56
00:03:02.469 --> 00:03:03.251
&gt;&gt; Ben: 0.
&gt;&gt; Will Sentance: Plus.

57
00:03:03.251 --> 00:03:04.529
&gt;&gt; Ben: 0.
&gt;&gt; Will Sentance: Who's the only

58
00:03:04.529 --> 00:03:05.739
one doing this?

59
00:03:05.739 --> 00:03:08.520
Thank you, Ben, amazing.

60
00:03:08.520 --> 00:03:12.908
If it's not, Ben, you're not allowed
to speak now, so everyone else.

61
00:03:12.908 --> 00:03:14.079
&gt;&gt; Speaker 3: Just like grade school.

62
00:03:14.079 --> 00:03:17.810
&gt;&gt; Will Sentance: [LAUGH] that's good.

63
00:03:17.810 --> 00:03:22.822
All right, 0 + 0 + 0 + 0 plus and
not allowed to talk everyone else.

64
00:03:22.822 --> 00:03:23.866
&gt;&gt; Speaker 4: Plus 0, 0.

65
00:03:23.866 --> 00:03:24.388
&gt;&gt; Will Sentance: Yeah.

66
00:03:24.388 --> 00:03:25.019
&gt;&gt; Speaker 4: Plus 0.

67
00:03:25.019 --> 00:03:26.608
&gt;&gt; Will Sentance: Yeah.
&gt;&gt; Speaker 4: Plus unknown.

68
00:03:26.608 --> 00:03:29.729
&gt;&gt; Will Sentance: I don't konw plus
unknown, that's why it's so important,

69
00:03:29.729 --> 00:03:30.396
everybody.

70
00:03:30.396 --> 00:03:34.040
Ben was carrying us, plus what, everyone?

71
00:03:34.040 --> 00:03:34.778
&gt;&gt; Speaker 5: Minus 1.

72
00:03:34.778 --> 00:03:38.367
&gt;&gt; Will Sentance: Negative 1,
1 multiplied by negative 1 and

73
00:03:38.367 --> 00:03:41.318
multiplier is negative 1 here plus.

74
00:03:41.318 --> 00:03:42.218
&gt;&gt; Speaker 4: 0.

75
00:03:42.218 --> 00:03:42.831
&gt;&gt; Will Sentance: Plus.

76
00:03:42.831 --> 00:03:43.537
&gt;&gt; Ben: 0.

77
00:03:43.537 --> 00:03:46.219
&gt;&gt; Will Sentance: Plus 0 by 1.

78
00:03:46.219 --> 00:03:46.758
&gt;&gt; Speaker 4: 0.

79
00:03:46.758 --> 00:03:49.638
&gt;&gt; Will Sentance: 0 Plus 1 by 0.

80
00:03:49.638 --> 00:03:50.727
&gt;&gt; Speaker 4: 0.

81
00:03:50.727 --> 00:03:53.030
&gt;&gt; Will Sentance: Sum is 2.

82
00:03:53.030 --> 00:03:53.885
&gt;&gt; Speaker 4: Negative 1.

83
00:03:53.885 --> 00:03:54.508
&gt;&gt; Speaker 5: Negative 1.

84
00:03:54.508 --> 00:03:57.297
&gt;&gt; Will Sentance: Negative 1,
so is this a smile?

85
00:03:57.297 --> 00:03:59.800
According to our samples,
definition of a smile.

86
00:03:59.800 --> 00:04:01.327
Is this a smile?

87
00:04:01.327 --> 00:04:03.644
No, well done everybody.

88
00:04:03.644 --> 00:04:06.905
No smile, well done folk.

89
00:04:06.905 --> 00:04:11.416
All right, so really good.

90
00:04:11.416 --> 00:04:13.331
Let's get some names of this stuff down.

91
00:04:13.331 --> 00:04:19.284
We've trained our set of multipliers
to work 100% accuracy for our sample.

92
00:04:19.284 --> 00:04:21.906
Our training stage is 100% accurate.

93
00:04:21.906 --> 00:04:26.810
We've then used that set
of multipliers to run

94
00:04:26.810 --> 00:04:31.083
on our new image of whatever this is, and

95
00:04:31.083 --> 00:04:35.609
said smile, and we've evaluated it, and

96
00:04:35.609 --> 00:04:40.911
we've inferred, inference, -1, no smile.

97
00:04:40.911 --> 00:04:42.929
So let's get some names of this stuff.

98
00:04:42.929 --> 00:04:46.969
What are these numbers known as?

99
00:04:46.969 --> 00:04:48.762
Who knows the name of these numbers?

100
00:04:48.762 --> 00:04:53.236
These people, 1,2,3,4,5,
these 12 are, what?

101
00:04:53.236 --> 00:04:53.766
&gt;&gt; Speaker 4: The vectors?

102
00:04:53.766 --> 00:04:55.140
&gt;&gt; Will Sentance: No.
&gt;&gt; Speaker 4: Parameters?

103
00:04:55.140 --> 00:04:56.943
&gt;&gt; Will Sentance: The weights.

104
00:04:56.943 --> 00:04:57.987
&gt;&gt; Speaker 5: The weights.

105
00:04:57.987 --> 00:04:59.477
&gt;&gt; Will Sentance: That's
all they are people.

106
00:04:59.477 --> 00:05:01.499
&gt;&gt; Speaker 4: Gotcha.
&gt;&gt; Will Sentance: That's all they are.

107
00:05:01.499 --> 00:05:04.356
The multipliers are the weights.

108
00:05:04.356 --> 00:05:05.547
That's all they are.

109
00:05:05.547 --> 00:05:07.712
That profound thing of neural networks.

110
00:05:07.712 --> 00:05:12.613
It's these 12 numbers multiplying our
input pixels that when multiplied,

111
00:05:12.613 --> 00:05:16.695
we get, and sum up an output, or
at least a converted output, and

112
00:05:16.695 --> 00:05:19.312
compare it to our target, if it matches.

113
00:05:19.312 --> 00:05:22.614
Our model's weights are good.

114
00:05:22.614 --> 00:05:26.954
Okay, our weights.

115
00:05:26.954 --> 00:05:31.121
This is a layer of weights.

116
00:05:31.121 --> 00:05:34.980
The word layer is used so
flexibly in this space that

117
00:05:34.980 --> 00:05:39.570
you could also say this is a layer
of pixels, an input layer.

118
00:05:39.570 --> 00:05:41.932
Input layer, layer weights.

119
00:05:41.932 --> 00:05:46.938
We could also call this output value,
the summed output value, the output layer.

120
00:05:46.938 --> 00:05:50.545
So in a sense, there's 1,
2, 3, layers here.

121
00:05:50.545 --> 00:05:52.964
But we'd never call this
a three layer network.

122
00:05:52.964 --> 00:05:56.592
We'd call this a single layer network,

123
00:05:56.592 --> 00:06:01.722
neural network because it has
a single layer of weights.

124
00:06:01.722 --> 00:06:06.088
So this here, people,
is a single layer neural network.

125
00:06:06.088 --> 00:06:08.689
Single layer of weights.

126
00:06:08.689 --> 00:06:13.199
And it's successfully
trained on our sample,

127
00:06:13.199 --> 00:06:19.411
on our training data,
to successfully trained, achieve a fit.

128
00:06:19.411 --> 00:06:25.080
For our sample, for our training data,

129
00:06:25.080 --> 00:06:34.096
that allows us to then make
inferences about new images, okay?

130
00:06:34.096 --> 00:06:36.673
Association with brain
structure more metaphorical.

131
00:06:36.673 --> 00:06:43.593
The term neural network, obviously,
suggests patterns similar to the brain.

132
00:06:43.593 --> 00:06:49.839
It's more metaphorical,
just to be specific, first the nodes here,

133
00:06:49.839 --> 00:06:54.524
that's the pixels, but
are equivalent to neurons,

134
00:06:54.524 --> 00:07:00.893
if you know biology or neuroscience
better than me and the connections.

135
00:07:00.893 --> 00:07:06.197
Things that take those input values and
connect them through

136
00:07:06.197 --> 00:07:11.709
to an output value are similar to
what you would say in America,

137
00:07:11.709 --> 00:07:18.274
the synapses that we say in the UK
synapses, but it's more metaphorical.

138
00:07:18.274 --> 00:07:23.040
The math that goes on in identifying
what the right weights or

139
00:07:23.040 --> 00:07:27.999
multipliers are, at least until recently,
does not appear.

140
00:07:27.999 --> 00:07:30.085
And in fact, is it Crick?

141
00:07:30.085 --> 00:07:35.804
The person who identified DNA, when these
ideas first started to emerge, wrote a big

142
00:07:35.804 --> 00:07:41.136
piece saying it is absolutely in no way
similar to a neural Network in the brain.

143
00:07:41.136 --> 00:07:45.810
But there is indication that some of the
ways in which multipliers are identified

144
00:07:45.810 --> 00:07:49.392
in an artificial, that's what we do and
we're doing today.

145
00:07:49.392 --> 00:07:52.725
Neural network might actually look
a lot more like the brain's way

146
00:07:52.725 --> 00:07:54.341
of developing these patterns.

147
00:07:54.341 --> 00:07:59.062
I think if you think about we've
identified the algorithm and

148
00:07:59.062 --> 00:08:04.146
your network that at scale best
captures complexity in our world,

149
00:08:04.146 --> 00:08:06.800
complexity data distributions.

150
00:08:06.800 --> 00:08:11.181
That is so similar or at least
analogous potentially to the brain,

151
00:08:11.181 --> 00:08:13.529
which is the most brilliant tool for

152
00:08:13.529 --> 00:08:18.167
understanding complexity of data
to distributions obviously ever.

153
00:08:18.167 --> 00:08:23.982
Well, I said that, depending on one's
belief system, but is pretty profound,

154
00:08:23.982 --> 00:08:28.386
it's not unlikely that there
might be some serious analogy.

155
00:08:28.386 --> 00:08:33.579
And the research right now looks at
are there ways in which the artificial,

156
00:08:33.579 --> 00:08:39.434
the ones that are in the brain, neural
networks might identify these multipliers,

157
00:08:39.434 --> 00:08:44.736
we're gonna see how to do that in a
moment, that is more like the brain does.

158
00:08:44.736 --> 00:08:49.172
And does the brain, actually, sometimes
do things that are more like the way that

159
00:08:49.172 --> 00:08:53.432
artificial neural networks go about
identifying these multipliers as well?

160
00:08:53.432 --> 00:09:02.045
And if it is, maybe there is greater
similarity than purely analogy, okay?

161
00:09:02.045 --> 00:09:07.420
Before you do thumbs or
I think we just keep going for

162
00:09:07.420 --> 00:09:14.171
a second and do thumbs so
do these multipliers have any meaning.

163
00:09:14.171 --> 00:09:19.186
They must do something it must be that
they mean something if they're that good.

164
00:09:19.186 --> 00:09:21.637
Converting, do they mean something?

165
00:09:21.637 --> 00:09:27.001
The different numbers multiply each pixel,
have some potential meaning,

166
00:09:27.001 --> 00:09:30.937
but it's very contingent on
how we set this problem up,

167
00:09:30.937 --> 00:09:35.230
how we label the data, and
what we say the pixel numbers are.

168
00:09:35.230 --> 00:09:42.833
So in this case, where pixels are dark
when they are a feature of the face.

169
00:09:42.833 --> 00:09:45.288
So, it's not actually,
literally the color of the feature.

170
00:09:45.288 --> 00:09:46.787
It's more the shadows.

171
00:09:46.787 --> 00:09:50.418
If you look at someone's eyes,
they're darker because of a shadow.

172
00:09:50.418 --> 00:09:52.445
There's an edge in a three
dimensional space.

173
00:09:52.445 --> 00:09:57.785
There's a going from my
hands all over my face,

174
00:09:57.785 --> 00:10:00.862
going from here to in here.

175
00:10:00.862 --> 00:10:03.478
Where the features are darker,
meaning shadow particularly.

176
00:10:03.478 --> 00:10:07.111
So mouth, again, lips, shadow eyes.

177
00:10:07.111 --> 00:10:11.733
If we've given numbers of
positive number for that and

178
00:10:11.733 --> 00:10:15.460
stuff where not much is
going on in the face.

179
00:10:15.460 --> 00:10:22.387
A 0 and we've said a positive number
of 1 when there's a smile and

180
00:10:22.387 --> 00:10:29.456
a negative number of negative 1,
sorry, when there's not then.

181
00:10:29.456 --> 00:10:36.639
The multipliers will be positive for those
pixels, there's a positive 1, for those,

182
00:10:36.639 --> 00:10:42.770
pixels that are most pixels being stuff,
pixels which are most distinctive

183
00:10:42.770 --> 00:10:48.066
stuffs going on in the smile images
where the output is positive.

184
00:10:48.066 --> 00:10:52.093
Because then the one multiplied by
the one is a one which is positive,

185
00:10:52.093 --> 00:10:53.701
which gives us our target.

186
00:10:53.701 --> 00:10:58.673
And the multipliers will be negative,
where the pixels

187
00:10:58.673 --> 00:11:03.870
with stuff going on are most
distinctive to the not smile.

188
00:11:03.870 --> 00:11:07.287
Because then we get a thing going on,
negative, negative, and

189
00:11:07.287 --> 00:11:09.324
that's associated with a not smile.

190
00:11:09.324 --> 00:11:14.258
So in this setup, the multipliers
act a little bit like correlations.

191
00:11:14.258 --> 00:11:18.286
You'll see high positive for
pixels, strongly correlated or

192
00:11:18.286 --> 00:11:21.934
associated with pixels that
are important in the smile or

193
00:11:21.934 --> 00:11:26.052
to pixels that it's important
that they're dark in the smile.

194
00:11:26.052 --> 00:11:33.360
So think about a smile,
the lower bit is where the dark is.

195
00:11:33.360 --> 00:11:36.497
And when you smile the lower
bit is where the light is or

196
00:11:36.497 --> 00:11:39.015
it's the north shadow Everyone got that?

197
00:11:39.015 --> 00:11:41.457
So in this case, there'll be correlations.

198
00:11:41.457 --> 00:11:46.688
High positive multipliers for
pixels strongly associated, correlated

199
00:11:46.688 --> 00:11:52.187
with a smile 1, and negative with those
strongly associated with smile 0.

200
00:11:52.187 --> 00:11:57.028
But it's only because we defined
smile 1 and minus 1 as the labels and

201
00:11:57.028 --> 00:11:59.172
therefore the numbers match.

202
00:11:59.172 --> 00:12:05.542
And we define not much going on as 0 and
lots of stuff going on as 1.

203
00:12:05.542 --> 00:12:09.053
So they look like correlations here,
but it's not intrinsic.

204
00:12:09.053 --> 00:12:10.170
It's how we label the stuff.

205
00:12:10.170 --> 00:12:12.832
We gotta label these other,
we gotta label these flipped and

206
00:12:12.832 --> 00:12:15.095
now they'd be reversed
[LAUGH] it doesn't matter.

207
00:12:15.095 --> 00:12:19.783
I think what is deeper true is that
the multipliers have more stuff

208
00:12:19.783 --> 00:12:24.825
going on when there's more important
stuff going on in those pixels.

209
00:12:24.825 --> 00:12:29.137
So there's some important stuff
going on expect bigger numbers,

210
00:12:29.137 --> 00:12:32.070
because we wanna generate
out some numbers.

211
00:12:32.070 --> 00:12:36.115
But even that's contingent on me
wanting the output of 1 and minus 1 and

212
00:12:36.115 --> 00:12:38.252
not an output of 0 for stuff going on.

213
00:12:38.252 --> 00:12:42.550
But at very least, whatever you do,
there's some association between

214
00:12:42.550 --> 00:12:45.728
stuff going on in the pixels and
the underlying data.

215
00:12:45.728 --> 00:12:48.539
Stuff happening and weights or

216
00:12:48.539 --> 00:12:54.276
multipliers being more non zero,
thing happening with them.

217
00:12:54.276 --> 00:12:59.665
For those pixels that have stuff going on
either towards an image of a smile or not.

218
00:12:59.665 --> 00:13:03.895
And that does capture,
even at a scale neural network,

219
00:13:03.895 --> 00:13:06.154
there's some sense of that.

220
00:13:06.154 --> 00:13:11.664
Stuff going on has greater,
weight or importance to it.

221
00:13:11.664 --> 00:13:15.822
But it's very specifically looks a bit
like correlation only because of how we

222
00:13:15.822 --> 00:13:16.899
set the problem up.

