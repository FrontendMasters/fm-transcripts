WEBVTT

1
00:00:00.000 --> 00:00:02.870
Now that we see that
it works let's go back

2
00:00:02.870 --> 00:00:06.980
to the question that I started
to ask you earlier which was.

3
00:00:06.980 --> 00:00:11.902
What's the performance implication
the difference that we've now made what's

4
00:00:11.902 --> 00:00:15.050
the implication of
the difference in performance?

5
00:00:15.050 --> 00:00:20.389
It is still the case that we
are recursing against the input word,

6
00:00:20.389 --> 00:00:25.534
and so the length of the input word,
the longer the input word,

7
00:00:25.534 --> 00:00:31.381
the more levels of call stack recursion,
we're going to end up doing.

8
00:00:31.381 --> 00:00:36.248
So in both solutions option one and now
option two we're gonna end up recursing

9
00:00:36.248 --> 00:00:38.916
over the same number of input characters.

10
00:00:38.916 --> 00:00:42.935
But for
each one of those input characters,

11
00:00:42.935 --> 00:00:47.716
notice what we're now doing
differently instead of

12
00:00:47.716 --> 00:00:53.379
effectively searching the entire
elements list every time.

13
00:00:53.379 --> 00:00:57.527
We are searching the small subset of
candidates that we already know to be

14
00:00:57.527 --> 00:00:58.751
possible to be in it,

15
00:00:58.751 --> 00:01:03.243
and we're ignoring all the other ones
that could not possibly have been in it.

16
00:01:15.429 --> 00:01:20.835
Remember in the previous solution we
had a four of loop over elements.

17
00:01:20.835 --> 00:01:26.217
So, if we took N to be the size of
the input characters that you type in,

18
00:01:26.217 --> 00:01:32.725
which is fixed somewhere between six and
12, or whatever somebody wants to type.

19
00:01:32.725 --> 00:01:35.017
If we take that as N, and

20
00:01:35.017 --> 00:01:41.097
we take the number of things that
we need to look at worst case for

21
00:01:41.097 --> 00:01:45.949
each one of those characters,
and we call that M.

22
00:01:45.949 --> 00:01:50.040
The big O of this solution
is O of N times M and

23
00:01:50.040 --> 00:01:55.760
the big O of the previous
solution is O of N times M.

24
00:01:55.760 --> 00:01:57.861
So, in a theoretical sense,

25
00:01:57.861 --> 00:02:03.160
I think we could say that these two
have the same theoretical performance.

26
00:02:04.420 --> 00:02:07.984
But in a practical performance sense,

27
00:02:07.984 --> 00:02:12.520
we know that the candidates
list is significantly

28
00:02:12.520 --> 00:02:17.108
shorter than the Elements list.

29
00:02:18.974 --> 00:02:22.185
Perhaps even an order
of magnitude shorter.

30
00:02:22.185 --> 00:02:25.988
So there's another takeaway that I want
you to get from this workshop which is,

31
00:02:25.988 --> 00:02:28.623
it is important to be able
to evaluate your solutions.

32
00:02:28.623 --> 00:02:32.309
For the theoretical characteristics,

33
00:02:32.309 --> 00:02:36.976
it is also important to be
pragmatic about things.

34
00:02:36.976 --> 00:02:41.560
For example, you could say theoretically,

35
00:02:41.560 --> 00:02:46.986
that big O of one and
big O of 2000, in theoretical

36
00:02:46.986 --> 00:02:53.030
terms are equal one unit of work and
2000 units of work.

37
00:02:53.030 --> 00:02:58.500
Are equal in the theoretical sense because
those never grow no matter how big your

38
00:02:58.500 --> 00:03:04.148
data set or input is, you either always
do one operation or you always do 2000.

39
00:03:04.148 --> 00:03:08.970
And so in the theoretical sense,
we consider both of those to be constant

40
00:03:08.970 --> 00:03:12.141
time because they don't
grow with the inputs.

41
00:03:13.591 --> 00:03:18.644
But I think you and I both know that
doing 2000 operations versus doing

42
00:03:18.644 --> 00:03:23.957
one operation is actually going to be
measurably different in performance.

43
00:03:23.957 --> 00:03:26.748
Even if it's not theoretically
different in performance,

44
00:03:26.748 --> 00:03:28.889
it's measurably different in performance.

45
00:03:28.889 --> 00:03:33.492
So algorithmists definitely play
in this space of theory and

46
00:03:33.492 --> 00:03:39.101
they validate and design algorithms
based upon the theoretical things.

47
00:03:39.101 --> 00:03:44.327
We cannot forget the practical
implementations,

48
00:03:44.327 --> 00:03:50.320
if I run an algorithm that can do O of N,

49
00:03:50.320 --> 00:03:55.279
and I run another algorithm
that can do O of 100N,

50
00:03:55.279 --> 00:03:59.690
theoretically those
are the same algorithm.

51
00:04:01.040 --> 00:04:07.105
I'm gonna choose the O of N, because it's
100 times more efficient than the O of N.

52
00:04:07.105 --> 00:04:10.841
All right, you follow the difference
between we're talking about?

53
00:04:10.841 --> 00:04:14.511
You do want to first consider
the theoretical space but

54
00:04:14.511 --> 00:04:17.639
don't ignore the practical consideration.

55
00:04:17.639 --> 00:04:20.103
In this particular case, in theory,

56
00:04:20.103 --> 00:04:23.876
these are the same big O as far
as I can tell but in practice,

57
00:04:23.876 --> 00:04:28.653
there would be a difference, would it
be a big measurable seconds delay?

58
00:04:28.653 --> 00:04:34.199
Absolutely not, we are talking
about maybe a dozen miliseconds,

59
00:04:34.199 --> 00:04:37.862
maybe probably not even that much right,
so

60
00:04:37.862 --> 00:04:42.034
not we're not talking
about a giant difference.

61
00:04:42.034 --> 00:04:44.931
But like we said, paper cuts add up so

62
00:04:44.931 --> 00:04:49.424
we don't want to do the extra
work if it's unnecessary.

63
00:04:49.424 --> 00:04:54.250
Any questions about this first exercise
hopefully it got your feet wet

64
00:04:54.250 --> 00:04:58.096
with working through thinking
about the algorithms and

65
00:04:58.096 --> 00:05:00.566
then translating them to code yes?

66
00:05:00.566 --> 00:05:03.280
&gt;&gt; Several people asking for
a quick recap.

67
00:05:03.280 --> 00:05:07.276
&gt;&gt; Fundamentally, the algorithmic
approaches were very similar.

68
00:05:07.276 --> 00:05:10.311
Both algorithmic approaches,
option one and

69
00:05:10.311 --> 00:05:13.431
option two,
recursed over the input strings.

70
00:05:13.431 --> 00:05:18.956
The big difference between option one and
option two, is that in option one,

71
00:05:18.956 --> 00:05:23.206
for each candidate will say
each chunk of the input string,

72
00:05:23.206 --> 00:05:26.696
we matched it against
the entire Elements list.

73
00:05:26.696 --> 00:05:29.808
Which was the most naive way of doing
it It's saying if I look at this

74
00:05:29.808 --> 00:05:31.976
one character,
go see if I can find it there and

75
00:05:31.976 --> 00:05:34.268
we didn't even have an index
in place by the way.

76
00:05:34.268 --> 00:05:37.964
Don't forget the whole index thing
to make it an O of one lookup, so

77
00:05:37.964 --> 00:05:39.693
we didn't even have an index.

78
00:05:39.693 --> 00:05:44.988
We just looked it up in the most naive,
dumb way possible.

79
00:05:44.988 --> 00:05:49.080
In the second approach, we said, we don't
need to look at all the elements for

80
00:05:49.080 --> 00:05:50.693
each one of these characters.

81
00:05:50.693 --> 00:05:54.329
We can actually do a pre-pass
through the inputs and

82
00:05:54.329 --> 00:05:58.718
collect any of the possible
candidates that ever could match.

83
00:05:58.718 --> 00:06:04.367
And only if we found those, those are the
ones to look at each time we recurse down.

84
00:06:04.367 --> 00:06:08.436
So we have the same theoretical big O,
but in practice,

85
00:06:08.436 --> 00:06:13.733
we're doing significantly less work for
each of the input characters.

86
00:06:17.376 --> 00:06:20.580
And the penalty that we
paid was one loop through.

87
00:06:20.580 --> 00:06:25.356
You'll notice that the find
candidates function has has an O of N

88
00:06:25.356 --> 00:06:26.775
complexity to it.

89
00:06:26.775 --> 00:06:30.379
So what we end up with and
this is a subtle but

90
00:06:30.379 --> 00:06:36.103
important point is we end up with
a big O (n+) rather than N times.

91
00:06:36.103 --> 00:06:41.199
We had to pay the N penalty N being
the size of the number of elements

92
00:06:41.199 --> 00:06:46.869
in the periodic table, which you could
argue that that's not even an N.

93
00:06:46.869 --> 00:06:51.756
They're not coming up with new periodic
table elements, it's pretty fixed.

94
00:06:51.756 --> 00:06:56.403
So you could argue that this is
O of 118 rather than O of N, but

95
00:06:56.403 --> 00:07:02.033
we did have to pay 118 iterations to
construct our indexes effectively.

96
00:07:02.033 --> 00:07:05.033
We're constructing
effectively a one-letter and

97
00:07:05.033 --> 00:07:09.815
two-letter symbol indexes into this array,
but only the ones that we care about.

98
00:07:09.815 --> 00:07:14.406
So it's a partial index, that's
effectively what candidates is doing.

99
00:07:14.406 --> 00:07:17.572
So, we had to pay an O of 118, to do that,

100
00:07:17.572 --> 00:07:22.198
but think about potentially
the longer the word that you write,

101
00:07:22.198 --> 00:07:26.497
the more times there's a call
stack recursion happening.

102
00:07:26.497 --> 00:07:30.277
All of that saved work of having to go
back over the Elements list over and

103
00:07:30.277 --> 00:07:31.417
over and over again.

104
00:07:31.417 --> 00:07:36.735
Many 100s or 1000s of operations saved and
doing that, there was another question?

105
00:07:36.735 --> 00:07:39.703
&gt;&gt; How did they compare in
terms of space complexity.

106
00:07:44.936 --> 00:07:50.313
&gt;&gt; So in memory, remember there's always
a trade off between the performance,

107
00:07:50.313 --> 00:07:54.724
the raw time performance versus
the memory usage performance.

108
00:07:57.666 --> 00:08:03.672
We still have the main data structure
elements the same between the two options.

109
00:08:03.672 --> 00:08:08.100
That would be the big usage of
memory that we've talked about and

110
00:08:08.100 --> 00:08:10.316
that's equal between the two.

111
00:08:10.316 --> 00:08:16.352
Option two did construct a little bit more
memory usage, in that we created this

112
00:08:16.352 --> 00:08:22.676
symbols object which had properties that
were references to those other objects.

113
00:08:22.676 --> 00:08:27.454
So we had an object with
118 properties on it, and

114
00:08:27.454 --> 00:08:34.086
then we created two arrays,
one letter symbols and two letter symbols.

115
00:08:34.086 --> 00:08:38.924
Total of which probably has on
average I'm just gonna guess I haven't

116
00:08:38.924 --> 00:08:42.942
actually calculated it but
I'm gonna guess on average for

117
00:08:42.942 --> 00:08:46.636
these words there's
probably 10 candidates max.

118
00:08:46.636 --> 00:08:49.912
So we're creating an array
with 10 elements and

119
00:08:49.912 --> 00:08:54.748
an object with 180 team properties
that just have references on them,

120
00:08:54.748 --> 00:08:58.350
that's a tiny bit more memory,
but it is more memory.

121
00:08:58.350 --> 00:09:05.124
Notably, from the algorithmist
perspective, that's still O of 1 memory.

122
00:09:06.770 --> 00:09:11.487
None of our memory grew
N proportionally or

123
00:09:11.487 --> 00:09:15.028
more based upon the input size.

124
00:09:15.028 --> 00:09:19.804
Slightly more candidate growth,
but it's definitely not linear,

125
00:09:19.804 --> 00:09:24.575
I don't even know how to what it would be,
but it would be sublinear,

126
00:09:24.575 --> 00:09:27.729
it would be logarithmic approaching fixed.

127
00:09:27.729 --> 00:09:30.629
Final check in here give me
some thumbs up thumbs down,

128
00:09:30.629 --> 00:09:32.594
how do you feel about this exercise?

129
00:09:32.594 --> 00:09:36.324
How do you feel about having got your
feet wet using some recursion and

130
00:09:36.324 --> 00:09:39.551
some algorithmic thinking and
translating into the code?

131
00:09:39.551 --> 00:09:42.538
We feel like the approach
made rough sense or

132
00:09:42.538 --> 00:09:46.582
do we feel like there's still
some difficult parts for us?

133
00:09:46.582 --> 00:09:50.883
Okay I see a few good thumbs and
a few wavering thumbs so

134
00:09:50.883 --> 00:09:57.497
that's all right I think somebody asked
me right before we started the workshop.

135
00:09:57.497 --> 00:10:02.161
And I'll say for the benefit of
those watching the recording,

136
00:10:02.161 --> 00:10:06.302
you're being presented
a highly compressed zip file.

137
00:10:06.302 --> 00:10:12.408
This information is something that many
people spend weeks, months years learning.

138
00:10:12.408 --> 00:10:15.752
And you're watching it over
the course of eight or 10 hours or

139
00:10:15.752 --> 00:10:18.287
whatever it ends up being
tightly compressed.

140
00:10:18.287 --> 00:10:20.861
So if you have that feeling
of I kind of get it but

141
00:10:20.861 --> 00:10:22.710
I really don't fully get it yet.

142
00:10:22.710 --> 00:10:28.844
You're in exactly the right spot,
you're in exactly the right spot so

143
00:10:28.844 --> 00:10:34.365
don't feel bad it will take a while
to re-review I'll take this

144
00:10:34.365 --> 00:10:40.935
moment to remind folks of what I always
say in my workshops, take more time.

145
00:10:40.935 --> 00:10:41.831
Go back over this,

146
00:10:41.831 --> 00:10:45.144
try it again from scratch, in fact,
I'll give you this suggestion.

147
00:10:45.144 --> 00:10:49.991
Right now, wherever you are and whatever
time it is that you're watching this,

148
00:10:49.991 --> 00:10:53.640
open up your calendar and
pick a date a week or two in advance.

149
00:10:53.640 --> 00:10:57.280
And mark yourself off a couple of
hours of review time for this, and

150
00:10:57.280 --> 00:10:59.949
then do another one a couple
of weeks after that.

151
00:10:59.949 --> 00:11:04.431
If you wait until those days come,
I promise you your calendar will fill up,

152
00:11:04.431 --> 00:11:06.042
but if you reserve it now and

153
00:11:06.042 --> 00:11:10.824
reserve time out in the future now, so
that you have an opportunity to come back.

154
00:11:10.824 --> 00:11:16.351
And try this stuff at a later time, you
will thank yourself because it does take

155
00:11:16.351 --> 00:11:21.738
time for our brains to unpack and review
and it is important for us to go back.

156
00:11:21.738 --> 00:11:26.508
We didn't have many slides for
this segment but go back over what we've

157
00:11:26.508 --> 00:11:30.731
gone over so far and
retry the code from scratch from yourself.

158
00:11:30.731 --> 00:11:34.015
Your future self will
thank your current self

