WEBVTT

1
00:00:01.110 --> 00:00:06.370
All right, so let's pick back up
with our night's dialer solution.

2
00:00:06.370 --> 00:00:08.807
When we were together last time,

3
00:00:08.807 --> 00:00:12.820
we completed actually both option one and
option two.

4
00:00:12.820 --> 00:00:17.579
You recall that I kind of jumped ahead
a little bit with factoring out that

5
00:00:17.579 --> 00:00:21.130
long function for
the nearby paths calculation.

6
00:00:21.130 --> 00:00:22.640
That's actually option two.

7
00:00:22.640 --> 00:00:25.540
So, you've already done option one and
option two.

8
00:00:25.540 --> 00:00:29.942
So, for what we're gonna talk about from
here forward, starting with option two as

9
00:00:29.942 --> 00:00:32.856
your base branch,
if you've got the repo checked out,

10
00:00:32.856 --> 00:00:36.390
you can start with option two and
we'll be working on option three.

11
00:00:37.420 --> 00:00:42.745
You also recall that we were able
to test a little bit that we sort

12
00:00:42.745 --> 00:00:48.090
of saw the performance benchmarking
of the growth of the time.

13
00:00:48.090 --> 00:00:51.020
And we saw that it was literally
growing just a little bit more than

14
00:00:51.020 --> 00:00:54.605
double every time we added one more hop,
scoring a little bit more than double.

15
00:00:54.605 --> 00:01:00.102
And that fit very perfectly with
our theoretical analysis that

16
00:01:00.102 --> 00:01:07.910
there was 2.222 paths on average that you
could go to from any one of the digits.

17
00:01:07.910 --> 00:01:11.997
So that fit nicely, and it doesn't
always happen that the theory and

18
00:01:11.997 --> 00:01:15.873
the practice, that the performance
benchmarking match up, but

19
00:01:15.873 --> 00:01:21.600
it's kinda nice when you can see a really
clear illustration of that principle.

20
00:01:21.600 --> 00:01:23.130
Well, obviously that's impractical.

21
00:01:23.130 --> 00:01:27.705
We can't roll out to production something
that's gonna be working in an exponential

22
00:01:27.705 --> 00:01:30.560
or even greater than
exponential sort of way.

23
00:01:30.560 --> 00:01:34.850
So let's talk about some ways that
we can optimize our solution.

24
00:01:34.850 --> 00:01:39.203
The first we wanna look at is we
want to observe that there are quite

25
00:01:39.203 --> 00:01:43.412
a few things that we are doing
work over and over and over again.

26
00:01:43.412 --> 00:01:48.468
We're repeating work, as I've said
multiple times in this course so far,

27
00:01:48.468 --> 00:01:53.454
the key thing is that once you do some
work, don't keep redoing that work.

28
00:01:53.454 --> 00:01:57.186
Find some way to remember or
take advantage of that work,

29
00:01:57.186 --> 00:02:02.321
cuz that's the biggest drain on your
performance is when your solution causes

30
00:02:02.321 --> 00:02:07.570
more work to be done just because it
didn't remember the work that it did.

31
00:02:07.570 --> 00:02:11.183
Or it didn't take care of a piece of
information that it could have saved,

32
00:02:11.183 --> 00:02:12.970
it just didn't save it.

33
00:02:12.970 --> 00:02:14.420
So let's look at this diagram.

34
00:02:14.420 --> 00:02:17.250
You recall this was kind
of our recursive diagram.

35
00:02:17.250 --> 00:02:19.670
And the tree itself doesn't exist.

36
00:02:19.670 --> 00:02:23.700
It's a conceptual tree, but it represents
the call stack tree, if you will.

37
00:02:23.700 --> 00:02:25.651
And so, in this call stack tree,

38
00:02:25.651 --> 00:02:29.440
we see that there are actually
quite a bit of repetition.

39
00:02:29.440 --> 00:02:32.274
For example, you'll notice that the f(4,

40
00:02:32.274 --> 00:02:37.142
4), that's the count paths 4, 4,
you'll notice that there are multiple

41
00:02:37.142 --> 00:02:41.320
other places in the tree
where we get to f(4, 4).

42
00:02:41.320 --> 00:02:45.774
So we've done that work over there on
the left, and then we come around to f(4,

43
00:02:45.774 --> 00:02:47.620
4) and we redo all of that work.

44
00:02:47.620 --> 00:02:50.970
We remake all of those calls
down that part of the tree.

45
00:02:50.970 --> 00:02:52.530
And in fact, that's not the only place.

46
00:02:52.530 --> 00:02:54.440
Even in just this small little diagram,

47
00:02:54.440 --> 00:02:57.930
we also see all of these are being
repeated in a different part of the tree.

48
00:02:59.190 --> 00:03:02.802
So all of that work is unnecessary,
and there's the technique for

49
00:03:02.802 --> 00:03:07.660
remembering the work that we do, and
that technique is called memoization.

50
00:03:07.660 --> 00:03:09.250
Now I don't know exactly,

51
00:03:09.250 --> 00:03:13.410
I've read various different histories
of where this word comes from.

52
00:03:13.410 --> 00:03:17.100
It's a little bit of an unusually
sounding or spelled word.

53
00:03:17.100 --> 00:03:21.250
I don't know where it comes from, but
I will tell you how I remember it, okay?

54
00:03:21.250 --> 00:03:23.050
This is my little mnemonic or something.

55
00:03:23.050 --> 00:03:24.360
This is how I remember it.

56
00:03:24.360 --> 00:03:28.870
Because memoization is about remembering,
it's about memorizing things.

57
00:03:28.870 --> 00:03:32.650
So the way I remember it is it's like the
word memorization, but they forgot the r.

58
00:03:32.650 --> 00:03:36.901
I don't know, that just helps me a little,
maybe it's too early in the morning for

59
00:03:36.901 --> 00:03:40.183
those puns, but anyway,
that's how I remember memoization,

60
00:03:40.183 --> 00:03:42.670
memorization without the r.

61
00:03:42.670 --> 00:03:46.682
So, this might sound like this is
a somewhat more complex technique, but

62
00:03:46.682 --> 00:03:50.420
again, it will feel potentially
a little anticlimactic.

63
00:03:50.420 --> 00:03:52.940
In terms of how much
code we have to write,

64
00:03:52.940 --> 00:03:56.756
it's a very small amount of code
change to our current existing

65
00:03:56.756 --> 00:04:00.910
option two solution to retrofit
it to be able to be memoized.

66
00:04:00.910 --> 00:04:06.103
Now, I do wanna point out that
memoization is not the magic hammer,

67
00:04:06.103 --> 00:04:10.304
the Thor's hammer that can
just do anything, right?

68
00:04:10.304 --> 00:04:13.200
It's not what you wanna
bang every problem with.

69
00:04:13.200 --> 00:04:17.290
And so there are several caveats
that we wanna be aware of.

70
00:04:17.290 --> 00:04:20.182
When we implement this, it will feel
like this magical thing that we

71
00:04:20.182 --> 00:04:22.280
should just do all the time, everywhere.

72
00:04:22.280 --> 00:04:26.280
But do keep in mind that there are only
specific circumstances where we should

73
00:04:26.280 --> 00:04:28.300
employ this technique.

74
00:04:28.300 --> 00:04:32.020
Let's switch back over to our code editor.

75
00:04:32.020 --> 00:04:38.090
We're in dialer, and what we wanna do
is memoize the countPaths function.

76
00:04:38.090 --> 00:04:39.620
So what does that mean?

77
00:04:39.620 --> 00:04:44.979
What that means is that we
want to take that function and

78
00:04:44.979 --> 00:04:49.173
cause it to cache the result, the output,

79
00:04:49.173 --> 00:04:54.547
the return value from it,
for any unique set of input.

80
00:04:54.547 --> 00:04:59.791
In other words, take the pairing of
inputs, here we have two integer inputs,

81
00:04:59.791 --> 00:05:03.367
the starting digit in
the hopCount here on line 27,

82
00:05:03.367 --> 00:05:07.829
take these two inputs and
treat them as if they're a key in a cache.

83
00:05:07.829 --> 00:05:12.913
And then by keying against that hash,
if we ever call the same function with

84
00:05:12.913 --> 00:05:18.410
exactly the same inputs, return exactly
the same output without recomputing.

85
00:05:18.410 --> 00:05:23.401
Compute it the first time,
remember that value, and return it.

86
00:05:23.401 --> 00:05:28.024
So this is actually
a quite common technique.

87
00:05:28.024 --> 00:05:31.601
You see it much more commonly
in functional programming, but

88
00:05:31.601 --> 00:05:36.870
the principle here requires something that
may not be super obvious to you at first.

89
00:05:36.870 --> 00:05:39.900
It requires that this function
be what we call pure.

90
00:05:39.900 --> 00:05:42.187
Again, another term from
functional programming.

91
00:05:42.187 --> 00:05:47.621
So what we need to do is, essentially
adapt or wrap the countPaths function,

92
00:05:47.621 --> 00:05:53.241
we're gonna use a utility that we're
gonna define called memoized to do that.

93
00:05:53.241 --> 00:05:55.292
So I'm gonna go down here
to the bottom of the file,

94
00:05:55.292 --> 00:05:58.346
that's just where I want to put it,
you can put it wherever you'd like, but

95
00:05:58.346 --> 00:06:00.189
I'm gonna write a function called memoize.

96
00:06:02.820 --> 00:06:06.356
And it takes in the function that
we want to do this adapting to,

97
00:06:06.356 --> 00:06:08.640
which will be the countPaths function.

98
00:06:08.640 --> 00:06:11.470
We will pass the countPaths function in.

99
00:06:11.470 --> 00:06:13.960
It takes that in,
it needs to create a cache, remember.

100
00:06:13.960 --> 00:06:18.750
I said that we want a cache to
remember the outputs from it.

101
00:06:18.750 --> 00:06:22.840
So we'll just use a plain old
simple object for this cache.

102
00:06:22.840 --> 00:06:26.144
We'll talk about a variety of
little caveats that exist with

103
00:06:26.144 --> 00:06:27.705
generalized memoization.

104
00:06:27.705 --> 00:06:30.257
All right, so
we won't need to produce a new function.

105
00:06:30.257 --> 00:06:34.609
Remember, we're adapting, so we're gonna
create and return a new function which

106
00:06:34.609 --> 00:06:38.970
I'll just call memoized, you could
call it really whatever you wanted.

107
00:06:38.970 --> 00:06:43.450
The signature of the new function needs to
be the same as the original function, and

108
00:06:43.450 --> 00:06:46.202
we're gonna take advantage
of the fact that we know

109
00:06:46.202 --> 00:06:48.450
exactly what that signature is.

110
00:06:48.450 --> 00:06:52.170
In other words, we're gonna avoid
trying to do any sort of general,

111
00:06:52.170 --> 00:06:53.720
I can memoize any function.

112
00:06:53.720 --> 00:06:58.080
That's not our goal here, we only
wanna memoize this specific function.

113
00:06:58.080 --> 00:07:01.300
In fact we could have named it
memoized count path or something.

114
00:07:01.300 --> 00:07:06.285
We only wanna do the minimal
work that we know is necessary.

115
00:07:06.285 --> 00:07:10.199
If you were trying to write a general
utility for this, you would have to handle

116
00:07:10.199 --> 00:07:14.374
any kind of inputs of any data types, they
could be objects, they could be arrays.

117
00:07:14.374 --> 00:07:18.985
And constructing a key for
any arbitrary number of and

118
00:07:18.985 --> 00:07:23.950
type of value inputs can
get quite complicated.

119
00:07:23.950 --> 00:07:28.600
And that's why generally you would not
implement your own general memoization

120
00:07:28.600 --> 00:07:29.660
utility.

121
00:07:29.660 --> 00:07:33.389
But in specific cases where you know
I only need it for this function,

122
00:07:33.389 --> 00:07:37.508
I fully recommend and think it's actually
better performance for you to use

123
00:07:37.508 --> 00:07:42.080
a purpose-built memoization just for
that function or just for that purpose.

124
00:07:42.080 --> 00:07:44.060
So that's what we're going to do here.

125
00:07:44.060 --> 00:07:48.716
This is significantly more complicated
when you wanna do it in the general sense,

126
00:07:48.716 --> 00:07:52.964
and in those cases you should just use
a utility from a library like Lodash or

127
00:07:52.964 --> 00:07:54.735
Ramdo or something like that.

128
00:07:54.735 --> 00:07:57.489
They all provide these memoized utilities.

129
00:07:57.489 --> 00:08:03.485
So memoized needs to take in, I think
that I call them up here in countPaths,

130
00:08:03.485 --> 00:08:07.340
what did I call them,
startingDigit hopCount.

131
00:08:07.340 --> 00:08:11.113
I'm gonna shorten that,
I'm just gonna call it start and length,

132
00:08:11.113 --> 00:08:14.570
but they're both gonna be integers
that are being passed in.

133
00:08:14.570 --> 00:08:15.680
So it's the same signature.

134
00:08:17.810 --> 00:08:22.656
And the fundamental job of a memoized
function is to check to make

135
00:08:22.656 --> 00:08:27.143
sure that the thing we're asking for,
that is the inputs,

136
00:08:27.143 --> 00:08:33.020
that those have not been seen before,
that they're not in the cache.

137
00:08:33.020 --> 00:08:35.675
If they're not in the cache,
we need to do the underlying work.

138
00:08:35.675 --> 00:08:43.281
So we're gonna just say if the cache
does not have, and we need a key.

139
00:08:43.281 --> 00:08:47.603
And this is kind of stylistic choice here,
but I'm just gonna take the two

140
00:08:47.603 --> 00:08:52.580
integers and concatenate them into
a string with a colon between them.

141
00:08:52.580 --> 00:08:53.710
You could do anything, right?

142
00:08:53.710 --> 00:08:57.819
Well, you wouldn't wanna do math on
the numbers unless you came up with

143
00:08:57.819 --> 00:09:00.628
a mathematic equation,
like exponentiation,

144
00:09:00.628 --> 00:09:02.780
that gave you a unique number.

145
00:09:02.780 --> 00:09:07.582
You do want these keys to be unique, but
it really doesn't actually matter how

146
00:09:07.582 --> 00:09:12.550
you choose this key, as long as you make
sure each input set is going to be unique.

147
00:09:12.550 --> 00:09:15.282
You don't want any collisions where
you're accidentally overwriting or

148
00:09:15.282 --> 00:09:17.100
returning the wrong value.

149
00:09:17.100 --> 00:09:21.726
Okay, so we're gonna take the start and
then a colon and

150
00:09:21.726 --> 00:09:28.950
then the length, Into that if statement.

151
00:09:28.950 --> 00:09:32.000
And we will actually do the work.

152
00:09:32.000 --> 00:09:36.500
So we'll set it, actually I'm just gonna
copy this cuz I don't wanna retype it.

153
00:09:38.260 --> 00:09:43.981
We're actually gonna set
that value into the cache

154
00:09:43.981 --> 00:09:49.981
by calling the function,
and then simply return it.

155
00:09:49.981 --> 00:09:54.932
Now, to adapt our countPaths function with
memoize, which is a fairly straightforward

156
00:09:54.932 --> 00:09:59.222
task, there's a couple of different
ways that you might choose to do it, and

157
00:09:59.222 --> 00:10:02.538
some people kinda bristle a little
bit of how I like to do it.

158
00:10:02.538 --> 00:10:06.365
But I literally just like to overwrite
the countPaths function with its memoized

159
00:10:06.365 --> 00:10:09.064
version, because there's no
case where I ever want both

160
00:10:09.064 --> 00:10:11.600
versions in my program at the same time.

161
00:10:11.600 --> 00:10:14.970
So I will just take countPaths and
reassign it.

162
00:10:14.970 --> 00:10:17.420
And we can do that because it
was a function declaration.

163
00:10:17.420 --> 00:10:20.394
You can't do that if you assign
with const or something.

164
00:10:20.394 --> 00:10:25.909
I will just reassign the result
of passing it into memoize.

165
00:10:31.939 --> 00:10:34.670
And that's it for
the code changes that we made.

166
00:10:34.670 --> 00:10:38.620
I promised you that it was a bit
anticlimactic to make the code changes.

167
00:10:38.620 --> 00:10:40.121
That's it for the code changes.

168
00:10:47.066 --> 00:10:52.435
If we go back to our slides, what we
can see then is that the things that

169
00:10:52.435 --> 00:10:58.469
we were eliminating, those are just
calls that don't even need to get made.

170
00:10:59.490 --> 00:11:03.299
And the bigger and bigger the tree it is,
the less and less of the tree actually

171
00:11:03.299 --> 00:11:07.160
even exists because we just skip
the call and pull it out from the cache.

172
00:11:07.160 --> 00:11:11.302
So conceptually, you should be able to
infer from this that it's gonna create

173
00:11:11.302 --> 00:11:13.970
quite a significant amount of savings.

174
00:11:13.970 --> 00:11:18.103
But I think it's gonna surprise you
just how much the savings is when we run

175
00:11:18.103 --> 00:11:18.720
the code.

176
00:11:18.720 --> 00:11:22.750
And that's where memoization sometimes
starts to feel kinda magical.

177
00:11:22.750 --> 00:11:26.320
So let's switch over to the web page.

178
00:11:26.320 --> 00:11:31.442
You might recall from before that
we were starting from digit 4 and

179
00:11:31.442 --> 00:11:35.655
we were doing things around
the 20 to 25 hop count.

180
00:11:35.655 --> 00:11:38.100
And we were starting to see that
it really started to add up.

181
00:11:38.100 --> 00:11:39.760
So I'm gonna redo that.

182
00:11:39.760 --> 00:11:44.870
And you can kind of remember the timings
that we had before and compare.

183
00:11:44.870 --> 00:11:50.004
So we're gonna do 20 hop count from 4,
and it was 1 millisecond.

184
00:11:50.004 --> 00:11:55.020
And then we're gonna go up to 21,
and it was 0.3 milliseconds.

185
00:11:55.020 --> 00:12:00.453
And then we're gonna go up to 22,
and it's getting even shorter and

186
00:12:00.453 --> 00:12:05.900
shorter because it's remembering
all of that work that it's doing.

187
00:12:05.900 --> 00:12:10.466
And each time we add a new hop count,
there's only a couple of extra functions

188
00:12:10.466 --> 00:12:15.080
that need to be called and
all the rest of that is now in our cache.

189
00:12:15.080 --> 00:12:19.809
So I could go up to huge, huge
numbers that would have taken hours or

190
00:12:19.809 --> 00:12:25.560
days to compute in the previous one, and
they run in fractions of a millisecond.

191
00:12:26.700 --> 00:12:29.880
In fact, I've run this up
with very large numbers, and

192
00:12:29.880 --> 00:12:32.830
I'm sure some of you
are starting to do this.

193
00:12:32.830 --> 00:12:35.362
That 500 number,
which is a number that's so

194
00:12:35.362 --> 00:12:38.330
big that it's overflowing
JavaScript's number time,

195
00:12:38.330 --> 00:12:42.620
it still only took 6.3 milliseconds
to do all of those function calls.

196
00:12:42.620 --> 00:12:45.680
Because most of that work
didn't need to be done.

197
00:12:45.680 --> 00:12:48.760
We were just sort of naively
redoing the work over and over.

198
00:12:48.760 --> 00:12:53.645
And by analyzing, I'm doing this
recursion in a lot of backtracking and

199
00:12:53.645 --> 00:12:58.170
a lot of revisiting of the same kinds
of work, that's what clues us in.

200
00:12:58.170 --> 00:13:03.250
Hey, maybe I ought to memoize this utility
and significantly improve the outcome.

201
00:13:04.970 --> 00:13:07.470
So you might think, well,
okay, then we're done, right?

202
00:13:07.470 --> 00:13:11.285
If I've memoized my recursion,
I should just memoize everything, and

203
00:13:11.285 --> 00:13:14.910
I don't need to worry about
all of my performance issues?

204
00:13:14.910 --> 00:13:19.141
We need to be very careful about some
of the caveats around memoization.

205
00:13:19.141 --> 00:13:25.820
The first big caveat is that, yes, we
are indeed saving a whole bunch of calls.

206
00:13:25.820 --> 00:13:30.572
But if we were to be doing some memory
profiling, anybody care to guess how many

207
00:13:30.572 --> 00:13:34.610
thousands or millions of entries
are cached in our house?

208
00:13:34.610 --> 00:13:39.504
Because think about all of the unique
different combinations of starting digit

209
00:13:39.504 --> 00:13:42.600
and hop count that we've put into there.

210
00:13:42.600 --> 00:13:46.053
It's gonna be a really,
really large number, and so

211
00:13:46.053 --> 00:13:51.480
what we are doing is we're trading the
memory usage to get a faster performance.

212
00:13:51.480 --> 00:13:55.510
And that's one of the classic trade
offs that we sometimes have to make.

213
00:13:55.510 --> 00:13:58.379
We sometimes say I need it to run faster,
so

214
00:13:58.379 --> 00:14:01.662
I'm just gonna have to
give up some more memory.

