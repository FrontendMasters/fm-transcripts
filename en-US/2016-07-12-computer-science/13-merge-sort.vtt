WEBVTT

1
00:00:00.037 --> 00:00:04.035
[MUSIC]

2
00:00:04.035 --> 00:00:07.158
&gt;&gt; Brian: So
we are returning to recursion land now.

3
00:00:07.158 --> 00:00:10.596
We're going to do our
very first divide and

4
00:00:10.596 --> 00:00:13.950
conquer algorithm which is a merge sort.

5
00:00:15.250 --> 00:00:19.600
Now, insertion sort has been occasionally
useful, bubble sort is never useful,

6
00:00:19.600 --> 00:00:24.060
merge sort is most often the one
that you're probably going to use.

7
00:00:24.060 --> 00:00:28.510
So if you're doing like array.sort,
90% of the time,

8
00:00:28.510 --> 00:00:31.616
it's going to use merge sort
underneath the hood, right?

9
00:00:31.616 --> 00:00:36.690
I say 90% because occasionally I believe
it's Firefox's JavaScript engine

10
00:00:36.690 --> 00:00:40.730
will use quick sort
depending on the data type.

11
00:00:40.730 --> 00:00:43.380
But for the most part,
you can use a merge sort and

12
00:00:43.380 --> 00:00:47.590
the recently merged sort is mostly
used is it's very consistent.

13
00:00:48.910 --> 00:00:51.400
It's very dependable what
you can to get out of it.

14
00:00:51.400 --> 00:00:52.320
Yeah, a question.

15
00:00:52.320 --> 00:00:54.770
&gt;&gt; Speaker 2: One question
about the previous exercise.

16
00:00:54.770 --> 00:00:58.660
If you, from Drew, if you insert,
doesn't it throw off the index?

17
00:00:59.830 --> 00:01:03.490
&gt;&gt; Brian: If you insert,
does it throw off the index?

18
00:01:03.490 --> 00:01:07.290
Yeah, it will, in fact, you can
probably break out of it at that point.

19
00:01:07.290 --> 00:01:09.976
So again, we're not doing
the micro-optimization at this point.

20
00:01:14.115 --> 00:01:16.612
&gt;&gt; Brian: Yeah, I guess you could
get some potential issues with that,

21
00:01:16.612 --> 00:01:19.685
it is throwing off the index and you could
break out of the loop to kind of short

22
00:01:19.685 --> 00:01:21.532
circuit going through
the rest of the array.

23
00:01:21.532 --> 00:01:26.787
So, it does throw off the index but at the
same time you're taking something out and

24
00:01:26.787 --> 00:01:31.610
putting it back in so, it's just
expanding the length of your sorted list.

25
00:01:31.610 --> 00:01:35.100
So, actually, would never be a problem

26
00:01:35.100 --> 00:01:38.780
because you would push out your
largest element in that array and

27
00:01:38.780 --> 00:01:41.900
it would never be smaller than anything
in the smaller part of the array.

28
00:01:41.900 --> 00:01:45.569
So, that actually ends up not
being a problem, fortunately.

29
00:01:45.569 --> 00:01:48.520
[LAUGH] It could be a problem.

30
00:01:49.810 --> 00:01:50.510
Good question, Drew.

31
00:01:50.510 --> 00:01:53.608
I like where you're head's at,
critical thinking.

32
00:01:53.608 --> 00:01:58.160
Okay, merge sort.

33
00:01:58.160 --> 00:02:02.150
Divide and conquer, meaning it's gonna use
recursion, and when you hear recursion,

34
00:02:02.150 --> 00:02:05.900
I hope you're thinking it's gonna be
log end something, log ends going to be

35
00:02:05.900 --> 00:02:10.980
throwing something into the big o,
which you would be correct.

36
00:02:10.980 --> 00:02:11.770
It's very useful.

37
00:02:11.770 --> 00:02:12.700
It's used a lot of places.

38
00:02:12.700 --> 00:02:14.740
It's a stable sort.

39
00:02:14.740 --> 00:02:19.120
We'll talk about stable sorting here
in a bit, and it's super consistent,

40
00:02:19.120 --> 00:02:21.090
whether it's sorted, unsorted, everything.

41
00:02:21.090 --> 00:02:24.340
It's all treated the same way,
it all goes pretty much the same speed.

42
00:02:26.500 --> 00:02:29.740
And dependability, even if it's dependably
a tiny bit slower, it's usually

43
00:02:29.740 --> 00:02:33.140
a good thing in computer science, because
then you have a very known quantity.

44
00:02:34.890 --> 00:02:37.891
So again,
if you having problem with recursion,

45
00:02:37.891 --> 00:02:41.830
like this gets a little bit tricky
because the ceases recursion.

46
00:02:43.680 --> 00:02:48.180
Okay, so the basic gist of merge
sort is you take a big list and

47
00:02:48.180 --> 00:02:49.890
you break it into two smaller lists,
right?

48
00:02:49.890 --> 00:02:51.860
And then you're gonna take
one of these lists and

49
00:02:51.860 --> 00:02:55.160
you're gonna break it into two smaller
lists and you're gonna break it into,

50
00:02:55.160 --> 00:02:59.430
basically, until you're
down to lists of one.

51
00:02:59.430 --> 00:03:02.600
At which point, you can no longer
break it down any further and

52
00:03:02.600 --> 00:03:05.840
as we've talked about before
a list of one is already sorted.

53
00:03:05.840 --> 00:03:08.010
So that's our base case.

54
00:03:08.010 --> 00:03:10.720
Our base case is we arrive
at a list of one and

55
00:03:10.720 --> 00:03:15.920
then we're just going to return
that sorted list of one and

56
00:03:15.920 --> 00:03:19.830
then, as we come back up, we're going
to have a list of one in a list of one.

57
00:03:19.830 --> 00:03:23.180
And we're going to kind of stitch
those together in a sorted way and

58
00:03:23.180 --> 00:03:25.122
then we're going to
return that sorted list.

59
00:03:25.122 --> 00:03:28.340
So now, we have a list of two and
a list of, maybe, two or one or

60
00:03:28.340 --> 00:03:33.022
something like that, and we're going
to stitch those together in a merge.

61
00:03:33.022 --> 00:03:35.640
We call it merge, you can call it stitch.

62
00:03:35.640 --> 00:03:36.660
You can call whatever you want.

63
00:03:36.660 --> 00:03:40.090
I called stitch just to make sure that you
get the difference that merge sort and

64
00:03:40.090 --> 00:03:41.890
merge are different.

65
00:03:41.890 --> 00:03:43.870
So I'm going to call it merge,
sort, and stitch.

66
00:03:43.870 --> 00:03:45.160
But you'll see a lot people call it merge.

67
00:03:46.500 --> 00:03:51.030
And I'll talk about that stitching
algorithm soon as I scroll down.

68
00:03:51.030 --> 00:03:51.910
Exactly after I scroll down.

69
00:03:53.460 --> 00:03:56.950
So you can do this in the same function.

70
00:03:56.950 --> 00:04:00.630
I recommend you split it out into merge,
sort, and stitch or

71
00:04:00.630 --> 00:04:01.330
merge, sort, and merge.

72
00:04:01.330 --> 00:04:02.770
Whatever you want to call it, that's fine.

73
00:04:03.850 --> 00:04:10.010
But the basic gist is you have, let's look
at this particular example right here.

74
00:04:12.160 --> 00:04:16.410
So you have, let's say that you're
somewhere in the middle of your merge sort

75
00:04:16.410 --> 00:04:22.194
and you have two sort of list that
come back to 1, 5, 6 and 2, 7, 8.

76
00:04:22.194 --> 00:04:26.630
One thing, because you know you're going
to write an algorithm that's going to be

77
00:04:26.630 --> 00:04:28.750
turned sorted list to, you can, therefore,

78
00:04:28.750 --> 00:04:32.190
always assume that you're going
to get a sorted list back.

79
00:04:32.190 --> 00:04:36.780
So this algorithm, the stitch algorithm
can assume that it has two sort of list.

80
00:04:36.780 --> 00:04:39.810
Meaning, you don't have to provide for
the cases of words unsorted right.

81
00:04:39.810 --> 00:04:43.950
Cuz if it gets to unsorted, that means
something else is broken somewhere else.

82
00:04:43.950 --> 00:04:47.750
And we talked about this earlier that
these algorithms are about making

83
00:04:47.750 --> 00:04:48.500
assumptions.

84
00:04:48.500 --> 00:04:50.760
As soon as we can make assumptions,
we can do powerful things.

85
00:04:52.540 --> 00:04:56.100
So, because these two, I know,
I'm positive, by the time it gets here,

86
00:04:56.100 --> 00:04:58.880
it has to be sorted, I can treat
them like they're gonna be sorted.

87
00:05:00.040 --> 00:05:04.270
Meaning, I can use this algorithm that
says that's only going to compare the top

88
00:05:04.270 --> 00:05:05.200
two things.

89
00:05:05.200 --> 00:05:09.764
So when you're first starting out,
only zero elements get compared.

90
00:05:09.764 --> 00:05:14.855
So one and two, I'm gonna compare one and
two and then I'm gonna say one is

91
00:05:14.855 --> 00:05:20.050
smaller sum, that's going to be the zero
element for sure in the new list.

92
00:05:20.050 --> 00:05:22.900
So we're going to be
creating a new list and

93
00:05:23.910 --> 00:05:26.950
we're going to be inserting
these in a sorted way.

94
00:05:26.950 --> 00:05:29.220
So I'm going to take one and
put it in the new list.

95
00:05:29.220 --> 00:05:32.570
So now I'm comparing two and five.

96
00:05:32.570 --> 00:05:35.750
I'm going to take 2,
because 2's the smaller one.

97
00:05:35.750 --> 00:05:38.500
So now I'm gonna be comparing 5 and 7.

98
00:05:39.520 --> 00:05:43.720
I'm gonna take 5, cuz that's smaller and
put it in the new list, okay?

99
00:05:43.720 --> 00:05:49.020
Compare 6 and 7, 6 is smaller so I'm gonna
take that and put it into the new list.

100
00:05:49.020 --> 00:05:51.230
And now I've reached the end of this list.

101
00:05:51.230 --> 00:05:54.910
There's nothing left in that top list,
sublist 1.

102
00:05:54.910 --> 00:05:59.660
So I can just assume, I can assume that I
can add everything from the second list,

103
00:05:59.660 --> 00:06:00.900
just in order.

104
00:06:00.900 --> 00:06:03.696
So, list one has no more elements so

105
00:06:03.696 --> 00:06:07.310
I just go ahead and add everything
from the second list on to there.

106
00:06:09.360 --> 00:06:10.247
Does that make sense?

107
00:06:10.247 --> 00:06:12.840
That's just the stitching
part of the algorithm.

108
00:06:12.840 --> 00:06:15.590
The merge sort part of
the algorithm is just breaking

109
00:06:15.590 --> 00:06:17.140
a big list into smaller list.

110
00:06:18.710 --> 00:06:19.960
That's it, that's pretty much all it does.

111
00:06:19.960 --> 00:06:23.620
It takes a big list based on the smaller
list, calls merge sort on those and

112
00:06:23.620 --> 00:06:28.250
then it just says, okay,
put list one and list two together.

113
00:06:28.250 --> 00:06:31.124
And hat's pretty much it.

114
00:06:31.124 --> 00:06:35.025
It's stable?

115
00:06:35.025 --> 00:06:38.680
So you have two elements
that are equivalent.

116
00:06:38.680 --> 00:06:40.360
In this particular case,
we're sorting numbers but

117
00:06:40.360 --> 00:06:42.570
you're not always sorting numbers.

118
00:06:42.570 --> 00:06:46.630
Say, you could be sorting,
I don't know, people by last names.

119
00:06:46.630 --> 00:06:49.920
Well, some people have the same last name.

120
00:06:49.920 --> 00:06:54.270
But say you want to keep them in
order that they were given to you in.

121
00:06:54.270 --> 00:07:00.370
So if I give you Holt, Brian and
then I give you Holt, Nicky.

122
00:07:00.370 --> 00:07:02.968
Let's say I wanna keep
both of those in order,

123
00:07:02.968 --> 00:07:07.250
so you don't want your algorithm to
return to Holt, Nicky or Holt, Brian.

124
00:07:07.250 --> 00:07:10.990
You wanted to keep Holt, Brian, Holt,
Nicky, so that would be a stable sort and

125
00:07:10.990 --> 00:07:13.120
some sorting algorithms like Quicksort,

126
00:07:13.120 --> 00:07:16.390
which we'll look at here in a second,
is not stable.

127
00:07:16.390 --> 00:07:19.808
If they're considered equivalent,
then they're gonna be jumbled and

128
00:07:19.808 --> 00:07:22.283
you don't know how they're
gonna come back to you.

129
00:07:25.266 --> 00:07:28.482
&gt;&gt; Brian: Now, you could argue, well,
I want to be sorting my first name and

130
00:07:28.482 --> 00:07:29.062
last name.

131
00:07:29.062 --> 00:07:31.910
Well, you just have to make your
sorting algorithm care about that.

132
00:07:31.910 --> 00:07:34.660
I'm saying, in the case that you're
only sorting by the last name,

133
00:07:34.660 --> 00:07:37.110
just FYI if that wasn't clear.

134
00:07:37.110 --> 00:07:41.660
Okay, so merge sort is stable,

135
00:07:41.660 --> 00:07:45.450
which is another reason that the merge
sort gets favored a lot of times is

136
00:07:45.450 --> 00:07:48.970
because stability is sometimes important,
it's sometimes not right.

137
00:07:48.970 --> 00:07:50.640
Sometimes you don't actually care.

138
00:07:50.640 --> 00:07:54.350
Like, if one four comes back and
in front of the other, you don't know nor

139
00:07:54.350 --> 00:07:54.990
care, right?

140
00:07:54.990 --> 00:07:55.860
A 4 is a 4 is a 4.

141
00:07:55.860 --> 00:08:01.110
So, in the case of sorting numbers,
stable sort makes no difference.

142
00:08:02.110 --> 00:08:03.630
So again, tradeoffs.

143
00:08:03.630 --> 00:08:08.220
Algorithms are all about tradeoffs,
and so stability is another thing you

144
00:08:08.220 --> 00:08:09.970
might wanna keep in mind when
you're picking an algorithm.

145
00:08:11.530 --> 00:08:13.560
Okay, what is big O?

146
00:08:13.560 --> 00:08:14.950
Well, it's n log n.

147
00:08:14.950 --> 00:08:18.030
So we have to go over thing
at everything at least once.

148
00:08:18.030 --> 00:08:19.830
In other words,
when you're doing a sorting algorithm,

149
00:08:19.830 --> 00:08:21.630
you have to look at every
element at least once.

150
00:08:21.630 --> 00:08:24.390
That's just a given, you can't sort things
you don't actually know what they are.

151
00:08:24.390 --> 00:08:26.460
So you have to look at
everything at least once, and

152
00:08:26.460 --> 00:08:28.660
that's why everything is
gonna have at least n.

153
00:08:28.660 --> 00:08:30.530
There is no sorting
algorithm faster than n.

154
00:08:30.530 --> 00:08:33.135
I promise, if you find it,
you can make billions of dollars.

155
00:08:33.135 --> 00:08:36.330
It'll be like Silicon Valley.

156
00:08:36.330 --> 00:08:40.620
You'll do the middle outsourting or
something like that.

157
00:08:40.620 --> 00:08:42.060
Okay, so then log in.

158
00:08:42.060 --> 00:08:45.590
So a lot of these other
arrays take everything and

159
00:08:45.590 --> 00:08:47.010
compare everything to everything, right?

160
00:08:47.010 --> 00:08:48.700
And that's why you get n squared,

161
00:08:48.700 --> 00:08:51.200
because everything has to be
compared against everything else.

162
00:08:52.370 --> 00:08:55.470
Because we're breaking lists
down into smaller lists,

163
00:08:55.470 --> 00:08:57.720
not everything has to be
compared to everything.

164
00:08:57.720 --> 00:09:03.340
That's why that stitching algorithms,
because it's making assumptions that it's

165
00:09:03.340 --> 00:09:07.510
getting sorted lists, it can be slightly
better than n, which is why we get log n.

166
00:09:11.030 --> 00:09:14.900
Spacial complexity is n, meaning, we're
creating arrays and destroying arrays,

167
00:09:14.900 --> 00:09:19.440
which means we're getting a little
bit less efficiency with memory which

168
00:09:19.440 --> 00:09:20.720
sometimes you care, sometimes you don't.

169
00:09:20.720 --> 00:09:23.690
For the most part, when you're in
a browser and they have 8 gigs of RAM,

170
00:09:23.690 --> 00:09:25.200
you don't really care.

171
00:09:25.200 --> 00:09:27.399
So we don't care.

