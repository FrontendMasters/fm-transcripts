WEBVTT

1
00:00:01.910 --> 00:00:10.204
So let's make a new file
called clustering.spec.ts,

2
00:00:10.204 --> 00:00:19.953
describe clustering, Okay.

3
00:00:24.930 --> 00:00:33.633
My cluster should load data.

4
00:00:33.633 --> 00:00:37.763
So one of the very simple tests
we can do is just say, hey,

5
00:00:37.763 --> 00:00:40.037
are we even having a data here?

6
00:00:40.037 --> 00:00:47.425
Dataset, dataset,

7
00:00:55.879 --> 00:01:00.509
No, I expect this to be imported, Sorry.

8
00:01:00.509 --> 00:01:09.720
Expecting it to come from here,
To match snapshot,

9
00:01:13.739 --> 00:01:19.379
Okay, so we can create a simple test
to just see if the data is matching.

10
00:01:19.379 --> 00:01:21.223
So, this test is again, not very useful,

11
00:01:21.223 --> 00:01:24.457
because we're just asserting
that the data hasn't changed.

12
00:01:24.457 --> 00:01:28.463
But I usually like to create a simple test
just to kind of get the harness working

13
00:01:28.463 --> 00:01:30.907
and proving to myself
that things are working.

14
00:01:30.907 --> 00:01:33.807
So, where is it?

15
00:01:36.187 --> 00:01:41.060
Running the test,
Why is our test not showing up?

16
00:01:42.472 --> 00:01:43.790
It is showing up, okay, great.

17
00:01:43.790 --> 00:01:46.340
So it's showing up now,
we create a snapshot.

18
00:01:46.340 --> 00:01:48.284
This doesn't really do anything,

19
00:01:48.284 --> 00:01:51.340
it just proves that the data
hasn't changed over time.

20
00:01:52.510 --> 00:01:56.021
Okay, but let's make a useful test,

21
00:01:56.021 --> 00:02:01.668
it should create a cluster, Now,

22
00:02:07.208 --> 00:02:10.758
You might be tempted to do something
like this, let's see, data set,

23
00:02:19.748 --> 00:02:22.016
You might be tempted to do
something like that, but

24
00:02:22.016 --> 00:02:24.446
a couple of problems with this approach.

25
00:02:24.446 --> 00:02:30.236
First of all, as you can see,
this is slow, because data set is huge.

26
00:02:30.236 --> 00:02:33.805
So a matter of fact,
I think the data set is so

27
00:02:33.805 --> 00:02:38.836
large that we have to slice
this which is the 100 I see.

28
00:02:38.836 --> 00:02:40.286
So you have to do 0,100.

29
00:02:42.302 --> 00:02:48.992
Sorry, let's try this again, Okay,

30
00:02:48.992 --> 00:02:53.552
so it ran, it asserted something.

31
00:02:53.552 --> 00:02:55.152
But the first problem is it's slow.

32
00:02:55.152 --> 00:03:01.176
And the second problem is,
is this the correct answer?

33
00:03:01.176 --> 00:03:06.036
I don't know, right,
if things go wrong, how would you know?

34
00:03:06.036 --> 00:03:09.222
Like yeah, you would know that things have
changed, something that [INAUDIBLE] But

35
00:03:09.222 --> 00:03:11.466
would you actually know if this
is a correct answer or not?

36
00:03:12.846 --> 00:03:17.182
And so, one of the things to kinda point
out is that when you write your tests,

37
00:03:17.182 --> 00:03:20.252
typically you don't wanna
test it on large data sets or

38
00:03:20.252 --> 00:03:24.348
on the actual datasets because you
wanna have it something very simple.

39
00:03:26.298 --> 00:03:30.568
So let's do something very simple,
let's create our own datasets in here.

40
00:03:30.568 --> 00:03:31.548
So what is a dataset?

41
00:03:31.548 --> 00:03:34.368
Well, the dataset is just
something like this, right?

42
00:03:34.368 --> 00:03:41.404
So now if you look at this, let's make
this easier here, let's do 10, 11, right?

43
00:03:41.404 --> 00:03:44.716
And now we just have four points.

44
00:03:44.716 --> 00:03:49.656
And when we do clustering, I think
one of the arguments is the distance.

45
00:03:49.656 --> 00:03:53.861
So in this case, we would say
if a point is within five units,

46
00:03:53.861 --> 00:03:57.516
then we would expect that
to be the same thing.

47
00:03:57.516 --> 00:04:00.010
So if you look at it 00 will
be in the corner, right?

48
00:04:00.010 --> 00:04:03.640
01 would be less than five
units away from the first one.

49
00:04:03.640 --> 00:04:06.100
So the first two should be a cluster,
right?

50
00:04:06.100 --> 00:04:11.480
10, 10 and 11, 11 they should also be
within the cluster of each other, right?

51
00:04:13.040 --> 00:04:16.720
So what we should expect to
see is two clusters in here.

52
00:04:16.720 --> 00:04:21.260
So one thing we can do is we can focus
the test this is always useful to do only.

53
00:04:21.260 --> 00:04:23.150
So we're running the test by itself.

54
00:04:23.150 --> 00:04:25.250
So now we have a snapshot.

55
00:04:25.250 --> 00:04:31.590
Now, I think that snapshotting is
really not the best way to do this.

56
00:04:31.590 --> 00:04:36.450
So I actually would prefer to just copy
this and put it in the test directly.

57
00:04:38.320 --> 00:04:39.450
So you do this.

58
00:04:42.074 --> 00:04:46.012
And basically instead of saying expect,

59
00:04:46.012 --> 00:04:53.744
you say to equal, Okay?

60
00:04:54.954 --> 00:04:57.201
And can we format this a little better?

61
00:04:57.201 --> 00:05:01.993
I think this is kind of easier to read and
it is basically doing what we expected,

62
00:05:01.993 --> 00:05:02.503
right?

63
00:05:02.503 --> 00:05:04.870
We expect to be passed in four things and

64
00:05:04.870 --> 00:05:09.433
we're seeing the distance to be
considered the same cluster as five.

65
00:05:09.433 --> 00:05:13.563
So 0, 0 and 10, 10 is clearly
more than five units apart and so

66
00:05:13.563 --> 00:05:17.123
we got a cluster one,
which contains 0 and 0 1, right?

67
00:05:17.123 --> 00:05:21.438
The first two points we get the minimum
and maximum for these values and

68
00:05:21.438 --> 00:05:26.194
we get the second cluster which also
gets its minimum maximum for the values,

69
00:05:26.194 --> 00:05:30.244
etcetera and then we get the minimum
maximum for the whole thing.

70
00:05:32.194 --> 00:05:36.446
And so the thing I wanna point out is
that when you're writing a unit test,

71
00:05:36.446 --> 00:05:39.204
you really want to have
super simple data sets.

72
00:05:39.204 --> 00:05:42.568
You don't wanna go on the big data
sets because you just can't really

73
00:05:42.568 --> 00:05:45.244
assert anything useful about them, right?

74
00:05:45.244 --> 00:05:49.986
And so here we could then maybe create
other unit tests that would create smaller

75
00:05:49.986 --> 00:05:52.334
things or something of that sort.

76
00:05:52.334 --> 00:05:54.774
By the way,
you can also create your own matchers.

77
00:05:54.774 --> 00:05:58.471
So if you get tired of copying this
particular thing, because this is pretty

78
00:05:58.471 --> 00:06:02.670
long, maybe you can have a matcher
that does something simpler for you.

79
00:06:02.670 --> 00:06:04.880
Also, we don't need to copy everything.

80
00:06:04.880 --> 00:06:08.813
So for example,
let's say we don't care about the min and

81
00:06:08.813 --> 00:06:14.330
the max like this to make the test
easier to read, we can just delete them.

82
00:06:14.330 --> 00:06:17.440
And of course, it's gonna complain
that we have missing things.

83
00:06:17.440 --> 00:06:22.660
And so there is another function called

84
00:06:22.660 --> 00:06:26.938
toMatchObject, I think it is.

85
00:06:29.058 --> 00:06:29.748
Right.

86
00:06:29.748 --> 00:06:33.718
So toMatchObject says it has
to have these properties.

87
00:06:33.718 --> 00:06:37.548
It may have other things, but
it has to have these ones, right?

88
00:06:37.548 --> 00:06:41.675
And so in this way, you can kind of
simplify it because you can tell

89
00:06:41.675 --> 00:06:45.917
the developer, look,
these are the important bits, right?

90
00:06:45.917 --> 00:06:49.399
The important bits is that we ended up
with two clusters, the first cluster has

91
00:06:49.399 --> 00:06:53.547
these two items inside of it, the second
cluster has those two items inside of it.

92
00:06:53.547 --> 00:06:57.837
And we have this particular output
in terms of min and max values.

93
00:06:57.837 --> 00:07:02.825
So that when the algorithm that actually
paints the stuff knows where to paint it.

94
00:07:02.825 --> 00:07:05.620
Yes.
&gt;&gt; So here does it make sense to also mark

95
00:07:05.620 --> 00:07:10.305
the DBSCAN algorithm or
is not because it's what we want to test?

96
00:07:10.305 --> 00:07:11.179
&gt;&gt; Does it make sense for the-

97
00:07:11.179 --> 00:07:12.095
&gt;&gt; [CROSSTALK]
&gt;&gt; To mark it,

98
00:07:12.095 --> 00:07:12.905
&gt;&gt; To mark it, okay,

99
00:07:12.905 --> 00:07:13.705
&gt;&gt; To mark Dbscan.

100
00:07:13.705 --> 00:07:18.617
&gt;&gt; No, so I think in this case you don't
wanna mark it because you specifically

101
00:07:18.617 --> 00:07:21.689
wanna make sure that
the interaction between,

102
00:07:21.689 --> 00:07:25.527
the code that prepares the data for
DBSCAN and the DBSCAN and

103
00:07:25.527 --> 00:07:30.650
what comes out of it and how you
prepare it out, actually works, right?

104
00:07:30.650 --> 00:07:36.330
So here's kind of the problem, we say unit
test, because we consider this a unit but

105
00:07:36.330 --> 00:07:40.260
you can always argue that
that's just a different layer.

106
00:07:40.260 --> 00:07:43.572
If you just go a little lower, like
it's an integration between a DBSCAN and

107
00:07:43.572 --> 00:07:44.865
whatever, right?

108
00:07:44.865 --> 00:07:50.205
So these are kind of just words that
we use very loosely with it, right?

109
00:07:50.205 --> 00:07:54.175
And it's kind of what makes sense
to you as a developer, right?

110
00:07:54.175 --> 00:07:59.912
And so the reason I wouldn't mark
a DBSCAN is, first of all, it's fast.

111
00:08:01.213 --> 00:08:05.433
Nothing behaves more true to
itself than a thing itself, right?

112
00:08:05.433 --> 00:08:08.043
So if you don't have to mark it,
you don't.

113
00:08:08.043 --> 00:08:12.233
The reason we marked fetch is because
fetch is not trustworthy, right?

114
00:08:12.233 --> 00:08:16.163
It's an external system, it takes time,
the system can change the output,

115
00:08:16.163 --> 00:08:18.193
it isn't trustworthy, right?

116
00:08:18.193 --> 00:08:22.959
Whereas the algorithm that we happen to
use called DBSCAN, that actually works.

117
00:08:24.209 --> 00:08:27.966
And so now we can go back to
clustering and for example,

118
00:08:27.966 --> 00:08:31.481
there are other algorithms
that you could select,

119
00:08:31.481 --> 00:08:35.779
I think if I remember correctly,
Is it from here?

120
00:08:37.899 --> 00:08:42.172
Right, you can do KMEANS/ghich I I
believe has this, no, let's do optics.

121
00:08:43.222 --> 00:08:45.412
So this is a different
algorithm that you can replace.

122
00:08:46.682 --> 00:08:48.882
And you still see that it
clustered the same way.

123
00:08:48.882 --> 00:08:50.274
So in this particular case,

124
00:08:50.274 --> 00:08:53.062
these two algorithms didn't
have any material impact.

125
00:08:53.062 --> 00:08:56.688
And we could maybe come up with
a corner case for the data points

126
00:08:56.688 --> 00:09:01.295
where there would be a material impact
between the two things in there.

127
00:09:01.295 --> 00:09:06.385
I'm just gonna put it back,
&gt;&gt; I feel like when you're

128
00:09:06.385 --> 00:09:13.445
working with legacy code, then something
like the snapshot could be really useful.

129
00:09:13.445 --> 00:09:13.955
&gt;&gt; Yes.

130
00:09:13.955 --> 00:09:17.065
&gt;&gt; Where are you actually just want to
make sure it doesn't change at all.

131
00:09:17.065 --> 00:09:18.265
&gt;&gt; Correct.
&gt;&gt; Yeah.

132
00:09:18.265 --> 00:09:18.765
&gt;&gt; Correct.

133
00:09:20.300 --> 00:09:24.306
Yeah, snapshots are super useful
where everything is guaranteed not to

134
00:09:24.306 --> 00:09:25.880
change, right?

135
00:09:25.880 --> 00:09:29.010
And legacy is an example for that, right?

136
00:09:29.010 --> 00:09:32.023
But if you're developing and
you wanna move things around,

137
00:09:32.023 --> 00:09:34.160
snapshots are difficult to read, right?

138
00:09:34.160 --> 00:09:37.422
Because when something does change,
it's like, well,

139
00:09:37.422 --> 00:09:39.528
was it the intended change or not?

140
00:09:39.528 --> 00:09:40.668
Then how do I review it?

141
00:09:40.668 --> 00:09:44.358
How do I make sure that
that was what I wanted?

142
00:09:44.358 --> 00:09:48.578
Also sometimes you have things like
timestamps embedded inside of your

143
00:09:48.578 --> 00:09:51.898
snapshot in which case,
those things become useless.

144
00:09:51.898 --> 00:09:55.333
You can't just do you have to kind
of massage it before you do the next

145
00:09:55.333 --> 00:09:57.118
step, right?

146
00:09:57.118 --> 00:09:58.638
Yes, Mark.

147
00:09:58.638 --> 00:10:01.858
&gt;&gt; It something like this be caught
statically by a strict return type in

148
00:10:01.858 --> 00:10:03.256
something like TypeScript?

149
00:10:05.876 --> 00:10:12.996
&gt;&gt; So type system is a form of testing,
but it is different, right?

150
00:10:12.996 --> 00:10:17.770
The type system could never ever assert,
let me go back to my test here, the type

151
00:10:17.770 --> 00:10:23.051
system could never assert that these
two items end up in the same cluster.

152
00:10:23.051 --> 00:10:26.891
The type system can assert that the output
shape of the object is correct.

153
00:10:26.891 --> 00:10:31.999
That I haven't made kind of a logical
mistake in terms of the way the types

154
00:10:31.999 --> 00:10:38.061
flow, but it will never assert that this
will return two separate clusters, right?

155
00:10:38.061 --> 00:10:42.244
And just kind of to prove to ourselves,
if I change this 5 to 15,

156
00:10:42.244 --> 00:10:45.401
you would expect to get a single cluster,
right?

157
00:10:46.591 --> 00:10:50.801
I just save this, you'll see that
there's a whole bunch of red here.

158
00:10:50.801 --> 00:10:52.099
But fundamentally,

159
00:10:52.099 --> 00:10:58.091
you see that we have a single object
now that has, Doesn't it show me?

160
00:11:02.450 --> 00:11:07.522
It just shows me the array
clusters.clusters, let me print it again.

161
00:11:11.085 --> 00:11:14.802
Come on, .data
&gt;&gt; [LAUGH]

162
00:11:14.802 --> 00:11:15.802
&gt;&gt; Clusters.

163
00:11:15.802 --> 00:11:19.798
Right, no, but we do see the fact there
is a single item inside of it, right?

164
00:11:21.118 --> 00:11:24.625
You see now there's a single item in
here that has a minimum of 0 to 11 and

165
00:11:24.625 --> 00:11:26.388
four items are inside of it, right?

166
00:11:26.388 --> 00:11:30.228
So it decided that all of these
items ended up in the same place.

167
00:11:32.128 --> 00:11:34.270
So the clustering is
doing the right stuff,

