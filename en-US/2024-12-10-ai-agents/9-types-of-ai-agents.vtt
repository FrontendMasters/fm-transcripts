WEBVTT

1
00:00:00.135 --> 00:00:04.675
&gt;&gt; Scott Moss: All right, so the next
thing we're going to do is build an agent.

2
00:00:04.675 --> 00:00:05.439
Let's get to it.

3
00:00:05.439 --> 00:00:07.778
Got a lot to cover, but
it's gonna be really cool.

4
00:00:07.778 --> 00:00:12.461
So we talk about agents, what is an agent?

5
00:00:12.461 --> 00:00:16.807
Really, I have a lot of bullet
points here, I'm gonna be honest.

6
00:00:16.807 --> 00:00:22.397
Really, the thing that I think about
an agent is it's an LLM that has memory,

7
00:00:22.397 --> 00:00:25.579
whether it's short-term or long-term,

8
00:00:25.579 --> 00:00:30.395
it can remember things, and
it has the ability to do tool calling.

9
00:00:30.395 --> 00:00:34.071
We'll talk about, or you'll hear me
say tool calling and function calling,

10
00:00:34.071 --> 00:00:35.307
they're the same thing.

11
00:00:35.307 --> 00:00:39.091
It has the ability to describe.

12
00:00:39.091 --> 00:00:44.372
It has the ability to tell your system
what function it wants your system to run.

13
00:00:44.372 --> 00:00:48.731
It's not to be confused
with code interpreter,

14
00:00:48.731 --> 00:00:52.037
which is an LLM running code for you.

15
00:00:52.037 --> 00:00:56.048
That's an internal tool that an LLM
might have or a platform might offer.

16
00:00:56.048 --> 00:01:00.977
OpenAI has Code Interpreter, and it will
run code on their system for you and

17
00:01:00.977 --> 00:01:02.683
give you back the result.

18
00:01:02.683 --> 00:01:05.807
That's not to be confused with
function calling or tool calling,

19
00:01:05.807 --> 00:01:09.397
which is something different, and
we'll dive more into that a little bit.

20
00:01:09.397 --> 00:01:13.107
But to me, an agent is just
something that has memory,

21
00:01:13.107 --> 00:01:16.264
short-term or long-term and tool calling.

22
00:01:16.264 --> 00:01:20.459
And because it does have tool calling,
it works on a loop, and

23
00:01:20.459 --> 00:01:23.217
we'll talk about that loop in a minute.

24
00:01:23.217 --> 00:01:24.890
But eventually, I mean,

25
00:01:24.890 --> 00:01:29.231
basically having those things
allows the agent to make decisions.

26
00:01:29.231 --> 00:01:33.653
Because if you give an agent, here are all
the functions that you have access to,

27
00:01:33.653 --> 00:01:37.245
the agent has to decide if, when,
or how to use those functions.

28
00:01:37.245 --> 00:01:41.968
You can only try to influence it
with different descriptions, but

29
00:01:41.968 --> 00:01:47.637
at the end of the day, it's gonna decide
what tool is appropriate for it to use.

30
00:01:47.637 --> 00:01:51.571
There's a way to be like,
you have to use this tool no matter what.

31
00:01:51.571 --> 00:01:58.000
But there isn't a way to dynamically say,
if this comes in, you have to use this.

32
00:01:58.000 --> 00:02:02.041
You have to make another LLM in front of
your LLM to classify that intent, and

33
00:02:02.041 --> 00:02:04.390
then, you got to make
sure that LLM is good.

34
00:02:04.390 --> 00:02:06.193
It's just LLMs all the way down, right?

35
00:02:06.193 --> 00:02:12.259
So [LAUGH] it just gets crazy, so
that's the way I think about an agent.

36
00:02:12.259 --> 00:02:15.236
So it has autonomous decision-making.

37
00:02:15.236 --> 00:02:17.025
It has task persistence.

38
00:02:17.025 --> 00:02:19.287
It has tool usage.

39
00:02:19.287 --> 00:02:23.682
It's aware of context, and
typically, it is goal oriented.

40
00:02:23.682 --> 00:02:27.518
So typically, when you interact with
an agent, you're like, can you do this for

41
00:02:27.518 --> 00:02:29.144
me, or can you answer this for me?

42
00:02:29.144 --> 00:02:33.678
And it creates a goal that is trying to
accomplish, so it'll keep looping and

43
00:02:33.678 --> 00:02:38.215
keep calling functions until it's
satisfied that it reached that goal, and

44
00:02:38.215 --> 00:02:39.916
then it'll respond to you.

45
00:02:39.916 --> 00:02:42.549
You won't always just get back
a response from an agent.

46
00:02:42.549 --> 00:02:45.894
Whereas every time we've
interacted with this tool so far,

47
00:02:45.894 --> 00:02:48.397
we get back a response immediately, right?

48
00:02:48.397 --> 00:02:52.134
So if I say, what is my name?

49
00:02:52.134 --> 00:02:54.170
I immediately get back a response.

50
00:02:54.170 --> 00:02:57.321
Whereas with an agent, you might
not get back a response immediate.

51
00:02:57.321 --> 00:02:59.798
They might be like, hold on,
let me think about this.

52
00:02:59.798 --> 00:03:03.279
Let me go check this, or okay,
I did check that, I still don't know.

53
00:03:03.279 --> 00:03:06.443
Let me go check,
let me go do this, kind of.

54
00:03:06.443 --> 00:03:09.760
And then it might come back and be like,
can you tell me more about this?

55
00:03:09.760 --> 00:03:11.254
Okay, cool, let me go check again.

56
00:03:11.254 --> 00:03:15.908
So it's trying to figure out what
to do before it finally responds.

57
00:03:15.908 --> 00:03:20.544
So if that sounds terrifying,
then yeah, it's pretty terrifying.

58
00:03:20.544 --> 00:03:24.554
I remember when agents were a thing,
two years ago I start work.

59
00:03:24.554 --> 00:03:27.450
I was like,
what in the hell am I looking at?

60
00:03:27.450 --> 00:03:33.199
I set up two agents to talk to each other,
to play chess or something like that.

61
00:03:33.199 --> 00:03:35.117
It was really entertaining.

62
00:03:35.117 --> 00:03:37.733
And I gave one the personality
of snoot dog, and

63
00:03:37.733 --> 00:03:41.931
other the personality of his best friend,
Martha Stewart, and it was fun.

64
00:03:41.931 --> 00:03:46.383
[LAUGH] So that's an agent.

65
00:03:46.383 --> 00:03:48.885
Different types of agents,
I talked about this earlier, but

66
00:03:48.885 --> 00:03:51.445
you have chat-based agents,
that's what we're building.

67
00:03:51.445 --> 00:03:54.151
The difference between
this chat based agent and

68
00:03:54.151 --> 00:03:57.658
a non-chat-based agent is that
this has long-term memory.

69
00:03:57.658 --> 00:04:00.415
We just talked about memory, so
we know what that looks like, that's it.

70
00:04:00.415 --> 00:04:06.142
It's an agent that has a recollection
of all your conversations,

71
00:04:06.142 --> 00:04:10.245
including the results
of previous tool calls.

72
00:04:10.245 --> 00:04:14.490
So functions that it called earlier, the
results of those functions are also stored

73
00:04:14.490 --> 00:04:17.798
in the conversation, so
it knows that too, it's pretty aware.

74
00:04:17.798 --> 00:04:22.578
So use cases are customer service,
representative, tutors, mental health,

75
00:04:22.578 --> 00:04:26.742
support assistants, technical
support agents, things like that.

76
00:04:26.742 --> 00:04:31.326
Here's some pseudocode that I created
just to kinda show you what this will

77
00:04:31.326 --> 00:04:32.063
look like.

78
00:04:32.063 --> 00:04:35.737
The only thing that's here that's
different is this, if check.

79
00:04:35.737 --> 00:04:40.495
We don't have this where you can check to
see if the AI responded with a tool, and

80
00:04:40.495 --> 00:04:43.619
then you find the right tool,
you run that tool, and

81
00:04:43.619 --> 00:04:46.696
then you respond back with
the result of that tool.

82
00:04:46.696 --> 00:04:51.048
Don't worry, we'll get into this,
but this is what makes it an agent.

83
00:04:51.048 --> 00:04:52.598
It's this part is that I like.

84
00:04:52.598 --> 00:04:56.547
The AI is telling you to go do something
on your machine and then report back

85
00:04:56.547 --> 00:05:00.706
with the results, that's what telling
to do, and we have to check for that.

86
00:05:00.706 --> 00:05:03.195
Task-based agents are just one of things,
right?

87
00:05:03.195 --> 00:05:09.297
So if I go into cursor right now and
I say, do the thing, that's task-based,

88
00:05:09.297 --> 00:05:13.843
it's not a chat-based,
it's not gonna remember that.

89
00:05:13.843 --> 00:05:18.080
Data analysis like,
look at the spreadsheet and do this thing.

90
00:05:18.080 --> 00:05:22.923
Research assistance is another one,
help me find something that does this.

91
00:05:22.923 --> 00:05:27.331
Content creation is probably the number
one thing when GPT 3.5 was out.

92
00:05:27.331 --> 00:05:32.209
I mean, I would say 99% of the use cases
was creating content, like blog posts,

93
00:05:32.209 --> 00:05:35.707
Twitter posts, SEO stuff,
it was just content creation.

94
00:05:35.707 --> 00:05:40.100
Nobody really knew what else to do
with it other than to make content,

95
00:05:40.100 --> 00:05:42.612
podcast, videos, things like that.

96
00:05:42.612 --> 00:05:45.316
And it's probably still
the number one use case.

97
00:05:45.316 --> 00:05:49.626
Because obviously, the direct export
of an LLM is text, it's content,

98
00:05:49.626 --> 00:05:51.652
so it makes sense to just use that.

99
00:05:51.652 --> 00:05:54.433
That's the exact use case, but

100
00:05:54.433 --> 00:05:59.790
LLMs are much more powerful than
only just creating content.

101
00:05:59.790 --> 00:06:03.265
But creating content itself
is not useless, it's great.

102
00:06:03.265 --> 00:06:05.269
But that's the obvious solution,

103
00:06:05.269 --> 00:06:09.359
and there's a lot of other non-obvious
solutions out there, I think.

104
00:06:09.359 --> 00:06:14.341
So an example of imitation of that is,
in this example,

105
00:06:14.341 --> 00:06:19.853
you have this while loop,
we'll talk about that in a minute,

106
00:06:19.853 --> 00:06:25.051
but you can see that the LLM
basically tries to plan a step.

107
00:06:25.051 --> 00:06:26.818
It tries to execute a step.

108
00:06:26.818 --> 00:06:28.232
It gets the results,

109
00:06:28.232 --> 00:06:33.034
and then it checks to see if the results
satisfies the original request.

110
00:06:33.034 --> 00:06:34.185
And if it doesn't,

111
00:06:34.185 --> 00:06:38.858
it loops again until it does it up until a
max amount of attempts before it just say,

112
00:06:38.858 --> 00:06:42.606
okay, we need to stop this runaway agent,
which is a thing in AI.

113
00:06:42.606 --> 00:06:45.752
You'd have an agent just
constantly contradicting itself,

114
00:06:45.752 --> 00:06:47.209
like I got the right answer.

115
00:06:47.209 --> 00:06:47.857
No, I didn't.

116
00:06:47.857 --> 00:06:48.925
Let me check again.

117
00:06:48.925 --> 00:06:50.879
I got the right answer,
no, that's not right.

118
00:06:50.879 --> 00:06:54.657
Let me check again, and it could just
do that over, and over, and over.

119
00:06:54.657 --> 00:06:57.578
There's so many ways to get around that,
but people do Mac steps and

120
00:06:57.578 --> 00:06:58.353
stuff like that.

121
00:06:58.353 --> 00:07:05.016
So, yeah, real world,
I talked about some of those already.

122
00:07:05.016 --> 00:07:09.017
Some coding ones are really cool,
like GitHub Copilots, actually Tab 9,

123
00:07:09.017 --> 00:07:12.158
I think they got bought out,
there's something else now.

124
00:07:12.158 --> 00:07:19.692
But some of these features are examples of
that, so not gonna go into all of these.

125
00:07:19.692 --> 00:07:22.583
Performance optimizations,
we can talk about that later, and

126
00:07:22.583 --> 00:07:25.269
then I think this was really interesting,
future trends.

127
00:07:25.269 --> 00:07:30.057
So I wrote this one, because people,
I think just like being able to

128
00:07:30.057 --> 00:07:35.013
see what's possible with some of
this just helps when developing it,

129
00:07:35.013 --> 00:07:37.540
so you have multi-agent systems.

130
00:07:37.540 --> 00:07:40.533
These are actually really cool.

131
00:07:40.533 --> 00:07:45.006
Instead of having one agent who can do all
these things, you have multiple agents and

132
00:07:45.006 --> 00:07:47.855
each agent is responsible for
one part of something.

133
00:07:47.855 --> 00:07:52.051
So, you might have one agent whose job
is to orchestrate other agents, and

134
00:07:52.051 --> 00:07:55.528
then, each one of those agents
has a single responsibility.

135
00:07:55.528 --> 00:08:00.066
This agent is anything related to email,
it can do email stuff.

136
00:08:00.066 --> 00:08:02.706
This agent, anything related to calendar,
it can do calendar stuff.

137
00:08:02.706 --> 00:08:05.568
This agent, anything related to research,
it can do research stuff.

138
00:08:05.568 --> 00:08:10.242
And then you have one agent that
orchestrates the communication between all

139
00:08:10.242 --> 00:08:13.235
three of them, and
its job is to get the result and

140
00:08:13.235 --> 00:08:16.969
pass it to another agent that
creates the response, right?

141
00:08:16.969 --> 00:08:22.780
And you can have all these things working
together like a team, it's kinda crazy.

142
00:08:22.780 --> 00:08:24.149
So that one's good.

143
00:08:25.528 --> 00:08:27.144
&gt;&gt; Scott Moss: Improved tool creation,
yeah,

144
00:08:27.144 --> 00:08:31.255
I think we'll talk about this when we get
to tools, cuz it's gonna make more sense.

145
00:08:31.255 --> 00:08:33.823
Enhanced reasoning capabilities,
that's any new model that comes out.

146
00:08:33.823 --> 00:08:38.814
So any new model that comes out usually
is an increase in reasoning capabilities,

147
00:08:38.814 --> 00:08:42.228
that's usually the biggest
benefit of a better model.

148
00:08:42.228 --> 00:08:45.519
That's how they score these models,
is how well it can reason.

149
00:08:45.519 --> 00:08:47.528
So typically,
if you want better reasoning,

150
00:08:47.528 --> 00:08:50.258
for instance, if you have an agent and
you're realizing it's

151
00:08:50.258 --> 00:08:53.054
just picking the wrong tools no
matter what prompts you give it.

152
00:08:53.054 --> 00:08:56.709
It's just not picking the right tools,
get a better model.

153
00:08:56.709 --> 00:08:59.210
It's that model you're using
is not good at reasoning, so

154
00:08:59.210 --> 00:09:00.469
you need to find a better one.

155
00:09:00.469 --> 00:09:04.434
Or make an intent classifier, which
is another LLM in front of your agent

156
00:09:04.434 --> 00:09:08.464
that its job is to figure out what
the right tool is, versus having an agent

157
00:09:08.464 --> 00:09:11.660
who not only figures out the right tool,
but also uses it.

158
00:09:11.660 --> 00:09:16.283
So you can separate the concern out to
another agent, which does make it easy.

159
00:09:16.283 --> 00:09:21.356
Better memory management, yeah,
right now, all the things that I

160
00:09:21.356 --> 00:09:26.439
talked about about summarizing,
ejecting, evicting messages.

161
00:09:26.439 --> 00:09:28.596
If the agents themselves
could just do that,

162
00:09:28.596 --> 00:09:31.788
or if the LLMs themselves could
just do that, that would be great.

163
00:09:31.788 --> 00:09:34.874
Always having to do it is kind of a pain.

164
00:09:34.874 --> 00:09:39.569
And then specialized domain experts, this
was really cool, I like the idea of this.

165
00:09:39.569 --> 00:09:41.722
Like I said, most LLMs are generic.

166
00:09:41.722 --> 00:09:44.268
They're trained on the whole Internet for
the big ones.

167
00:09:44.268 --> 00:09:48.112
But if you compare them to one of us,
very specifically trained for one thing,

168
00:09:48.112 --> 00:09:50.512
that one is gonna be way
better at that one thing.

169
00:09:50.512 --> 00:09:52.938
It's gonna be faster,
cheaper, and more accurate.

170
00:09:52.938 --> 00:09:58.112
So I think we're gonna see a lot of agents
that are just experts at just one thing,

171
00:09:58.112 --> 00:10:00.482
and that's all they do versus like.

172
00:10:00.482 --> 00:10:04.264
There's always gonna be the OpenAIs and
the Claudes of the world whose job is to

173
00:10:04.264 --> 00:10:07.772
make AGI and to make the biggest,
most general intelligence out there.

174
00:10:07.772 --> 00:10:12.342
But I think for most people, especially
when you start thinking of running AI

175
00:10:12.342 --> 00:10:17.122
on a phone where the processing is not
that strong, you're gonna need smaller,

176
00:10:17.122 --> 00:10:21.620
specialized agents that know how to do
this one thing very well versus like,

177
00:10:21.620 --> 00:10:23.897
I'm gonna run ChatGPT 6 on my phone.

178
00:10:23.897 --> 00:10:26.932
Okay, good luck,
it's not gonna be the accurate thing.

179
00:10:26.932 --> 00:10:29.043
So, yes?

180
00:10:29.043 --> 00:10:33.847
&gt;&gt; Speaker 2: Your production uses of AI,
have you ever found the need to validate

181
00:10:33.847 --> 00:10:39.601
LLM responses with a follow-up LLM query,
or is that just generally overkill?

182
00:10:39.601 --> 00:10:41.019
&gt;&gt; Scott Moss: That's a great question.

183
00:10:41.019 --> 00:10:41.777
Times are changing.

184
00:10:41.777 --> 00:10:46.011
So the question was, have I ever found
the need to, like I got a response from

185
00:10:46.011 --> 00:10:49.397
the LLM and then now I need to
validate that with another LLM?

186
00:10:49.397 --> 00:10:51.144
Yes, for many different reasons.

187
00:10:51.144 --> 00:10:56.325
So long time ago,
two years ago, I don't know.

188
00:10:56.325 --> 00:10:57.591
It's not a long time ago.

189
00:10:57.591 --> 00:11:02.152
Before, there was JSON output or
structured output where the LLM,

190
00:11:02.152 --> 00:11:07.530
you can give it a schema, and then it'll
put data in that exact schema, right?

191
00:11:07.530 --> 00:11:12.366
Before, that was a reality, you would
have to ask the AI to do it nicely.

192
00:11:12.366 --> 00:11:15.669
You have to put that in a prompt, like can
you please just send me back something

193
00:11:15.669 --> 00:11:18.995
that looks like this, and then sometimes
it would, sometimes it wouldn't.

194
00:11:18.995 --> 00:11:23.964
So before you try to JSON.parse() that
thing and destroy your whole system,

195
00:11:23.964 --> 00:11:26.274
you would check it with another LLM.

196
00:11:26.274 --> 00:11:28.889
Hey, is the output of
this match this scheme?

197
00:11:28.889 --> 00:11:30.872
If not, run it back, right?

198
00:11:30.872 --> 00:11:33.859
And actually, that's a lot with
LangChained, LanChain did a lot of that.

199
00:11:33.859 --> 00:11:38.048
So it would take a schema you gave it, it
would put it in your prompt for you, and

200
00:11:38.048 --> 00:11:42.113
it will keep running it over and over
again, up until max amount of retries,

201
00:11:42.113 --> 00:11:45.318
until it actually came back
with the shape that you wanted.

202
00:11:45.318 --> 00:11:47.042
Now, that's built into models now.

203
00:11:47.042 --> 00:11:50.155
You can just say, actually, return me this
shape and what we're gonna use it today,

204
00:11:50.155 --> 00:11:51.248
so you don't have to do that.

205
00:11:51.248 --> 00:11:57.133
So for other reasons I might wanna do
this is sometimes the LLM comes back and

206
00:11:57.133 --> 00:12:00.134
it's like, it's just not correct.

207
00:12:00.134 --> 00:12:02.098
It's not doing the right thing.

208
00:12:02.098 --> 00:12:03.422
So there's different strategies.

209
00:12:03.422 --> 00:12:06.342
You might ask it to come back
with a confidence score.

210
00:12:06.342 --> 00:12:11.206
You might say something like, cool, when
you send me back this answer, also give

211
00:12:11.206 --> 00:12:15.875
me a score from 0 to 1 or 1 to 100 on
how confident you think this answer is.

212
00:12:15.875 --> 00:12:19.375
And then, if that confidence score
isn't past some threshold that you're

213
00:12:19.375 --> 00:12:22.829
comfortable with, you run it through
another LLM or something like that.

214
00:12:22.829 --> 00:12:24.963
So you have this QA LLM.

215
00:12:24.963 --> 00:12:28.437
Yeah, I've had that many different
times for many situations and

216
00:12:28.437 --> 00:12:31.800
I'm pretty sure I have some of
that in production at some point.

217
00:12:31.800 --> 00:12:34.009
But yeah,
I do have a lot of that in production,

218
00:12:34.009 --> 00:12:36.681
so,
&gt;&gt; Scott Moss: Cool, any question?

219
00:12:39.718 --> 00:12:43.543
&gt;&gt; Speaker 3: How do you approach
insulating yourself from the kind

220
00:12:43.543 --> 00:12:48.473
of bigger LLMs just absorbing
the functionality you're creating,

221
00:12:48.473 --> 00:12:50.435
just becoming ingrained?

222
00:12:50.435 --> 00:12:52.022
&gt;&gt; Scott Moss: Yeah,
that's a good question.

223
00:12:52.022 --> 00:12:58.225
How do I think about being cannibalized
by the big general foundational models?

224
00:12:58.225 --> 00:12:58.951
I don't.

225
00:12:58.951 --> 00:13:00.375
Actually, I really don't.

226
00:13:00.375 --> 00:13:05.403
Actually, I had a, how long ago, couple
of weeks ago, we all had to sit down and

227
00:13:05.403 --> 00:13:10.360
we talked with Sam Altman from OpenAI
about what they're doing, OpenAI, and

228
00:13:10.360 --> 00:13:11.582
things like that.

229
00:13:11.582 --> 00:13:16.262
I think at the end of the day, those
companies, they're trying to create AGI.

230
00:13:16.262 --> 00:13:17.597
They're trying to create
the most general thing.

231
00:13:17.597 --> 00:13:20.403
It's literally in the name,
artificial general intelligence.

232
00:13:20.403 --> 00:13:25.710
And I think even with AGI,
it doesn't solve everything,

233
00:13:25.710 --> 00:13:29.949
even AGI is gonna have
a lot of these problems.

234
00:13:29.949 --> 00:13:35.097
So I think there's a lot of value in
going after something that's vertical and

235
00:13:35.097 --> 00:13:37.284
very specific to a set of people.

236
00:13:37.284 --> 00:13:40.739
Because I think ultimately,
when you think of the economics of things,

237
00:13:40.739 --> 00:13:42.790
it's okay, let's say AGI is here today.

238
00:13:42.790 --> 00:13:46.481
It's gonna cost so much damn money
to use it that no one's ever gonna,

239
00:13:46.481 --> 00:13:50.861
I don't know, it'll probably cost you $1
to run it once or something like that,

240
00:13:50.861 --> 00:13:52.130
extremely expensive.

241
00:13:52.130 --> 00:13:54.349
And that's assuming you
have the compute to do it.

242
00:13:54.349 --> 00:13:58.060
So because of that,
there's still gonna be use cases for

243
00:13:58.060 --> 00:14:02.792
things that can run today that are also
quite good and tons of verticals.

244
00:14:02.792 --> 00:14:07.260
Another thing is, I think it comes
down to experience, user experience.

245
00:14:07.260 --> 00:14:12.771
If a chat interface isn't gonna be the
experience for every single AI app, right?

246
00:14:12.771 --> 00:14:16.382
In my app,
we actually do have a chat experience now,

247
00:14:16.382 --> 00:14:21.300
because It's mimicking what you would
have as an executive assistant.

248
00:14:21.300 --> 00:14:23.465
And you would actually chat
with an executive assistant,

249
00:14:23.465 --> 00:14:24.622
so it's kinda of works there.

250
00:14:24.622 --> 00:14:28.189
But me personally, I don't think
chatting is a good interface for

251
00:14:28.189 --> 00:14:29.918
chatting to get Figma designs.

252
00:14:29.918 --> 00:14:31.288
That feels kind of weird to me.

253
00:14:31.288 --> 00:14:33.208
It's like I don't wanna
chat to make designs.

254
00:14:33.208 --> 00:14:35.231
It doesn't feel creative.

255
00:14:35.231 --> 00:14:40.422
So I think, because of that, people
are still gonna be able to make really

256
00:14:40.422 --> 00:14:45.449
unique experiences for very niche
problems that no one, like OpenAI or

257
00:14:45.449 --> 00:14:51.184
Anthropic is ever interested in solving,
because it's too specific for them.

258
00:14:51.184 --> 00:14:53.689
It's like, I don't care about
solving that, we have an AGI.

259
00:14:53.689 --> 00:14:57.283
So as we're more of a platform, we wanna
empower the people who are making these

260
00:14:57.283 --> 00:15:01.057
products that can go make these unique
experiences, because then we win, right?

261
00:15:01.057 --> 00:15:06.201
So, yeah, I'm really not concerned about
them doing any of that, because at the end

262
00:15:06.201 --> 00:15:11.289
of the day, there's a GPT store right now
and it has tons of functionality in there.

263
00:15:11.289 --> 00:15:14.412
And people still don't really use it for
a lot of this stuff.

264
00:15:14.412 --> 00:15:15.521
It's also kinda like Zapier.

265
00:15:15.521 --> 00:15:17.952
Zapier can kinda do a lot
of stuff right now.

266
00:15:17.952 --> 00:15:19.491
You can even talk to OpenAI, but

267
00:15:19.491 --> 00:15:22.911
I don't see people just throwing away
every single app they ever had and

268
00:15:22.911 --> 00:15:26.337
just going to Zapier and making all
these apps that can automate stuff.

269
00:15:26.337 --> 00:15:28.558
Because it's like, yeah,
even though it can do,

270
00:15:28.558 --> 00:15:31.620
setting it up is kind of difficult,
and I don't like the experience.

271
00:15:31.620 --> 00:15:35.409
So yeah, I think there's still
lots of opportunity there,

272
00:15:35.409 --> 00:15:39.287
if you think about going after
something vertical and niche.

