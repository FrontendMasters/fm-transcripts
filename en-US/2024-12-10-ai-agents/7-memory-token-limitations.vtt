WEBVTT

1
00:00:00.010 --> 00:00:04.364
I had talked about how memory works and
why it matters.

2
00:00:04.364 --> 00:00:10.345
For example if I said, what is the weather
like, and it is said its 72 and

3
00:00:10.345 --> 00:00:16.350
sunny and then I get fallow ups,
follow ups, follow ups are so critical.

4
00:00:16.350 --> 00:00:21.277
They are so hard to do right especially
if you get tool calling and RAG and

5
00:00:21.277 --> 00:00:25.316
all this stuff to be like as humans,
we do stuff like this.

6
00:00:25.316 --> 00:00:28.047
We don't we keep context in our head.

7
00:00:28.047 --> 00:00:31.946
And if I'm talking to you, I imagine
that you have that context in your head.

8
00:00:31.946 --> 00:00:34.557
So I'm just gonna be what about tomorrow?

9
00:00:34.557 --> 00:00:37.675
Imagine if some random person came up
to you and said, what about tomorrow?

10
00:00:37.675 --> 00:00:39.939
You're what the hell
are you talking about?

11
00:00:39.939 --> 00:00:40.506
[LAUGH] What Who are you?

12
00:00:40.506 --> 00:00:41.673
What are you talking about?

13
00:00:41.673 --> 00:00:45.472
It's cuz you didn't see this other
conversation they had, right?

14
00:00:45.472 --> 00:00:46.513
You don't have the context.

15
00:00:46.513 --> 00:00:49.793
So it's very important for
the AI to, have the context.

16
00:00:49.793 --> 00:00:53.317
So if you ask follow up questions like
this, it can answer it, because either,

17
00:00:53.317 --> 00:00:56.474
depending on the reasoning capabilities
of that model you're using,

18
00:00:56.474 --> 00:01:00.498
it's either gonna hallucinate and be like,
I'm just gonna make something up.

19
00:01:00.498 --> 00:01:03.739
Or it's gonna be like, I don't know what
the hell you're talking about, right,

20
00:01:03.739 --> 00:01:04.866
what are you talking about?

21
00:01:04.866 --> 00:01:09.847
So that is probably the number one use
case for having memory, is that you wanna

22
00:01:09.847 --> 00:01:14.999
be able to offer follow up capabilities,
and you can't do that without memory.

23
00:01:14.999 --> 00:01:16.174
So that's really good.

24
00:01:16.174 --> 00:01:21.129
Also task continuity, we'll talk
about that when we get into loops and

25
00:01:21.129 --> 00:01:23.212
multi-turn interactions.

26
00:01:23.212 --> 00:01:25.835
Yes, agents can run on loops and
things like that.

27
00:01:25.835 --> 00:01:28.287
We'll talk about that but then,
yeah, memory limitations, so

28
00:01:28.287 --> 00:01:29.812
let's talk about this for a little bit.

29
00:01:29.812 --> 00:01:31.178
LLMs have fixed context windows.

30
00:01:31.178 --> 00:01:32.842
I've been talking about this for a while.

31
00:01:34.132 --> 00:01:39.498
So you have to think of different
strategies of balancing like, I need this

32
00:01:39.498 --> 00:01:45.300
thing to know all this detail, so I can
offer a follow up and have a conversation.

33
00:01:45.300 --> 00:01:48.464
But damn, this person that's
using it is talking a lot, and

34
00:01:48.464 --> 00:01:50.214
it's running out of memory.

35
00:01:50.214 --> 00:01:50.997
What do I do?

36
00:01:50.997 --> 00:01:53.454
So you have to think about
what does that look like?

37
00:01:53.454 --> 00:01:55.124
I've seen a million different
ways to do that, right?

38
00:01:55.124 --> 00:02:00.085
You might see some apps that are like
after you send X amount they'll Count

39
00:02:00.085 --> 00:02:05.285
every token that you send, and after you
send X amount of tokens, or if you get

40
00:02:05.285 --> 00:02:10.938
past a certain threshold, so they know
how many tokens their model can hold.

41
00:02:10.938 --> 00:02:14.076
Once you reach a certain threshold,
they'll start evicting tokens.

42
00:02:14.076 --> 00:02:18.805
So like an LRU cache,
they'll go back to the oldest thing, and

43
00:02:18.805 --> 00:02:23.284
they'll start removing older
parts of the conversation.

44
00:02:23.284 --> 00:02:26.892
So, you're now your assistant
doesn't have long term memory.

45
00:02:26.892 --> 00:02:28.604
It has great short term memory.

46
00:02:28.604 --> 00:02:31.920
But if you ask it something 12 days
ago and you use it every single day,

47
00:02:31.920 --> 00:02:34.906
it's not gonna remember that
even though you're scrolling and

48
00:02:34.906 --> 00:02:36.855
you see it, it's visually in your chat.

49
00:02:36.855 --> 00:02:39.964
They're not feeding that to
the AI cuz they just evicted it.

50
00:02:39.964 --> 00:02:41.427
So that could be a bad user experience.

51
00:02:41.427 --> 00:02:45.427
But sometimes that works for
apps that don't have a lot of friends,

52
00:02:45.427 --> 00:02:50.004
if you notice that your app, people
don't send thousands of messages a day.

53
00:02:50.004 --> 00:02:52.247
They use it for two messages a day or
something like that.

54
00:02:52.247 --> 00:02:55.147
So maybe you can get away with that,
because by time they run out of memory,

55
00:02:55.147 --> 00:02:57.974
that's a month later, and
they don't really care about that anymore.

56
00:02:57.974 --> 00:02:59.524
So you can just evict those messages.

57
00:02:59.524 --> 00:03:06.063
Other things you'll see is every x amount
of tokens, or every x amount of messages.

58
00:03:06.063 --> 00:03:09.640
Summarize the conversation so far and
put that in a system prompt, and

59
00:03:09.640 --> 00:03:12.863
that way I don't have to send
every single message every time.

60
00:03:12.863 --> 00:03:19.420
Maybe I only send the last five messages,
everything else is a summary of so far.

61
00:03:19.420 --> 00:03:22.129
With an emphasis on details,
emphasis on personal details,

62
00:03:22.129 --> 00:03:23.488
put that in the system prompt.

63
00:03:23.488 --> 00:03:28.520
And then, yeah, you lost some things,
but at least you have enough there.

64
00:03:28.520 --> 00:03:32.016
And I guess the way I think about it is
that's probably the closest how a human

65
00:03:32.016 --> 00:03:33.010
would work, right?

66
00:03:33.010 --> 00:03:35.536
I guess it depends on your
memory constraints, but

67
00:03:35.536 --> 00:03:39.666
I would say most people probably remember
things that are more recent, right?

68
00:03:39.666 --> 00:03:42.712
And things that are longer, it's a lot
harder to recall because, the details

69
00:03:42.712 --> 00:03:46.221
are a little fuzzy, it's hard to remember
something like, I don't know, 10 years ago

70
00:03:46.221 --> 00:03:49.580
that wasn't that special in your life,
versus something that happened yesterday.

71
00:03:49.580 --> 00:03:51.536
It was very ordinary, right?

72
00:03:51.536 --> 00:03:53.688
So it's because it just happened
yesterday, it's more recent.

73
00:03:53.688 --> 00:03:57.928
So that's what they're doing with AIs,
like, take all these important things and

74
00:03:57.928 --> 00:04:00.271
not important things, summarize them.

75
00:04:00.271 --> 00:04:03.976
Emphasis on details put them in the
long-term memory in the system prompt and

76
00:04:03.976 --> 00:04:06.087
then only show the last five or
so messages.

77
00:04:06.087 --> 00:04:10.408
So, it knows very accurately about those
things that just happened that works

78
00:04:10.408 --> 00:04:11.401
people do that.

79
00:04:11.401 --> 00:04:14.975
I mean over time, you have to like
make sure your summary is constrained

80
00:04:14.975 --> 00:04:18.331
to X amount of tokens,
otherwise your summary keeps getting big.

81
00:04:18.331 --> 00:04:22.016
So, eventually if you just had this
chat running for two years and

82
00:04:22.016 --> 00:04:23.758
it kept generating a summary,

83
00:04:23.758 --> 00:04:28.486
cuz when you generate a summary you
gotta give it the previous summary to.

84
00:04:28.486 --> 00:04:30.389
Otherwise, it doesn't know what that was,
so

85
00:04:30.389 --> 00:04:33.547
it's like make a new summary off of these
messages plus the previous summary.

86
00:04:33.547 --> 00:04:37.509
Eventually, it's gonna start to forget
things that happened 10 summaries

87
00:04:37.509 --> 00:04:38.236
ago, right?

88
00:04:38.236 --> 00:04:40.169
So eventually,
you still run into problems and

89
00:04:40.169 --> 00:04:42.641
there's like really no perfect
solution about doing that.

90
00:04:42.641 --> 00:04:44.542
It's really just about like balance.

91
00:04:44.542 --> 00:04:46.824
That's why in the early days of ChatGPT,
there's like,

92
00:04:46.824 --> 00:04:48.976
that's why they encourage
you just to make a new chat.

93
00:04:48.976 --> 00:04:50.762
It's like, can you just make a new one?

94
00:04:50.762 --> 00:04:52.824
Cuz like us trying to
figure this shit out for

95
00:04:52.824 --> 00:04:54.898
you trying to remember
it is not gonna work.

96
00:04:54.898 --> 00:04:55.962
We just can't do it.

97
00:04:55.962 --> 00:04:56.846
Just make a new chat, please.

98
00:04:56.846 --> 00:05:00.791
And so that's usually the solution
is just make a new chat, yeah.

99
00:05:00.791 --> 00:05:06.389
&gt;&gt; Student: But could things like
RAG be used to help with this?

100
00:05:06.389 --> 00:05:08.551
&gt;&gt; Scott Moss: Yes, RAG, yeah.

101
00:05:08.551 --> 00:05:10.651
RAG stands for
Retrieval Augmented Generation.

102
00:05:10.651 --> 00:05:15.841
It's a fancy word for,
I won't get into too much detail.

103
00:05:15.841 --> 00:05:19.645
But basically,
it allows the AI to go search for

104
00:05:19.645 --> 00:05:24.596
the most relevant parts of
a previous conversation according

105
00:05:24.596 --> 00:05:28.801
to the user message, and
bring just those parts in.

106
00:05:28.801 --> 00:05:32.689
Yes, that can help if you build
a good rack pipeline, and

107
00:05:32.689 --> 00:05:37.719
that is a multi billion dollar company
of just figuring out how to do rack.

108
00:05:37.719 --> 00:05:42.708
If there's one flashlight app of
AI right now It's trying to figure

109
00:05:42.708 --> 00:05:44.380
out how to do RAG good.

110
00:05:44.380 --> 00:05:47.162
And every day there's two
white papers that come out,

111
00:05:47.162 --> 00:05:50.154
and it's like,
this is the best way to do RAG now.

112
00:05:50.154 --> 00:05:51.770
And it's like impossible to keep up.

113
00:05:51.770 --> 00:05:55.870
It is literally sent out a tweet a week
ago, or maybe two weeks ago and was like,

114
00:05:55.870 --> 00:05:57.814
why is no one making RAG as a service?

115
00:05:57.814 --> 00:06:01.391
This is so hard, and everyone needs it,
this should just be a thing, and

116
00:06:01.391 --> 00:06:02.573
it just really isn't.

117
00:06:02.573 --> 00:06:05.861
Cuz it really is very hard.

118
00:06:05.861 --> 00:06:09.115
I had to spend like a month on
our app figuring out our garbage

119
00:06:09.115 --> 00:06:10.752
implementation of it today.

120
00:06:10.752 --> 00:06:15.371
So like it's quite difficult, but
when it works well, you're right.

121
00:06:15.371 --> 00:06:16.299
It will do that, yeah.

