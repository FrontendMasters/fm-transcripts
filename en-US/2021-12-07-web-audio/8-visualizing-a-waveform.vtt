WEBVTT

1
00:00:00.000 --> 00:00:02.048
So let's jump into some of the code for

2
00:00:02.048 --> 00:00:04.940
building out these Waveforms
with the Web Audio API.

3
00:00:06.860 --> 00:00:13.992
So in the demos here, if you scroll down,
you'll see the waveform demo.

4
00:00:13.992 --> 00:00:18.223
[SOUND] This is showing
the waveform of whatever is playing

5
00:00:18.223 --> 00:00:20.578
through the audio context.

6
00:00:20.578 --> 00:00:23.937
But if I layer it up,
it gets a little bit bigger.

7
00:00:23.937 --> 00:00:28.522
And I'm just gonna open
that up locally here.

8
00:00:42.529 --> 00:00:45.548
And actually, if I stretch the browser,

9
00:00:45.548 --> 00:00:50.132
you'll see, as this is happening,
it's really just a line.

10
00:00:50.132 --> 00:00:51.904
May be hard to see.

11
00:00:51.904 --> 00:00:55.932
But the wider your browser is the more
you'll start to see that it's just a line

12
00:00:55.932 --> 00:00:58.937
just like the graph that I've
been showing on the slides.

13
00:01:06.820 --> 00:01:12.274
So within this demo, we have a few things
that are very similar to the buffer

14
00:01:12.274 --> 00:01:17.170
example that we've shown earlier and
a few additional things.

15
00:01:17.170 --> 00:01:21.930
So we have the gain node,
as I showed, we create a Gain node.

16
00:01:23.100 --> 00:01:26.182
This is on top of the usual
loading the buffer and

17
00:01:26.182 --> 00:01:29.430
then playing the buffer
after it's been loaded.

18
00:01:30.550 --> 00:01:33.616
But there's another sort of set of things
that we're doing here that's a little

19
00:01:33.616 --> 00:01:34.120
different.

20
00:01:35.830 --> 00:01:40.990
We first create an Analyser node,
that's this one here.

21
00:01:42.260 --> 00:01:47.653
And this Analyser node is what's gonna
allow us to actually take the signal

22
00:01:47.653 --> 00:01:53.404
that's coming into the node and figure
out what the waveform is of that signal.

23
00:01:53.404 --> 00:01:55.065
And it doesn't need to be an MP3.

24
00:01:55.065 --> 00:01:57.131
It could be really whatever
node is coming into it.

25
00:01:57.131 --> 00:01:58.550
So maybe that's it.

26
00:01:58.550 --> 00:02:01.946
The microphone or maybe that's from
a video that's playing in the browser or

27
00:02:01.946 --> 00:02:03.160
something else like that.

28
00:02:04.230 --> 00:02:07.910
And so we do audioContext.createanalyser.

29
00:02:07.910 --> 00:02:12.424
And then the next thing we need to do is
set up an array that will store all of

30
00:02:12.424 --> 00:02:16.650
that data that I was showing
in the examples in the slides.

31
00:02:16.650 --> 00:02:19.746
And it's gonna be a Float32Array.

32
00:02:19.746 --> 00:02:24.905
And here we pass in
the property called fftSize.

33
00:02:24.905 --> 00:02:27.583
FFT is something we'll
talk about in a bit.

34
00:02:27.583 --> 00:02:31.480
It stands for fast Fourier transform.

35
00:02:31.480 --> 00:02:36.479
And all you need to know for
now is that this variable here is

36
00:02:36.479 --> 00:02:40.674
something around 2048 or 1024 values.

37
00:02:40.674 --> 00:02:43.770
And we're gonna be able
to change that in a bit.

38
00:02:43.770 --> 00:02:46.414
But for now, we just leave it as it is.

39
00:02:46.414 --> 00:02:50.689
It will know what to use is the best,
depending on your browser, and

40
00:02:50.689 --> 00:02:53.315
things like that, depending on the API.

41
00:02:53.315 --> 00:02:58.567
And we have to use Float32 for
this because I find that

42
00:02:58.567 --> 00:03:04.405
it's sort of the future facing API for
analyzing the audio.

43
00:03:04.405 --> 00:03:11.347
But in some browsers, you might be
forced to use the older byte data API.

44
00:03:11.347 --> 00:03:16.269
So if the browser is not new enough,
it might not support float data for

45
00:03:16.269 --> 00:03:21.288
audio analysis, in which case you
have to use, instead Uint8Array.

46
00:03:21.288 --> 00:03:24.444
And then you'll have to
also change your functions.

47
00:03:24.444 --> 00:03:27.782
Instead of it being get
float time domain data,

48
00:03:27.782 --> 00:03:31.690
you have to use get byte time domain data.

49
00:03:31.690 --> 00:03:34.386
But just for now,
I'm gonna stick with Float32Array,

50
00:03:34.386 --> 00:03:37.200
that'll give us the highest precision and
the most detail.

51
00:03:38.810 --> 00:03:42.394
And then once we create our
analyser node and get our data,

52
00:03:42.394 --> 00:03:45.625
we have to make sure that we
connect all of our nodes.

53
00:03:45.625 --> 00:03:49.980
So remember what I was saying earlier,
if you create an audio context node,

54
00:03:49.980 --> 00:03:53.859
an audio node, if you create it
without connecting it to anything or

55
00:03:53.859 --> 00:03:58.234
without connecting anything into it,
it's not really gonna do anything.

56
00:03:58.234 --> 00:04:02.049
It's just floating in the middle
of nowhere not doing anything.

57
00:04:02.049 --> 00:04:05.180
So we first have to connect our gain node,

58
00:04:05.180 --> 00:04:08.673
which is our master gain for
the audio source.

59
00:04:08.673 --> 00:04:11.890
We have to connect that into the analyser.

60
00:04:13.720 --> 00:04:20.280
And the way it looks is just like this,
connecting the gain into the analyser.

61
00:04:20.280 --> 00:04:24.960
And then we also wanna connect
the gain node into the destination.

62
00:04:24.960 --> 00:04:26.600
So it's splitting off there.

63
00:04:26.600 --> 00:04:32.500
One of them is going to the speaker and
one of them is going to the analyser.

64
00:04:32.500 --> 00:04:37.318
And then here, as we scroll down, when
we're playing the sound from the audio

65
00:04:37.318 --> 00:04:42.209
buffer, we're just connecting it straight
to the gain node, connecting it to

66
00:04:42.209 --> 00:04:46.900
that master gain, which is gonna split
off to the speaker and the analyser.

67
00:04:46.900 --> 00:04:50.360
And then here we get
into the actual analysis.

68
00:04:50.360 --> 00:04:55.182
So I'm gonna try and I'm just gonna
copy paste this into a new tab

69
00:04:55.182 --> 00:04:58.320
just to make sure I don't lose anything.

70
00:04:58.320 --> 00:05:04.762
Whoops, and
I'll start again from the ground up.

71
00:05:04.762 --> 00:05:09.089
So in our draw function,
as we're playing this audio,

72
00:05:09.089 --> 00:05:11.584
we wanna start to visualize it.

73
00:05:11.584 --> 00:05:14.670
And the way we're gonna do that
is just by drawing a graph.

74
00:05:14.670 --> 00:05:20.280
And so the first step is to use
that API function I was mentioning,

75
00:05:20.280 --> 00:05:24.161
analyserNode.getFloatTimeDomainData.

76
00:05:24.161 --> 00:05:26.613
And it looks like that.

77
00:05:26.613 --> 00:05:31.741
And we just pass in our analyserData here.

78
00:05:34.553 --> 00:05:37.991
That's the array that's gonna
receive all of this data.

79
00:05:37.991 --> 00:05:40.139
And we're gonna reuse
the same array every frame.

80
00:05:45.429 --> 00:05:50.186
And now the next thing we're gonna
do is loop through that array.

81
00:05:50.186 --> 00:05:55.797
And for each element in the array,
we're gonna draw a line,

82
00:05:55.797 --> 00:05:59.879
a vertex in a line,
polyline kind of shape.

83
00:05:59.879 --> 00:06:03.031
And to do that,
we're gonna start with beginShape.

84
00:06:03.031 --> 00:06:08.010
And we're also gonna have endShape.

85
00:06:08.010 --> 00:06:12.682
And just note here that with p5.js, if
you're using beginShape, endShape and then

86
00:06:12.682 --> 00:06:17.298
you create some vertices in between, you
created a shape, which might be a polygon.

87
00:06:17.298 --> 00:06:20.936
And, in this case, we don't want
to create like a filled polygon.

88
00:06:20.936 --> 00:06:22.395
So we say noFill.

89
00:06:22.395 --> 00:06:24.688
And we set the stroke to a certain color,

90
00:06:24.688 --> 00:06:29.222
just to make sure we're only getting
a single line instead of a filled polygon.

91
00:06:29.222 --> 00:06:34.682
And then we're gonna
loop through our array,

92
00:06:34.682 --> 00:06:39.162
analyserData.length, and i++.

93
00:06:39.162 --> 00:06:47.556
And what we'll do here is we will
get the amplitude from the data.

94
00:06:47.556 --> 00:06:52.054
And this value goes between
negative one and positive one

95
00:06:56.159 --> 00:07:01.570
And let's convert that
to a y pixel position.

96
00:07:01.570 --> 00:07:06.931
So, if I was to try and draw a graph based
on this amplitude, the graph would be very

97
00:07:06.931 --> 00:07:12.920
small because it would just be going from,
one pixel up here to the next pixel down.

98
00:07:12.920 --> 00:07:15.389
So we have to find out,
based on this amplitude,

99
00:07:15.389 --> 00:07:19.246
what is the pixel position that's goinna
be up here at the top of the screen,

100
00:07:19.246 --> 00:07:23.128
all the way down to the pixel position
is gonna be at the bottom of the screen.

101
00:07:23.128 --> 00:07:28.049
And so for that,
I'd like to use p5.js has a map function

102
00:07:28.049 --> 00:07:32.568
where you pass in the value
you pass in the minimum that

103
00:07:32.568 --> 00:07:37.098
the value will be and
the maximum of the value will be.

104
00:07:37.098 --> 00:07:41.263
So our amplitude is always going
from negative one to positive one.

105
00:07:41.263 --> 00:07:44.316
And then you pass in the output.

106
00:07:44.316 --> 00:07:47.215
What you want to map this from to.

107
00:07:47.215 --> 00:07:51.971
So you're mapping it from negative
one to one into, let's say, for

108
00:07:51.971 --> 00:07:53.535
now we'll just do it.

109
00:07:54.850 --> 00:07:56.395
Actually, we'll do it this way.

110
00:07:56.395 --> 00:08:00.772
So we go from the very top.

111
00:08:00.772 --> 00:08:03.223
So I'm gonna do width / 2,

112
00:08:03.223 --> 00:08:08.647
which is the center of the screen
minus let's say some amount.

113
00:08:08.647 --> 00:08:10.259
We could do width / 4 for now.

114
00:08:10.259 --> 00:08:12.342
We can change that later.

115
00:08:12.342 --> 00:08:17.110
And then, again, the same, except instead
of it being minus, it's gonna be plus.

116
00:08:19.250 --> 00:08:23.574
And what that should do is it should say,
if the amplitude is close to this,

117
00:08:23.574 --> 00:08:26.140
give back a result that's close to this.

118
00:08:26.140 --> 00:08:29.913
If the amplitude is close to this,
give back a result that's close to this.

119
00:08:29.913 --> 00:08:34.577
So it will just linearly interpolate,
which is a bit technical.

120
00:08:34.577 --> 00:08:38.300
But basically, it'll just kind of map
the value from the top to bottom.

121
00:08:40.520 --> 00:08:44.715
And we also need to map the value
from the start of the array, 0,

122
00:08:44.715 --> 00:08:51.510
to the end of the array, which might be,
let's say 10, 24 or 20, 48 or whatever.

123
00:08:51.510 --> 00:08:55.485
And we need to make that so that it goes
from the very left of the screen in pixels

124
00:08:55.485 --> 00:08:57.641
to the very right of the screen in pixels.

125
00:08:57.641 --> 00:08:59.586
So again, I'm gonna use map.

126
00:08:59.586 --> 00:09:03.409
I'm gonna say I, for
index, starts from zero.

127
00:09:03.409 --> 00:09:06.340
And goes to analyserData.length.

128
00:09:06.340 --> 00:09:08.512
I'm actually gonna do length -1, just so

129
00:09:08.512 --> 00:09:10.870
that it goes all the way
to the end of the screen.

130
00:09:12.320 --> 00:09:14.578
Just something I tend to do.

131
00:09:14.578 --> 00:09:20.460
And then the output of that is
gonna be from 0 to the width.

132
00:09:20.460 --> 00:09:23.780
This is a built-in variable
by the way from p5.js.

133
00:09:25.620 --> 00:09:29.526
Now when we try and draw this vertex,

134
00:09:29.526 --> 00:09:35.200
we can see it's not perfect but
it's getting there.

135
00:09:36.980 --> 00:09:41.888
So there's a little bit of an issue
here with how I'm mapping my amplitude

136
00:09:41.888 --> 00:09:46.810
to the pixel values, because it's
a little bit higher than it should be.

137
00:09:49.036 --> 00:09:55.351
Of course, so I should be using height for
this y value.

138
00:09:55.351 --> 00:09:58.832
So, because I'm mapping it from the top of
the screen to the bottom of the screen,

139
00:09:58.832 --> 00:10:01.505
you don't wanna use the width
of the screen cuz, in this case,

140
00:10:01.505 --> 00:10:03.128
the width is shorter than the height.

141
00:10:03.128 --> 00:10:06.083
You need to make sure that
you're using the height,

142
00:10:06.083 --> 00:10:09.316
which represents a horizontal axis,
just a bit of a bug.

143
00:10:09.316 --> 00:10:11.005
There we go.

144
00:10:11.005 --> 00:10:15.697
[SOUND] And so from that now,
we're able to visualize this waveform.

145
00:10:20.679 --> 00:10:24.730
There's a little bit more of an advanced
demo that I won't try to explain too

146
00:10:24.730 --> 00:10:27.660
much because it's just a lot
of extra little details.

147
00:10:27.660 --> 00:10:31.740
But there is here this advanced demo,
which you can see.

148
00:10:33.180 --> 00:10:35.869
It builds on the same ideas and
I'll open it up.

149
00:10:35.869 --> 00:10:41.552
[MUSIC]

150
00:10:41.552 --> 00:10:43.266
It does a few things differently.

151
00:10:43.266 --> 00:10:47.827
It has a few extra little features and
browser support.

152
00:10:47.827 --> 00:10:51.935
So one of the things that does
a little differently is that,

153
00:10:51.935 --> 00:10:56.537
instead of just playing the audio
right away as we had in our earlier

154
00:10:56.537 --> 00:11:01.164
streaming examples, it only waits
until the audio file can play.

155
00:11:01.164 --> 00:11:05.102
And then it resumes,
the context and calls play.

156
00:11:05.102 --> 00:11:07.455
And it just makes sure
that it does that once.

157
00:11:07.455 --> 00:11:08.835
It's a slight detail.

158
00:11:08.835 --> 00:11:12.529
I don't know if it's gonna really make
much of a difference in these demos.

159
00:11:12.529 --> 00:11:15.098
But maybe it's good
practice to only try and

160
00:11:15.098 --> 00:11:19.201
trigger these things once the audio
files are actually ready to play.

161
00:11:19.201 --> 00:11:24.594
Because before they can be played,
typically they have to load some metadata.

162
00:11:24.594 --> 00:11:29.809
They have to load just the basics of what
is the file, what kinda file format is it.

163
00:11:29.809 --> 00:11:33.299
And then once that's all ready,
this canplay event gets triggered.

164
00:11:33.299 --> 00:11:35.750
And then you can actually play the audio.

165
00:11:35.750 --> 00:11:39.149
So I don't think it'll make much of
a difference whether you use this event or

166
00:11:39.149 --> 00:11:40.886
whether you just call play right away.

167
00:11:40.886 --> 00:11:42.887
But it might be good practice.

168
00:11:42.887 --> 00:11:47.545
Another thing that it's doing
here is it's checking whether

169
00:11:47.545 --> 00:11:52.844
the browser can support float or
not for things like time domain data.

170
00:11:55.969 --> 00:11:58.019
And that just looks like this.

171
00:11:58.019 --> 00:12:00.201
I won't go into detail.

172
00:12:00.201 --> 00:12:05.628
But basically, it's a bit of
a slightly different way of coding.

173
00:12:05.628 --> 00:12:10.741
If you're using the byte data,
it's between 0 and 255.

174
00:12:10.741 --> 00:12:12.355
Those are the values you're getting.

175
00:12:12.355 --> 00:12:17.179
And so you have to scale those
from 0 to 255 into a -1 to

176
00:12:17.179 --> 00:12:21.813
positive 1 range to make it
behave like the float data.

177
00:12:21.813 --> 00:12:25.865
Another thing that's actually kind
of useful to know is this FFT size.

178
00:12:25.865 --> 00:12:31.417
So we can adjust the resolution of
these kinds of analyzer nodes and

179
00:12:31.417 --> 00:12:36.386
analysis, we can adjust it by
just giving it more samples.

180
00:12:36.386 --> 00:12:40.417
In the case of a waveform,
when we give it more samples here,

181
00:12:40.417 --> 00:12:43.588
we're increasing
the window size basically.

182
00:12:43.588 --> 00:12:47.263
Or perhaps increasing
the density of samples.

183
00:12:47.263 --> 00:12:51.338
That's actually something that might
be worth just checking the API for

184
00:12:51.338 --> 00:12:52.283
exact details.

185
00:12:52.283 --> 00:12:57.498
But in either case, we're gonna end up
with a more dense sort of output here.

186
00:12:57.498 --> 00:13:00.140
Just more data, as opposed to less data.

187
00:13:01.510 --> 00:13:06.524
So if you're willing to compromise,
and potentially it might run

188
00:13:06.524 --> 00:13:11.447
a little slower or it might not
perform as well on mobile devices,

189
00:13:11.447 --> 00:13:16.476
but you can set this value to a higher
value If you want more of that.

190
00:13:16.476 --> 00:13:20.680
And then another thing that this is doing
that's a little different is that instead

191
00:13:20.680 --> 00:13:24.838
of just every single frame, getting the
new data and rendering that every frame.

192
00:13:24.838 --> 00:13:26.172
I thought it was kinda nice.

193
00:13:26.172 --> 00:13:29.592
And I've done this in a few
installations now and

194
00:13:29.592 --> 00:13:33.104
sort of audio projects now
where I use smoothing.

195
00:13:33.104 --> 00:13:38.811
So I'll get the new audio data every
12 frames per second or something.

196
00:13:38.811 --> 00:13:42.386
But then 60 frames a second,
I'm still rendering the visualization.

197
00:13:42.386 --> 00:13:46.894
And I'm just smoothing the data
from one frame to the next.

198
00:13:46.894 --> 00:13:51.023
And that just creates a bit more
of a sorta noticeable look.

199
00:13:51.023 --> 00:13:56.060
You can really start to see the peaks and
the troughs of the waveform.

200
00:13:56.060 --> 00:13:59.835
Whereas if it's just going every
single frame, it's happening so

201
00:13:59.835 --> 00:14:03.950
fast that sometimes you don't
really get to see those details.

202
00:14:03.950 --> 00:14:08.208
It's just sort of a change of graphics
that are just constantly changing.

203
00:14:08.208 --> 00:14:11.025
And it kinda loses some
of the quality there.

204
00:14:13.894 --> 00:14:16.870
So yeah, that's this demo,
a little bit more complicated.

205
00:14:16.870 --> 00:14:18.251
I won't go into it too much.

206
00:14:18.251 --> 00:14:22.760
But it's definitely worth a look if you
want a little bit more robustness out of

207
00:14:22.760 --> 00:14:24.480
this kind of waveform stuff.

