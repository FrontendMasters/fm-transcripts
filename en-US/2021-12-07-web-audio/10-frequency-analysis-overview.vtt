WEBVTT

1
00:00:00.000 --> 00:00:06.498
So, that's a bit of how to use this API
to create visualizations of waveforms.

2
00:00:06.498 --> 00:00:10.990
And how to even use the waveform data to
start to create some really interesting

3
00:00:10.990 --> 00:00:15.292
visualizations based on frequency,
if you're using the by code filter.

4
00:00:15.292 --> 00:00:19.199
But now let's talk a little bit
more about analysis of frequency,

5
00:00:19.199 --> 00:00:21.780
what it means to analyze the frequency,
and

6
00:00:21.780 --> 00:00:25.435
we'll do it in a way that isn't
relying on the by code filter.

7
00:00:25.435 --> 00:00:29.056
We're gonna do it in a way
that's a little bit lower level,

8
00:00:29.056 --> 00:00:31.453
little bit rougher maybe a little bit.

9
00:00:31.453 --> 00:00:36.356
Yeah, maybe a little bit more mathy,
but hopefully it will start to

10
00:00:36.356 --> 00:00:41.358
break apart what is going on and
how we can use this in different ways.

11
00:00:41.358 --> 00:00:45.701
So, remember how I was talking earlier
about low and high frequency sounds.

12
00:00:45.701 --> 00:00:50.056
And showing this image here where
the waves will look compressed or

13
00:00:50.056 --> 00:00:55.358
strung out like if it's a slinky that
you're pulling, or pushing it together.

14
00:00:55.358 --> 00:01:00.161
And that corresponds to these
different tones that we're hearing.

15
00:01:00.161 --> 00:01:03.496
Now, if we were to take the time
domain data, so time domain

16
00:01:03.496 --> 00:01:07.854
represents the graph that we've been
talking about, that waveform graph.

17
00:01:07.854 --> 00:01:11.855
And we were to apply what's called
a fast Fourier transform to it,

18
00:01:11.855 --> 00:01:14.222
which is just a mathematical concept.

19
00:01:14.222 --> 00:01:19.413
If we were to apply that mathematical
idea to that time domain data,

20
00:01:19.413 --> 00:01:25.532
what we would end up getting is frequency,
a frequency response kind of graph.

21
00:01:25.532 --> 00:01:30.043
And it's kind of broken down like
this in this graphic here where on

22
00:01:30.043 --> 00:01:34.329
the left is the time domain data,
that's the graph with time.

23
00:01:34.329 --> 00:01:36.737
And then each of these
little things in the middle,

24
00:01:36.737 --> 00:01:38.982
those are the different
bands of frequencies.

25
00:01:38.982 --> 00:01:44.118
So, the one that's closest to the time
domain, that's a rather low frequency

26
00:01:44.118 --> 00:01:49.113
band, and then in the middle it's
a middle mid tone, sort of mid frequency.

27
00:01:49.113 --> 00:01:53.986
And on the end it's a high frequency
when the slinky is pushed together, and

28
00:01:53.986 --> 00:01:58.330
what it's doing is it's showing,
this frequency graph is showing

29
00:01:58.330 --> 00:02:02.697
the signal strength of each of
these different bands of frequency.

30
00:02:02.697 --> 00:02:06.842
And so right now in this example we have
three different bands of frequency and

31
00:02:06.842 --> 00:02:09.727
we can see the blue is peaking
at those three moments.

32
00:02:09.727 --> 00:02:13.968
But perhaps there'd be thousands
of different bands of frequency

33
00:02:13.968 --> 00:02:17.385
if we're analyzing the audio
with the web audio API.

34
00:02:17.385 --> 00:02:19.371
That's a little bit hard
to wrap your head around so

35
00:02:19.371 --> 00:02:21.276
I'm gonna show it in
a couple of different ways.

36
00:02:21.276 --> 00:02:24.582
This is another way of visualizing
the frequency spectrum.

37
00:02:24.582 --> 00:02:29.340
This is very common in audio workspaces
when you're trying to analyze audio and

38
00:02:29.340 --> 00:02:32.972
starting to EQ it and equalize it,
and shape it a little bit.

39
00:02:32.972 --> 00:02:37.687
And it looks like this on
the left on the vertical axis,

40
00:02:37.687 --> 00:02:40.875
we have signal which is in decibels.

41
00:02:40.875 --> 00:02:43.003
Decibels is a relative unit, for

42
00:02:43.003 --> 00:02:47.335
the purpose of this course we're
gonna really just be talking about

43
00:02:47.335 --> 00:02:51.976
the decimal value from negative 30
which we can assume is rather loud.

44
00:02:51.976 --> 00:02:56.145
To negative 100 which is the lowest
that we're gonna really deal with,

45
00:02:56.145 --> 00:02:59.533
which we can assume to be rather quiet,
pretty much silent.

46
00:02:59.533 --> 00:03:02.527
But these are very relative terms, and

47
00:03:02.527 --> 00:03:07.252
we're just gonna be using these values for
the sake of today.

48
00:03:07.252 --> 00:03:11.850
But you might have to tweak those
values depending on your audio files,

49
00:03:11.850 --> 00:03:17.076
depending on the sort of setup you have
and how loud your your sources really are.

50
00:03:17.076 --> 00:03:20.324
Cuz they might not be within that range,
they might be quieter or

51
00:03:20.324 --> 00:03:21.476
they might be louder.

52
00:03:21.476 --> 00:03:24.915
And then on the horizontal,
we have the frequency,

53
00:03:24.915 --> 00:03:27.507
which typically goes from zero hertz.

54
00:03:27.507 --> 00:03:32.825
Hertz is a measure of a change per second,
basically.

55
00:03:32.825 --> 00:03:37.745
And it goes from zero hertz to,
let's say some very high numbers.

56
00:03:37.745 --> 00:03:40.955
So, like 10,000 or 20,000 hertz.

57
00:03:40.955 --> 00:03:46.262
The exact number that it goes to is
actually called the Nyquist variable,

58
00:03:46.262 --> 00:03:51.226
and that has to do with the sample
rate of the the audio context which we

59
00:03:51.226 --> 00:03:54.581
typically don't control the audio context.

60
00:03:54.581 --> 00:03:59.416
When we create it is usually
set up with whatever the device

61
00:03:59.416 --> 00:04:04.446
wants it to be set up with,
which might be 44,100, and

62
00:04:04.446 --> 00:04:11.671
the Nyquist is that divided by two, which
is typically around 21K in terms of hertz.

63
00:04:11.671 --> 00:04:14.698
But in this graph,
it just maxes out at 10K, but

64
00:04:14.698 --> 00:04:17.941
in the web audio typically
you can kind of imagine that

65
00:04:17.941 --> 00:04:21.782
it's gonna be like either 10 or
20 K in terms of frequency.

66
00:04:21.782 --> 00:04:24.196
And when it reaches that point, it's so

67
00:04:24.196 --> 00:04:27.181
high pitched that we can
no longer really hear it.

68
00:04:27.181 --> 00:04:31.840
So typically in an audio file
you won't really need any

69
00:04:31.840 --> 00:04:35.194
signal that goes beyond these values.

70
00:04:35.194 --> 00:04:38.944
I think the human hearing maxes
out at something like 20K, or

71
00:04:38.944 --> 00:04:42.222
something like that,
I don't know the exact number.

72
00:04:42.222 --> 00:04:44.532
But once it reaches that
point it just becomes so

73
00:04:44.532 --> 00:04:46.621
high pitch that we can't hear it anymore.

74
00:04:46.621 --> 00:04:51.110
And so typically Web Audio and
just audio in digital formats

75
00:04:51.110 --> 00:04:55.072
doesn't really try to
capture those frequencies.

76
00:04:55.072 --> 00:05:00.566
Another way to visualize this, instead of
it being a graph with all of these many

77
00:05:00.566 --> 00:05:06.143
thousands of bands and sort of detailed
line going from zero to some large value.

78
00:05:06.143 --> 00:05:10.798
Imagine we were to split the frequency
spectrum from zero to 22k,

79
00:05:10.798 --> 00:05:14.320
we would split it into
discrete individual bands.

80
00:05:14.320 --> 00:05:18.922
And so, let's say we were to use these
bands that I've defined here just

81
00:05:18.922 --> 00:05:24.291
arbitrarily like 0, 50,
200, 1,000, 5,000, 22,000.

82
00:05:24.291 --> 00:05:29.219
If you were to listen to a kick drum and
pass that through a spectrum analyzer, or

83
00:05:29.219 --> 00:05:33.043
some sort of graph like this,
it might end up with a result like

84
00:05:33.043 --> 00:05:37.774
this where the kick drum has these bass
tones, really low frequency tones.

85
00:05:37.774 --> 00:05:40.946
And it's pumping the signal
in that end of the graph,

86
00:05:40.946 --> 00:05:44.331
whereas a piano might be more
around the mid-tones, and

87
00:05:44.331 --> 00:05:48.939
it might be shifting depending on which
octave you're playing on the piano.

88
00:05:48.939 --> 00:05:52.679
Voice again is kind of mid-tones
maybe higher mid-tones,

89
00:05:52.679 --> 00:05:54.964
maybe lower depending on the voice.

90
00:05:54.964 --> 00:05:59.894
And then something like treble,
so chime and high pitched tones,

91
00:05:59.894 --> 00:06:04.308
those might be more in the thousands
of hertz kind of range.

92
00:06:04.308 --> 00:06:09.186
And so, just with these graphs you
can start to see how we can start

93
00:06:09.186 --> 00:06:13.724
to sort of split apart an audio
file into different buckets.

94
00:06:13.724 --> 00:06:16.921
And maybe do some different
visualizations based on those buckets.

95
00:06:16.921 --> 00:06:19.680
So, maybe we have
something where the circles

96
00:06:19.680 --> 00:06:22.438
are only changing when the kick drum hits,
but

97
00:06:22.438 --> 00:06:26.416
then we have some lines that are only
changing when the piano hits.

98
00:06:26.416 --> 00:06:30.463
And maybe some text is moving
around when the voice is happening.

99
00:06:30.463 --> 00:06:35.809
You can start to visualize things based
on these different frequency bins.

100
00:06:35.809 --> 00:06:40.319
Here's how it looks in an array, so we
use the function get float frequency data

101
00:06:40.319 --> 00:06:44.446
which is kind of like the time domain,
just now we're using frequency.

102
00:06:44.446 --> 00:06:50.603
We pass it into a frequency array where
the lowest index is zero index here,

103
00:06:50.603 --> 00:06:56.290
this represents the zero hertz, so
the lowest amount of frequency.

104
00:06:56.290 --> 00:07:00.619
Whereas the highest index in the array
represents the highest amount of frequency

105
00:07:00.619 --> 00:07:03.643
we're trying to capture,
which might be around 22k.

106
00:07:03.643 --> 00:07:08.216
And the actual value within each element
of the array, as I was saying earlier,

107
00:07:08.216 --> 00:07:13.078
it's gonna go, let's say from around
negative 100 to negative 30 decibels.

108
00:07:13.078 --> 00:07:17.990
Just as a little note, if you do have
a different audio signal that's within

109
00:07:17.990 --> 00:07:20.293
a very specific range of decibels or

110
00:07:20.293 --> 00:07:23.548
within a range that's not
really captured here.

111
00:07:23.548 --> 00:07:28.030
You can change the minimum and
maximum decimals of the analyzer node, so

112
00:07:28.030 --> 00:07:32.586
that it's giving you back variables
that are a little bit more in line with

113
00:07:32.586 --> 00:07:35.177
the type of signal you're working with.

114
00:07:35.177 --> 00:07:39.952
And one other little way to sort of
visualize this just trying to really bring

115
00:07:39.952 --> 00:07:45.027
this home is, let's say you're trying
to create a graphic where you're trying

116
00:07:45.027 --> 00:07:50.122
to scale circles based on the different
frequencies, based on kick drum voice.

117
00:07:50.122 --> 00:07:52.727
And maybe something like a cymbal crash,

118
00:07:52.727 --> 00:07:57.418
with the red band here what I'm doing
is I'm taking some starting point and

119
00:07:57.418 --> 00:08:02.567
some ending point, and averaging the whole
signal between those sort of points.

120
00:08:02.567 --> 00:08:06.919
So within everything within that red band
I'm taking the average signal of it and

121
00:08:06.919 --> 00:08:09.229
mapping that to the size
of the red circle.

122
00:08:09.229 --> 00:08:12.759
And then doing the same for the blue
band and the same for the green band.

123
00:08:12.759 --> 00:08:15.786
And that's gonna be the kind of code
we're gonna to be looking at here in

124
00:08:15.786 --> 00:08:16.501
the next demos.

125
00:08:19.539 --> 00:08:22.802
I have a little tool which is
I've found it quite useful.

126
00:08:22.802 --> 00:08:27.644
It's modeled based on a filter
that is an Ableton Live.

127
00:08:27.644 --> 00:08:32.775
It's called spectrum.search.sh,
and what it does is it

128
00:08:32.775 --> 00:08:39.458
visualizes with an audio spectrum like
an analyzer node using Web Audio API.

129
00:08:39.458 --> 00:08:43.811
And it gives us back the frequency graph
for any audio file that we pass into it.

130
00:08:43.811 --> 00:08:48.436
So, for example,
I'll just open up our source audio, and

131
00:08:48.436 --> 00:08:53.170
I'll just put in this piano track here,
drag and drop it in.

132
00:08:53.170 --> 00:08:58.500
And it will play the audio, and
show the graph as it plays.

133
00:08:58.500 --> 00:09:04.695
[MUSIC]

134
00:09:04.695 --> 00:09:09.660
And so something here on the bottom left
to note is that you can move your mouse

135
00:09:09.660 --> 00:09:13.090
around and
see the frequency at where your mouse is.

136
00:09:13.090 --> 00:09:16.017
So, here on the left is
low frequency sounds,

137
00:09:16.017 --> 00:09:20.457
you can hear this piano track is not
too high and low frequency sounds.

138
00:09:20.457 --> 00:09:28.079
It's really sort of the signal is
very high in this middle range,

139
00:09:28.079 --> 00:09:34.192
between 170 hertz to
around 1.5k kilohertz.

140
00:09:34.192 --> 00:09:39.988
And you can actually hear, if you listen
to the sound, as the piano notes are being

141
00:09:39.988 --> 00:09:45.371
hit, the person who's playing the piano
is going up and down the keyboard.

142
00:09:45.371 --> 00:09:50.173
And you can see that signal is pumping in
a way that you can actually sort of see

143
00:09:50.173 --> 00:09:52.059
the different frequencies.

144
00:09:52.059 --> 00:09:55.152
[MUSIC]

145
00:09:55.152 --> 00:10:01.289
So, one of the interesting things actually
with frequency that I think is kinda

146
00:10:01.289 --> 00:10:07.993
cool is that, if you put your mouse let's
say on the 440 hertz here, this one here.

147
00:10:07.993 --> 00:10:11.876
This band here represents the note C.

148
00:10:11.876 --> 00:10:15.299
And so when we're talking about music, and

149
00:10:15.299 --> 00:10:19.278
talking about different
notes in music like C, D,

150
00:10:19.278 --> 00:10:23.914
A, etc., those are just
representations of frequency.

151
00:10:23.914 --> 00:10:27.599
And so C is represented,
depending on the tuning and

152
00:10:27.599 --> 00:10:32.229
things like that, but
generally we represent C as 440 hertz.

153
00:10:32.229 --> 00:10:36.112
And so
if you hear a constant 440 hertz signal,

154
00:10:36.112 --> 00:10:40.835
you're hearing something in the note of C,
or in pitch of C.

155
00:10:40.835 --> 00:10:45.334
And I just find that really interesting
that we're just labeling these notes

156
00:10:45.334 --> 00:10:48.806
are really just frequencies
they're hearing to our ears.

157
00:10:48.806 --> 00:10:52.712
And based on that you can actually
start to get some kind of accurate

158
00:10:52.712 --> 00:10:57.459
visualizations based on different notes
that are being played if you're able to

159
00:10:57.459 --> 00:10:58.387
capture that.

160
00:10:58.387 --> 00:11:01.610
One more thing here is that
the vertical axis of your mouse is

161
00:11:01.610 --> 00:11:03.031
giving you the decibels.

162
00:11:03.031 --> 00:11:06.923
So, you can actually even find out,
let's say,

163
00:11:06.923 --> 00:11:12.219
let's say you want to visualize
something between this band here.

164
00:11:12.219 --> 00:11:17.808
You might know that it's always going
from the maximum for negative 30 decibels

165
00:11:17.808 --> 00:11:22.763
to the minimum around negative 70
decibels, or maybe a little lower.

166
00:11:22.763 --> 00:11:27.246
And so you can just look within that
range and sort of shape the wave, and

167
00:11:27.246 --> 00:11:30.708
shape the data that you're
getting to be within that.

168
00:11:30.708 --> 00:11:33.273
[MUSIC]

