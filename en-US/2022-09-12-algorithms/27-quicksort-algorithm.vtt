WEBVTT

1
00:00:00.470 --> 00:00:05.106
So now, we're actually to the end
of the ArrayList section.

2
00:00:05.106 --> 00:00:09.643
Actually, for real, this is it,
we're gonna do one last algorithm, and

3
00:00:09.643 --> 00:00:10.443
that's it.

4
00:00:10.443 --> 00:00:14.052
So hopefully,
we all feel pretty dang good about this.

5
00:00:14.052 --> 00:00:18.127
Remember, you may have forgotten, but
I said we're gonna do two sorts, right?

6
00:00:18.127 --> 00:00:20.857
We're gonna do bubble sort,
now we're doing it, we're doing it.

7
00:00:20.857 --> 00:00:22.597
And two, QuickSort.

8
00:00:22.597 --> 00:00:25.874
QuickSort is a fantastic algorithm,
it's shockingly simple, and

9
00:00:25.874 --> 00:00:29.728
at the same time it's shockingly brilliant
how someone could come up with this.

10
00:00:29.728 --> 00:00:31.975
To me, it just blows my mind.

11
00:00:31.975 --> 00:00:34.359
I don't think I could come
up with it by myself.

12
00:00:34.359 --> 00:00:38.229
But whoever did it, maybe the constraints
of having a really slow CPU would have

13
00:00:38.229 --> 00:00:41.779
made me come up with this, but
I just didn't have that problem, right?

14
00:00:41.779 --> 00:00:43.704
I've been born in the gigahertz days,
right?

15
00:00:43.704 --> 00:00:45.874
Kinda makes you forget
how great things are.

16
00:00:45.874 --> 00:00:49.650
There's actually an algorithm
technique known as Divide and Conquer.

17
00:00:49.650 --> 00:00:53.424
So normally in algorithm's book, often
you'll see Merge Sort as the one they use,

18
00:00:53.424 --> 00:00:56.612
but this one we're gonna use QuickSort,
cuz I wanted to be different,

19
00:00:56.612 --> 00:00:58.863
you can go read about
someone else's Merge Sort.

20
00:00:58.863 --> 00:01:02.795
That way you have more breadth
of things people explain.

21
00:01:02.795 --> 00:01:04.072
So what is Divide and Conquer?

22
00:01:04.072 --> 00:01:07.385
Effectively, divide and conquering
is to be able to split your input

23
00:01:07.385 --> 00:01:11.112
into two chunks, three chunks,
four chunks, whatever that splitting is.

24
00:01:11.112 --> 00:01:15.795
And then be able to go over those
smaller subsets and solve things faster.

25
00:01:15.795 --> 00:01:19.383
Then you could resplit it again, and
resplit it again, and resplit it again.

26
00:01:19.383 --> 00:01:22.078
It becomes something in which
progressively gets smaller and

27
00:01:22.078 --> 00:01:24.511
smaller until it gets to some
sort of fundamental unit,

28
00:01:24.511 --> 00:01:26.185
in which you can solve really easily.

29
00:01:26.185 --> 00:01:30.989
So think about sorting,
an array of one element is always sorted.

30
00:01:30.989 --> 00:01:34.038
So that would be,
say the fundamental unit in Merge Sort,

31
00:01:34.038 --> 00:01:37.040
is once you get down to that point,
your array is sorted.

32
00:01:37.040 --> 00:01:41.408
Now, we need to just do the Undo function,
which involves merging, hence the name,

33
00:01:41.408 --> 00:01:42.084
Merge Sort.

34
00:01:42.084 --> 00:01:45.724
All right, there are a bunch of
different algorithm strategies.

35
00:01:45.724 --> 00:01:48.806
I didn't technically really name any
of the algorithm strategies as we go,

36
00:01:48.806 --> 00:01:49.586
there's greedy.

37
00:01:49.586 --> 00:01:51.632
So linear search is a greedy search.

38
00:01:51.632 --> 00:01:54.331
We go until we find the first one,
we're done.

39
00:01:54.331 --> 00:01:56.086
There's also dynamic programming.

40
00:01:56.086 --> 00:01:59.049
[SOUND] Dynamic programming
is one of those things that,

41
00:01:59.049 --> 00:02:01.959
until you really get it,
it's really, really hard.

42
00:02:01.959 --> 00:02:06.341
And for whatever reason, almost every
single company asks you the same,

43
00:02:06.341 --> 00:02:09.814
if you had a stock chart,
what is the best day to invest in?

44
00:02:09.814 --> 00:02:12.227
Which is just a dynamic
programming problem.

45
00:02:12.227 --> 00:02:13.556
It's very annoying.

46
00:02:13.556 --> 00:02:18.157
All right, so first,
we're gonna go over QuickSort algorithm,

47
00:02:18.157 --> 00:02:20.633
it really is a super fun algorithm.

48
00:02:20.633 --> 00:02:24.236
Yeah, by far, one of my most favorite
ones, I think I've get the program.

49
00:02:24.236 --> 00:02:26.778
I have a fun story about it which
I'll go over here in a little bit.

50
00:02:26.778 --> 00:02:29.650
But for now, let's just talk QuickSort.

51
00:02:29.650 --> 00:02:33.732
All right, you liked that the like,
we can even use QuickSort.

52
00:02:33.732 --> 00:02:40.149
All right, so QuickSort works in such
a way that it divides and it conquers.

53
00:02:40.149 --> 00:02:44.423
So let's just pretend that we pick
some element out of the array.

54
00:02:44.423 --> 00:02:49.196
Doesn't really matter what the element is,
we're just gonna call it p.

55
00:02:49.196 --> 00:02:53.742
And the reason why I call it p is, often
this element is referred to as the pivot.

56
00:02:53.742 --> 00:02:56.830
And so let's just say, for
our sake we'll just make it simple.

57
00:02:56.830 --> 00:02:59.713
We pick the last item in the array.

58
00:02:59.713 --> 00:03:03.353
We pick the last item, and
then what we do is we have

59
00:03:03.353 --> 00:03:08.044
an index that hangs out over here,
and we walk our entire array.

60
00:03:08.044 --> 00:03:11.503
So then we have a second one,
that's gonna walk our entire array.

61
00:03:11.503 --> 00:03:15.463
Any element that is less than or
equal to our pivot

62
00:03:15.463 --> 00:03:20.401
will be put in the first little
runner's position, right?

63
00:03:20.401 --> 00:03:23.085
So we have that first pointer that
just starts at the beginning,

64
00:03:23.085 --> 00:03:24.734
a second one that just walks the array.

65
00:03:24.734 --> 00:03:27.021
Every time we find one that's
smaller than our pivot,

66
00:03:27.021 --> 00:03:29.666
we put it in that first position,
increment our first runner.

67
00:03:29.666 --> 00:03:32.529
So we're putting all the ones
that are smaller than,

68
00:03:32.529 --> 00:03:35.835
or equal to our pivot on one side
of the array, then our pivot,

69
00:03:35.835 --> 00:03:38.972
then all the ones that are bigger
than it on the other side.

70
00:03:38.972 --> 00:03:43.428
So, starting to kinda look like sort,
you can already see a sorted item in here.

71
00:03:43.428 --> 00:03:47.968
So eventually, what we should see is that
our first pivot should be somewhere in

72
00:03:47.968 --> 00:03:49.339
the middlish, right?

73
00:03:49.339 --> 00:03:51.108
Who knows where it's going to be?

74
00:03:51.108 --> 00:03:55.093
And everything on this side
is going to be less than or

75
00:03:55.093 --> 00:03:59.636
equal to, everything on this
side should be greater than.

76
00:03:59.636 --> 00:04:02.179
This is referred to as a weak sort.

77
00:04:02.179 --> 00:04:06.073
At this point, you'll see other data
structures tomorrow that actually take

78
00:04:06.073 --> 00:04:09.617
advantage of an idea called weak sort,
to make super fast operations.

79
00:04:09.617 --> 00:04:12.270
And so it's actually pretty cool.

80
00:04:12.270 --> 00:04:17.109
And then at this point, we need to
split our problem in twain, yes, twain.

81
00:04:17.109 --> 00:04:21.206
We are gonna take the positions
betwixt the pivot and

82
00:04:21.206 --> 00:04:25.488
the ending, and
betwixt the other side of the pivot and

83
00:04:25.488 --> 00:04:29.417
the beginning, and
we repeat the process again.

84
00:04:29.417 --> 00:04:32.012
Pick another pivot,
we'll call this one pivot 1.

85
00:04:32.012 --> 00:04:35.520
Eventually, pivot 1 will be somewhere,
say in the middle.

86
00:04:35.520 --> 00:04:40.859
And pivot 2 will be somewhere, say in
the middle, and then we'll split it again.

87
00:04:40.859 --> 00:04:46.040
Or we don't include the pivot, but
we include everything around the pivot.

88
00:04:46.040 --> 00:04:50.252
And we just keep on doing this operation
until we get to a specific case.

89
00:04:50.252 --> 00:04:55.156
Of course, you can imagine an element
of nothing, or an array of nothing, or

90
00:04:55.156 --> 00:04:58.865
an array of, say a single item,
they're always sorted.

91
00:04:58.865 --> 00:05:02.566
Once we get to that point,
we're completely sorted.

92
00:05:02.566 --> 00:05:03.169
Makes sense?

93
00:05:03.169 --> 00:05:04.340
Hopefully, it does.

94
00:05:04.340 --> 00:05:07.410
And what can we say about, say P1?

95
00:05:07.410 --> 00:05:13.925
Everything on this side is greater than
P1, but we can also say something else.

96
00:05:13.925 --> 00:05:19.831
Everything right here, it's still smaller
than or equal to our parent pivot.

97
00:05:19.831 --> 00:05:23.168
So it becomes progressively
more sorted at this point,

98
00:05:23.168 --> 00:05:25.727
progressively more sorted at this point.

99
00:05:25.727 --> 00:05:28.108
So let's kind of think of
it in a different sense,

100
00:05:28.108 --> 00:05:29.764
let's draw it in a different way.

101
00:05:29.764 --> 00:05:31.526
How I'm gonna draw it is in a tree.

102
00:05:31.526 --> 00:05:35.389
This really would help visualize
also the execution of it all.

103
00:05:35.389 --> 00:05:36.895
And from here on out,

104
00:05:36.895 --> 00:05:42.006
I'll probably be referring to this
thing as the low, one side, right?

105
00:05:42.006 --> 00:05:43.865
And the high, the other side.

106
00:05:43.865 --> 00:05:46.948
Should kind of be reminiscent
of binary search.

107
00:05:46.948 --> 00:05:48.038
But there is gonna be one difference.

108
00:05:48.038 --> 00:05:52.118
As I program and as I do things,
I'm gonna have my low be inclusive, and

109
00:05:52.118 --> 00:05:54.299
I'm gonna have my high be inclusive.

110
00:05:54.299 --> 00:05:56.689
Very unusual,
most algorithms don't do this,

111
00:05:56.689 --> 00:06:00.320
I find that this one's much easier to
be inclusive instead of exclusive.

112
00:06:00.320 --> 00:06:02.118
You'll see why as we get there,

113
00:06:02.118 --> 00:06:05.320
just remove some plus ones
that can make things tricksy.

114
00:06:05.320 --> 00:06:08.959
All right, that's Gollum for tricky.

115
00:06:08.959 --> 00:06:14.187
All right, so let's just say we
have an array that is 32 big,

116
00:06:14.187 --> 00:06:16.665
and so we have from 0 to 31.

117
00:06:16.665 --> 00:06:20.792
And we pick a pivot and
it ends up being the middle element,

118
00:06:20.792 --> 00:06:22.656
which is going to be 16.

119
00:06:22.656 --> 00:06:27.743
That means when we do it again,
we're gonna have two subarrays, right?

120
00:06:27.743 --> 00:06:30.656
And that subarray is
gonna be from 0 to 15,

121
00:06:30.656 --> 00:06:35.191
we don't include 16 cuz we've
already sorted that singular item.

122
00:06:35.191 --> 00:06:39.223
And it's going to be from 17 to 31.

123
00:06:42.139 --> 00:06:44.001
Does that make sense?

124
00:06:44.001 --> 00:06:47.393
Yeah, all right, then again,
we get the middle element.

125
00:06:47.393 --> 00:06:48.816
We can do it on both sides.

126
00:06:48.816 --> 00:06:49.714
What is the middle element here?

127
00:06:49.714 --> 00:06:51.578
24, that seems to make sense.

128
00:06:51.578 --> 00:06:55.054
I'll just keep on going down this one
side because I don't think you need to

129
00:06:55.054 --> 00:06:57.271
see both sides being created,
just repeat it.

130
00:06:57.271 --> 00:06:58.964
That means we're gonna
have to do two more.

131
00:06:58.964 --> 00:07:05.305
We're gonna have to have 1,7 and
we're going to have 9-15, right?

132
00:07:05.305 --> 00:07:08.630
Oops, I'm changing up my symbols there.

133
00:07:08.630 --> 00:07:10.046
I used a comma for whatever reason.

134
00:07:10.046 --> 00:07:11.442
All right, awesome.

135
00:07:11.442 --> 00:07:15.658
Again, we pick a pivot,
it's in the center, we do it again.

136
00:07:15.658 --> 00:07:16.988
So what is the center of this one?

137
00:07:16.988 --> 00:07:17.655
Is it 4?

138
00:07:17.655 --> 00:07:21.815
I think it's 4, and this one, we're gonna
have the center of here of 12, right?

139
00:07:21.815 --> 00:07:27.363
So that means we're
going to have 9- 11 and

140
00:07:27.363 --> 00:07:30.561
13- 15, awesome.

141
00:07:30.561 --> 00:07:34.343
Man, I'm running out of space, aren't I?

142
00:07:34.343 --> 00:07:38.540
Then we're gonna have 5,7.

143
00:07:38.540 --> 00:07:41.381
Apparently, I'm using commas every now and
then.

144
00:07:41.381 --> 00:07:45.708
Things happen, your brain just makes
new decisions as time goes on.

145
00:07:45.708 --> 00:07:51.176
And eventually, we get down to the point
where if we pick another pivot,

146
00:07:51.176 --> 00:07:57.556
we'll have 2, then we'll have 1,
1, 3, 3, 4, 4, oops, it's 4, 4.

147
00:07:57.556 --> 00:08:02.404
5, 5, 6, 7, 7, 9,

148
00:08:02.404 --> 00:08:08.060
9, 10, 11, 11, 13,

149
00:08:08.060 --> 00:08:12.921
13, 14, 15,15.

150
00:08:12.921 --> 00:08:14.243
See how that kinda broke down?

151
00:08:14.243 --> 00:08:17.134
We slowly kept dividing the array
in half and half and half.

152
00:08:17.134 --> 00:08:20.986
And eventually,
when we're at this bottom part,

153
00:08:20.986 --> 00:08:24.397
all of those pieces
are sorted at this point.

154
00:08:24.397 --> 00:08:26.968
We're done sorting, we have them all.

155
00:08:26.968 --> 00:08:30.192
And so again,
what we're seeing here is that we're

156
00:08:30.192 --> 00:08:33.271
seeing a way that we break
the problem down more and

157
00:08:33.271 --> 00:08:37.251
more to the point where everything
eventually becomes sorted.

158
00:08:37.251 --> 00:08:40.591
Obviously, everything in this
direction is less than or equal to,

159
00:08:40.591 --> 00:08:44.002
which this direction is less than or
equal to, less than or equal to.

160
00:08:44.002 --> 00:08:46.479
And so eventually,
then it becomes simply sorted.

161
00:08:46.479 --> 00:08:49.651
Then this whole thing is sorted,
then this whole thing is sorted,

162
00:08:49.651 --> 00:08:53.238
then this whole thing is sorted,
then this whole thing is sorted, right?

163
00:08:53.238 --> 00:08:56.860
It walks back up and it does the whole
sorting, and it can do it all in place,

164
00:08:56.860 --> 00:08:58.307
which is really impressive.

165
00:08:58.307 --> 00:09:01.749
Instead of having to create a bunch of
temporary structures for holding values.

166
00:09:01.749 --> 00:09:06.290
And I think that that is a very kind
of key point to this whole QuickSort

167
00:09:06.290 --> 00:09:07.086
business.

168
00:09:07.086 --> 00:09:11.368
Again, this is why we did recursion before
we did this step, is because you can see

169
00:09:11.368 --> 00:09:15.112
right away, we have this branching
factor within how we're solving.

170
00:09:15.112 --> 00:09:16.446
The branching factor is,

171
00:09:16.446 --> 00:09:20.517
of course, two, we have two branches
every single time we execute QuickSort.

172
00:09:20.517 --> 00:09:23.957
And something else you should
probably observe right away,

173
00:09:23.957 --> 00:09:27.599
which is based on this little
thing that I've drawn right here,

174
00:09:27.599 --> 00:09:30.240
we had to go over all of the input once,
right?

175
00:09:30.240 --> 00:09:35.584
Then when we were at this level, we had
to go over still all of the input, right?

176
00:09:35.584 --> 00:09:38.521
Save this one little pivot.

177
00:09:38.521 --> 00:09:42.469
Then we went over all of the input again,
save this one little,

178
00:09:42.469 --> 00:09:45.240
the couple pivots that we've now created.

179
00:09:45.240 --> 00:09:49.624
We keep having to scan the entire input
every single time until we get down to

180
00:09:49.624 --> 00:09:51.025
the very bottom level.

181
00:09:51.025 --> 00:09:55.504
Which means that we have to do n
operations all the way down to when n

182
00:09:55.504 --> 00:09:57.541
equals 1, which of course,

183
00:09:57.541 --> 00:10:01.783
is our beautiful equation of
n over 2k = 1, remember that?

184
00:10:01.783 --> 00:10:03.309
Do we all remember what that equals?

185
00:10:03.309 --> 00:10:06.205
Log N, there we go.

186
00:10:06.205 --> 00:10:13.119
Which means our running time for doing
this is going to be log N, or n log N.

187
00:10:13.119 --> 00:10:19.764
We scan n times, we do an n log of N,
we do a log n amount of n's.

188
00:10:19.764 --> 00:10:21.000
Yeah, there we go.

189
00:10:21.000 --> 00:10:23.726
I knew eventually we'd come out of it,
eventually I'd get there.

190
00:10:23.726 --> 00:10:25.090
But is that true?

191
00:10:25.090 --> 00:10:26.661
Is that true?

192
00:10:26.661 --> 00:10:28.422
Is that what's gonna happen?

193
00:10:28.422 --> 00:10:31.926
Does anyone see any problems
with how I kinda describe this?

194
00:10:31.926 --> 00:10:34.160
&gt;&gt; I'm thinking like,
what if you don't get in the middle?

195
00:10:34.160 --> 00:10:36.353
&gt;&gt; Boom, that is exactly it.

196
00:10:36.353 --> 00:10:40.988
QuickSort doesn't always sort quickly.

197
00:10:40.988 --> 00:10:43.335
I know, it's a very deceiving name.

198
00:10:43.335 --> 00:10:44.747
You never know what you're
gonna get out of this one.

199
00:10:44.747 --> 00:10:50.530
So, can anyone think of a condition,
based on how I've described the algorithm,

200
00:10:50.530 --> 00:10:54.513
which will actually produce
the worst possible answer?

201
00:10:54.513 --> 00:10:56.720
I'll let you go back up, and
I'll show you how I did it.

202
00:10:59.585 --> 00:11:01.835
Make it a little bit easier.

203
00:11:01.835 --> 00:11:03.439
&gt;&gt; If you started at the beginning.

204
00:11:03.439 --> 00:11:07.104
&gt;&gt; If we were right there,
yeah, so, my, perfect!

205
00:11:07.104 --> 00:11:10.332
It's ridiculous,
a reverse sorted array, right?

206
00:11:10.332 --> 00:11:14.793
If you are handed an array that goes 10,
9, 8, blah, blah, blah,

207
00:11:14.793 --> 00:11:19.563
blah, blah, down to 1, and I pick this
number, what happens to our pivot?

208
00:11:19.563 --> 00:11:22.198
Well, our pivot looks something like this,
1,

209
00:11:22.198 --> 00:11:24.534
cuz it's just hanging out there by itself.

210
00:11:24.534 --> 00:11:28.832
Cuz remember, we put everything on this
side of the array that is smaller or

211
00:11:28.832 --> 00:11:32.106
equal to it, and
then we put it at the pivot point.

212
00:11:32.106 --> 00:11:36.849
That kinda sucks,
cuz we now are sorting n- 1, right?

213
00:11:36.849 --> 00:11:41.615
Then we do it again, which is now 2,
goes over, goes over, goes over.

214
00:11:41.615 --> 00:11:44.807
It goes all the way up for
n amount of scans,

215
00:11:44.807 --> 00:11:48.376
n- 1 amount of scans,
n- 2 amount of scans.

216
00:11:48.376 --> 00:11:51.412
What's the running time of this one again?

217
00:11:51.412 --> 00:11:51.979
&gt;&gt; N squared.

218
00:11:51.979 --> 00:11:56.099
&gt;&gt; N squared, that is right,
because it follows the old

219
00:11:56.099 --> 00:12:00.599
third grader formula of n(n + 1) over 2,
fantastic.

220
00:12:00.599 --> 00:12:04.855
We have now just done that, which of
course, breaks down into the classic n

221
00:12:04.855 --> 00:12:09.531
squared over 2 + n over 2, which drop all
the constants and lower all the stuff.

222
00:12:09.531 --> 00:12:12.327
And all we get left is that, right there.

223
00:12:12.327 --> 00:12:13.135
So that's what happens.

224
00:12:13.135 --> 00:12:16.986
So QuickSort is not just simply n log n,

225
00:12:16.986 --> 00:12:21.669
it can also be n squared,
which totally sucks.

226
00:12:21.669 --> 00:12:22.746
That's not what you want.

227
00:12:22.746 --> 00:12:24.700
And so there are some strategies.

228
00:12:24.700 --> 00:12:27.726
One of the big strategies is
always pick the middle element.

229
00:12:27.726 --> 00:12:30.669
If it's reverse sorted,
you should get perfect bisecting.

230
00:12:30.669 --> 00:12:37.547
If it's sorted, you should get zero swaps.

231
00:12:37.547 --> 00:12:38.932
If it's just completely random,

232
00:12:38.932 --> 00:12:42.044
you'll have a random chance of being
somewhere nearest the middle, right?

233
00:12:42.044 --> 00:12:43.180
I think over time,

234
00:12:43.180 --> 00:12:48.160
you'll probably fall within a certain
middle region more often than the fringes.

235
00:12:48.160 --> 00:12:52.497
I'm pretty sure everything usually always
ends up being a normally distributed

236
00:12:52.497 --> 00:12:56.335
function, but you'll get somewhere
in this n log n to n squared range.

237
00:12:56.335 --> 00:12:58.657
So this is why QuickSort is kinda tricky.

238
00:12:58.657 --> 00:13:03.258
If you read about Merge Sort and
you see it, it always does n log n time.

239
00:13:03.258 --> 00:13:07.565
But the constant in front of Merge Sort is
rather large, because it has to do this

240
00:13:07.565 --> 00:13:12.262
whole array copying, kinda moving things
around, type item that isn't necessarily

241
00:13:12.262 --> 00:13:15.512
the most conducive to high speed,
low memory algorithms.

242
00:13:15.512 --> 00:13:19.764
And so QuickSort is often the one that
is reached for, that does really, really

243
00:13:19.764 --> 00:13:24.221
well, but it can have poor performance,
if you just hit all the right conditions.

244
00:13:24.221 --> 00:13:28.180
Again, the chances of you hitting
all the right conditions all the way

245
00:13:28.180 --> 00:13:31.824
through to get n squared is
exceptionally low, I would assume.

246
00:13:31.824 --> 00:13:35.724
So, it's somewhere between
n log n best case,

247
00:13:35.724 --> 00:13:40.026
n squared worst case,
somewhere in betwixt there.

248
00:13:40.026 --> 00:13:42.531
So, pretty fun one,
it's kinda interesting one.

249
00:13:42.531 --> 00:13:44.939
It's one that you can't really
fit into a running time,

250
00:13:44.939 --> 00:13:47.560
which I think just makes it more
fun in general to learn about.

