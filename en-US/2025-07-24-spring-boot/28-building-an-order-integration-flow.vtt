WEBVTT

1
00:00:00.320 --> 00:00:02.720
&gt;&gt; Josh Long: So let's actually take
a look at a simple example here.

2
00:00:02.720 --> 00:00:05.680
And I've actually got the example
in the source code here.

3
00:00:05.680 --> 00:00:08.280
Okay, and
it's a pretty trivial example, I think.

4
00:00:08.280 --> 00:00:12.320
I'm pretty sure I put
the JSON config files.

5
00:00:12.320 --> 00:00:13.200
Let me see if I did.

6
00:00:13.200 --> 00:00:14.834
So it's called Messaging integration, and

7
00:00:14.834 --> 00:00:17.120
I'm going to call it
Enterprise Integration Patterns, EIP.

8
00:00:18.720 --> 00:00:22.240
I should have a folder
also in that root folder.

9
00:00:22.240 --> 00:00:23.560
It's called Purchase Orders.

10
00:00:23.560 --> 00:00:27.810
It's just a bunch of JSON files
that I had CHATGPT generate for me.

11
00:00:27.810 --> 00:00:28.730
Okay, there you go.

12
00:00:28.730 --> 00:00:32.530
So it's just a bunch of nonsense
JSON files, just purchase orders.

13
00:00:32.530 --> 00:00:36.203
So we're going to build a system to look
for those purchase orders, process them,

14
00:00:36.203 --> 00:00:40.130
do something with them, split them up,
aggregate them, and then write them out.

15
00:00:40.130 --> 00:00:41.809
Are you gonna ship this
to production tomorrow?

16
00:00:41.809 --> 00:00:45.730
Probably not, but you'll have the
foundations that you could use to do so.

17
00:00:45.730 --> 00:00:48.191
Okay, so let me close this out here.

18
00:00:48.191 --> 00:00:50.410
Goodbye, Kafka, go back to the lab again.

19
00:00:50.410 --> 00:00:52.330
Start that Spring IO.

20
00:00:52.330 --> 00:00:54.090
And we're going to be using.

21
00:00:55.130 --> 00:00:59.450
I guess just let's use eip, okay?

22
00:00:59.450 --> 00:01:00.730
We're gonna use spring integration.

23
00:01:00.730 --> 00:01:03.210
We're going to use the web support and
maybe we use.

24
00:01:03.210 --> 00:01:04.210
I don't know what we want to use.

25
00:01:04.210 --> 00:01:04.730
I guess that's it.

26
00:01:04.730 --> 00:01:06.410
Let's just use Spring
integration in the web support.

27
00:01:07.450 --> 00:01:12.250
Hit enter, uao eip.zip.

28
00:01:15.050 --> 00:01:20.820
Okay, remember, the nice thing about
this is no golf games required.

29
00:01:20.820 --> 00:01:25.140
This will work in your machine, in your
infrastructure tonight if you wanted to.

30
00:01:25.140 --> 00:01:27.060
You don't have to schedule a meeting.

31
00:01:27.060 --> 00:01:29.060
So what are we going to do again?

32
00:01:29.060 --> 00:01:31.060
You're defining an integration flow,
right?

33
00:01:31.060 --> 00:01:35.136
That's the thing that arranges the
sequence of steps that you're trying to

34
00:01:35.136 --> 00:01:36.260
achieve, okay?

35
00:01:36.260 --> 00:01:39.620
And our integration flow is going
to be an order integration flow.

36
00:01:39.620 --> 00:01:42.910
It's going to handle purchase orders,
that kind of thing.

37
00:01:42.910 --> 00:01:44.590
Nothing particularly interesting there.

38
00:01:44.590 --> 00:01:47.630
Just a very generic kind of thing.

39
00:01:47.630 --> 00:01:51.070
The way you typically do it is
you do integration flow from.

40
00:01:51.070 --> 00:01:54.670
Well, what's the from going to be?

41
00:01:54.670 --> 00:01:58.669
So you could put the inbound
adapter here directly, right?

42
00:01:58.669 --> 00:02:00.030
And I'm going to use files.

43
00:02:00.030 --> 00:02:01.950
That's gonna be my inbound domain.

44
00:02:01.950 --> 00:02:04.910
So you don't need to install anything
in particular to make this work.

45
00:02:04.910 --> 00:02:08.263
I'm going to do spring integration and

46
00:02:08.263 --> 00:02:13.200
I'm going to add spring integration file,
okay?

47
00:02:13.200 --> 00:02:15.600
And again,
that could add spring integration Kafka.

48
00:02:15.600 --> 00:02:17.480
I could add spring integration Pulsar.

49
00:02:17.480 --> 00:02:20.226
I could add spring integration mongodb.

50
00:02:20.226 --> 00:02:24.160
Or whatever, I mean, there's all
sorts of modules you can add here.

51
00:02:24.160 --> 00:02:26.720
And then I'm going to.

52
00:02:26.720 --> 00:02:27.680
Let's keep it simple.

53
00:02:27.680 --> 00:02:30.560
We'll do the files inbound adapter.

54
00:02:30.560 --> 00:02:37.770
Okay, so file.inbound adapter.

55
00:02:37.770 --> 00:02:40.570
And I'm going to look at
a directory of purchase orders.

56
00:02:40.570 --> 00:02:42.330
So that directory is.

57
00:02:42.330 --> 00:02:44.001
Let me make my life
a little bit easier here.

58
00:02:44.001 --> 00:02:49.641
I'm gonna cheat, copy -r
-/Desktop/frontend/messaging-integration/-

59
00:02:49.641 --> 00:02:52.410
purchase-orders, okay?

60
00:02:52.410 --> 00:02:56.730
-/Desktop/po, nope, that's not right.

61
00:02:56.730 --> 00:02:58.250
Just call it purchase orders.

62
00:03:00.260 --> 00:03:01.220
Okay, there we go.

63
00:03:02.820 --> 00:03:10.786
Okay,
@Value("file"://$(HOME)/Desktop/purchase--

64
00:03:10.786 --> 00:03:12.820
orders, yeah?

65
00:03:14.340 --> 00:03:20.100
So I'm going to inject it as a file,
good, file.

66
00:03:20.100 --> 00:03:24.260
And I'll tell it I want to create
the directory if it doesn't exist, okay?

67
00:03:24.260 --> 00:03:27.930
And then that's it,
that's the inbed adapter, okay?

68
00:03:28.970 --> 00:03:33.530
And you can see the type here is
a file inbound channel adapter spec.

69
00:03:33.530 --> 00:03:36.490
But basically,
ultimately it's an adapter of some sort.

70
00:03:36.490 --> 00:03:37.690
Files inbound adapter.

71
00:03:37.690 --> 00:03:38.650
And I'm going to handle it.

72
00:03:38.650 --> 00:03:40.649
I'll say new generic handler and

73
00:03:40.649 --> 00:03:44.010
I'm going to get a object of
type file there by default.

74
00:03:45.370 --> 00:03:49.209
So the output, the thing that we
get as a result of the inbound

75
00:03:49.209 --> 00:03:52.900
adapter is going to be
a Java I O file object.

76
00:03:52.900 --> 00:03:53.540
What can I do with that?

77
00:03:53.540 --> 00:03:54.340
Well, I can't.

78
00:03:54.340 --> 00:03:55.220
I mean, it's a file.

79
00:03:55.220 --> 00:03:56.980
What I want to do is
actually transform it.

80
00:03:56.980 --> 00:04:01.860
So maybe I'll do a new file to string,
right, FileToString.

81
00:04:01.860 --> 00:04:03.140
Yeah, transformer.

82
00:04:03.140 --> 00:04:04.180
Do that.

83
00:04:04.180 --> 00:04:06.245
Now, the inbound component type for

84
00:04:06.245 --> 00:04:09.180
this is a string because
I've just transformed it.

85
00:04:09.180 --> 00:04:11.660
Right, so file string.

86
00:04:11.660 --> 00:04:13.140
And now I'm dealing with a string.

87
00:04:13.140 --> 00:04:14.156
And I'm just.

88
00:04:14.156 --> 00:04:17.069
Whenever you wanna do
a generic sort of intercept,

89
00:04:17.069 --> 00:04:21.420
if you wanna just kind of look at what's
going on here, use a handle, okay?

90
00:04:21.420 --> 00:04:22.540
So I'm creating these components.

91
00:04:22.540 --> 00:04:24.300
I'm stitching them together, okay?

92
00:04:24.300 --> 00:04:26.766
So let's just try confirming
that this has worked.

93
00:04:26.766 --> 00:04:31.820
And I'm actually dealing with
stuff here correctly, okay?

94
00:04:31.820 --> 00:04:32.860
So system out.

95
00:04:34.460 --> 00:04:35.180
There we go.

96
00:04:35.180 --> 00:04:36.580
This becomes a lambda.

97
00:04:36.580 --> 00:04:37.420
Of course it does.

98
00:04:37.420 --> 00:04:38.380
I'm going to start this up.

99
00:04:38.380 --> 00:04:39.340
Let's see what it gives us.

100
00:04:40.380 --> 00:04:42.940
It should give us a lot of messages.

101
00:04:42.940 --> 00:04:45.540
Unless I have typed it incorrectly.

102
00:04:45.540 --> 00:04:47.220
I did, awkward.

103
00:04:47.220 --> 00:04:48.980
Okay, take five.

104
00:04:48.980 --> 00:04:51.540
And now that since I typed it incorrectly,
I'll have this.

105
00:04:52.740 --> 00:04:53.660
Wait, do I have.

106
00:04:53.660 --> 00:04:54.340
This is wrong.

107
00:04:55.540 --> 00:04:56.500
And that's wrong.

108
00:04:57.860 --> 00:04:59.100
It's because I did this wrong.

109
00:04:59.100 --> 00:04:59.780
So here we go.

110
00:05:02.660 --> 00:05:05.620
Okay, good.

111
00:05:05.620 --> 00:05:06.140
Take five.

112
00:05:06.140 --> 00:05:07.380
112, restart.

113
00:05:08.500 --> 00:05:13.110
Okay, and do we have data in there?

114
00:05:13.110 --> 00:05:14.510
We don't have data in there either.

115
00:05:14.510 --> 00:05:15.950
Okay, so let me see.

116
00:05:15.950 --> 00:05:19.888
Copy
-/Desktop/frontend-masters/messaging-inte-

117
00:05:19.888 --> 00:05:25.590
gration/purchase-orders, all that
goes into -/Desktop/frontend-master.

118
00:05:25.590 --> 00:05:28.110
No, -/Desktop/purchase-orders.

119
00:05:29.310 --> 00:05:32.790
Okay, so this is gonna cause
my application to freak out.

120
00:05:32.790 --> 00:05:37.045
You see that it's going to
deliver one message per second.

121
00:05:37.045 --> 00:05:43.310
So the question then is, how did it know
when to consume the messages, right?

122
00:05:43.310 --> 00:05:46.030
So file systems don't tell
you when something is done.

123
00:05:46.030 --> 00:05:48.350
You have to ask, you have to pull.

124
00:05:48.350 --> 00:05:51.190
Okay, some things can tell
you when something is done.

125
00:05:51.190 --> 00:05:56.550
So for example, POP is an email protocol.

126
00:05:56.550 --> 00:05:59.535
You have to pull imap.

127
00:05:59.535 --> 00:06:03.090
You can establish a socket and
it'll push, right?

128
00:06:03.090 --> 00:06:05.170
But the problem is you're
keeping a network socket open.

129
00:06:05.170 --> 00:06:06.450
It's bad for battery.

130
00:06:06.450 --> 00:06:10.290
So a lot of the old blackberries and
trios for example, would be like.

131
00:06:10.290 --> 00:06:11.690
We support both, right?

132
00:06:11.690 --> 00:06:14.141
If you want, if you don't mind,
if you want your,

133
00:06:14.141 --> 00:06:17.961
if you gotta get that email right now,
we can open up an imac connection for you,

134
00:06:17.961 --> 00:06:21.690
but warning your trio will run out of
battery in 20% less time or whatever.

135
00:06:21.690 --> 00:06:23.050
You know, something like that, right?

136
00:06:23.050 --> 00:06:26.688
So if you don't mind opening up a socket
and keeping a connection, IMAP is gonna

137
00:06:26.688 --> 00:06:31.340
give you instantaneous notifications when
there's a new email pop you have to pull.

138
00:06:31.340 --> 00:06:32.808
This is a discussion you have to have for

139
00:06:32.808 --> 00:06:34.820
every protocol with which
you integrate databases.

140
00:06:34.820 --> 00:06:37.660
You want to query a SQL database
whenever there's a new message.

141
00:06:37.660 --> 00:06:41.456
Databases don't push, except for postgres,
which has an extension, which is weird,

142
00:06:41.456 --> 00:06:42.700
but ignore that.

143
00:06:42.700 --> 00:06:43.900
Databases don't push.

144
00:06:43.900 --> 00:06:45.340
Messaging Queues do though.

145
00:06:45.340 --> 00:06:49.100
RabbitMQ, Pulsar, Kafka, they can all
tell you when something has changed.

146
00:06:49.100 --> 00:06:51.782
So that's a distinction that
you have to understand and

147
00:06:51.782 --> 00:06:54.140
care about in the inbound adapter.

148
00:06:54.140 --> 00:06:57.280
In this case, the file system does
not push, you have to pull it.

149
00:06:57.280 --> 00:07:00.173
So by default, if it requires polling,

150
00:07:00.173 --> 00:07:04.760
spring negation will poll P O L L,
not P U L L every one second.

151
00:07:04.760 --> 00:07:06.120
But you can control that.

152
00:07:06.120 --> 00:07:08.320
You can configure the poller here.

153
00:07:08.320 --> 00:07:11.396
So I'm gonna say pm., let's say,

154
00:07:11.396 --> 00:07:15.880
every Tuesday I could do
a crime expression, right?

155
00:07:15.880 --> 00:07:17.880
Every Tuesday at noon I'm
going to pull the messages.

156
00:07:17.880 --> 00:07:20.584
Or I can do a quant expression,

157
00:07:20.584 --> 00:07:25.370
or I can do a fixed rate dot,
fixed delay or fixed rate.

158
00:07:25.370 --> 00:07:28.690
So every 1,000.

159
00:07:28.690 --> 00:07:29.730
Every 1,000 what?

160
00:07:29.730 --> 00:07:34.050
Well, every 1,000 durations.

161
00:07:34.050 --> 00:07:41.410
So actually duration of minutes there,
I can now pull one every minute.

162
00:07:41.410 --> 00:07:43.757
So you have full control
over the frequency and

163
00:07:43.757 --> 00:07:45.450
the way that the polling is done.

164
00:07:45.450 --> 00:07:46.690
But by default it's one second.

165
00:07:46.690 --> 00:07:50.893
So even though the embed adapter did a
sweep of that directory and it said, hey,

166
00:07:50.893 --> 00:07:54.406
there's a dozen files here,
it knows about all dozen of them, but

167
00:07:54.406 --> 00:07:57.510
it's not giving you all 12
of them at the same time.

168
00:07:57.510 --> 00:07:58.870
It's buffering.

169
00:07:58.870 --> 00:08:02.187
So it gives you one message every
second because that's the puller.

170
00:08:02.187 --> 00:08:05.590
So it means that this is a staged
event driven architecture already.

171
00:08:05.590 --> 00:08:08.301
The whole point of staged event driven
architecture is you have a bunch of

172
00:08:08.301 --> 00:08:09.270
steps in a sequence.

173
00:08:09.270 --> 00:08:11.670
Each of those steps might get overwhelmed.

174
00:08:11.670 --> 00:08:14.530
So you serialize the results
that go into those things.

175
00:08:14.530 --> 00:08:18.173
They get absorbed by the intrinsic
buffering nature of the thing in that

176
00:08:18.173 --> 00:08:20.930
component and
then they get delivered onward.

177
00:08:20.930 --> 00:08:24.437
So when you do true pipes and filters,
staged event driven architecture,

178
00:08:24.437 --> 00:08:26.450
you use something like Kafka or RabbitMQ.

179
00:08:26.450 --> 00:08:30.314
You send a message to Kafka, deliver it
to a component, process it, deliver it to

180
00:08:30.314 --> 00:08:34.210
Kafka, deliver it to a component,
process it, et cetera, et cetera.

181
00:08:34.210 --> 00:08:36.410
Okay, so this is easy.

182
00:08:36.410 --> 00:08:37.050
I got the data.

183
00:08:37.050 --> 00:08:40.490
Yeah, not very interesting though,
but it's a pretty simple example.

184
00:08:40.490 --> 00:08:45.829
So what I want to do now is actually
turn this JSON into a Java object.

185
00:08:45.829 --> 00:08:50.189
And I happen to have three Java objects
that I've taken the time because I care.

186
00:08:50.189 --> 00:08:52.709
I've pre written these six lines of code.

187
00:08:52.709 --> 00:08:56.709
Now I don't want to do these lines
of code live because also I care.

188
00:08:56.709 --> 00:09:02.349
So these are Java objects that I can use
to map that JSON into a domain model.

189
00:09:02.349 --> 00:09:07.492
So purchase order, which in turn has
a set of line items and the line items,

190
00:09:07.492 --> 00:09:12.000
we don't need this just yet
will eventually be turned into that.

191
00:09:12.000 --> 00:09:14.600
So these are the two domain
models that can map our JSON.

192
00:09:15.720 --> 00:09:20.082
So what we're going to do is we're going
to say new file to string transformer and

193
00:09:20.082 --> 00:09:22.135
then we'll do a transform yet again,

194
00:09:22.135 --> 00:09:25.240
new JSON to object transformer
purchase order .class.

195
00:09:26.520 --> 00:09:30.200
So now when I get down to this point,
the payload is a purchase order.

196
00:09:32.040 --> 00:09:36.248
So if I do payload, dot,
line items, foreach,

197
00:09:36.248 --> 00:09:41.090
et cetera, let me make sure
this is a little bit longer.

198
00:09:44.530 --> 00:09:45.410
Okay, there you go.

199
00:09:45.410 --> 00:09:47.490
So you can see line item.

200
00:09:47.490 --> 00:09:52.210
Okay, stop, line item, sku,
line item, blah, blah, blah.

201
00:09:52.210 --> 00:09:54.710
So now I've read data in from
these files and I'm processing,

202
00:09:54.710 --> 00:09:56.180
I'm also printing out the headers.

203
00:09:56.180 --> 00:09:59.016
Notice that each envelope,
each message has a payload,

204
00:09:59.016 --> 00:10:01.911
which is the type that we've converted,
and some headers

205
00:10:01.911 --> 00:10:05.830
that give you the out of band information
about the payload, the origin of it.

206
00:10:05.830 --> 00:10:08.052
Like in the case of the file,
since it's a file,

207
00:10:08.052 --> 00:10:11.590
you can see there's a header called
file name and the original file name.

208
00:10:11.590 --> 00:10:14.668
So if I wanted to print that out,

209
00:10:14.668 --> 00:10:19.350
I could say headers,
get file, original file.

210
00:10:19.350 --> 00:10:21.190
Okay, system out.

211
00:10:21.190 --> 00:10:21.830
There you go.

212
00:10:23.350 --> 00:10:24.630
Let me just copy and paste it.

213
00:10:24.630 --> 00:10:25.750
Typing.
Not my thing.

214
00:10:27.190 --> 00:10:28.150
Okay, there we go.

215
00:10:30.870 --> 00:10:33.910
So here's the original file.

216
00:10:33.910 --> 00:10:35.394
These are out of band information,

217
00:10:35.394 --> 00:10:38.790
supplementary information that
are included in the body of the request.

218
00:10:38.790 --> 00:10:41.750
See that headers purchase order.

219
00:10:41.750 --> 00:10:45.305
Okay, so I've taken the string, turned
it into an object, taken the object,

220
00:10:45.305 --> 00:10:46.590
I've got purchase orders.

221
00:10:46.590 --> 00:10:47.630
What can I do with it now?

222
00:10:47.630 --> 00:10:50.070
Well, I mean just about anything, right?

223
00:10:50.070 --> 00:10:54.070
Maybe I want to split it along
the lines of the line items.

224
00:10:54.070 --> 00:10:55.670
So this is a payload.

225
00:10:55.670 --> 00:10:58.038
If you have a component
here that returns null,

226
00:10:58.038 --> 00:11:00.870
that will stop the subsequent
execution of the flow.

227
00:11:00.870 --> 00:11:04.550
So I'm going to use payload, I'll continue
the flow and I'm going to split it.

228
00:11:04.550 --> 00:11:06.190
And so I have to tell it how to split.

229
00:11:06.190 --> 00:11:10.589
I'm going to say given
a type of purchase order,

230
00:11:10.589 --> 00:11:16.390
I want to take that and
return some data here, right?

231
00:11:16.390 --> 00:11:18.230
I guess I could do line items.

232
00:11:18.230 --> 00:11:19.190
I mean, you could do that, right?

233
00:11:19.190 --> 00:11:23.068
And then now at the end of that,
if you do this,

234
00:11:23.068 --> 00:11:29.143
if you do a generic handler here,
what you've got is a line item object.

235
00:11:29.143 --> 00:11:37.050
And then I can print out got
line item payload, good.

236
00:11:37.050 --> 00:11:37.850
So run that.

237
00:11:40.970 --> 00:11:41.530
So there you go.

238
00:11:41.530 --> 00:11:44.066
You can see now I'm getting a chance
to process each one of these and

239
00:11:44.066 --> 00:11:44.890
you can do subflows.

240
00:11:44.890 --> 00:11:45.560
This could be.

241
00:11:45.560 --> 00:11:46.280
I split it here.

242
00:11:46.280 --> 00:11:48.400
Now I've got a separate
flow that's branching out.

243
00:11:48.400 --> 00:11:51.937
I can do a subflow where I actually call
another integration flow where I say,

244
00:11:51.937 --> 00:11:55.422
okay, send it to Kafka, wait for the thing
to come back and then process it,

245
00:11:55.422 --> 00:11:56.680
that kind of thing.

246
00:11:56.680 --> 00:12:00.753
So split, and then of course, once I've
handled it, I can process the data,

247
00:12:00.753 --> 00:12:03.560
move that back again, and
then you can do aggregate.

248
00:12:03.560 --> 00:12:05.960
And then you should at the end of this.

249
00:12:07.080 --> 00:12:11.869
And the way it's doing the aggregation is
of course it's got headers that tell it

250
00:12:11.869 --> 00:12:17.020
you this is message 1 of 2 or 1 of 5 or
whatever it was when you did the split.

251
00:12:17.020 --> 00:12:18.620
So system out.

252
00:12:18.620 --> 00:12:22.460
Final payload is this.

253
00:12:24.860 --> 00:12:25.900
So the final payload.

254
00:12:25.900 --> 00:12:27.768
Stop it, stop, there we go.

255
00:12:27.768 --> 00:12:32.228
Final payload is this,
it's a list of line items,

256
00:12:32.228 --> 00:12:36.140
it's aggregated the original ones back.

257
00:12:36.140 --> 00:12:37.260
So you did the split.

258
00:12:37.260 --> 00:12:39.980
I could have transformed
them along the way.

259
00:12:39.980 --> 00:12:40.740
I didn't in this case.

260
00:12:40.740 --> 00:12:44.180
But in this case, I split the purchase
order into a bunch of line items.

261
00:12:44.180 --> 00:12:47.670
I could have transformed the line items
into a network call or a status check or

262
00:12:47.670 --> 00:12:48.780
something like that.

263
00:12:48.780 --> 00:12:51.871
Then I aggregated all the messages
back into one aggregate,

264
00:12:51.871 --> 00:12:55.819
which gave me all the split off line
items back together in one list.

265
00:12:55.819 --> 00:12:56.940
So I started back where I started.

266
00:12:56.940 --> 00:13:00.300
So this is basic integration flow 101.

267
00:13:01.980 --> 00:13:06.151
There's a component here for
routing, for splitting, for

268
00:13:06.151 --> 00:13:10.750
control bus, for all this stuff,
transformations, et cetera.

