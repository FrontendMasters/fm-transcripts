WEBVTT

1
00:00:00.300 --> 00:00:04.850
Now we can learn about streams in Node.js.

2
00:00:04.850 --> 00:00:09.750
Streams are a handy way
of shuffling data around.

3
00:00:09.750 --> 00:00:14.930
So if you need to build some IO glue,
where you've got some sources of data,

4
00:00:14.930 --> 00:00:18.580
you've got some destinations
where the data needs to go.

5
00:00:18.580 --> 00:00:21.460
You've got some steps in between,
streams are pretty good fit.

6
00:00:22.590 --> 00:00:29.160
Some examples of that might be if you need
to use compression, if you need to add

7
00:00:29.160 --> 00:00:34.485
different kinds of transformations
to build the data pipeline.

8
00:00:34.485 --> 00:00:36.390
Streams are fantastic for
that kind of problem.

9
00:00:38.240 --> 00:00:40.960
Streams are a really old idea.

10
00:00:40.960 --> 00:00:46.220
This is a quote from
1964 from Doug McIlroy

11
00:00:46.220 --> 00:00:50.950
who is working on what would
become the Unix system.

12
00:00:50.950 --> 00:00:55.370
Back then it was still called Multics,
which was a group project between MIT,

13
00:00:55.370 --> 00:00:57.787
Bell Labs, and General Electric.

14
00:00:57.787 --> 00:01:01.690
But then AT&amp;T split off and
made Unix in 1869.

15
00:01:01.690 --> 00:01:06.170
But anyways, just read this quote
because it's a pretty fantastic

16
00:01:06.170 --> 00:01:10.940
idea about like chaining programs
together with pipes which is one

17
00:01:12.360 --> 00:01:15.210
of the main influences of node js streams.

18
00:01:15.210 --> 00:01:20.360
So, we should have some ways of
connecting programs like a garden hose,

19
00:01:20.360 --> 00:01:25.180
screw in another segment when it becomes
necessary to massage data in another way.

20
00:01:25.180 --> 00:01:26.770
This is the way of IO also.

21
00:01:29.070 --> 00:01:33.660
This idea is that instead of
building these like big pieces that

22
00:01:33.660 --> 00:01:39.030
will kind of like deal
with the entire data

23
00:01:39.030 --> 00:01:43.370
pipeline internally, you can split
them out into separate pieces.

24
00:01:43.370 --> 00:01:46.270
That's kind of like do one thing and
do it well.

25
00:01:46.270 --> 00:01:49.930
And handoff that information to
the next piece in the pipeline,

26
00:01:49.930 --> 00:01:51.790
which is what pipes let you do in Unix.

27
00:01:51.790 --> 00:01:54.440
And it's also what the stream
implementation in Node.js

28
00:01:54.440 --> 00:01:57.010
which has a method called pipe does.

29
00:01:57.010 --> 00:01:57.650
It's very similar.

30
00:02:00.100 --> 00:02:05.270
Another great reason to use streams aside
from just the logical separation, which is

31
00:02:05.270 --> 00:02:12.000
useful, is that streams operate on data
in a kind of like piecewise manner.

32
00:02:12.000 --> 00:02:13.140
So chunk by chunk.

33
00:02:13.140 --> 00:02:18.100
So instead of having to passing very
large objects and to keep a lot of

34
00:02:18.100 --> 00:02:22.580
things in memory, with streams you can
deal with like much smaller pieces.

35
00:02:22.580 --> 00:02:26.340
So this is really useful if you have
to build something like a web server,

36
00:02:27.550 --> 00:02:32.720
where you might have to stream out
100 megabyte video file, right?

37
00:02:32.720 --> 00:02:37.330
So you wouldn't want to have to read
in the entire file and then write

38
00:02:37.330 --> 00:02:42.020
it out because maybe you have thousands of
video files or millions on your servers.

39
00:02:42.020 --> 00:02:45.420
And that would be an awful
lot of expensive RAM

40
00:02:45.420 --> 00:02:47.030
to serve up that kind of thing.

41
00:02:47.030 --> 00:02:51.880
So streams will let you pick apart those
video files chunk by chunk and only keep,

42
00:02:51.880 --> 00:02:57.330
like kilobytes or maybe like a megabyte in
main memory instead of the whole thing.

43
00:02:59.870 --> 00:03:05.440
So, in the Unix workshop I gave,
we came up with this little

44
00:03:05.440 --> 00:03:10.285
example of a downloaded Moby Dick from
Project Gutenberg, which is gzipped.

45
00:03:11.680 --> 00:03:15.730
We came up with this little pipeline
to count the number of times that whale

46
00:03:15.730 --> 00:03:17.930
was said in Moby Dick.

47
00:03:17.930 --> 00:03:22.870
And it's really a useful way of
thinking about breaking apart

48
00:03:22.870 --> 00:03:24.800
problems on the command line.

49
00:03:24.800 --> 00:03:29.190
And this is also kind of how you can
solve a lot of problems in Node.js in

50
00:03:29.190 --> 00:03:30.520
a similar way.

51
00:03:30.520 --> 00:03:35.100
So what that might look like
with some hypothetical,

52
00:03:35.100 --> 00:03:40.030
with some real and some as yet
unwritten methods, is you could use

53
00:03:40.030 --> 00:03:45.480
some methods like FSX create read stream
to read in that file chunk by chunk.

54
00:03:45.480 --> 00:03:49.236
And it would return a readable
stream that you can call .pipe on.

55
00:03:49.236 --> 00:03:53.480
And you can pipe that into createGunzip
which is a transformed stream that takes

56
00:03:53.480 --> 00:03:57.955
gzipped input as output, so compressed
input and provides uncompressed output.

57
00:03:57.955 --> 00:04:04.090
The next step might be a little
function that can split on whitespace,

58
00:04:04.090 --> 00:04:08.460
and turn those any whitespace
character into a new line.

59
00:04:08.460 --> 00:04:15.940
And then you could turn that output
into the input of a filter program,

60
00:04:15.940 --> 00:04:18.610
that would search the number
of times that you see whale.

61
00:04:18.610 --> 00:04:21.860
Then maybe you could have another thing
at the very end that just counts up

62
00:04:21.860 --> 00:04:22.900
the number of occurrences.

63
00:04:22.900 --> 00:04:26.870
So this is kind of like how you could
decompose the problem in a similar way

64
00:04:26.870 --> 00:04:29.650
with the more Node.js style interface.

65
00:04:29.650 --> 00:04:33.743
So this version in Unix this version yeah,
question?

66
00:04:33.743 --> 00:04:39.599
&gt;&gt; So all of those commands will
be running at the same time?

67
00:04:39.599 --> 00:04:42.830
&gt;&gt; They-
&gt;&gt; Or would they be sequential?

68
00:04:42.830 --> 00:04:46.874
&gt;&gt; So some of these would operate
on chunks of information.

69
00:04:46.874 --> 00:04:49.260
So like gzip, I think operates in chunks,

70
00:04:49.260 --> 00:04:54.350
I don't know maybe like 500 bytes,
a kilobyte in size.

71
00:04:54.350 --> 00:04:55.300
I'm not exactly sure.

72
00:04:56.610 --> 00:04:57.940
But basically yes,

73
00:04:57.940 --> 00:05:04.520
so every one of those steps is going
to be emitting little chunks of data.

74
00:05:04.520 --> 00:05:10.080
Sometimes they have to buffer a little
bit up to like fill up like a chunk size.

75
00:05:10.080 --> 00:05:14.030
This is especially the case with things
like compression and with encryption,

76
00:05:14.030 --> 00:05:19.210
but otherwise, yeah, things are mostly
happening all at the same time and

77
00:05:19.210 --> 00:05:21.190
sort of like feeding
through this pipeline.

78
00:05:23.080 --> 00:05:27.930
&gt;&gt; For each chunk it like goes
through each step, like one at a time.

79
00:05:27.930 --> 00:05:33.230
&gt;&gt; Yeah, each chunk, like goes in
order from one step into the next.

80
00:05:33.230 --> 00:05:36.400
Yes, just like on the command line.

81
00:05:36.400 --> 00:05:37.020
It's how it works.

82
00:05:39.350 --> 00:05:44.890
So, here's an example

83
00:05:44.890 --> 00:05:49.240
of just something that really simple
that you can try out yourself.

84
00:05:50.490 --> 00:05:53.200
So if you make a file called greets.txt or

85
00:05:53.200 --> 00:05:57.360
whatever you like,
you can just print it out.

86
00:05:57.360 --> 00:06:01.690
So this is basically the Unix cat
commands without the concatenation part,

87
00:06:01.690 --> 00:06:03.050
just print a file.

88
00:06:04.140 --> 00:06:11.790
So if we type that out,
I'll call it print.js.

89
00:06:11.790 --> 00:06:15.880
Maybe instead of hard coding the file,
I'll take the file name as an argument.

90
00:06:15.880 --> 00:06:20.820
That'll be, so
would you createReadStream, and

91
00:06:20.820 --> 00:06:23.990
then I'll read process argv2,
which is the first command

92
00:06:23.990 --> 00:06:29.250
that you specify after the node and
then the file name and then the arguments.

93
00:06:29.250 --> 00:06:32.780
And I'll call that pipe
to process.standard out.

94
00:06:34.600 --> 00:06:37.480
And now if I run this program on a file,
maybe I'll

95
00:06:38.580 --> 00:06:43.080
provide the program
itself as the input file.

96
00:06:44.390 --> 00:06:48.080
So here we go, the program prints
its own source, that's kind of fun.

97
00:06:48.080 --> 00:06:54.559
Also, if I had another file like
hello.txt, I could run that as well.

98
00:06:59.826 --> 00:07:05.150
Great, so
we're just copying input into output.

99
00:07:05.150 --> 00:07:06.511
It's all that this program does.

100
00:07:06.511 --> 00:07:07.660
It's good place to start.

