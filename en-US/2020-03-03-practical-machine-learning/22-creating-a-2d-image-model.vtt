WEBVTT

1
00:00:00.150 --> 00:00:05.190
Next, what we need to do is come
up with the model we want to use.

2
00:00:05.190 --> 00:00:10.398
And the most easiest
way to start is to use

3
00:00:10.398 --> 00:00:16.950
Keras' APIs sequentials which
I will explain in a second.

4
00:00:16.950 --> 00:00:22.632
So, we need to first import a couple
of things, so we can say from,

5
00:00:23.686 --> 00:00:28.811
tensorflow.keras.

6
00:00:31.576 --> 00:00:34.520
And then, we need to,

7
00:00:34.520 --> 00:00:39.768
it's actually a question
right in the Keras, so

8
00:00:39.768 --> 00:00:45.786
we can say from tensorflow.keras
import Sequential.

9
00:00:45.786 --> 00:00:50.940
So Sequential is the class
which will describe the type

10
00:00:50.940 --> 00:00:55.790
of the models and
why it's called sequential?

11
00:00:55.790 --> 00:01:00.630
Because our layers will
be edit sequentially,

12
00:01:00.630 --> 00:01:03.450
alternatively you can
have different models.

13
00:01:03.450 --> 00:01:08.710
Recurrent neural networks will require
almost like a recurrence into itself.

14
00:01:08.710 --> 00:01:14.000
So we're not gonna go there yet, so
we're just gonna use sequential models,

15
00:01:14.000 --> 00:01:18.330
and now we need to also import layers.

16
00:01:18.330 --> 00:01:23.965
So from TensorFlow, [LAUGH] Okay,

17
00:01:23.965 --> 00:01:28.708
it's easier to just type
without have to completion.

18
00:01:28.708 --> 00:01:34.412
So Keras and I believe it's called layers,

19
00:01:34.412 --> 00:01:42.443
we can import a particular class
called Dense and Flattened.

20
00:01:42.443 --> 00:01:47.629
So Dense, that's our fully
connected layer, meaning that with

21
00:01:47.629 --> 00:01:52.830
the Dense layer, if you have,
for instance, two layers right?

22
00:01:52.830 --> 00:01:57.905
And one of them is Dense,
pretty much all the neurons from

23
00:01:57.905 --> 00:02:05.010
the previous layers will be connected
to all the neurons of this layer.

24
00:02:05.010 --> 00:02:12.450
And Flatten, we need it because we want
to simply have our two dimensional image.

25
00:02:12.450 --> 00:02:15.840
Remember, we have 28 by
28 pixels right now,

26
00:02:15.840 --> 00:02:19.830
we want to actually flatten it
out into one dimensional array.

27
00:02:19.830 --> 00:02:25.049
Because that's gonna be our one
dimensional array feed into the model,

28
00:02:26.170 --> 00:02:28.040
does it make sense or?

29
00:02:28.040 --> 00:02:31.010
So, basically from two dimensional image,

30
00:02:31.010 --> 00:02:35.960
we are simply taking the second row and
truncating.

31
00:02:35.960 --> 00:02:42.520
Or editing it to the first 28 pixels we
got from the first row and that's it.

32
00:02:42.520 --> 00:02:45.960
So we simply creating this one long,

33
00:02:45.960 --> 00:02:51.890
specifically 784 pixels long, one array.

34
00:02:51.890 --> 00:02:56.270
And that's gonna be our input we will
be providing to our neural network,

35
00:02:56.270 --> 00:02:58.570
fully connected neural network, all right.

36
00:02:58.570 --> 00:03:03.050
So, we import those things, so

37
00:03:03.050 --> 00:03:06.458
what we need to do next is to
actually specify our model.

38
00:03:06.458 --> 00:03:11.110
So model =, and
we can just say sequential, so

39
00:03:11.110 --> 00:03:14.570
we're creating the instance
of this sequential class.

40
00:03:14.570 --> 00:03:19.680
And what we can do we can say model,
let's use add functions,

41
00:03:19.680 --> 00:03:24.040
so now we adding layers to our model.

42
00:03:24.040 --> 00:03:26.250
When I just said model sequential,

43
00:03:26.250 --> 00:03:30.340
it's just clarified what type
of model I will be having.

44
00:03:30.340 --> 00:03:34.590
But nothing about how it's
actually organized inside, so

45
00:03:34.590 --> 00:03:39.951
by using model.add for instance,
just saying I want to first, Flatten.

46
00:03:43.062 --> 00:03:46.141
And yes, I need to provide input_shape.

47
00:03:48.392 --> 00:03:53.905
Oops, shape=, and
here it will be adjust the resolution

48
00:03:53.905 --> 00:03:59.065
of my original image, so 28 by 28 pixels.

49
00:03:59.065 --> 00:04:03.486
And the result of this operation,
if I, for instance,

50
00:04:03.486 --> 00:04:08.859
just execute this right now and
do something like model.summary.

51
00:04:12.245 --> 00:04:17.710
It'll tell me what exactly happening here,
so a sequential model, right?

52
00:04:17.710 --> 00:04:21.630
In this model, I have only one layer,
a layer called flatten.

53
00:04:21.630 --> 00:04:25.890
And in the input, it will take 28 by 28,

54
00:04:25.890 --> 00:04:30.472
but as the output,
it will return simply one array with

55
00:04:30.472 --> 00:04:35.960
784 pixels.

56
00:04:35.960 --> 00:04:38.520
And the thing is we're not using
any additional parameters,

57
00:04:38.520 --> 00:04:42.010
in this layer we don't have any weights or
biases.

58
00:04:42.010 --> 00:04:46.240
It just doing the flattening
of the two dimensional array,

59
00:04:46.240 --> 00:04:49.470
that's it what's happening here.

60
00:04:49.470 --> 00:04:54.765
Right now, we're not working with data,
I'm just specifying the model and

61
00:04:54.765 --> 00:05:01.732
input_shape is telling
this layer what to expect.

62
00:05:01.732 --> 00:05:06.850
What kinda input data,
in which structure we should

63
00:05:06.850 --> 00:05:11.290
expect data to come into the model,
doesn't make sense?

64
00:05:11.290 --> 00:05:11.840
&gt;&gt; Yeah, it does.

65
00:05:11.840 --> 00:05:15.310
&gt;&gt; Okay, and the thing is
the next layer's, for instance,

66
00:05:15.310 --> 00:05:16.640
the one we're gonna be creating.

67
00:05:16.640 --> 00:05:22.390
It doesn't even need to know what
the previous layer will be printing out,

68
00:05:22.390 --> 00:05:26.350
because it will do automatically
behind the scenes for you.

69
00:05:26.350 --> 00:05:29.220
So with the sequential model,
when we print out the summary.

70
00:05:29.220 --> 00:05:34.598
You'll see that we just simply did
the transformation of this original image,

71
00:05:34.598 --> 00:05:35.780
28 by 28 pixels.

72
00:05:35.780 --> 00:05:38.800
But the thing is we haven't
provided even the images yet,

73
00:05:38.800 --> 00:05:41.640
we're just saying that that's
the input you should expect.

74
00:05:41.640 --> 00:05:46.596
Some just images 28 by 28,
two dimensional images, but

75
00:05:46.596 --> 00:05:52.827
our first flattened layer will simply
produce this one dimensional array.

76
00:05:52.827 --> 00:06:00.120
If you multiply 28 by 28, 784, that's
exactly how many elements you will have.

77
00:06:00.120 --> 00:06:02.920
And the thing is we can add more layers,
for

78
00:06:02.920 --> 00:06:06.930
instance, the next one, let's say is
gonna be fully connected neural networks.

79
00:06:06.930 --> 00:06:11.695
So we can, say, use Dense and
to the Dense we then provide

80
00:06:11.695 --> 00:06:16.579
how many neurons we want to
have in this particular layer.

81
00:06:16.579 --> 00:06:22.035
So, for Dense,
let's say we want, I don't know,

82
00:06:22.035 --> 00:06:26.747
256, so, what that means and by the way,

83
00:06:26.747 --> 00:06:31.495
we can also specify additional parameters.

84
00:06:31.495 --> 00:06:38.020
So, units, that's exactly how many
neurons you want to have, right?

85
00:06:38.020 --> 00:06:42.290
So I can exclusively instead
of specifying 256 here,

86
00:06:42.290 --> 00:06:49.770
I can say that's the number of units or
neurons I want to have in my layer.

87
00:06:49.770 --> 00:06:52.130
And there are additional
parameters you can specify, for

88
00:06:52.130 --> 00:06:54.330
instance, activation function.

89
00:06:54.330 --> 00:06:59.460
So, activation function, remember I said
that when you get all of those inputs.

90
00:06:59.460 --> 00:07:01.580
Multiplied them by the weights and

91
00:07:01.580 --> 00:07:06.550
sum that to the result,
then that's the argument to your function.

92
00:07:06.550 --> 00:07:10.810
And for instance, you can say that
activation function should be sigmoid.

93
00:07:10.810 --> 00:07:15.490
And that will simply flatten the
distribution to something between 0 and 1.

