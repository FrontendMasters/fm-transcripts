WEBVTT

1
00:00:00.000 --> 00:00:06.434
Let's kinda step back and
think about it abstractly.

2
00:00:06.434 --> 00:00:11.954
Imagine that we have
some compute blackbox,

3
00:00:11.954 --> 00:00:14.867
right, some compute.

4
00:00:16.345 --> 00:00:21.345
And it can be your,
I don't know, CPU, GPU, TPU,

5
00:00:21.345 --> 00:00:26.050
FPGA, I can probably
talk about those later.

6
00:00:26.050 --> 00:00:30.110
But it just doing some calculations.

7
00:00:30.110 --> 00:00:34.150
So what kind of calculations,
what kind of operations it is doing?

8
00:00:34.150 --> 00:00:36.060
Well, it depends on what
you provide to it, right?

9
00:00:36.060 --> 00:00:40.698
So we need to provide the algorithm.

10
00:00:40.698 --> 00:00:45.192
Or just model something, right?

11
00:00:45.192 --> 00:00:51.157
The least of the instructions for
your compute to process,

12
00:00:51.157 --> 00:00:56.380
so let's just draw it as
kinda couple of lines.

13
00:00:56.380 --> 00:00:58.860
That's what our compute will be doing,
right?

14
00:00:58.860 --> 00:01:02.520
This is our algorithm, and
we're just executing it.

15
00:01:02.520 --> 00:01:07.390
To get something useful,
we also need to provide input.

16
00:01:08.910 --> 00:01:13.248
So it can be input data or
some text, right, and

17
00:01:13.248 --> 00:01:16.750
then this input data is processed.

18
00:01:16.750 --> 00:01:19.380
We'll get some data out.

19
00:01:19.380 --> 00:01:23.612
Something will be printed out, or
we can store something on disk, right?

20
00:01:23.612 --> 00:01:30.240
But that's kinda conceptually what
the computer science is teaching us about.

21
00:01:30.240 --> 00:01:34.220
We have some computes,
we're providing the instructions for

22
00:01:34.220 --> 00:01:37.081
that compute to follow
in form of algorithm.

23
00:01:37.081 --> 00:01:43.360
We're providing the input data in and
getting update data as the result.

24
00:01:43.360 --> 00:01:48.353
In machine learning, Basically,
we can see that those

25
00:01:48.353 --> 00:01:53.619
two, Are interchanged.

26
00:01:53.619 --> 00:02:01.291
Meaning that, we're just simply grabbing,
Output result when we, sorry.

27
00:02:04.551 --> 00:02:08.691
What we're doing in machine learning,
we're just taking those output data when

28
00:02:08.691 --> 00:02:15.353
we're training our model, And
providing it to our compute.

29
00:02:18.497 --> 00:02:22.594
Also to use, Right?

30
00:02:22.594 --> 00:02:28.595
So remember on the previous diagram,
pretty messy one.

31
00:02:28.595 --> 00:02:33.938
[LAUGH] But when we did for
propagation, we needed to know

32
00:02:33.938 --> 00:02:39.570
if we're looking at the hot dog or
not hot dog, right?

33
00:02:39.570 --> 00:02:42.938
So we needed an annotated data set.

34
00:02:42.938 --> 00:02:47.554
Meaning that,
we are not only need thousands of those

35
00:02:47.554 --> 00:02:51.145
images with hot dogs and not hot dogs, but

36
00:02:51.145 --> 00:02:56.190
we also need to know if we're
looking at the hot dog or not.

37
00:02:56.190 --> 00:03:00.078
So back to our schema,
the one we just drew,

38
00:03:03.478 --> 00:03:09.396
It means that's to our compute when
we're training the neural network,

39
00:03:09.396 --> 00:03:13.693
we're providing images,
let's actually switch,

40
00:03:13.693 --> 00:03:18.240
images of the hot dogs and
images of not hot dogs.

41
00:03:18.240 --> 00:03:22.759
But also, when we deem this training,
we should say what is the label, right?

42
00:03:22.759 --> 00:03:26.537
So, hot dog or not.

43
00:03:28.000 --> 00:03:33.884
And our compute, when just
readjusting those weights and biases,

44
00:03:36.068 --> 00:03:40.990
It will somehow return back or
train this model, right?

45
00:03:40.990 --> 00:03:42.600
So conceptually,

46
00:03:42.600 --> 00:03:46.780
that's what machine learning is doing
when you're doing the training.

47
00:03:46.780 --> 00:03:52.131
Provided the input data and
corresponding labels, it will retrain or

48
00:03:52.131 --> 00:03:56.677
adopt the weights and
biases to return the correct result.

49
00:03:56.677 --> 00:04:01.590
But what you're getting is the model,
all of those weights and biases.

50
00:04:01.590 --> 00:04:04.380
So when the model is trained,

51
00:04:04.380 --> 00:04:10.410
now you can actually freeze them,
right, and do the predictions.

52
00:04:10.410 --> 00:04:12.826
If you're looking at the hot dog or

53
00:04:12.826 --> 00:04:18.008
not hot dog by just putting some new
image our model has never seen before.

54
00:04:18.008 --> 00:04:20.276
And it will just do the prediction,

55
00:04:20.276 --> 00:04:25.193
correct prediction if it's looking at
the hot dog or not, by utilizing all of

56
00:04:25.193 --> 00:04:29.370
those previously reinforced
connections between the neurons.

