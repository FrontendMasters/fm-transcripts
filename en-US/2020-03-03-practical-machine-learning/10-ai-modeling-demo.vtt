WEBVTT

1
00:00:00.520 --> 00:00:02.230
That was the original picture.

2
00:00:02.230 --> 00:00:06.270
That's our style image and stylized image.

3
00:00:06.270 --> 00:00:12.210
Now you can see that you can kinda
recognize the bridge right here.

4
00:00:12.210 --> 00:00:13.910
There's downtown right but

5
00:00:13.910 --> 00:00:18.980
all of those details are actually
grabbed from the style image.

6
00:00:18.980 --> 00:00:22.286
So now we kinda can create something,
right?

7
00:00:22.286 --> 00:00:27.480
And for me that is the representation
of artificial intelligence.

8
00:00:27.480 --> 00:00:34.620
And with AI now we can even synthesize
ways in a video, video can be now

9
00:00:34.620 --> 00:00:39.810
created worth deep fakes, for instance,
[LAUGH] A pretty well known example.

10
00:00:39.810 --> 00:00:45.640
So, AI is, for
me at least all those kind of neat tricks

11
00:00:45.640 --> 00:00:50.685
which can help you to get
closer to kinda creativity but

12
00:00:50.685 --> 00:00:54.546
still, it's somewhat scripted, right?

13
00:00:54.546 --> 00:00:57.650
AI cannot completely create
something from scratch,

14
00:00:57.650 --> 00:01:02.000
you still can have to use those
building blocks to degrade something.

15
00:01:02.000 --> 00:01:04.299
Yes Micheal the next question.

16
00:01:04.299 --> 00:01:06.830
&gt;&gt; Yes.
So I get how you get the original

17
00:01:06.830 --> 00:01:11.610
image from the first layer because
it's just the data that came in.

18
00:01:11.610 --> 00:01:12.800
&gt;&gt; Yeah.

19
00:01:12.800 --> 00:01:17.864
&gt;&gt; But then we're in that
[COUGH] Process of recreating

20
00:01:17.864 --> 00:01:22.350
the image do you get the style applied?

21
00:01:22.350 --> 00:01:25.650
I mean the style came
from training the model.

22
00:01:25.650 --> 00:01:31.112
&gt;&gt; All right let me switch to our diagrams
and probably even start from scratch.

23
00:01:31.112 --> 00:01:36.290
So process,
let's just draw it like this, right?

24
00:01:36.290 --> 00:01:39.240
Our sunglasses.

25
00:01:39.240 --> 00:01:46.500
So originally, let's take, let's say
we took the style picture, right?

26
00:01:46.500 --> 00:01:51.863
And if you just take style picture so all

27
00:01:51.863 --> 00:01:58.520
right, now I think I know where
the question is coming from.

28
00:01:58.520 --> 00:02:04.380
The original model was trained
on a lot of different pictures.

29
00:02:04.380 --> 00:02:09.308
So we used image net with those 1.4
million pictures and simply trained to

30
00:02:09.308 --> 00:02:14.710
recognize so we have nought zero Neuron
but actually thousands of them, neurons.

31
00:02:14.710 --> 00:02:20.179
But it's still on the input we
have pretty large pictures for

32
00:02:20.179 --> 00:02:25.260
instance, I know 256 by 256 pixels, right?

33
00:02:25.260 --> 00:02:29.720
And it is reducing to
thousands Pixels here and

34
00:02:29.720 --> 00:02:34.050
then deconvoluted back
to the original size.

35
00:02:34.050 --> 00:02:39.760
But when we train our model to do that,
it will recognize

36
00:02:39.760 --> 00:02:43.760
all those different objects right, so
particularly neurons will be activated.

37
00:02:43.760 --> 00:02:49.010
But it will also learn this part
right here with all the neurons,

38
00:02:49.010 --> 00:02:52.530
all the weight, how to recreate
their original image, right?

39
00:02:52.530 --> 00:02:57.440
So you can think about
this model that it's not

40
00:02:57.440 --> 00:03:03.480
only learning how to based on the image,
assign a particular label to it,

41
00:03:03.480 --> 00:03:09.140
but it also trying to figure out
how to given a particular label

42
00:03:09.140 --> 00:03:11.360
recreate this object, redraw it.

43
00:03:13.420 --> 00:03:16.795
So that's what, for instance,
that topology called,

44
00:03:16.795 --> 00:03:20.510
U-nex that's what it can do.

45
00:03:22.040 --> 00:03:27.190
And what we doing next with this
stylizing, right, so when we kinda have

46
00:03:27.190 --> 00:03:33.160
our model trained, we're doing forward
propagation on the strange model.

47
00:03:33.160 --> 00:03:38.820
So it will just somehow analyze the image,

48
00:03:38.820 --> 00:03:43.190
right and kinda some of
the neurons will be activated.

49
00:03:43.190 --> 00:03:47.264
And maybe we will even got
some prediction here and

50
00:03:47.264 --> 00:03:51.435
it might gonna recreate
this image back again, but

51
00:03:51.435 --> 00:03:55.510
we don't care about this
part of the model at all.

52
00:03:56.580 --> 00:04:03.330
We only care about the first few layers
which grabbed the style of drawing.

53
00:04:04.490 --> 00:04:07.360
And why that exactly happening
I will explain when we

54
00:04:07.360 --> 00:04:10.250
will talk about convolution
narrow networks.

55
00:04:10.250 --> 00:04:13.850
But trust me on the first layers
we are looking at kind of tiny

56
00:04:13.850 --> 00:04:17.200
details of particular colors, right?

57
00:04:19.210 --> 00:04:23.090
Have we diagonal lines there are vertical
lines or something like that.

58
00:04:23.090 --> 00:04:29.470
So we only care about this information,
but when we do the photo, we

59
00:04:31.710 --> 00:04:36.520
actually do the full
convolution deconvolution.

60
00:04:36.520 --> 00:04:40.700
So if we provided the image
of the downtown at the ance,

61
00:04:40.700 --> 00:04:47.440
without any modification, we will
reproduce the downtown image back again.

62
00:04:47.440 --> 00:04:50.740
But we can grab this layer,

63
00:04:50.740 --> 00:04:56.070
actually this layer,
they are connected to each other.

64
00:04:56.070 --> 00:05:00.554
So when I'm saying this layer was
important because it layers it build

65
00:05:00.554 --> 00:05:02.690
a fact the weights in this layer.

66
00:05:03.870 --> 00:05:11.330
So we can just grab this part and
substitute it into our photo.

67
00:05:12.800 --> 00:05:17.750
And that what will help
our model instead of

68
00:05:17.750 --> 00:05:22.192
recreating the original image recreates
the stylized image of the downtown,

69
00:05:22.192 --> 00:05:27.330
it's kinda conceptually what
the neural network is doing.

70
00:05:27.330 --> 00:05:30.720
But it's pretty cool you
can actually play with it.

71
00:05:30.720 --> 00:05:34.720
I've included the source codes and
all that is executable there,

72
00:05:34.720 --> 00:05:41.350
a couple of available other original
images and stylized images.

73
00:05:41.350 --> 00:05:45.630
So, different monologue and
Picasso paintings.

74
00:05:45.630 --> 00:05:48.580
So, you can play around with those,
for instance.

75
00:05:50.070 --> 00:05:54.140
The only recommendation is trying to avoid

76
00:05:54.140 --> 00:05:57.510
original photos with
a lot of tiny details.

77
00:05:58.910 --> 00:06:02.820
Because this kind of information,
the more details you have,

78
00:06:02.820 --> 00:06:04.460
those details will be ignored.

79
00:06:04.460 --> 00:06:08.810
So the most important parts,
right, so kinda the big objects,

80
00:06:08.810 --> 00:06:12.730
what we see on the image, that will
be propagated to the final result.

81
00:06:13.870 --> 00:06:16.150
But I think it's pretty interesting,
right?

82
00:06:16.150 --> 00:06:19.780
And it's all about the information if
you think about it like we started

83
00:06:19.780 --> 00:06:22.480
with the multi dimensional photo.

84
00:06:22.480 --> 00:06:23.455
What is photo?

85
00:06:23.455 --> 00:06:25.586
It's like a huge amount of information.

86
00:06:25.586 --> 00:06:29.870
But we kinda reducing it to something and
yeah that's what

87
00:06:29.870 --> 00:06:34.020
machine learning is doing, is basically
doing something within the transformation,

88
00:06:34.020 --> 00:06:35.760
within the data, all right?

89
00:06:35.760 --> 00:06:39.530
And it's only doing is by figuring
out what should be the weights and

90
00:06:39.530 --> 00:06:42.330
biases and
connections between the neurons.

91
00:06:42.330 --> 00:06:43.800
Yeah, that's another thing.

92
00:06:43.800 --> 00:06:47.760
Right now I mostly talking
about it's really simple.

93
00:06:47.760 --> 00:06:50.990
The original kind of topology,
fully connected neural networks when

94
00:06:50.990 --> 00:06:54.810
all the neurons connected from
the previous layer to the next layer.

95
00:06:54.810 --> 00:06:56.860
But there are multiple modifications.

96
00:06:58.840 --> 00:06:59.620
For instance,

97
00:06:59.620 --> 00:07:05.048
Google come up with their architecture
where they don't even have the symmetry.

98
00:07:05.048 --> 00:07:10.150
They have kinda ad hoc branches which
can do predictions by themselves, right?

99
00:07:10.150 --> 00:07:14.580
And that was actually the winner
of the latest, not the latest but

100
00:07:14.580 --> 00:07:16.660
a couple years ago ImageNet competition.

