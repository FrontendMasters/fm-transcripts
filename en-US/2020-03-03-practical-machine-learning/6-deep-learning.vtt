WEBVTT

1
00:00:00.020 --> 00:00:03.749
You're gonna ask kinda okay,
that's the basic concepts, but

2
00:00:03.749 --> 00:00:06.340
why, why are we doing all of this?

3
00:00:07.780 --> 00:00:13.610
Well, the thing is you can now
stack those neurons into layers.

4
00:00:13.610 --> 00:00:17.947
Or you can have several neurons right next
to each other processing simultaneously.

5
00:00:17.947 --> 00:00:23.540
So for instance, you can just combine
neurons into one layer, right?

6
00:00:23.540 --> 00:00:28.450
And then have multiple inputs or
maybe even the same inputs

7
00:00:28.450 --> 00:00:33.250
provided to different neurons, right?

8
00:00:33.250 --> 00:00:38.000
And they can just somehow do
something with the information

9
00:00:39.430 --> 00:00:43.970
we input into our,
in this case layers of neurons.

10
00:00:43.970 --> 00:00:48.724
On top of that,
we can have multiple layers of the neurons

11
00:00:48.724 --> 00:00:53.687
interconnected partially or
fully with a previous layer.

12
00:00:53.687 --> 00:00:58.218
And you can have multiple
layers like this.

13
00:00:58.218 --> 00:01:03.434
And remember, I was saying that we'll
be talking about deep learning.

14
00:01:03.434 --> 00:01:06.540
And have this connection between
machine learning and deep learning.

15
00:01:07.820 --> 00:01:15.507
So deep is actually coming
from this architecture.

16
00:01:15.507 --> 00:01:21.187
With layers of neurons you can
simply gonna take the input signal.

17
00:01:21.187 --> 00:01:25.004
And input signal can be for
instance visual information, right?

18
00:01:25.004 --> 00:01:31.620
Some picture or sound or even text
as we will see during this course.

19
00:01:31.620 --> 00:01:34.861
So you can just provide some numbers,
right?

20
00:01:34.861 --> 00:01:41.380
And neurons will do those
transformation and use the signal.

21
00:01:41.380 --> 00:01:46.527
And somehow for instance scan,
the last neuron can be a classifier,

22
00:01:46.527 --> 00:01:53.870
which can, say, for instance, let's say we
provided the input text, just our emails.

23
00:01:53.870 --> 00:01:57.449
And this model, let's call it just model,

24
00:02:01.142 --> 00:02:09.599
What it did, at the end, it just said that
we are looking at spam, Or, not spam.

25
00:02:13.480 --> 00:02:16.346
It can be anything, we can provide,
for instance, image,

26
00:02:16.346 --> 00:02:18.271
picture we took with our phone, right?

27
00:02:18.271 --> 00:02:26.946
And our model with those tons of neurons
connected with each other at the end scan,

28
00:02:26.946 --> 00:02:31.735
say if it's looking at hot dog or
not hot dog.

29
00:02:34.368 --> 00:02:38.130
It is possible,
you can do that easily with this system.

30
00:02:38.130 --> 00:02:42.950
So the question is now, once again,

31
00:02:42.950 --> 00:02:49.170
where deep is coming from, deep
learning came from all of those layers.

32
00:02:49.170 --> 00:02:53.845
So in 60s, in 50s, people were
playing with just single neuron, or

33
00:02:53.845 --> 00:02:55.925
maybe two neurons in one layer.

34
00:02:55.925 --> 00:02:57.102
But actually,

35
00:02:57.102 --> 00:03:03.175
we come up with the idea that you can have
multiple layers stuck with each other.

36
00:03:03.175 --> 00:03:07.073
And kind of jump, I'm sorry,
that's gonna be mathematical jargon here.

37
00:03:07.073 --> 00:03:11.114
But having multiple layers like
that help you to jump from

38
00:03:11.114 --> 00:03:16.320
the linearity to more complex polynomials,
I'm done with math.

39
00:03:16.320 --> 00:03:20.290
It means basically that we can
better fit into distributions or

40
00:03:20.290 --> 00:03:25.330
whatever information transformation we're
trying to get if we have multiple layers.

41
00:03:25.330 --> 00:03:29.930
And this deep learning means that
we basically can put more and

42
00:03:29.930 --> 00:03:33.240
more, deeper and
deeper layers into our model.

43
00:03:33.240 --> 00:03:37.562
And we started with something like, seven,

44
00:03:37.562 --> 00:03:42.692
eight layers, for
instance in AlexNet in 2012.

45
00:03:42.692 --> 00:03:47.351
That's the model which
won ImageNet competition.

46
00:03:47.351 --> 00:03:52.000
And I will, well, I can probably
tell you right now about it.

47
00:03:52.000 --> 00:03:57.222
It's basically the contest and
datasets created by

48
00:03:57.222 --> 00:04:03.163
Stanford University and
a couple of other collaborators.

49
00:04:03.163 --> 00:04:06.592
Where they have 1.4, or at least in 2012,

50
00:04:06.592 --> 00:04:10.849
they had 1.4 million images
with different resolutions.

51
00:04:10.849 --> 00:04:14.818
And the competition task
was to find objects,

52
00:04:14.818 --> 00:04:19.819
not objects, but
basically say what you see on the image.

53
00:04:19.819 --> 00:04:27.185
And there were 1,000 different objects,
so we can say 1,000 different classes.

54
00:04:27.185 --> 00:04:32.445
And the competition was just to process
all of those 1.4 million pictures, right?

55
00:04:32.445 --> 00:04:37.290
And do your predictions and then,
basically, different models or

56
00:04:37.290 --> 00:04:40.782
different algorithms were competing,
right?

57
00:04:40.782 --> 00:04:43.512
And they were trying to figure
out which model is the best.

58
00:04:43.512 --> 00:04:49.287
And in 2012, the competition
was significant better result,

59
00:04:49.287 --> 00:04:54.390
was won by convolution neural
network now called AlexNet.

60
00:04:54.390 --> 00:04:59.786
Krasinski, Alex, professor, the author of
the model and his collaborative group.

61
00:04:59.786 --> 00:05:04.986
I think the difference in the performance,
and by the way, when we talk about

62
00:05:04.986 --> 00:05:10.029
performance in machine learning,
it means the accuracy mostly, right?

63
00:05:10.029 --> 00:05:14.116
They won by something like 20% better
compared to support vector machines,

64
00:05:14.116 --> 00:05:18.132
which were the winners of that
competition the year prior.

65
00:05:18.132 --> 00:05:25.360
So, interesting, so yeah, deep learning
is coming from just those layers.

66
00:05:25.360 --> 00:05:30.345
But at the same time you
see that those models

67
00:05:30.345 --> 00:05:35.560
in deep learning it's usually almost
have this triangle architecture, right?

68
00:05:35.560 --> 00:05:40.533
We're starting with a lot of
different inputs, for instance,

69
00:05:40.533 --> 00:05:42.566
intensity of the pixels.

70
00:05:42.566 --> 00:05:47.413
And then we're reducing something
to relatively small, one neuron,

71
00:05:47.413 --> 00:05:52.070
or in case of AlexNet,
it will be just 1,000 neurons, right?

72
00:05:52.070 --> 00:05:56.256
And the one will be activated which have
the corresponding label, for instance.

73
00:05:56.256 --> 00:05:59.966
If I'm providing the image of the dog,

74
00:05:59.966 --> 00:06:04.581
then the neuron which had
dog will be activated.

75
00:06:04.581 --> 00:06:09.841
But I haven't told you
how those weights and

76
00:06:09.841 --> 00:06:13.690
biases are actually selected.

77
00:06:14.710 --> 00:06:19.572
And the thing is, no one is selecting
them, it is actually trained.

78
00:06:19.572 --> 00:06:24.247
And that's the process of
in machine learning how we

79
00:06:24.247 --> 00:06:27.760
get all of this magic of deep learning.

