WEBVTT

1
00:00:00.030 --> 00:00:02.618
Let's actually do something fun.

2
00:00:02.618 --> 00:00:05.710
It's pose demo, what it's doing?

3
00:00:05.710 --> 00:00:10.570
It's simply gonna grab
the image from the web camera.

4
00:00:10.570 --> 00:00:12.980
We can probably just, yeah,
let's mount it a little bit.

5
00:00:14.070 --> 00:00:17.695
And it's analyzing the image and

6
00:00:17.695 --> 00:00:20.870
it's trying to figure out
a couple of interesting points.

7
00:00:20.870 --> 00:00:24.571
For instance, those five points on my
face, they correspond to you nose,

8
00:00:24.571 --> 00:00:25.525
eyes and the ears.

9
00:00:25.525 --> 00:00:29.507
It's a little bit lagging,
so if I'm moving too fast,

10
00:00:29.507 --> 00:00:33.323
it's just because it's
updating the image first and

11
00:00:33.323 --> 00:00:37.160
then the overlay coming as
the next frame on top of it.

12
00:00:37.160 --> 00:00:42.451
But on top of just
tracking the face points,

13
00:00:42.451 --> 00:00:46.175
it can track the whole figure.

14
00:00:46.175 --> 00:00:51.539
I'm not sure if I can stand here,
yeah, I will risk pulling the mic.

15
00:00:54.859 --> 00:00:56.710
Yeah, you cannot see it exactly.

16
00:00:56.710 --> 00:01:02.918
But the thing is, the whole figure,
all my hands, they can be tracked.

17
00:01:02.918 --> 00:01:10.982
[LAUGH] Okay [LAUGH] try it yourself.

18
00:01:10.982 --> 00:01:15.803
If you just go to the GitHub repo and
click the link,

19
00:01:15.803 --> 00:01:19.401
just allow your web camera to be used.

20
00:01:19.401 --> 00:01:23.815
And do you want to try multiple
people in the same frame?

21
00:01:23.815 --> 00:01:31.108
[LAUGH]
Try to wave your hand or something.

22
00:01:31.108 --> 00:01:33.931
[LAUGH]
&gt;&gt; [LAUGH]

23
00:01:33.931 --> 00:01:37.468
&gt;&gt; It's pretty cool, all right,

24
00:01:37.468 --> 00:01:42.449
play around with it, it's pretty awesome.

25
00:01:42.449 --> 00:01:44.660
And it's using machine learning.

26
00:01:44.660 --> 00:01:49.920
So right now the architecture
is MobileNetV1,

27
00:01:49.920 --> 00:01:53.150
right here, I can highlight it.

28
00:01:53.150 --> 00:01:56.310
You can actually switch
from mobile to ResNet,

29
00:01:56.310 --> 00:01:59.320
but ResNet is significantly bigger.

30
00:01:59.320 --> 00:02:04.622
So right now,
we have six frames per second, right?

31
00:02:04.622 --> 00:02:08.110
You can see the image is
a little bit sluggish.

32
00:02:08.110 --> 00:02:12.030
If we switch to ResNet I think it
will drop to something like three

33
00:02:12.030 --> 00:02:13.410
frames per seconds.

34
00:02:13.410 --> 00:02:18.270
Maybe even less than that, zero,
[LAUGH] no, back to three.

35
00:02:18.270 --> 00:02:25.130
Okay, but you can improve the speed if you
for instance, change the input resolution.

36
00:02:25.130 --> 00:02:28.995
It's not the resolution
of the image shown here,

37
00:02:28.995 --> 00:02:34.140
it's the resolution of the image
provided to the neural network.

38
00:02:34.140 --> 00:02:38.833
Yeah, you can see it, it didn't affect
the performance of the model itself,

39
00:02:38.833 --> 00:02:41.978
but significantly improved
the frames per second.

40
00:02:41.978 --> 00:02:47.390
And if you're gonna be playing around with
it, right now algorithm is multipose.

41
00:02:47.390 --> 00:02:49.537
It means it will be
analyzing multiple people.

42
00:02:49.537 --> 00:02:53.749
You can switch to single pose,
which will increase the performance.

43
00:02:53.749 --> 00:02:59.323
But unfortunately, it seems that Google
guys [LAUGH] made a bug in the code.

44
00:02:59.323 --> 00:03:03.330
Because right now those
points are mirrored.

45
00:03:03.330 --> 00:03:08.910
So you can see [LAUGH],
the overlay at least, is mirrored.

46
00:03:08.910 --> 00:03:12.541
So, yeah, we should probably
file a bug report to them.

47
00:03:12.541 --> 00:03:15.484
But anyway, it's a really fun demo, and

48
00:03:15.484 --> 00:03:19.785
you can play with it yourself and
just see how it works there.

49
00:03:19.785 --> 00:03:23.124
A couple of things you can do,
just turning on and

50
00:03:23.124 --> 00:03:28.310
off things and kind of modifying
the parameters of the model itself.

51
00:03:28.310 --> 00:03:32.140
It's pretty fun, and
the source code is available.

52
00:03:32.140 --> 00:03:39.500
So if you just go to TFJS examples and
look for PoseNet.

53
00:03:39.500 --> 00:03:44.440
That's the demo with the source code,
the one they used.

