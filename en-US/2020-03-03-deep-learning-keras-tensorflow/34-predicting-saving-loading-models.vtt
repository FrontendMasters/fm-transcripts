WEBVTT

1
00:00:00.080 --> 00:00:04.516
The only thing I wanted to show you
right now we played around with

2
00:00:04.516 --> 00:00:09.367
different neural networks right
with fully connected neural network

3
00:00:09.367 --> 00:00:14.236
with the convolutional neural
network to recognize those seizures.

4
00:00:14.236 --> 00:00:19.230
But I haven't actually show you what to do
with the model after you've trained it.

5
00:00:19.230 --> 00:00:25.267
So after you trained the model, there are
actually a couple of things you can do.

6
00:00:25.267 --> 00:00:31.110
For instance,
let's quickly see if I have it here.

7
00:00:31.110 --> 00:00:37.040
If not, then I will,
you can access individual layers, right?

8
00:00:37.040 --> 00:00:41.618
And for instance,
you can get layer by the index or

9
00:00:41.618 --> 00:00:47.068
just go through the weights
with corresponding index which

10
00:00:47.068 --> 00:00:53.390
simply gonna to be the number of
the layer you trying to access to you.

11
00:00:53.390 --> 00:00:56.210
And yeah, you can even do the predictions.

12
00:00:56.210 --> 00:01:04.620
So for instance, if you just do
the model.predict and provide the input.

13
00:01:05.950 --> 00:01:10.712
The only thing with the images
remember that's our

14
00:01:10.712 --> 00:01:15.260
image it was simply 28 by 28 pixels,
right?

15
00:01:15.260 --> 00:01:21.390
But our model takes several of images when
we're training so we need to reshape it.

16
00:01:22.640 --> 00:01:28.530
So basically in create list which
will contain only one image.

17
00:01:28.530 --> 00:01:32.910
But if we create several lives,
we can create.

18
00:01:32.910 --> 00:01:36.851
For instance, if we want to process
multiple images simultaneously,

19
00:01:36.851 --> 00:01:40.725
we can just create the list of those
images and then do model predict and

20
00:01:40.725 --> 00:01:42.827
provide this list and as the results,

21
00:01:42.827 --> 00:01:46.330
our model will create predict
what it's actually observing.

22
00:01:46.330 --> 00:01:54.940
And you always can do a saving so
model is it safe?

23
00:01:54.940 --> 00:02:02.060
I think I already
terminated this notebook.

24
00:02:02.060 --> 00:02:05.460
Yeah, sorry about browsing.

25
00:02:05.460 --> 00:02:11.325
Let's quickly just restart we initialize
the green data and our model.

26
00:02:17.060 --> 00:02:20.650
And we can even quickly train it,
as far as I remember,

27
00:02:20.650 --> 00:02:22.690
the training was pretty fast.

28
00:02:22.690 --> 00:02:24.009
And by the way, yeah,

29
00:02:24.009 --> 00:02:27.630
if you want to visualize
the topology of your neural network.

30
00:02:31.350 --> 00:02:33.120
[LAUGH] This one is actually wrong.

31
00:02:33.120 --> 00:02:41.015
You can simply use plot model from
TensorFlow Kerris utilities utils.

32
00:02:41.015 --> 00:02:47.780
It gives you a pretty nice graphic and
you can save it into file, PNG.

33
00:02:47.780 --> 00:02:53.885
Or if you want a higher resolution vector
graphics, you can even use SVG format.

34
00:02:53.885 --> 00:02:59.060
Just pretty good if you will want to
use kind of visualize the topologies,

35
00:02:59.060 --> 00:03:01.720
right off your neural network.

36
00:03:01.720 --> 00:03:04.330
Once again, a model summary works as well.

37
00:03:04.330 --> 00:03:09.650
So, let's quickly just retrain our model.

38
00:03:09.650 --> 00:03:12.360
This one should be pretty fast.

39
00:03:12.360 --> 00:03:17.307
And as I said, if you want to,
after you're done training,

40
00:03:17.307 --> 00:03:22.020
just save you model,
what you can do, you can use model,

41
00:03:22.020 --> 00:03:27.990
I'll just wait for it to finish.

42
00:03:27.990 --> 00:03:32.140
Or actually let me interrupt, reduce.

43
00:03:32.140 --> 00:03:36.829
We don't need 40 epochs here
we need probably only 5 and

44
00:03:36.829 --> 00:03:39.130
they can restart the wrong.

45
00:03:39.130 --> 00:03:42.850
Let's see,
we're already actually it's 99% accuracy.

46
00:03:42.850 --> 00:03:49.093
So I think we good and it's with fully
connected neural network it's pretty,

47
00:03:49.093 --> 00:03:55.350
pretty small and how many layers we
have here only one hidden layer right?

48
00:03:55.350 --> 00:04:00.515
The last dense layer we can think about it
as the just the player with the neurons

49
00:04:00.515 --> 00:04:05.200
which will be activated depending on
which digit we're actually looking at.

50
00:04:05.200 --> 00:04:13.834
And if you want to save,
You can do save the model completely,

51
00:04:13.834 --> 00:04:18.550
in this case it will
save the topology itself.

52
00:04:18.550 --> 00:04:25.369
And yeah, we can just specify by
a file path or just the name for

53
00:04:25.369 --> 00:04:30.495
instance model.h5 or something like this.

54
00:04:30.495 --> 00:04:38.190
If we execute it, it will save the file
it will also appear as a modelh5.

55
00:04:38.190 --> 00:04:44.433
So all the weights and topology of
the model will be simply stored

56
00:04:44.433 --> 00:04:49.758
in this file and
we can even load it from a new notebook.

57
00:04:49.758 --> 00:04:54.348
If we just for instance,
open a new notebook and say,

58
00:04:54.348 --> 00:04:57.714
although I have to now, for the model,

59
00:04:57.714 --> 00:05:02.814
let's actually return back and
just use the new cell here,

60
00:05:02.814 --> 00:05:07.424
just because my Kerris is
already implemented here.

61
00:05:07.424 --> 00:05:13.130
So I can do something
like this model load.

62
00:05:13.130 --> 00:05:14.910
And I can only load weights.

63
00:05:14.910 --> 00:05:18.490
So I should do save weights in this case.

64
00:05:19.840 --> 00:05:24.657
Save weights and then the model
will have to be recreated with

65
00:05:24.657 --> 00:05:27.970
all the layers used during the training.

66
00:05:27.970 --> 00:05:32.260
But then I can simply load
weights from the file.

67
00:05:34.020 --> 00:05:38.727
Right, and for instance if you don't
want to spend time retraining your model

68
00:05:38.727 --> 00:05:42.578
every time you can just dump those
weights on your file system and

69
00:05:42.578 --> 00:05:45.310
download them whenever you need them.

70
00:05:45.310 --> 00:05:52.290
But the initialization of the model
itself, so model definition have to be.

71
00:05:52.290 --> 00:05:58.698
I have actually two models here,
right, here and this one.

72
00:05:58.698 --> 00:06:03.537
But anyway, you got the idea is the way
how you can train it, save it and

73
00:06:03.537 --> 00:06:09.300
then use it for later on and doing the
prediction as I said, it's pretty, simple.

74
00:06:14.570 --> 00:06:17.190
I've showed it right here.

75
00:06:17.190 --> 00:06:22.334
So first you just reshaping your image so

76
00:06:22.334 --> 00:06:27.940
it was, let me actually do the explicitly.

77
00:06:27.940 --> 00:06:36.722
So if we printix_text (0) shape and

78
00:06:36.722 --> 00:06:42.050
print our input shape.

79
00:06:43.290 --> 00:06:47.539
You'll see what happened.
So original image was only 28 by 28 pixel

80
00:06:47.539 --> 00:06:50.356
but I just grabbed this image and

81
00:06:50.356 --> 00:06:55.070
by reshaping means that I
put it inside another list.

82
00:06:56.090 --> 00:06:56.695
That's it.
And

83
00:06:56.695 --> 00:07:02.620
just what's our model expect to be
the input to do the predictions.

84
00:07:02.620 --> 00:07:07.804
And then if we print
the results of the prediction

85
00:07:07.804 --> 00:07:12.490
we should see this 10 different numbers.

86
00:07:12.490 --> 00:07:19.980
That's the simply getting the signal
coming out of all our 10 neurons, right?

87
00:07:19.980 --> 00:07:25.700
And actually the number we're
looking at is number 7.

88
00:07:25.700 --> 00:07:32.050
So if we calculate 0, 1, 2, 3, 4, 5, 6,
7, that's the highest number among those.

89
00:07:32.050 --> 00:07:33.760
So you can see all of those have minus.

90
00:07:33.760 --> 00:07:35.620
7 power minus 10.

91
00:07:35.620 --> 00:07:37.070
And this one is pretty close to 1.

92
00:07:37.070 --> 00:07:43.017
So our model is super confidence
that we're looking at seven and

93
00:07:43.017 --> 00:07:47.210
you can even visualize those distribution.

94
00:07:47.210 --> 00:07:52.058
So you see we have the peak seven and
the rest is pretty small.

95
00:07:52.058 --> 00:07:58.020
So, yeah and that's the number
we're analyzing, number 7.

