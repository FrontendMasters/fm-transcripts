WEBVTT

1
00:00:00.120 --> 00:00:03.706
I think next I want to talk a little bit

2
00:00:03.706 --> 00:00:08.220
about the explainability
of deep learning and

3
00:00:08.220 --> 00:00:12.980
convolutional neural
networks specifically.

4
00:00:12.980 --> 00:00:17.826
So far we played around with fully
connected neural networks, right, so

5
00:00:17.826 --> 00:00:19.945
we went through this notebook.

6
00:00:19.945 --> 00:00:24.616
We talked a little bit about information
theory and played around with principal

7
00:00:24.616 --> 00:00:28.684
component analysis, looked at
the convolutional neural networks.

8
00:00:28.684 --> 00:00:33.837
So yes, by the way,
if you want convolution kernels on

9
00:00:33.837 --> 00:00:40.118
pooling probably will explain
what convolution is doing better.

10
00:00:40.118 --> 00:00:46.030
So, let's actually run this notebook very,
very quickly.

11
00:00:46.030 --> 00:00:51.669
So let's say we have
filter which looks like,

12
00:00:53.247 --> 00:00:59.223
This, so actually let's put 1s here and
-1s here.

13
00:00:59.223 --> 00:01:03.884
Right, so it's gonna positive
numbers at the top than just 0s and

14
00:01:03.884 --> 00:01:05.724
negative numbers there.

15
00:01:05.724 --> 00:01:10.377
And in my notebook I just have
couple of helper functions

16
00:01:10.377 --> 00:01:15.230
which will do the convolutions and
will do pooling for me.

17
00:01:15.230 --> 00:01:19.882
And I can simply visualize
what this particular

18
00:01:19.882 --> 00:01:23.843
filter will do with this image, right.

19
00:01:23.843 --> 00:01:26.808
So imagine that we just
grab some random image.

20
00:01:26.808 --> 00:01:31.283
Well, in my case,
it was the image of one of our model.

21
00:01:31.283 --> 00:01:34.949
And.

22
00:01:34.949 --> 00:01:37.906
Okay, ignore this for now.

23
00:01:37.906 --> 00:01:42.310
So what we will do we'll just
take this original image and

24
00:01:42.310 --> 00:01:46.635
apply convolution with this
filter the one we defined.

25
00:01:46.635 --> 00:01:48.696
Can you guess what it's gonna be doing?

26
00:01:50.544 --> 00:01:55.308
It actually looking for
the vertical lines specifically, right.

27
00:01:55.308 --> 00:01:58.664
So remember we had boxes here, but

28
00:01:58.664 --> 00:02:03.413
all the horizontal lines
simply disappeared and

29
00:02:03.413 --> 00:02:09.202
only this bright white color
means we have high intensity,

30
00:02:09.202 --> 00:02:13.973
so only those vertical
lines were highlighted.

31
00:02:13.973 --> 00:02:19.236
So basically filter defined
like this will find

32
00:02:19.236 --> 00:02:24.246
all the vertical lines on our image,
right.

33
00:02:24.246 --> 00:02:29.277
And if we do the pooling, Now you can

34
00:02:29.277 --> 00:02:36.621
see previously we had 200 by 200 image
now we reduced to 100 by 100 but

35
00:02:36.621 --> 00:02:40.844
still, the general idea preserved, right.

36
00:02:40.844 --> 00:02:43.600
It's gonna more blur, I guess.

37
00:02:43.600 --> 00:02:49.542
But we can still find where
we had those vertical lines.

38
00:02:49.542 --> 00:02:54.851
We can find, for instance, areas
the same thing with horizontal lines.

39
00:02:54.851 --> 00:02:59.576
Or, for instance,
if your filter is defined like

40
00:02:59.576 --> 00:03:04.535
this 0s everywhere except
one point in the middle.

41
00:03:04.535 --> 00:03:09.890
Can you guess what's this
will do with our image?

42
00:03:09.890 --> 00:03:12.396
All right, let's just see.

43
00:03:12.396 --> 00:03:18.739
It only will show the areas where we
have a lot of color, the same color.

44
00:03:18.739 --> 00:03:23.242
So, for instance,
those areas they will have the highest,

45
00:03:23.242 --> 00:03:25.902
well actually quite the opposite.

46
00:03:25.902 --> 00:03:27.238
Those will be ignored and

47
00:03:27.238 --> 00:03:30.810
the rest remember that white color
is the high intensity, right?

48
00:03:30.810 --> 00:03:36.900
So basically everywhere
where we had white will be

49
00:03:36.900 --> 00:03:41.978
highlighted and the black will be black.

50
00:03:41.978 --> 00:03:46.404
So it helps us to find basically
those two points where we had

51
00:03:46.404 --> 00:03:49.158
the black color the most so to speak.

52
00:03:49.158 --> 00:03:53.178
So it's gonna really simple demonstration
of how kernels actually applied.

53
00:03:53.178 --> 00:03:59.606
But once again it's not your job to
choose those kernels, those filters.

54
00:03:59.606 --> 00:04:04.112
They will be automatically created when
you do the training of your convolution

55
00:04:04.112 --> 00:04:05.128
neural network.

56
00:04:05.128 --> 00:04:09.398
So once again, you will be providing
the original images and what the labels,

57
00:04:09.398 --> 00:04:12.906
right, and then those 3 by 3
filters they will be readjusted.

58
00:04:12.906 --> 00:04:17.936
So during the training phase the model
will figure out itself what filter

59
00:04:17.936 --> 00:04:23.798
should look like to recognize a particular
features to get the correct prediction.

60
00:04:25.191 --> 00:04:29.537
All right, so now the fun parts,
and we can experiment with this-

61
00:04:29.537 --> 00:04:30.559
&gt;&gt; Can I interrupt with a question-

62
00:04:30.559 --> 00:04:31.069
&gt;&gt; Yes, please.

63
00:04:31.069 --> 00:04:31.671
&gt;&gt; Real quick?

64
00:04:31.671 --> 00:04:36.191
So if we go back to the first
convolutional neural network

65
00:04:36.191 --> 00:04:38.271
workbook you have there.

66
00:04:38.271 --> 00:04:41.608
&gt;&gt; First?
You mean fully connected or convolution?

67
00:04:41.608 --> 00:04:42.641
&gt;&gt; That one.

68
00:04:42.641 --> 00:04:44.771
&gt;&gt; Okay.

69
00:04:44.771 --> 00:04:47.079
&gt;&gt; And then go to the layers.

70
00:04:47.079 --> 00:04:50.524
Okay, so you have the convolutional 2D-
&gt;&gt; Yep.

71
00:04:50.524 --> 00:04:52.434
&gt;&gt; Feeding and max pooling 2D.

72
00:04:52.434 --> 00:04:53.055
&gt;&gt; Yep.

73
00:04:53.055 --> 00:04:57.201
&gt;&gt; So the convolutional 2D is
identifying a 3 by 3 pattern if you

74
00:04:57.201 --> 00:04:58.057
will-
&gt;&gt; Mm-hm.

75
00:04:58.057 --> 00:04:58.668
&gt;&gt; Right?

76
00:04:58.668 --> 00:05:01.587
&gt;&gt; 32 of them, mm-hm.

77
00:05:01.587 --> 00:05:06.021
&gt;&gt; 32 of them over the 28 by 28

78
00:05:06.021 --> 00:05:09.188
pixel image or-
&gt;&gt; So-

79
00:05:09.188 --> 00:05:11.739
&gt;&gt; 32 different-

80
00:05:11.739 --> 00:05:13.815
&gt;&gt; Filters.

81
00:05:13.815 --> 00:05:19.406
&gt;&gt; Permutations or whatever of filters for
that 3 by 3 pixel.

82
00:05:19.406 --> 00:05:20.744
&gt;&gt; Yes.

83
00:05:20.744 --> 00:05:23.741
So basically we will have,

84
00:05:25.292 --> 00:05:30.425
As the input we will have
this 28 by 28 image, right?

85
00:05:30.425 --> 00:05:36.222
But then during the convolution we
will apply 32 different filters and

86
00:05:36.222 --> 00:05:39.082
each of them will be 3 by 3 pixels.

87
00:05:39.082 --> 00:05:43.794
And basically some of the filters
as I said probably will

88
00:05:43.794 --> 00:05:47.310
learn how to distinguish diagonal line.

89
00:05:47.310 --> 00:05:49.962
The next one probably vertical line and
so on and so forth.

90
00:05:49.962 --> 00:05:50.528
So or

91
00:05:50.528 --> 00:05:55.602
if we will be training on color images-
&gt;&gt; Okay.

92
00:05:55.602 --> 00:05:59.190
&gt;&gt; It will learn even to
distinguish different colors.

93
00:05:59.190 --> 00:06:03.634
&gt;&gt; So we're essentially looking for
the 32 strongest 3 by 3 patterns?

94
00:06:03.634 --> 00:06:04.796
&gt;&gt; Yep.

95
00:06:04.796 --> 00:06:09.332
&gt;&gt; Okay, and
then feeding that into the pooling 2D,

96
00:06:09.332 --> 00:06:13.553
so we're taking each of those 3 by 3,
sorry,

97
00:06:13.553 --> 00:06:17.376
we're taking the original 3 by 3-
&gt;&gt; Okay,

98
00:06:17.376 --> 00:06:22.776
let me stop you here because I think I
will probably just Google [LAUGH] for

99
00:06:22.776 --> 00:06:26.389
a nice picture of
demonstrating convolution.

100
00:06:26.389 --> 00:06:31.124
On the first layer we simply recognize
those different patterns, right?

101
00:06:31.124 --> 00:06:33.413
Like horizontal lines and all of that.

102
00:06:33.413 --> 00:06:38.582
But if you combine those particular
patterns you can come up with

103
00:06:38.582 --> 00:06:43.856
something more complex like
a particular facial parts, right.

104
00:06:43.856 --> 00:06:50.734
So when you're doing convolution this 28
by 28 you're just taking this filter and

105
00:06:50.734 --> 00:06:55.079
just going through all of
the original image, right.

106
00:06:55.079 --> 00:06:58.265
And a convolutional operation, as I said,

107
00:06:58.265 --> 00:07:03.173
is just multiplying the values of
the pixels and value just adding,

108
00:07:03.173 --> 00:07:07.064
so the result will be 9,
sum of 9 multiplications.

109
00:07:07.064 --> 00:07:08.367
But if you filter,

110
00:07:08.367 --> 00:07:13.760
you can think about it like if you filter
look exactly like these three pixels.

111
00:07:13.760 --> 00:07:17.166
Somewhere in the image this will return,
so

112
00:07:17.166 --> 00:07:21.871
the layer is not gonna be looking
like the original picture.

113
00:07:21.871 --> 00:07:26.749
It will only highlight
the places on the original image

114
00:07:26.749 --> 00:07:30.575
where this particular feature was found.

115
00:07:30.575 --> 00:07:33.391
So-
&gt;&gt; [INAUDIBLE] the filters matches

116
00:07:33.391 --> 00:07:34.118
strongly?

117
00:07:34.118 --> 00:07:34.662
&gt;&gt; Exactly.

118
00:07:34.662 --> 00:07:35.936
&gt;&gt; Okay.

119
00:07:35.936 --> 00:07:40.538
&gt;&gt; And basically,
if you now see that the result of

120
00:07:40.538 --> 00:07:45.718
convolution from the first
filter showed you that you

121
00:07:45.718 --> 00:07:50.781
have one kinda really high
intensity in this area but

122
00:07:50.781 --> 00:07:55.845
second filter when it went
through all the pixels and

123
00:07:55.845 --> 00:08:02.089
highlighted this area but
that's gonna be different results.

124
00:08:02.089 --> 00:08:06.164
But we can take the inputs on
the next layer and say okay,

125
00:08:06.164 --> 00:08:09.113
those areas are close to each other, and

126
00:08:09.113 --> 00:08:13.830
the convolution will actually
see because they are connected.

127
00:08:16.650 --> 00:08:22.697
Yeah, probably just drilling the
architecture would be easier to explain.

128
00:08:22.697 --> 00:08:27.798
But yeah, highlighting the areas
on the higher level it will kind

129
00:08:27.798 --> 00:08:32.624
of recognize that we have
a particular features recognized,

130
00:08:32.624 --> 00:08:35.962
and they are sitting next to each other,
so

131
00:08:35.962 --> 00:08:41.463
we can progress to more kind of
complex recognition if it makes sense.

132
00:08:41.463 --> 00:08:42.013
&gt;&gt; I think so.

133
00:08:42.013 --> 00:08:47.683
So I think what you're saying is like the
convolutional layer will say okay, right

134
00:08:47.683 --> 00:08:50.857
here we have a strong match to filter one-
&gt;&gt; Yes.

135
00:08:50.857 --> 00:08:52.880
&gt;&gt; Right next to it we have
a strong match to filter two.

136
00:08:52.880 --> 00:08:54.298
&gt;&gt; Mm-hm.

137
00:08:54.298 --> 00:08:57.445
&gt;&gt; And then in the pooling,
it'll say one and

138
00:08:57.445 --> 00:09:01.945
two together that weighted highly,
and so we have a feature there.

139
00:09:01.945 --> 00:09:04.039
&gt;&gt; With the pooling so, okay,

140
00:09:04.039 --> 00:09:09.980
you recognized a particular feature when
you did the convolutional operation,

141
00:09:09.980 --> 00:09:14.714
but the main task of pooling is
just reduce the dimensionality.

142
00:09:16.804 --> 00:09:21.971
But spatially it means that
most probably their recognized

143
00:09:21.971 --> 00:09:26.217
feature now gonna be really
close to each other.

144
00:09:26.217 --> 00:09:29.577
So the next convolution
layer now can say okay,

145
00:09:29.577 --> 00:09:33.273
this particular filter from
the previous operation

146
00:09:33.273 --> 00:09:38.067
recognized horizontal lines this
one recognized vertical lines.

147
00:09:38.067 --> 00:09:42.715
So having this and that together
it looks like something blah,

148
00:09:42.715 --> 00:09:46.056
like eye, for instance, right, or a nose.

149
00:09:46.056 --> 00:09:51.201
And then once again you kinda okay, we
recognize nose here we recognize eye here.

150
00:09:51.201 --> 00:09:55.591
We're doing pooling and
once again it's gonna shrink

151
00:09:55.591 --> 00:10:00.180
the dimensionality of the input
data to this next layer.

152
00:10:00.180 --> 00:10:05.533
It's done to basically reduce
the amount of computation you're doing.

153
00:10:05.533 --> 00:10:10.489
You can probably just ignore pooling
half times of convolutions, but

154
00:10:10.489 --> 00:10:15.782
the problem is your filter is pretty
small, and we want to keep it that way.

155
00:10:15.782 --> 00:10:20.226
But if you're doing pooling, the idea
is that you are reducing the size of

156
00:10:20.226 --> 00:10:25.330
the image you're processing, right, so
you're doing less and less operations.

157
00:10:25.330 --> 00:10:28.072
But the idea is that the most
useful information will be still

158
00:10:28.072 --> 00:10:29.107
propagated, right?

159
00:10:29.107 --> 00:10:33.820
Because we picking the maximum intensity
out of those like four pixels for

160
00:10:33.820 --> 00:10:34.587
instance.

161
00:10:34.587 --> 00:10:39.985
And it means that your next convolutional
layers will have larger and

162
00:10:39.985 --> 00:10:43.999
larger view, so to speak,
on the original image.

163
00:10:43.999 --> 00:10:49.907
So the view of your filter
to some degree increases.

164
00:10:49.907 --> 00:10:54.305
But it's not looking at
the original filter it's just

165
00:10:54.305 --> 00:10:57.752
looking on already recognized patterns.

166
00:10:57.752 --> 00:11:00.112
And that's how you kinda
build a complex list.

167
00:11:00.112 --> 00:11:04.574
That's how you can interpret what
the convolutional neural net is doing.

168
00:11:04.574 --> 00:11:10.108
It's looking at something really, really
small and really detailed at the beginning

169
00:11:10.108 --> 00:11:15.360
but then trying to make sense out of those
small details into more larger objects.

