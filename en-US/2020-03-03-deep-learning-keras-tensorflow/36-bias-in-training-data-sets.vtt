WEBVTT

1
00:00:00.354 --> 00:00:03.960
So do we want to try anything else?

2
00:00:03.960 --> 00:00:10.248
Let's see creative common images.

3
00:00:10.248 --> 00:00:14.879
Let's grab the image address.

4
00:00:14.879 --> 00:00:15.980
So, JPG file, perfect.

5
00:00:15.980 --> 00:00:20.442
Okay, let's feed it into
our neural networks.

6
00:00:20.442 --> 00:00:27.790
So, What we need to do,
is simply download this image.

7
00:00:27.790 --> 00:00:33.244
So what I will do here is
write the second command,

8
00:00:33.244 --> 00:00:36.695
ir maybe just create the new cell.

9
00:00:40.850 --> 00:00:47.730
The location of the image and
the image name will be the following.

10
00:00:47.730 --> 00:00:50.520
So all right, image downloaded, so

11
00:00:50.520 --> 00:00:54.305
now I can just simply put
it as the name of our file.

12
00:00:54.305 --> 00:00:56.747
Seriously, I am doing for
the first time and

13
00:00:56.747 --> 00:00:59.565
I have no idea what
prediction we're gonna get.

14
00:00:59.565 --> 00:01:01.745
So it should be pretty fun.

15
00:01:01.745 --> 00:01:08.141
Okay, so with the 36% accuracy,
we are looking at the notebook,

16
00:01:08.141 --> 00:01:14.480
which is cracked, 29% laptop,
and that was a mouse, really?

17
00:01:14.480 --> 00:01:18.771
[LAUGH] There's no mouse on the image, and

18
00:01:18.771 --> 00:01:25.523
that's actually really good example
of biases in the data sets.

19
00:01:25.523 --> 00:01:31.423
So you see that our model actually did a
prediction that it's looking at the mouse

20
00:01:31.423 --> 00:01:36.720
with yes, 8% not super accurate but
still, it did this prediction.

21
00:01:36.720 --> 00:01:41.141
And the reason why it did this
because most probably a lot

22
00:01:41.141 --> 00:01:46.140
of images from the training data
set had laptop and mouse on it.

23
00:01:46.140 --> 00:01:52.027
And that's kind of biases you probably
want to avoid in your training data sets,

24
00:01:52.027 --> 00:01:52.640
right?

25
00:01:52.640 --> 00:01:57.330
When you have the almost like correlations
between the particular classes.

26
00:01:57.330 --> 00:02:02.178
And ideally what you want to
have is equal distribution of

27
00:02:02.178 --> 00:02:06.410
laptops with mouses,
laptops without mouses.

28
00:02:06.410 --> 00:02:10.340
Mouses without laptops, and of course,
nothing, no mouse, no laptop.

29
00:02:10.340 --> 00:02:14.192
In this case,
that's the balanced data set and

30
00:02:14.192 --> 00:02:18.070
what we want to have in
your training data sets.

31
00:02:18.070 --> 00:02:24.730
But yes, it is working and we can even
see okay, we need to change the index.

32
00:02:24.730 --> 00:02:27.632
So the notebook,

33
00:02:27.632 --> 00:02:33.440
that was our neuron number 681.

34
00:02:33.440 --> 00:02:37.325
So everything is good,

35
00:02:37.325 --> 00:02:42.970
I just need to change this number.

36
00:02:42.970 --> 00:02:50.500
And now we can visualize the intensity,
interesting, interesting, okay?

37
00:02:50.500 --> 00:02:54.184
Now, I'm kinda curious,
if we overlaid those where the, [LAUGH] So

38
00:02:54.184 --> 00:03:01.674
when this prediction was made that we're
looking at the laptop wasn't actually,

39
00:03:01.674 --> 00:03:06.061
well, it was partially looking the laptop,
but

40
00:03:06.061 --> 00:03:12.950
it paid a lot of intention to
the hands on the laptop, interesting.

41
00:03:12.950 --> 00:03:17.622
So it's just one of the way to kinda play
around with the potential where the neural

42
00:03:17.622 --> 00:03:18.375
network is.

43
00:03:21.430 --> 00:03:24.235
Where was the location of the neurons,

44
00:03:24.235 --> 00:03:29.000
which activated the prediction,
which the neural network done.

45
00:03:29.000 --> 00:03:36.400
And it might help to avoid, as I said,
biases or missed trained neural networks.

46
00:03:36.400 --> 00:03:44.340
One interesting example was when there was
a task to recognize dogs versus wolves.

47
00:03:44.340 --> 00:03:47.540
And well, they kinda look alike, right?

48
00:03:47.540 --> 00:03:51.176
And neural network was actually doing
really good job predicting when it's

49
00:03:51.176 --> 00:03:53.920
looking at the wolves and
when it's looking at the dogs.

50
00:03:53.920 --> 00:03:57.524
And when this method was applied
we're gonna pay attention and

51
00:03:57.524 --> 00:04:01.180
figuring out where the neural
network is looking at.

52
00:04:01.180 --> 00:04:05.649
They figured that's when the image of the
wolf was provided it was all the snow on

53
00:04:05.649 --> 00:04:06.660
the background.

54
00:04:06.660 --> 00:04:11.443
So neural network is just simply,
it wasn't dog versus wolf predictor,

55
00:04:11.443 --> 00:04:16.020
it was simply telling you if it's
recognized snow on the image or not.

56
00:04:16.020 --> 00:04:20.918
And if snow was present it was simply
labeling all of that as wolf, is that it?

57
00:04:20.918 --> 00:04:22.920
Well, you got the idea.

58
00:04:22.920 --> 00:04:25.832
But yeah, it's interesting and
that's one of the way how you

59
00:04:25.832 --> 00:04:28.410
can see where the neural
network is paying attention.

