WEBVTT

1
00:00:00.210 --> 00:00:05.162
I was telling about the deep learning,
about the model, and

2
00:00:05.162 --> 00:00:11.182
the next logical stuff used to explain
how the model is actually trained,

3
00:00:11.182 --> 00:00:14.408
how is learning to do the predictions?

4
00:00:14.408 --> 00:00:20.047
And there was a comment about [LAUGH]
connectivity of the neural network.

5
00:00:20.047 --> 00:00:24.679
So usually,
in fully connected neural networks, and

6
00:00:24.679 --> 00:00:30.735
that's what people played with
originally before AlexNet actually.

7
00:00:30.735 --> 00:00:34.244
Well, as the name suggests,
fully connected neural network means that

8
00:00:34.244 --> 00:00:38.670
all the neurons of the previous layer are
connected with all neurons the next layer.

9
00:00:38.670 --> 00:00:43.330
So for
example with three neurons right here,

10
00:00:43.330 --> 00:00:45.510
it means that this neuron
will be connected.

11
00:00:47.700 --> 00:00:50.870
This neuron will be connected and
this one will be connected.

12
00:00:50.870 --> 00:00:56.322
And it means that in the layer,

13
00:00:56.322 --> 00:01:01.144
we will have W1, W2, and

14
00:01:01.144 --> 00:01:09.420
W3 associated with this particular neuron.

15
00:01:09.420 --> 00:01:14.577
And there will be W1, W2, wait, so W3.

16
00:01:14.577 --> 00:01:18.080
But basically,
associated with this neuron, right?

17
00:01:18.080 --> 00:01:22.890
So each neuron will have its own
set of Ws, weights and biases.

18
00:01:22.890 --> 00:01:26.180
So there will be additional bias here,
additional bias here.

19
00:01:26.180 --> 00:01:31.125
So that's why people usually put
weights 1112131 and 1222232, sorry,

20
00:01:31.125 --> 00:01:36.310
[LAUGH]
just to

21
00:01:36.310 --> 00:01:43.010
kind of differentiate that we have
different weights and different biases.

22
00:01:43.010 --> 00:01:47.880
In convolutional neural network,
that's what AlexNet used,

23
00:01:47.880 --> 00:01:52.470
not all the neurons connected, so
if it's not fully connected layers,

24
00:01:52.470 --> 00:01:55.510
it's a convolutional operations.

25
00:01:55.510 --> 00:02:00.900
I think I will get to it when we
will be discussing image processing.

26
00:02:00.900 --> 00:02:03.100
So it will be basically in segments.

27
00:02:03.100 --> 00:02:06.150
Now let's talk about
training of the model.

28
00:02:06.150 --> 00:02:11.061
So how do we know what weights and
biases to use to actually do

29
00:02:11.061 --> 00:02:16.182
the prediction if we're looking
at the hot dog or not hot dog?

30
00:02:16.182 --> 00:02:20.570
And that's what we need
training data set for.

31
00:02:20.570 --> 00:02:23.100
So what is training data sets?

32
00:02:23.100 --> 00:02:28.259
For instance, if we are providing the
images to our neural network to train on,

33
00:02:28.259 --> 00:02:29.799
we need tons of images.

34
00:02:29.799 --> 00:02:34.333
And when I say tons,
it means we need about, well,

35
00:02:34.333 --> 00:02:40.350
ideally several thousands for
each class you want to try train for.

36
00:02:41.660 --> 00:02:44.630
And those images should be annotated.

37
00:02:44.630 --> 00:02:48.220
So for instance,
we need thousand images with hot dog and

38
00:02:48.220 --> 00:02:51.760
thousand images with not hot dog.

39
00:02:51.760 --> 00:02:56.290
And what we will do,
we'll just provide the image,

40
00:02:56.290 --> 00:02:59.748
let's say with the hot dog,
I don't know how to draw a hot dog.

41
00:03:01.520 --> 00:03:06.212
Yeah I dont wanna mess with my
[LAUGH] lines and boxes here, but

42
00:03:06.212 --> 00:03:09.344
imagine that that's a hot dog, right?

43
00:03:09.344 --> 00:03:13.275
And at the end, we just seen our model.

44
00:03:13.275 --> 00:03:15.905
Just because our training
data set is annotated,

45
00:03:15.905 --> 00:03:19.612
I was saying that you're looking
right now at the hot dog, actually.

46
00:03:19.612 --> 00:03:23.266
And all those weights and
biases, originally,

47
00:03:23.266 --> 00:03:28.245
when the model is not trained,
it's activated randomly.

48
00:03:28.245 --> 00:03:33.037
Meaning that we just
simply using those Ws and

49
00:03:33.037 --> 00:03:40.200
Bs randomly somewhere,
let's say ideally around zero, right?

50
00:03:40.200 --> 00:03:47.620
And maybe in the normal distribution
between something like minus one and one.

51
00:03:47.620 --> 00:03:51.300
So all of them are randomly activated.

52
00:03:51.300 --> 00:03:55.660
And our model first do the forwards and

53
00:03:55.660 --> 00:04:00.240
that's the words we will be hearing
quite a bit, forward propagation.

54
00:04:00.240 --> 00:04:01.574
So what is forward propagatio?

55
00:04:01.574 --> 00:04:07.087
It means that it's just taking this image
of the hot dog and do those calculations,

56
00:04:07.087 --> 00:04:10.968
right, with this random weights and
biases originally.

57
00:04:10.968 --> 00:04:14.647
So some of the neurons will be for
instance activated and

58
00:04:14.647 --> 00:04:17.631
will propagate the signal further, right?

59
00:04:17.631 --> 00:04:23.072
And depending on those random weights in
the second layer, some of the neurons

60
00:04:23.072 --> 00:04:28.027
here will be activated and so on and
so forth until we get to the last one.

61
00:04:28.027 --> 00:04:32.000
And it can be activated or
it can be not activated.

62
00:04:32.000 --> 00:04:37.240
So basically, this neuron will say
if it's looking at the hot dog or

63
00:04:37.240 --> 00:04:40.100
if it's not looking at the hot dog.

64
00:04:41.760 --> 00:04:43.900
All of that at this point is random,
right?

65
00:04:43.900 --> 00:04:47.540
We just did forward propagation.

66
00:04:47.540 --> 00:04:52.960
But our model is randomly activated so
we just get some random answer.

67
00:04:52.960 --> 00:04:55.135
The trick is coming next.

68
00:04:55.135 --> 00:05:00.160
Based on the prediction our model did,
if it was correct answer, right, if

69
00:05:00.160 --> 00:05:05.830
we actually correctly said that you know
what, most probably, that's the hot dog.

70
00:05:07.160 --> 00:05:12.060
In this case, we'll just go back and
reinforce all of

71
00:05:12.060 --> 00:05:17.050
the previously made correct decision.

72
00:05:17.050 --> 00:05:23.040
So basically if this neuron was activate
and this neuron was activated and

73
00:05:23.040 --> 00:05:26.892
we'll simply reinforce this
connection between those neurons.

74
00:05:26.892 --> 00:05:28.040
And how we do that?

75
00:05:28.040 --> 00:05:33.070
By simply increasing weight, and

76
00:05:33.070 --> 00:05:38.010
go to the next level and next level and
basically gonna go to all the previous

77
00:05:38.010 --> 00:05:40.940
levels and
slightly modified those weights.

78
00:05:40.940 --> 00:05:43.260
And what is happening right now,

79
00:05:43.260 --> 00:05:47.540
this whole process of going back
is called backward propagation.

80
00:05:47.540 --> 00:05:51.428
So in machine learning you probably
if you heard just a little bit

81
00:05:51.428 --> 00:05:53.588
about machine learning backprop or

82
00:05:53.588 --> 00:05:58.353
backward propagation is this process
when we training the machine learning.

83
00:05:58.353 --> 00:06:03.044
But we're changing those weights
just a little bit and the way how,

84
00:06:03.044 --> 00:06:06.416
what should be the difference
in those weights,

85
00:06:06.416 --> 00:06:10.136
it's actually calculated
through the derivative.

86
00:06:10.136 --> 00:06:14.359
And I don't wanna go too deep
into the math, but just trust me,

87
00:06:14.359 --> 00:06:18.343
what we do here is if we're
seeing those decisions we made,

88
00:06:18.343 --> 00:06:21.070
if the prediction was correct, right?

89
00:06:21.070 --> 00:06:26.390
And then if a kinda similar image for
instance will be provided, there

90
00:06:26.390 --> 00:06:29.990
is a chance that the same neurons will be
activated and we will get the same result.

91
00:06:29.990 --> 00:06:35.570
But if for instance the prediction by our
random activated model was incorrect,

92
00:06:35.570 --> 00:06:39.280
for instance,
although we're looking at the hot dog but

93
00:06:39.280 --> 00:06:42.160
predicted that it's not a hot dog.

94
00:06:42.160 --> 00:06:46.670
We will penalize our neural network
by doing exactly the same thing,

95
00:06:46.670 --> 00:06:50.270
just going through those
activated channels and

96
00:06:50.270 --> 00:06:53.320
simply shrinking down
the weights a little bit.

97
00:06:53.320 --> 00:06:57.896
So the idea is that you reinforce
the correct predictions and

98
00:06:57.896 --> 00:07:01.495
penalize the incorrectly
predicted results.

99
00:07:01.495 --> 00:07:07.410
And you're just doing it over and over
again by showing multiple images, right?

100
00:07:07.410 --> 00:07:10.240
So that's how you do it.

101
00:07:10.240 --> 00:07:12.100
That's how you train neural network.

