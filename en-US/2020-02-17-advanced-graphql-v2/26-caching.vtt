WEBVTT

1
00:00:00.110 --> 00:00:01.440
Now, I wanna talk about cache.

2
00:00:01.440 --> 00:00:02.860
It is a very important thing.

3
00:00:02.860 --> 00:00:05.800
It's no point of building all this and
become an expert in deploying,

4
00:00:05.800 --> 00:00:11.100
if we don't understand the elephant in the
room, which is caching what GraphQL is,

5
00:00:11.100 --> 00:00:14.030
it's a big problem, or
at least it used to be announced.

6
00:00:14.030 --> 00:00:15.470
It's gotta be installed.

7
00:00:15.470 --> 00:00:17.180
So there's many types of caching.

8
00:00:17.180 --> 00:00:21.080
We have application caching, and
that's basically stuff we're doing inside

9
00:00:21.080 --> 00:00:25.900
the code, like things in the database,
things on the resolvers.

10
00:00:25.900 --> 00:00:30.580
Anything that's revolves us writing
code at runtime, execution time,

11
00:00:30.580 --> 00:00:31.780
that's application caching.

12
00:00:32.830 --> 00:00:35.800
So database,
external data source, resolvers.

13
00:00:35.800 --> 00:00:38.650
Then you have network caching,
and this is probably what

14
00:00:38.650 --> 00:00:43.500
a lot of us are used to is something on a
CDN level, we're using some cache headers.

15
00:00:43.500 --> 00:00:46.420
We're doing something like CloudFlare,
or whatever we're doing.

16
00:00:46.420 --> 00:00:50.220
And we're caching our rest
GET request on the CDN is so

17
00:00:50.220 --> 00:00:54.080
easy, cuz the URL just works, and
it's good to go, that's network caching.

18
00:00:54.080 --> 00:00:58.292
So HTTP caching, stuff like that, and
then, we have client side caching.

19
00:00:58.292 --> 00:01:02.640
So if you take in the Frontend GraphQL
course with react that we have,

20
00:01:02.640 --> 00:01:04.320
you understand client side caching.

21
00:01:04.320 --> 00:01:09.010
But if you've ever used anything
like Redux, or Vuex, or

22
00:01:09.010 --> 00:01:12.650
any client side state management,
that's client side caching.

23
00:01:12.650 --> 00:01:15.110
So that's the other type
of caching you will do.

24
00:01:16.350 --> 00:01:18.590
So let's talk about Application Caching.

25
00:01:18.590 --> 00:01:22.300
This is the preferred way
to cache GraphQL right now.

26
00:01:23.360 --> 00:01:25.500
It's changing, but it's the preferred way,

27
00:01:25.500 --> 00:01:30.550
because it's the easiest to understand,
there's more available tools and

28
00:01:30.550 --> 00:01:36.050
scenarios, and
you can go pretty far with it.

29
00:01:36.050 --> 00:01:39.190
Although this is changing, they're
moving over to network caching, and

30
00:01:39.190 --> 00:01:39.965
we'll talk about that.

31
00:01:39.965 --> 00:01:42.377
But right now, and
is the preferred way to cache.

32
00:01:42.377 --> 00:01:45.120
And you have many options and
levels to cache depending on your server.

33
00:01:45.120 --> 00:01:50.850
So again, you could be a traditional
Redis database in front of,

34
00:01:50.850 --> 00:01:54.010
I don't know your Mongo database, or
actually use something like Mongo, and

35
00:01:54.010 --> 00:01:55.010
you got your indexes, right.

36
00:01:55.010 --> 00:01:57.290
You don't even need Redis,
cuz it's already indexed.

37
00:01:57.290 --> 00:01:58.870
And sitting in a good cache.

38
00:01:58.870 --> 00:02:00.140
So, it really,

39
00:02:00.140 --> 00:02:04.650
you have ultimate flexibility is more
traditional to what you're used to.

40
00:02:04.650 --> 00:02:06.770
You can also use things like data loaders,

41
00:02:06.770 --> 00:02:11.530
which are like per request caches for
GraphQL.

42
00:02:11.530 --> 00:02:17.270
So that prevents people from having these
circular queries that they send you,

43
00:02:17.270 --> 00:02:20.340
and you haven't go to the database to
ask for something that you already got.

44
00:02:20.340 --> 00:02:23.210
To resolvers ago,
you can catch that per request.

45
00:02:23.210 --> 00:02:25.260
So things like Data Loader help with that.

46
00:02:25.260 --> 00:02:28.470
So yeah, a lot more options when
you're caching application side.

47
00:02:28.470 --> 00:02:31.210
I think,
that doesn't really help you if you

48
00:02:31.210 --> 00:02:35.720
wanna be the closest to your customers all
across the world and on different nodes.

49
00:02:35.720 --> 00:02:37.510
You need something on the network layer,
but

50
00:02:37.510 --> 00:02:40.810
at least when they do go to origin,
the data access is pretty fast.

51
00:02:40.810 --> 00:02:46.065
So a bunch, and then, there's also, like I
said, the reason a lot of people do this,

52
00:02:46.065 --> 00:02:49.170
cuz there's just a bunch of
misunderstandings around HTTP caching and

53
00:02:49.170 --> 00:02:50.220
GraphQL.

54
00:02:50.220 --> 00:02:53.430
And also, because the technology
is just now getting there

55
00:02:53.430 --> 00:02:56.650
to take advantage of the HTTP
network based caching with GraphQL.

56
00:02:58.110 --> 00:02:59.340
So let's talk about that.

57
00:02:59.340 --> 00:03:03.930
So HTTP caching, it can be a more
complicated, unless you use services and

58
00:03:03.930 --> 00:03:10.510
features like Apollo cast control, Apollo
engine, and automatic persistent queries.

59
00:03:10.510 --> 00:03:13.886
So what I'm talking about there,
is I'll just show you.

60
00:03:13.886 --> 00:03:20.510
So Apollo cache control allows
you to use directives on types,

61
00:03:20.510 --> 00:03:25.480
so you can cache on a tight basis with
different ttl, and stuff like that.

62
00:03:25.480 --> 00:03:32.000
These directives basically help
HTTP network calls on header level,

63
00:03:32.000 --> 00:03:36.480
understand what to do, it gives a meta
data on what to do to handle caching.

64
00:03:36.480 --> 00:03:41.330
So it makes caching a lot simpler,
very easy to work with,

65
00:03:41.330 --> 00:03:44.820
this is a system that you have to opt
in to, and you need an interpreter, so

66
00:03:44.820 --> 00:03:47.600
something [INAUDIBLE] needs
to actually interpret this.

67
00:03:47.600 --> 00:03:51.532
And right now, the only thing that I know
of that automatically interprets this for

68
00:03:51.532 --> 00:03:53.260
you is a paid product by Apollo.

69
00:03:53.260 --> 00:03:55.220
So you gotta buy the product
to interpret this.

70
00:03:55.220 --> 00:03:57.370
But there's nothing stopping you
from writing your own interpreter,

71
00:03:57.370 --> 00:04:00.030
especially using some of
the technologies that I'll talk about.

72
00:04:00.030 --> 00:04:02.499
So that's pretty good.

73
00:04:02.499 --> 00:04:06.450
I've never used it, never had to use it,
but I've heard it works pretty well.

74
00:04:06.450 --> 00:04:10.890
You also have what I mentioned here,
which is persistent queries.

75
00:04:12.000 --> 00:04:17.580
A persistent query is basically, instead
of writing your queries on the client,

76
00:04:17.580 --> 00:04:20.930
and then, whenever those queries need
to run an execution time at runtime,

77
00:04:20.930 --> 00:04:23.070
you send them up, and
then, they get evaluated,

78
00:04:23.070 --> 00:04:25.130
and they get executed,
and the result comes back.

79
00:04:25.130 --> 00:04:28.500
What you do at build time, is you
have all your queries on the client.

80
00:04:28.500 --> 00:04:31.960
And before you even deploy, you send all
those queries up to the server with tool,

81
00:04:31.960 --> 00:04:34.000
or whatever, however you do it.

82
00:04:34.000 --> 00:04:36.640
And the server pre validates
all the queries right there.

83
00:04:36.640 --> 00:04:39.450
And it saves them in some type of
database, or something like that.

84
00:04:39.450 --> 00:04:40.980
And it gives them all like an ID.

85
00:04:40.980 --> 00:04:44.760
So this is query 1, this is query 2,
this is query 3, this is query 4.

86
00:04:44.760 --> 00:04:46.080
And then, now, on the client,

87
00:04:46.080 --> 00:04:50.760
all you have to do is just say,
just run a graphical query for query one.

88
00:04:50.760 --> 00:04:54.470
And it will just execute that
query less across the wire.

89
00:04:54.470 --> 00:04:58.690
And because it's just a get request
with a parameter in it, it's cacheable.

90
00:04:58.690 --> 00:04:59.490
So you can cache it.

91
00:04:59.490 --> 00:05:00.910
You don't have to do all this crazy stuff.

92
00:05:00.910 --> 00:05:05.796
It's gonna cache the same way as every
other rest API calls ever cache before.

93
00:05:05.796 --> 00:05:08.280
And you get that for
free automatically with Apollo.

94
00:05:08.280 --> 00:05:11.660
So this Apollo client on the front end,
and Apollo server on the back end,

95
00:05:11.660 --> 00:05:14.410
that automatically works for you,
you don't have to do anything.

96
00:05:14.410 --> 00:05:15.260
It automatically does it.

97
00:05:15.260 --> 00:05:17.490
So when it makes,
when Apollo makes a query,

98
00:05:17.490 --> 00:05:21.520
the first time from the client is gonna
make another query to get the ID, and

99
00:05:21.520 --> 00:05:24.460
try to persist it, and
try to store it for you and memory.

100
00:05:24.460 --> 00:05:26.830
So it'll try to persist those for you.

101
00:05:26.830 --> 00:05:29.380
You don't have to worry about it, it
doesn't do like a pre-validation step, but

102
00:05:29.380 --> 00:05:33.400
it will persist the queries, cuz it's
trying to get you to opt in to their

103
00:05:33.400 --> 00:05:36.210
caching implementation,
which is really cool.

104
00:05:36.210 --> 00:05:38.820
So yeah, there's a lot of features
like that that you can get now.

105
00:05:39.950 --> 00:05:42.800
You can also use Edge Applications
to program your own cache logic.

106
00:05:42.800 --> 00:05:43.680
So when I said,

107
00:05:43.680 --> 00:05:47.520
you need an interpreter to interpret
that metadata that's being generated.

108
00:05:47.520 --> 00:05:49.570
Well, you couldn't really
do that before until now.

109
00:05:49.570 --> 00:05:55.008
So now, you can use something
like cloud flare workers,

110
00:05:55.008 --> 00:05:59.776
which are basically
JavaScript apps on the edge.

111
00:05:59.776 --> 00:06:02.730
And you can just write
JavaScript literally on a CDN.

112
00:06:03.750 --> 00:06:05.680
They're not even in beta anymore.

113
00:06:05.680 --> 00:06:08.720
So really cool package to use.

114
00:06:08.720 --> 00:06:14.200
Different alternatives are lambda edge or
lambda at edge.

115
00:06:14.200 --> 00:06:15.810
There you go,
which is basically the same thing.

116
00:06:15.810 --> 00:06:19.940
It's writing lambda functions
on the edge of CloudFront,

117
00:06:19.940 --> 00:06:24.060
which is AWS, CDN product, pretty cool.

118
00:06:24.060 --> 00:06:26.020
This is one of the first ones I've used.

119
00:06:26.020 --> 00:06:26.780
I mean, it's cloud front.

120
00:06:26.780 --> 00:06:28.276
You can't get more powerful than that.

121
00:06:28.276 --> 00:06:33.011
And then, there's other ones like fly IO,
which is a really cool product that

122
00:06:33.011 --> 00:06:36.261
kind of does the same thing,
JavaScript at the edge.

123
00:06:36.261 --> 00:06:37.960
This one's open source, though.

124
00:06:37.960 --> 00:06:40.460
So you can kinda hack in and
do all types of crazy stuff.

125
00:06:40.460 --> 00:06:42.730
But all of these allow you to
write applications on the edge.

126
00:06:42.730 --> 00:06:45.330
In fact, you can deploy a GraphQL
server on the edge, and

127
00:06:45.330 --> 00:06:48.300
have your graphical server be
a gateway to all your other services.

128
00:06:48.300 --> 00:06:50.920
So there's a lot of different
things you can do there.

129
00:06:50.920 --> 00:06:54.620
But at minimum, you could
definitely cache whatever you want.

130
00:06:54.620 --> 00:06:57.950
You can take an incoming post
requests that's a GraphQL mutation,

131
00:06:57.950 --> 00:07:00.730
converted to a Git request, and
cache it globally if you want.

132
00:07:00.730 --> 00:07:03.420
There's a lot of different strategies
that you can take advantage of

133
00:07:03.420 --> 00:07:08.550
other than just interpreting cache
control from Apollo's cache directors.

134
00:07:08.550 --> 00:07:11.460
So pretty cool, all this stuff
is relatively new like what in

135
00:07:11.460 --> 00:07:16.270
the last two and a half, three years, so,
is coming of age, and it's really awesome.

136
00:07:16.270 --> 00:07:18.610
So I'd highly recommend
checking on this stuff.

137
00:07:18.610 --> 00:07:22.360
You can really get to the point where you
don't even have an origin server anymore.

138
00:07:22.360 --> 00:07:23.630
You just deploy apps to the edge.

139
00:07:23.630 --> 00:07:25.110
And that's where your app lives.

140
00:07:25.110 --> 00:07:28.290
You never even have an origin, which
you think about it sounds ridiculous.

141
00:07:28.290 --> 00:07:31.040
But it's possible, especially,

142
00:07:31.040 --> 00:07:34.570
if all you have is like a single page app,
it's really possible.

143
00:07:34.570 --> 00:07:35.290
The other thing is,

144
00:07:35.290 --> 00:07:38.820
you can restrict or handle mutations over
Git, which is basically what I said.

145
00:07:38.820 --> 00:07:43.710
So inside the edge applications,
you could change puts to Gits,

146
00:07:43.710 --> 00:07:48.060
and things like that, you can make sure
everything is over Git, which is possible,

147
00:07:48.060 --> 00:07:50.530
you can send the mutation
out with a Git request.

148
00:07:50.530 --> 00:07:52.869
It will just be bound by the browsers,

149
00:07:53.960 --> 00:07:57.070
restrictions of how many characters you
can have in a URL, and things like that.

150
00:07:57.070 --> 00:08:02.520
But yeah, you can totally do it, and
get queries, work with Git already,

151
00:08:02.520 --> 00:08:04.790
even though they might default to post,
so they automatically work.

152
00:08:04.790 --> 00:08:06.418
There's nothing stopping
you from doing all that,

153
00:08:06.418 --> 00:08:07.685
you just have different restrictions.

154
00:08:09.305 --> 00:08:12.258
Client side caching,
Paulo handles this pretty well, or

155
00:08:12.258 --> 00:08:14.199
your own implementation like Redux.

156
00:08:15.410 --> 00:08:18.515
UX, RXJS, NGRX, whatever your flavor is,

157
00:08:18.515 --> 00:08:21.881
you can just cache it yourself,
pretty simple.

158
00:08:21.881 --> 00:08:24.978
And then, again, persistent queries
in coordination with the server.

159
00:08:24.978 --> 00:08:28.060
The client kinda takes over and
does a lot of that stuff, too.

160
00:08:28.060 --> 00:08:32.300
But this isn't really specific to GraphQL,
this is just client side in general,

161
00:08:32.300 --> 00:08:35.600
you should just cache things from
the server, and your client, that way,

162
00:08:35.600 --> 00:08:37.690
you don't have to always go to
the server if you don't need to.

163
00:08:39.830 --> 00:08:41.282
So how should you cache?

164
00:08:41.282 --> 00:08:44.030
If you're able to use ACB caching,
enabled.

165
00:08:44.030 --> 00:08:47.570
So when I say you're able to, is
basically using some of the technologies

166
00:08:47.570 --> 00:08:51.700
that I just walked over, maybe you got
an edge CDN that you can program, too.

167
00:08:51.700 --> 00:08:55.174
Maybe you're using Apollo's paid service,
I don't know,

168
00:08:55.174 --> 00:08:58.910
however implementation you want,
if you can do it, I highly recommend just

169
00:08:58.910 --> 00:09:02.500
throwing it an HTTP, and then, just never
having to deal with application cache,

170
00:09:02.500 --> 00:09:05.720
because there's just so many options,
and so many different ways.

171
00:09:05.720 --> 00:09:09.434
And so many different things
that you have to deal with,

172
00:09:09.434 --> 00:09:11.418
I would just throw it on edge.

173
00:09:11.418 --> 00:09:15.245
Whatever implementation you use, if it has
an API that you can call from your API,

174
00:09:15.245 --> 00:09:18.519
to bust the cache and add new things
to it, you're in a perfect world,

175
00:09:18.519 --> 00:09:21.710
like you literally,
you will almost never hit origin.

176
00:09:21.710 --> 00:09:25.690
So that sounds like a fantasy,
but it's possible.

177
00:09:25.690 --> 00:09:30.550
And I would say, cache,
any external HTTP data sources.

178
00:09:30.550 --> 00:09:35.780
So if your resolvers are talking to
other HTTP sources, like a rest server,

179
00:09:35.780 --> 00:09:39.580
or I know you have an SDK
that's talking to stripe, and

180
00:09:39.580 --> 00:09:41.150
you don't need it to be
updated all the time.

181
00:09:41.150 --> 00:09:44.520
I don't know, if you wanna cache stripe
thing, but anything that's not on your

182
00:09:44.520 --> 00:09:50.450
server, and your resolvers are talking
to it, cache those things, because you

183
00:09:50.450 --> 00:09:54.870
you don't want your server being dependent
on whether, an external server is slow or

184
00:09:54.870 --> 00:09:57.900
not, so you probably wanna cache it,
and that thing crashes.

185
00:09:57.900 --> 00:09:59.538
What do you gonna do?
Your whole, it's,

186
00:09:59.538 --> 00:10:03.290
you have this whole query that's
got all these fields on it.

187
00:10:03.290 --> 00:10:05.850
One of them goes to strive, strives down.

188
00:10:05.850 --> 00:10:08.680
So your whole feels, that kind of sucks.

189
00:10:08.680 --> 00:10:10.480
Maybe you do want that, but I don't know.

190
00:10:10.480 --> 00:10:11.960
So you probably wanna
handle a lot of that stuff.

191
00:10:11.960 --> 00:10:13.710
And caching is just one of
the ways you should handle it.

192
00:10:15.070 --> 00:10:17.250
And of course, do client side caching.

193
00:10:17.250 --> 00:10:19.710
Client side caching is gonna
solve a lot of problems.

194
00:10:19.710 --> 00:10:22.670
And if you're only working on the server,
then that's not even your job.

195
00:10:22.670 --> 00:10:23.900
So let them do it.

196
00:10:23.900 --> 00:10:27.830
But client side caching will definitely
solve a lot of problems here.

