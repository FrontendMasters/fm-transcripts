WEBVTT

1
00:00:00.000 --> 00:00:03.800
&gt;&gt; Steve Kinney: So then we talked
a little bit about what do we

2
00:00:03.800 --> 00:00:06.575
do with the multiple strings and

3
00:00:06.575 --> 00:00:12.354
how do we hello world versus hello
world today, so on and so forth.

4
00:00:12.354 --> 00:00:13.567
We can see that padding.

5
00:00:13.567 --> 00:00:16.480
So we've got a batch of texts.

6
00:00:16.480 --> 00:00:22.598
Make sure I run all the various things in
this case because if I don't run them,

7
00:00:22.598 --> 00:00:24.000
they won't run.

8
00:00:24.000 --> 00:00:25.440
I'm just talking and not paying attention.

9
00:00:28.340 --> 00:00:29.283
That's actually marked down.

10
00:00:29.283 --> 00:00:30.972
So we've got batch_encoding.

11
00:00:30.972 --> 00:00:33.451
We take a tokenizer and
an array of text or a list,

12
00:00:33.451 --> 00:00:35.871
if we're speaking in
proper Python parlance,

13
00:00:35.871 --> 00:00:39.940
that we do want to have the padding and
then some amount of truncation very long.

14
00:00:39.940 --> 00:00:42.980
This PT is just what kind
of tensors do you want?

15
00:00:42.980 --> 00:00:44.300
We're using pytorch.

16
00:00:44.300 --> 00:00:46.980
There's also TensorFlow and
a few other ones.

17
00:00:46.980 --> 00:00:51.140
But just to make a decision,
we chose to use Pytorch today.

18
00:00:52.920 --> 00:00:55.833
I will be very honest where
that decision came from.

19
00:00:55.833 --> 00:00:59.906
A year, year and a half ago,
when I was researching which one to use,

20
00:00:59.906 --> 00:01:04.542
because choice is hard, there was a bunch
of people saying TensorFlow is if you

21
00:01:04.542 --> 00:01:08.357
already have it in Pytorch,
if you're starting a new project.

22
00:01:08.357 --> 00:01:14.260
I did not endorse that message, but
I read it and then started using Pytorch.

23
00:01:14.260 --> 00:01:17.788
Now you do too, if you're running these.

24
00:01:17.788 --> 00:01:20.091
Cool, so if we have the cat
sat on the mat and the cat.

25
00:01:20.091 --> 00:01:23.568
We should see the cat sat, pad, pad, pad.

26
00:01:23.568 --> 00:01:27.652
So we can actually go ahead and
take a look at this in practice and

27
00:01:27.652 --> 00:01:29.050
play around with it.

28
00:01:29.050 --> 00:01:31.623
Okay, so let's take a look what we have.

29
00:01:31.623 --> 00:01:33.332
So first we're gonna show the input IDs.

30
00:01:33.332 --> 00:01:36.350
Those are the tokens.

31
00:01:36.350 --> 00:01:39.550
So we have the cat sat and
the cat sat on the mat.

32
00:01:39.550 --> 00:01:43.358
And so you can pretty much
see we've got that probably

33
00:01:43.358 --> 00:01:48.271
that cls beginning of the statement token,
the cat sat are the same.

34
00:01:48.271 --> 00:01:50.154
Then we have.

35
00:01:50.154 --> 00:01:57.692
If you look that that is both basically
probably the period in both sentences and

36
00:01:57.692 --> 00:02:03.429
then the extra three words and
then the end of the statement,

37
00:02:03.429 --> 00:02:08.155
then what it does to make
them effectively equal is

38
00:02:08.155 --> 00:02:13.130
pad the shorter one, right,
With a bunch of zeros.

39
00:02:14.650 --> 00:02:17.130
So now they are effectively
the same length.

40
00:02:17.130 --> 00:02:18.490
So you can look at the relation.

41
00:02:18.490 --> 00:02:21.690
And then you do have for
the actual attention mask.

42
00:02:21.690 --> 00:02:23.690
Well, that one has all the words.

43
00:02:24.810 --> 00:02:28.734
This one obviously has
some empty space in there.

44
00:02:28.734 --> 00:02:32.292
So it tells you which ones are actually
important and which ones are not,

45
00:02:32.292 --> 00:02:34.567
which used to inform
the attention later on and

46
00:02:34.567 --> 00:02:37.210
where we should actually
put those things together.

47
00:02:38.240 --> 00:02:42.029
So we can take any given thing and you can
see that there are consistent numbers for

48
00:02:42.029 --> 00:02:43.600
every given one of these tokens.

49
00:02:45.600 --> 00:02:46.560
We gotta find out.

50
00:02:54.960 --> 00:02:57.160
We need one where it shows us
every step of the way through.

51
00:02:57.160 --> 00:02:58.960
Which didn't occur to
me until that question.

52
00:03:00.400 --> 00:03:01.800
I thought about the happy path.

53
00:03:01.800 --> 00:03:03.225
I did not think about the unhappy path.

54
00:03:03.225 --> 00:03:06.721
But luckily these notebooks are something
you can play around with as well and

55
00:03:06.721 --> 00:03:09.040
kind of move around and change also.

56
00:03:09.040 --> 00:03:10.640
So I definitely encourage you to do them.

57
00:03:10.640 --> 00:03:11.280
You can easily.

58
00:03:11.280 --> 00:03:11.880
They're all shared.

59
00:03:11.880 --> 00:03:14.200
You can easily just like make your
own copies and play around with them.

60
00:03:14.200 --> 00:03:15.360
And you absolutely should be.

61
00:03:16.800 --> 00:03:19.760
But for the happy path,
let's just run that again real quick.

62
00:03:19.760 --> 00:03:21.484
We can see that the tokens
do have unique IDs.

63
00:03:21.484 --> 00:03:24.726
There is this idea of keeping track of
which ones were meaningful tokens and

64
00:03:24.726 --> 00:03:28.320
which ones you'd be like, wouldn't
the zeros get you most of the way there?

65
00:03:28.320 --> 00:03:29.160
You could argue that.

66
00:03:29.160 --> 00:03:34.025
But like I think also having which ones
are actually meaningful in a 1:0 format is

67
00:03:34.025 --> 00:03:35.147
powerful as well.

68
00:03:35.147 --> 00:03:38.364
Cool, and so effectively that
is the process of tokening and

69
00:03:38.364 --> 00:03:40.771
vectorizing it and
stuff along those lines.

70
00:03:40.771 --> 00:03:41.515
Yeah, awesome.

71
00:03:41.515 --> 00:03:43.083
&gt;&gt; Male: So you're trying to
guess at kind of which one

72
00:03:43.083 --> 00:03:44.248
translates to which character.

73
00:03:44.248 --> 00:03:46.722
Is there a scenario where
you look up a dictionary and

74
00:03:46.722 --> 00:03:49.318
try to understand if
something's translated wrong?

75
00:03:49.318 --> 00:03:50.997
&gt;&gt; Steve Kinney: No,
that's the model's job.

76
00:03:50.997 --> 00:03:53.325
&gt;&gt; Male: I figured it just-
&gt;&gt; Steve Kinney: That's the model's

77
00:03:53.325 --> 00:03:54.179
job, right?

78
00:03:54.179 --> 00:03:58.110
Yeah, ideally, right.

79
00:03:58.110 --> 00:04:00.430
Especially cuz it's effectively a mapping.

80
00:04:00.430 --> 00:04:05.275
I wonder, at the time I was clearing
out all those progress bars because

81
00:04:05.275 --> 00:04:07.550
they were taking up a lot of room.

82
00:04:07.550 --> 00:04:11.267
But you can see of the files
that are downloaded,

83
00:04:11.267 --> 00:04:15.810
I'm not entirely sure where
COLAB is storing everything.

84
00:04:17.490 --> 00:04:18.810
We could probably find it.

85
00:04:18.810 --> 00:04:24.990
But one of the things you could see
it pulling down was a vocab JSON.

86
00:04:27.070 --> 00:04:30.950
My suspicion is that there's
something interesting in there.

87
00:04:30.950 --> 00:04:34.825
I'm just not entirely sure where in
this Linux file system that is pulled

88
00:04:34.825 --> 00:04:35.470
down into.

89
00:04:35.470 --> 00:04:38.864
You can probably go into Hugging Face
to look at the models too.

90
00:04:38.864 --> 00:04:42.970
It is most likely just a hash map.

91
00:04:42.970 --> 00:04:48.423
So I think I feel pretty confident
that it's not gonna mess that up.

92
00:04:48.423 --> 00:04:52.150
&gt;&gt; Male: Does that mean that the JSON
will expand as you add new characters?

93
00:04:52.150 --> 00:04:56.510
&gt;&gt; Steve Kinney: Or is it- I mean it's
of the mapping of a token to the id.

94
00:04:56.510 --> 00:04:57.077
Right.
&gt;&gt; Male: So

95
00:04:57.077 --> 00:04:59.734
there'll never be a token created
that it doesn't know how to process?

96
00:04:59.734 --> 00:05:02.811
&gt;&gt; Steve Kinney: I mean that's been
our current thought exercise, right?

97
00:05:02.811 --> 00:05:07.119
We see the unknown token, we haven't
figured out how to get to one, right?

98
00:05:07.119 --> 00:05:11.483
But there's a whole bunch of weird ASCII
characters that we have not gone the dark

99
00:05:11.483 --> 00:05:13.931
road of like what will
I be doing later today?

100
00:05:13.931 --> 00:05:18.806
I'll be holding the option key and the
shift key and and putting in crazy stuff

101
00:05:18.806 --> 00:05:23.835
like that apple and trying to see if I
can get something crazy to happen, right?

102
00:05:23.835 --> 00:05:28.870
Do I feel the need to do that all
in front of you for the next hour?

103
00:05:28.870 --> 00:05:30.390
I feel like I shouldn't.

104
00:05:31.670 --> 00:05:32.870
Feel like I shouldn't.

105
00:05:34.470 --> 00:05:37.110
I feel like I should, but
I know that I shouldn't.

106
00:05:37.110 --> 00:05:41.670
And Dustin will look at me if I
start any longer and redirect me.

107
00:05:41.670 --> 00:05:42.470
So we won't.

108
00:05:43.920 --> 00:05:45.490
But the larger scale or

109
00:05:45.490 --> 00:05:50.040
the high level thing is that we
break the words apart into tokens.

110
00:05:50.040 --> 00:05:50.945
The tokens become numbers.

111
00:05:50.945 --> 00:05:55.807
We'll do something with those numbers
momentarily to figure out meaning and

112
00:05:55.807 --> 00:06:01.132
then we will string them all back together
when it comes time for a response, right?

113
00:06:01.132 --> 00:06:05.796
So what happens when you have too many
like minded people in the room as you

114
00:06:05.796 --> 00:06:08.480
start going down the road of mad science?

