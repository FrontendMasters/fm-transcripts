[00:00:00]
>> Steve Kinney: What we're going to talk about next is this idea of fine tuning, right? Which is again, like right now we're going on. However this model was trained. Let's say, you know, you always want a particular format. You know you want it to stylistically do a thing. If you are just trying to get it to know more content, you are probably better off using like, as we've been alluding to that kind of like augmenting the prompts with the relevant data and giving it to a giant model, right?

[00:00:26]
The interesting game as we talk about fine tuning that we'll go into is the bigger the model, the more things you have to fine tune. That is expensive, right? So my heuristic for you is if you are trying to just have it know about more things, you should just augment the prompts with the more things that it should be working with, right?

[00:00:50]
Whether you do that as you use chatgpt and just paste in a bunch of stuff, or whether you use some kind of vector database to augment it, if you want to change the style in which it produces output, that is usually better for fine tuning, can you do one or the other?

[00:01:08]
Either way, of course, it's just like, do you like your money or not? And what is more efficient based on what you want to do? So if you want to add more context, using a vector database where you get the embeddings and just jamming on that context is probably faster and cheaper.

[00:01:25]
And the better way to do it if you would like to change the style, then you come to the world where doing the fine tuning makes a little bit more sense. All right, let's talk a little bit about fine tuning. We're gonna do metaphors because mathematical formulas are boring.

[00:01:50]
So fine tuning is. You're not necessarily creating a new model from scratch. Remember, we said before, the way that you train a model, effectively, figuratively, is you start out with a bunch of stuff pointed in random places. You have the answer key already. You give it the first word, you tell it to guess the second word.

[00:02:09]
If it's right, you give it a cookie. If it's wrong, you don't. And it begins. It randomly tweaks the knobs until it gets good enough that it has somehow tweaked the knobs to all the right places, where it is mostly right all the time. That's expensive. That takes a lot of time.

[00:02:28]
And GPU and electricity and in this current day and age, fossil fuels and all those fun things. What's probably better in A lot of cases is take a model that already knows most things and just pick up from there and feed it more stuff, right? So imagine you speak English.

[00:02:48]
You want to learn about AI. At first, Steve said a bunch of words to you. You're like, I don't know what any of those mean. And hopefully if he keeps saying them at you, you not only still know English, which is a good starting, because if you didn't know English when you walked in here, everything I've said has probably not worked out super well for.

[00:03:04]
You. But you ideally can over time kind of pick up from all of the stuff you already know and just add more stuff onto it. You just need to learn what a causal attention mask is or a vector database or an embedding and what that means in this case and add it into the fact that you already know what a computer is.

[00:03:26]
That's effectively what we're doing with this fine tuning. Because the model already knows general how sentences work. You don't want to teach a model how sentences work. I mean, maybe you do. If you do, OpenAI will happily hire you. But generally speaking, for the practical thing, you're probably going to sit down to tomorrow starting from scratch.

[00:03:46]
I mean, they don't even want to start from scratch tomorrow, right? They have some models that know the structure of language. It's fine. But if you wanted to show it a specific set of things to kind of build on top of standing on the shoulder of giants, you could do something like fine tuning, right?

[00:04:04]
Be like, this is the structure of this. This is the shape of what a response should be. This is kind of like more. And again, it's more about the structure and style than it is about the content, because they're easier, cheaper ways to just literally shove the content into the context window programmatically.

[00:04:22]
But this will allow you to basically turn those knobs on top of the existing turns of the knobs. Yeah, and so it's again, learning new specialty without having to relearn how to read. Normal fine tuning, again, the bigger the model, the harder it is, right? So normal fine tuning is.

[00:04:48]
You are literally tweaking every knob, right? And obviously on a small like GPT2, that's still expensive and you can only imagine what it is like, like the numbers of like, even the initial training of like GPT4 were like what, 50, like million? I don't even. A big number a big money that I don't have personally.

[00:05:16]
And so. But even doing it on a regular model isn't great. So step one, if you decide that I want to go down the fine tuning road. You should probably do a small model. But I'm going to argue you shouldn't fine tune an entire model. Anyway, when I say I'm going to argue, I'm going to say research says hence, thereby I will argue.

[00:05:39]
And so with fine tuning, you are effectively going through the entire textbook. The textbook is there, but you are going and effectively updating the entire textbook, right? And depending on the size of the book, could be expensive. Then came this idea of what if instead of rewriting the entire textbook, we just added like another chapter at the end, right?

[00:06:05]
Like an addendum, right? Like a post credit scene, if you will. What if we just added a little bit of layer on top of it and tried that out instead? And that is what we call parameter efficient fine tuning.

