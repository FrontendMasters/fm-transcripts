WEBVTT

1
00:00:00.400 --> 00:00:04.252
&gt;&gt; Speaker 1: So when you tokenize it,
you're assigning a number to a word or

2
00:00:04.252 --> 00:00:05.760
token, right?

3
00:00:05.760 --> 00:00:09.576
But then through the transformer block,

4
00:00:09.576 --> 00:00:14.264
it's almost like you're
developing like another

5
00:00:14.264 --> 00:00:19.075
layer of meaning to each token,
given the context.

6
00:00:19.075 --> 00:00:20.754
&gt;&gt; Steve Kinney: Yeah.
&gt;&gt; Speaker 1: Is that called a vector

7
00:00:20.754 --> 00:00:22.748
that-
&gt;&gt; Steve Kinney: Effectively, right?

8
00:00:22.748 --> 00:00:24.270
&gt;&gt; Speaker 1: The vector-
&gt;&gt; Steve Kinney: The vector is

9
00:00:24.270 --> 00:00:25.372
the number, right?

10
00:00:25.372 --> 00:00:26.579
&gt;&gt; Speaker 1: But
it's just like another number.

11
00:00:26.579 --> 00:00:27.194
&gt;&gt; Steve Kinney: Yeah.

12
00:00:27.194 --> 00:00:29.171
&gt;&gt; Speaker 1: Right.
&gt;&gt; Speaker 3: Like bank and bank,

13
00:00:29.171 --> 00:00:30.416
when you token.

14
00:00:30.416 --> 00:00:31.939
&gt;&gt; Steve Kinney: They're the same ID,
always, right?

15
00:00:31.939 --> 00:00:32.766
&gt;&gt; Speaker 1: One number, but

16
00:00:32.766 --> 00:00:36.795
then now you've got like a different set
of numbers given context or something.

17
00:00:36.795 --> 00:00:41.572
&gt;&gt; Steve Kinney: Yeah, so
in that neural network, for instance,

18
00:00:41.572 --> 00:00:46.464
whatever token has the ID
of 35 is not necessarily

19
00:00:46.464 --> 00:00:50.351
closer to the one that has 36, right?

20
00:00:50.351 --> 00:00:54.223
They are just effectively like numbers,
right?

21
00:00:54.223 --> 00:00:57.929
And then it goes into this giant
neural network where you start out,

22
00:00:57.929 --> 00:01:02.548
where everything is just the relationship
between any two of those IDs is completely

23
00:01:02.548 --> 00:01:04.020
random, right?

24
00:01:04.020 --> 00:01:08.419
And you start training it, which is like,
hey, I'm gonna give you two words.

25
00:01:08.419 --> 00:01:09.780
Guess what the next word is?

26
00:01:09.780 --> 00:01:11.780
You have the third word already, right?

27
00:01:11.780 --> 00:01:13.660
Nope, nope, nope, nope, nope.

28
00:01:13.660 --> 00:01:16.723
So it keeps twisting the knob to
figure out what it needs to do

29
00:01:16.723 --> 00:01:17.900
to get there, right?

30
00:01:17.900 --> 00:01:22.700
And so those initial numbers that
are the IDs of the tokens aren't.

31
00:01:22.700 --> 00:01:23.914
Because they're numbers,

32
00:01:23.914 --> 00:01:26.700
they're not actually meaningful
in terms of the organization.

33
00:01:26.700 --> 00:01:30.819
It's like, what function did you have to
go into to come out with the right answer

34
00:01:30.819 --> 00:01:31.900
for the next one?

35
00:01:31.900 --> 00:01:33.251
And all the weights and

36
00:01:33.251 --> 00:01:36.820
the math is tweaked through
just brute force effectively.

37
00:01:36.820 --> 00:01:41.319
It's like, for the 50 years of AI
research that we've done, we're like,

38
00:01:41.319 --> 00:01:43.340
what if we just brute force it?

39
00:01:43.340 --> 00:01:47.474
And what if we just start
everything random and

40
00:01:47.474 --> 00:01:51.930
just hammer at it, right,
until the weird math?

41
00:01:51.930 --> 00:01:54.010
Cuz it's not like any human
is tweaking that math.

42
00:01:54.010 --> 00:01:55.410
It's just a brute force.

43
00:01:55.410 --> 00:02:00.520
As you random, you turn the dolls in the
giant neural network to the point where

44
00:02:00.520 --> 00:02:05.555
it's like, cool, we've just hammered
at it so hard that now all those dials

45
00:02:05.555 --> 00:02:10.610
from randomly tweaking them at the scale
of billions more than that, right?

46
00:02:10.610 --> 00:02:15.260
Cuz you've got a billion parameters,
I can't do that math [LAUGH].

47
00:02:17.660 --> 00:02:21.660
And you end up with figuring out
where all of them come along to.

48
00:02:21.660 --> 00:02:26.433
So it's effectively, there's no PhD
student writing the math of how you get

49
00:02:26.433 --> 00:02:29.900
robbing banks and
the banks of the Mississippi River.

50
00:02:29.900 --> 00:02:34.476
It is just like you feed it
a whole bunch of strings, right,

51
00:02:34.476 --> 00:02:39.700
which should be the desired output,
right, it takes a guess.

52
00:02:39.700 --> 00:02:43.860
You slap its wrist when it's wrong,
it tweaks some knobs randomly.

53
00:02:43.860 --> 00:02:47.551
You keep slapping its wrist until it
figures out its own algorithm for

54
00:02:47.551 --> 00:02:49.278
not getting its wrist slapped.

55
00:02:49.278 --> 00:02:54.427
&gt;&gt; Speaker 1: So just like you can
get the tokens, you can convert it

56
00:02:54.427 --> 00:02:59.816
back to strings,
can you get those vector numbers out?

57
00:02:59.816 --> 00:03:01.881
So it's gone through, it's processed it.

58
00:03:01.881 --> 00:03:04.613
Now he knows if it's a bank of a river,
a bank.

59
00:03:04.613 --> 00:03:05.390
&gt;&gt; Steve Kinney: Yeah.

60
00:03:05.390 --> 00:03:06.230
&gt;&gt; Speaker 1: Can you get those numbers?

61
00:03:06.230 --> 00:03:10.270
I would say, okay,
now this word represents this number.

62
00:03:10.270 --> 00:03:12.830
&gt;&gt; Steve Kinney: You can
see all the tensors.

63
00:03:12.830 --> 00:03:14.990
If it's an open source model, you can.

64
00:03:14.990 --> 00:03:21.790
No you can't for GPT 4.5, but for the open
source models now there's not a lot.

65
00:03:21.790 --> 00:03:22.710
Can you look at them?

66
00:03:22.710 --> 00:03:24.030
Yes.

67
00:03:24.030 --> 00:03:26.190
Will your brain make any sense of it?

68
00:03:27.310 --> 00:03:30.460
So when we get to fine tuning,
what's interesting,

69
00:03:30.460 --> 00:03:35.080
the idea of fine tuning is you take a
pre-existing model that has been tuned and

70
00:03:35.080 --> 00:03:37.610
you just pick up where it left off, right?

71
00:03:37.610 --> 00:03:40.075
And you start feeding it more strings and

72
00:03:40.075 --> 00:03:43.130
you say this is the output
I expect to get, right?

73
00:03:43.130 --> 00:03:44.850
And you tweak those
knobs a little bit more.

74
00:03:44.850 --> 00:03:49.349
But you don't technically need
an open source model because like

75
00:03:49.349 --> 00:03:53.027
OpenAI has an API where they
will allow you to give them

76
00:03:53.027 --> 00:03:56.490
money to have a layer of
fine tuning over theirs.

77
00:03:56.490 --> 00:04:00.820
&gt;&gt; Speaker 1: I had this argument with my
boss about, about we're using Cursor and

78
00:04:00.820 --> 00:04:02.770
it has access to our code base.

79
00:04:02.770 --> 00:04:03.450
&gt;&gt; Steve Kinney: Yeah.

80
00:04:03.450 --> 00:04:06.298
&gt;&gt; Speaker 1: And I'm like,
my understanding was like, okay,

81
00:04:06.298 --> 00:04:10.739
well now we're just taking our code base
and we're uploading it to the cloud and

82
00:04:10.739 --> 00:04:14.729
it's going to train the model and
you know, it's going to influence.

83
00:04:14.729 --> 00:04:16.490
He's like, no, no, it's not like that.

84
00:04:16.490 --> 00:04:24.020
It's sort of a temporary thing that
doesn't actually train the model.

85
00:04:24.020 --> 00:04:26.019
I don't actually trust him.

86
00:04:26.019 --> 00:04:30.266
&gt;&gt; Steve Kinney: Yeah, those are tricky
cuz on one hand, like Curses of Rapp,

87
00:04:30.266 --> 00:04:35.590
OpenAI, and Anthropic, but at the end
of the day, bytes are going on a wire.

88
00:04:35.590 --> 00:04:38.710
To be clear, there are privacy modes and
stuff like that.

89
00:04:38.710 --> 00:04:40.965
Somebody who previously worked
in an open source project,

90
00:04:40.965 --> 00:04:42.677
I didn't have to flip
any of those switches so

91
00:04:42.677 --> 00:04:45.750
I can't speak to all their various privacy
modes and stuff along those lines.

92
00:04:45.750 --> 00:04:49.452
&gt;&gt; Speaker 1: We use some
particular privacy mode, but

93
00:04:49.452 --> 00:04:55.269
I don't understand how it can
ingest our code and adjust itself,

94
00:04:55.269 --> 00:05:01.960
it would readjust the weights or
whatever to like what comes next, right?

95
00:05:01.960 --> 00:05:02.951
&gt;&gt; Steve Kinney: Yeah.

96
00:05:02.951 --> 00:05:05.479
&gt;&gt; Speaker 1: And not be changed.

97
00:05:05.479 --> 00:05:10.115
Unless you had your own private VPs
in the cloud that nobody else access,

98
00:05:10.115 --> 00:05:12.396
but I don't think it's like that.

99
00:05:12.396 --> 00:05:13.200
&gt;&gt; Steve Kinney: Well, it's different.

100
00:05:13.200 --> 00:05:19.280
There's whether it's the pre-training or
the fine tuning, slash post training.

101
00:05:19.280 --> 00:05:22.660
Like then you are adjusting the weights
when you go to ChatGPT, for instance.

102
00:05:22.660 --> 00:05:23.380
&gt;&gt; Speaker 1: Yes.
&gt;&gt; Steve Kinney: They're not

103
00:05:23.380 --> 00:05:24.660
changing the weights at that moment.

104
00:05:24.660 --> 00:05:25.540
That is inference.

105
00:05:25.540 --> 00:05:27.220
That is, I'm putting this stuff out.

106
00:05:27.220 --> 00:05:29.740
It's coming out the other end of this,
right?

107
00:05:29.740 --> 00:05:34.580
The act of then, they can then take a
bunch of those strings later and train it.

108
00:05:34.580 --> 00:05:36.740
But like, as you use it,
no one's doing it.

109
00:05:36.740 --> 00:05:39.680
&gt;&gt; Speaker 3: If you start
a conversation with ChatGPT,

110
00:05:39.680 --> 00:05:44.660
how does it remember what you just
typed in like five prompts ago?

111
00:05:44.660 --> 00:05:47.140
&gt;&gt; Steve Kinney: Because you're sending
the whole thing back and forth every time.

112
00:05:48.312 --> 00:05:50.430
&gt;&gt; Speaker 1: You're
sending the whole thing.

113
00:05:50.430 --> 00:05:55.190
You're sending it the entire
conversation every time.

114
00:05:55.190 --> 00:05:57.710
&gt;&gt; Steve Kinney: Yep, that's when you
start blowing up the context window.

115
00:05:57.710 --> 00:06:00.311
If a chat gets too long,
Claude will actually be like,

116
00:06:00.311 --> 00:06:02.910
it's time to start a new chat, right?

117
00:06:02.910 --> 00:06:05.630
Cuz everything's going
over the wire every time.

118
00:06:05.630 --> 00:06:08.830
It's effectively a stateless protocol,
right?

119
00:06:08.830 --> 00:06:12.670
You are sending the entire chat back and
forth every time.

120
00:06:12.670 --> 00:06:15.721
Yep, so it's not remembering,
now, granted,

121
00:06:15.721 --> 00:06:20.600
play a game with ChatGPT later, cuz
OpenAI, you can turn this off, by the way.

122
00:06:20.600 --> 00:06:24.577
OpenAI has a memory feature where they
will also do that when we're talking about

123
00:06:24.577 --> 00:06:29.828
retrieval augmented generation, where they
will also store your stuff and then find.

124
00:06:29.828 --> 00:06:36.360
ChatGPT knows what kinda car I drive,
right?

125
00:06:36.360 --> 00:06:38.040
That's not cuz the model does.

126
00:06:38.040 --> 00:06:39.800
The model doesn't technically know.

127
00:06:39.800 --> 00:06:44.340
They are also storing that
information on top of that and

128
00:06:44.340 --> 00:06:47.441
feeding it in with my prompt, right?

129
00:06:47.441 --> 00:06:48.975
&gt;&gt; Speaker 1: So
it's just like start off on the side.

130
00:06:48.975 --> 00:06:49.720
&gt;&gt; Steve Kinney: Exactly.

131
00:06:49.720 --> 00:06:51.800
&gt;&gt; Speaker 1: And
then it's like, here's context.

132
00:06:51.800 --> 00:06:52.440
&gt;&gt; Steve Kinney: Exactly.

133
00:06:52.440 --> 00:06:54.320
&gt;&gt; Speaker 1: So
how big is the context window?

134
00:06:54.320 --> 00:06:55.400
Like how many bytes?

135
00:06:55.400 --> 00:06:56.440
&gt;&gt; Steve Kinney: Depends on the model.

136
00:06:57.560 --> 00:07:04.360
Gemini and Claude Opus and
03 are like 2 million tokens, right?

137
00:07:04.360 --> 00:07:07.800
Gemini was the big dog for a while there.

138
00:07:07.800 --> 00:07:12.630
Yeah, Gemini was the big dog for
a while there with the 2 million.

139
00:07:12.630 --> 00:07:17.590
And then Opus 4 and 03, I think,
definitely have 2 million.

140
00:07:17.590 --> 00:07:20.590
And wait for the next generation,
they'll be bigger, right?

141
00:07:20.590 --> 00:07:23.630
So a ton of context in there that
they can load in there as well.

142
00:07:23.630 --> 00:07:24.227
But yeah.
&gt;&gt; Speaker 1: But

143
00:07:24.227 --> 00:07:27.230
it's also interesting if you
could run it locally, right?

144
00:07:27.230 --> 00:07:30.580
You had enough GPU to just
run it completely locally,

145
00:07:30.580 --> 00:07:33.269
then you could actually
train it as you go.

146
00:07:33.269 --> 00:07:35.180
It wouldn't have to feed
the context all the time.

147
00:07:35.180 --> 00:07:35.770
&gt;&gt; Steve Kinney: Yeah.

148
00:07:35.770 --> 00:07:37.730
&gt;&gt; Speaker 1: It could just
be learning as you go.

149
00:07:37.730 --> 00:07:42.525
&gt;&gt; Steve Kinney: And I mean, you can
technically do that with like a ChatGPT or

150
00:07:42.525 --> 00:07:47.610
cloud, which is again,
like one of the tricks that people use.

151
00:07:47.610 --> 00:07:49.497
Its not really a trick, it's just a thing,

152
00:07:49.497 --> 00:07:53.090
which is you do basically your version
of that OpenAI memory thing, right?

153
00:07:53.090 --> 00:07:57.168
Where let's say you have a bunch of
data that's important to whatever you're

154
00:07:57.168 --> 00:07:58.290
working on, right?

155
00:07:59.650 --> 00:08:01.210
You vectorize all of that.

156
00:08:01.210 --> 00:08:06.787
So you turn into those numbers,
right, and a vector database,

157
00:08:06.787 --> 00:08:12.380
like Pinecone or Lance DB or
like a thousand other ones, right?

158
00:08:12.380 --> 00:08:18.099
You can basically, you take your text,
you vectorize it, right?

159
00:08:18.099 --> 00:08:21.525
You turn into those numbers,
you store it in this database, right?

160
00:08:21.525 --> 00:08:24.687
And then let's say you
are gonna use ChatGPT, but

161
00:08:24.687 --> 00:08:26.650
you wanted to know more about.

162
00:08:26.650 --> 00:08:30.280
You wanted to know more about your
information because you're trying to query

163
00:08:30.280 --> 00:08:31.382
your own data, right?

164
00:08:31.382 --> 00:08:33.837
What you do is I'm gonna
type something to ChatGPT.

165
00:08:33.837 --> 00:08:38.438
Before it goes to ChatGPT,
you grab it, you tokenize that prompt,

166
00:08:38.438 --> 00:08:42.716
you find all of the strings of
your data that seem relevant, and

167
00:08:42.716 --> 00:08:46.750
then you kind of just like at
the end of your prompt, go, and

168
00:08:46.750 --> 00:08:51.710
here's some context for you, and
you jack your stuff in there, right?

169
00:08:51.710 --> 00:08:56.190
And then it goes,
based on the other stuff in this prompt.

170
00:08:56.190 --> 00:08:57.346
Hello, right.

171
00:08:57.346 --> 00:09:01.162
&gt;&gt; Speaker 1: Okay, so going back to
my original question, which was that,

172
00:09:01.162 --> 00:09:03.682
did they tokenize our entire code base and

173
00:09:03.682 --> 00:09:07.070
then use that as context every
time we ask it a question?

174
00:09:08.190 --> 00:09:14.190
&gt;&gt; Steve Kinney: Yeah, they tokenize it
and they send it along with that prompt.

175
00:09:14.190 --> 00:09:15.950
Whether or not they're storing
it is a different question.

176
00:09:15.950 --> 00:09:17.470
Because they have to.

177
00:09:17.470 --> 00:09:23.083
If it's a given question you're asking,
it will scan that file and

178
00:09:23.083 --> 00:09:27.920
the related files and
there's a whole set of heuristics.

179
00:09:27.920 --> 00:09:31.781
It's like the first 250 lines of any
given file, so on and so forth, and

180
00:09:31.781 --> 00:09:35.154
it will vectorize that and
figure out which parts are relevant and

181
00:09:35.154 --> 00:09:37.320
send it along to get you an answer, yeah.

182
00:09:37.320 --> 00:09:41.197
Whether or not they're training the model
on that, they're not technically their

183
00:09:41.197 --> 00:09:45.017
models anyway, so, no, but like, is it
scanning your code base, doing stuff and

184
00:09:45.017 --> 00:09:47.330
sending them over the wire,
absolutely, yeah.

185
00:09:49.490 --> 00:09:52.130
So, yeah, and
then we guess what the next word is.

186
00:09:52.130 --> 00:09:58.370
And then we also, again, in here,
there are mechanisms in these models.

187
00:09:58.370 --> 00:10:02.955
Right, in the underlying architecture
that are also going to try to figure out

188
00:10:02.955 --> 00:10:07.410
how important one given word is in
relation to another one, right?

189
00:10:07.410 --> 00:10:12.214
And so, the is probably not
super meaningful to river

190
00:10:12.214 --> 00:10:17.610
unless you're talking
about Bruce Springsteen.

191
00:10:17.610 --> 00:10:22.285
Right, but generally speaking,
certain words are going to pull

192
00:10:22.285 --> 00:10:26.366
the meaning of those words
closer together than others.

193
00:10:26.366 --> 00:10:32.297
It's probably not strong words, but,
again, thief and bank, river and

194
00:10:32.297 --> 00:10:38.970
bank are probably gonna pull the meaning
of bank towards a given meaning, right?

195
00:10:38.970 --> 00:10:40.010
In that mechanism.

