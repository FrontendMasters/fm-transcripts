WEBVTT

1
00:00:00.480 --> 00:00:05.662
&gt;&gt; Steve Kinney: Question answering you
might think is what like ChatgGPT and

2
00:00:05.662 --> 00:00:11.920
Claude do, but like it's actually
you can argue better or worse.

3
00:00:11.920 --> 00:00:14.919
But I would argue it depends on
what you're trying to achieve, so

4
00:00:14.919 --> 00:00:17.921
what's interesting about question
answering is you're like,

5
00:00:17.921 --> 00:00:20.389
when I ask ChatGPT a question,
that's what it does.

6
00:00:20.389 --> 00:00:25.044
No, it does text generation, and
like it's got some nuance where like that

7
00:00:25.044 --> 00:00:28.040
whole assistant you user
thing is like not real.

8
00:00:28.040 --> 00:00:32.348
It's just characters that break up special
tokens that will break up the different

9
00:00:32.348 --> 00:00:34.200
pieces based on how it's trained.

10
00:00:34.200 --> 00:00:38.555
And when we fine tune a model, we'll talk
a little bit about how that looks, but

11
00:00:38.555 --> 00:00:40.720
it's just making up words right now.

12
00:00:40.720 --> 00:00:43.823
You can make up words when you
are trained on all of the Internet and

13
00:00:43.823 --> 00:00:47.280
every book as like anthropic,
like tore them all up and scanned them in.

14
00:00:48.320 --> 00:00:52.459
Google did that a decade ago, so
they got that part over with, but

15
00:00:52.459 --> 00:00:56.451
they are just generating the next
word tuned to a probability of

16
00:00:56.451 --> 00:00:59.080
every public word out there.

17
00:00:59.080 --> 00:01:02.652
Question answering is
a little bit different,

18
00:01:02.652 --> 00:01:07.562
question answering will only use
the context that you give it, so

19
00:01:07.562 --> 00:01:12.360
it's not probabilistically
coming up with the next word.

20
00:01:12.360 --> 00:01:17.236
It is taking whatever body of
text that you handed it and

21
00:01:17.236 --> 00:01:23.920
then doing the math to come up with based
on that context what the answer is.

22
00:01:23.920 --> 00:01:29.126
So like if this is a very
short thing on hot dogs,

23
00:01:29.126 --> 00:01:33.813
my family's going to Chicago next week and

24
00:01:33.813 --> 00:01:37.588
then there was like something, so

25
00:01:37.588 --> 00:01:43.600
like hot dogs were a topic
of conversation in my house.

26
00:01:45.930 --> 00:01:49.667
And so if you ask it something not
about hot dogs, it's not gonna go well,

27
00:01:49.667 --> 00:01:53.826
or even something about hot dogs that's
not in here, which you can argue, well,

28
00:01:53.826 --> 00:01:55.130
that's not good.

29
00:01:55.130 --> 00:01:59.758
Or it's very good if you just wanted
to get understanding about a particular

30
00:01:59.758 --> 00:02:01.290
document.

31
00:02:01.290 --> 00:02:04.784
If it is based on this particular content,
I need to know something and

32
00:02:04.784 --> 00:02:08.636
I don't want you to use the world's
information to answer this question just

33
00:02:08.636 --> 00:02:10.250
based on what I'm showing you.

34
00:02:10.250 --> 00:02:14.882
Then you want question answering
over anything that Claude,

35
00:02:14.882 --> 00:02:18.190
Gemini, GPT-4o what have will give you.

36
00:02:18.190 --> 00:02:20.727
So like again, the answer for

37
00:02:20.727 --> 00:02:25.710
all of these things will give
you like different answers.

38
00:02:25.710 --> 00:02:28.974
I think this is inspired by like there was
some clip that came out recently where

39
00:02:28.974 --> 00:02:31.710
Barack Obama said no one over
the age of eight should eat ketchup.

40
00:02:31.710 --> 00:02:35.908
&gt;&gt; Male: So this seems like good for
like internal company documents or

41
00:02:35.908 --> 00:02:38.894
internal company data
only want to have it,

42
00:02:38.894 --> 00:02:43.430
you don't want it to hallucinate,
make exactly up random stuff.

43
00:02:43.430 --> 00:02:46.489
&gt;&gt; Steve Kinney: Exactly,
you don't want it to use anything else,

44
00:02:46.489 --> 00:02:51.270
not even hallucinate, you just only want
to know based on this data that I have.

45
00:02:52.310 --> 00:02:54.646
And it will only do that in this case and

46
00:02:54.646 --> 00:02:57.350
it will give you
a confidence score as well.

47
00:02:58.870 --> 00:03:01.624
So if we say, where are the first
hot dogs?, stand up here,

48
00:03:01.624 --> 00:03:05.190
these are all things in there, let's go
ahead and run this and see what we get.

49
00:03:07.670 --> 00:03:11.194
Again, this model, if you look at
it coming down off the wire and

50
00:03:11.194 --> 00:03:15.633
is 261 megabytes, so not a giant model,
and there are, if you need something

51
00:03:15.633 --> 00:03:19.460
a little bit more sophisticated,
there are slightly bigger ones.

52
00:03:19.460 --> 00:03:24.685
But could you have this on a single VM or
connect some storage

53
00:03:24.685 --> 00:03:29.703
to a serverless function and
do this rapidly, quickly,

54
00:03:29.703 --> 00:03:37.070
on very small things at some cost,
but not a lot of cost?, absolutely.

55
00:03:37.070 --> 00:03:41.912
And that's the interesting thing I think
all of our brains are wrapped around

56
00:03:41.912 --> 00:03:44.830
when I think AI,
I think one of these big dogs.

57
00:03:46.270 --> 00:03:49.337
But actually there's
a bunch of very practical,

58
00:03:49.337 --> 00:03:53.070
less glamorous use cases that
are super easily accessible.

59
00:03:53.070 --> 00:03:56.567
And again, I've said it before, I'll say
it one more time for all the tech stuff

60
00:03:56.567 --> 00:04:00.430
we're doing today, TypeScript SDK
support is exactly the same as Python's.

61
00:04:00.430 --> 00:04:04.497
It's just when we want to get
to all the fancy image stuff,

62
00:04:04.497 --> 00:04:08.070
which is fun sometimes,
so we're going to do it.

63
00:04:08.070 --> 00:04:10.573
Question where did the first
hot dog stand appear?,

64
00:04:10.573 --> 00:04:15.270
I know the answer to that one because I'm
from New York City metropolitan area.

65
00:04:15.270 --> 00:04:17.574
Answer is Coney Island,
so on and so forth, and

66
00:04:17.574 --> 00:04:19.430
there's confidence level in there.

67
00:04:19.430 --> 00:04:22.166
Now, if you change the question to like

68
00:04:31.374 --> 00:04:35.671
It doesn't really matter what I say,

69
00:04:35.671 --> 00:04:40.370
it will only use
the content that it has and

70
00:04:40.370 --> 00:04:46.560
it is not confident about that answer,
as you can see.

71
00:04:48.080 --> 00:04:53.397
In fact, I think let's actually,
instead of even trying to

72
00:04:53.397 --> 00:04:58.520
format the answer,
let's actually just print the full.

73
00:05:00.280 --> 00:05:04.334
It'll be a little gnarly to look at, but

74
00:05:04.334 --> 00:05:09.350
we'll actually see the full
answer in this case.

75
00:05:13.391 --> 00:05:19.615
The interesting part that I want to draw
to your attention here is when it answers,

76
00:05:19.615 --> 00:05:24.574
not only is it giving us a confidence
score, but it's also giving

77
00:05:24.574 --> 00:05:29.470
us the index in that larger string
of where it found that answer.

78
00:05:31.390 --> 00:05:36.798
And so thereby, if it's not necessarily in
there, it's got that low confidence score,

79
00:05:36.798 --> 00:05:41.280
but all of its answers are legit coming
from that string to the point where it

80
00:05:41.280 --> 00:05:46.510
will show you the index of where its
answer started from and where it ended.

81
00:05:46.510 --> 00:05:50.294
So it is by definition locked into
whatever context you give it,

82
00:05:50.294 --> 00:05:55.100
which again is either 100% not what
you want or absolutely what you want.

83
00:05:55.100 --> 00:05:59.265
And probably something that
unless you have these tools,

84
00:05:59.265 --> 00:06:01.900
you probably don't have access to.

85
00:06:01.900 --> 00:06:06.940
Luckily, again, tiny little model that
took us about 10 seconds to download and

86
00:06:06.940 --> 00:06:09.900
ran incredibly quickly
on commodity hardware.

87
00:06:11.020 --> 00:06:14.808
&gt;&gt; Male: In a practical setting, would you
just filter out low confidence answers and

88
00:06:14.808 --> 00:06:16.220
get a canned response?

89
00:06:16.220 --> 00:06:19.672
&gt;&gt; Steve Kinney: You would set
a threshold, and that could obviously,

90
00:06:19.672 --> 00:06:24.474
should you dump all of this into a
database, clearly then you could filter on

91
00:06:24.474 --> 00:06:27.870
that on a simple level,
even if it was just on ingest.

92
00:06:29.390 --> 00:06:33.433
A filter function will work,
you know what I mean,

93
00:06:33.433 --> 00:06:37.110
if above this store,
if not, do other thing.

94
00:06:37.110 --> 00:06:42.245
And so all of the programming constructs
that you have ready to rock and

95
00:06:42.245 --> 00:06:46.350
roll work just as well and
become incredibly powerful.

96
00:06:48.030 --> 00:06:51.639
A term that I kind of want
to stick in your head for

97
00:06:51.639 --> 00:06:57.620
the vocabulary test later will be this
idea of extractive versus generative.

98
00:07:00.820 --> 00:07:04.148
Maybe I'm going to expose that
I'm not very smart right now,

99
00:07:04.148 --> 00:07:09.140
because I kept hearing the term generative
AI and I'm like, isn't that just AI?

100
00:07:09.140 --> 00:07:11.823
I see people generating images and
they're generating text and

101
00:07:11.823 --> 00:07:15.620
they're generating blog posts and they're
generating slop that seems generative.

102
00:07:15.620 --> 00:07:20.068
And because those big models
that we see and know and

103
00:07:20.068 --> 00:07:24.103
love depending on the day
are all generative,

104
00:07:24.103 --> 00:07:28.440
we tend to think that AI
is always generative AI.

105
00:07:28.440 --> 00:07:33.760
In the case of this question
answering set of models and pipeline,

106
00:07:33.760 --> 00:07:40.200
it's actually extractive, we're
extracting data out of it in useful ways.

107
00:07:40.200 --> 00:07:43.640
And for a lot of these, that's what we're
doing, we're extracting the sentiment out.

108
00:07:43.640 --> 00:07:48.394
We're just taking given things and
getting metadata from it that a younger

109
00:07:48.394 --> 00:07:53.601
version of me, to be clear, much younger
version of me, less gray version of me,

110
00:07:53.601 --> 00:07:58.450
maybe try to do with a series of regexes
that I would have regretted forever.

111
00:08:00.450 --> 00:08:04.226
And all of these code snippets
are very small and very lightweight,

112
00:08:04.226 --> 00:08:07.747
they're going to get gnarly at one point,
the last one today.

113
00:08:07.747 --> 00:08:11.901
We will not even step line by line
through the code because it's wild, but

114
00:08:11.901 --> 00:08:15.330
it's more to show a concept
more than anything else.

115
00:08:15.330 --> 00:08:17.878
They start small, you can get big and
complicated with them, but

116
00:08:17.878 --> 00:08:19.790
we're at the beginning of our journey,
small.

117
00:08:20.990 --> 00:08:25.310
But like I said, that span of a start and
end will show you where in the text.

118
00:08:25.310 --> 00:08:28.941
&gt;&gt; Male: So for example, if you gave
Nathan's first name at the beginning of

119
00:08:28.941 --> 00:08:33.210
the paragraph and then you mentioned his
last name at the end of the paragraph and

120
00:08:33.210 --> 00:08:36.350
you prompted it for
like Nathan's full name.

121
00:08:36.350 --> 00:08:38.846
Would it be able to do that?,
would it be able to say,

122
00:08:38.846 --> 00:08:42.783
well we learned his first name up here and
his last name down here, or would it not?,

123
00:08:42.783 --> 00:08:45.920
because that's not a direct
quote from the past.

124
00:08:45.920 --> 00:08:50.458
&gt;&gt; Steve Kinney: I think for this one it
wouldn't, but like that's definitely,

125
00:08:50.458 --> 00:08:56.160
do we have Nathan's full name?, [LAUGH]
does anyone know Nathan's last name?

126
00:08:56.160 --> 00:09:00.494
I guess it doesn't really matter in
this sense, I'm trying to figure out how

127
00:09:00.494 --> 00:09:04.561
to even like the hard part is like
tweaking the content in a way to do that,

128
00:09:04.561 --> 00:09:07.200
I'm like, how would I write that sentence?

129
00:09:07.200 --> 00:09:10.389
Let's definitely play around with it and
let's see, I don't think it would,

130
00:09:10.389 --> 00:09:13.400
I think because it is starting with
the starting index, the ending index.

131
00:09:13.400 --> 00:09:17.507
I am like at a 0.98% confidence,
if I may use the parlance,

132
00:09:17.507 --> 00:09:21.400
that it won't, but
like that's a question I haven't got.

133
00:09:21.400 --> 00:09:23.753
&gt;&gt; Male: It has to gather
text from different parts,

134
00:09:23.753 --> 00:09:26.880
it has to be together in
the content is what I'm thinking.

135
00:09:26.880 --> 00:09:30.955
&gt;&gt; Steve Kinney: But then you could think
about like, could you like, and again,

136
00:09:30.955 --> 00:09:33.039
we're just using the pre baked.

137
00:09:33.039 --> 00:09:35.395
These again are doing the thing
where they are grabbing a model,

138
00:09:35.395 --> 00:09:38.104
they're grabbing a tokenizer,
they're grabbing all of these things,

139
00:09:38.104 --> 00:09:39.958
they're grabbing it and
better and doing it all.

140
00:09:39.958 --> 00:09:46.078
Like if you started to pull
apart the various pieces,

141
00:09:46.078 --> 00:09:51.926
could you pull,
tweak one of these a little bit?,

142
00:09:51.926 --> 00:09:54.930
my sense is probably yes.

143
00:09:54.930 --> 00:09:57.918
Pitfalls, the answers down the context,

144
00:09:57.918 --> 00:10:02.490
ambiguous questions,
obviously it can only find you the facts.

145
00:10:03.850 --> 00:10:07.552
And with anything this is true
of the generative ones as well,

146
00:10:07.552 --> 00:10:11.253
the longer the context,
the more it degrades because again,

147
00:10:11.253 --> 00:10:14.260
the more things it could find,
so on and so forth.

148
00:10:15.300 --> 00:10:18.914
That's true even if for
a lot of the larger tools,

149
00:10:18.914 --> 00:10:24.954
one methodology that people use is called
RAG Retrieval-Augmented Generation.

150
00:10:24.954 --> 00:10:28.108
If you want ChatGPT to
know about your stuff,

151
00:10:28.108 --> 00:10:30.764
what you do is you take all your stuff,

152
00:10:30.764 --> 00:10:37.030
you put in a vector database which you
turn into numbers, we'll see that later.

153
00:10:37.030 --> 00:10:41.864
But you have to always do that in small
chunks too, and this is what I deal

154
00:10:41.864 --> 00:10:46.150
with my day to day life now is what
size chunk is the right chunk.

155
00:10:46.150 --> 00:10:50.220
I'm working on this thing right now,
where for a given webpage,

156
00:10:50.220 --> 00:10:55.178
we want to highlight the part of the DOM
relevant to the topic you just asked, but

157
00:10:55.178 --> 00:10:59.030
like, how much DOM do I want?,
what is the right size chunk?

158
00:10:59.030 --> 00:11:02.860
And then you throw in things like spans
and like, the DOM tree is a mess.

159
00:11:02.860 --> 00:11:07.720
But getting stuff right for
the given thing that you're doing,

160
00:11:07.720 --> 00:11:13.210
of the size of the context or chunk
versus how you feed it into the system,

161
00:11:13.210 --> 00:11:16.540
there's not a known right answer for that.

162
00:11:16.540 --> 00:11:19.709
It depends on what you are trying to do,
the data you are working with,

163
00:11:19.709 --> 00:11:22.300
the questions that you are asking.

164
00:11:22.300 --> 00:11:27.206
But if you do hand it an entire book and
say, find me one fact in it,

165
00:11:27.206 --> 00:11:31.680
your chances of getting what
you want is going to get worse.

166
00:11:31.680 --> 00:11:36.162
And so do you break it up?, do you break
everything up by paragraph, by sentence?,

167
00:11:36.162 --> 00:11:40.360
too little context, you have a problem,
too big context, you have a problem.

168
00:11:40.360 --> 00:11:45.123
And it really depends on the questions
you're asking and the content itself,

169
00:11:45.123 --> 00:11:48.240
do you strip content that
we think is meaningless?

170
00:11:48.240 --> 00:11:52.172
And we'll see that these models do that
themselves in, like, minor ways as well,

171
00:11:52.172 --> 00:11:55.280
and then it's not us to do it kind
of in the macro ways, even less.

172
00:11:55.280 --> 00:11:57.960
Like, what is the best brand of mustard
for hot dog?, I don't think it's in there.

