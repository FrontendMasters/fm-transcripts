WEBVTT

1
00:00:00.215 --> 00:00:02.881
&gt;&gt; Steve Kinney: All right, so
we got one more kinda conceptual,

2
00:00:02.881 --> 00:00:05.556
it's more of a extension
of a conceptual thing.

3
00:00:05.556 --> 00:00:08.480
And then we can fine-tune some models and
it's gonna be dope.

4
00:00:09.920 --> 00:00:12.800
So we know about encoders and
we know about decoders, right?

5
00:00:15.360 --> 00:00:19.488
And decoders are effectively when we
think a lot about one word at a time, and

6
00:00:19.488 --> 00:00:22.480
we're only looking backwards, right?

7
00:00:22.480 --> 00:00:26.689
And we know encoder takes the word, turns
it into the vectors, a list of numbers.

8
00:00:26.689 --> 00:00:29.300
We capture that meaning and
we kind of start to figure this out.

9
00:00:29.300 --> 00:00:33.100
The words are gone at that point,
right, we've turned it into these IDs.

10
00:00:33.100 --> 00:00:36.409
When it's looking at Cat,
that has the idea of,

11
00:00:36.409 --> 00:00:41.684
I almost remember the number that Cat had,
but whatever, doesn't matter.

12
00:00:41.684 --> 00:00:43.260
It's now only working with those numbers.

13
00:00:43.260 --> 00:00:51.020
It doesn't really care, the neural network
doesn't necessarily care about the words.

14
00:00:51.020 --> 00:00:55.508
It just literally has these IDs, it's
putting in this multidimensional space,

15
00:00:55.508 --> 00:00:58.119
and coming up with the relationships,
right?

16
00:00:58.119 --> 00:01:01.899
Once they are encoded and they go in the
model, the words are gone, effectively.

17
00:01:01.899 --> 00:01:07.790
So we need the part of, then, okay, I need
to figure out what the next word might be.

18
00:01:07.790 --> 00:01:12.350
So decoder takes that and then tries to
decode it back into a sequence of words.

19
00:01:12.350 --> 00:01:15.993
The goal is to produce a meaningful
sentence that actually makes sense,

20
00:01:15.993 --> 00:01:19.710
which, if we even saw some of those
early examples we didn't always get.

21
00:01:22.130 --> 00:01:25.372
The best way to think about
it is a zip file encoding is

22
00:01:25.372 --> 00:01:29.058
effectively zipping up all your data and
then unencoding is

23
00:01:29.058 --> 00:01:33.703
unarchiving all of that data because
ultimately those numbers will also be

24
00:01:33.703 --> 00:01:38.515
smaller than the words that they represent
and they can be handed off to a gpu.

25
00:01:38.515 --> 00:01:41.090
The GPU has no idea about words.

26
00:01:41.090 --> 00:01:42.850
It's not familiar with
this concept of words.

27
00:01:42.850 --> 00:01:44.530
It's been mining crypto all day.

28
00:01:44.530 --> 00:01:45.890
It doesn't know what words are.

29
00:01:46.990 --> 00:01:51.972
And so then obviously coming back
out is how we deal with that stuff.

30
00:01:51.972 --> 00:01:56.989
And so we said before, encoder-only is
BERT kinda getting inside the transformer

31
00:01:56.989 --> 00:02:01.946
itself, for us, getting the words in and
out that we have encoders and decoders.

32
00:02:01.946 --> 00:02:06.023
But in the actual model itself, our GPTs,

33
00:02:06.023 --> 00:02:12.930
what we're trying to move towards now,
when we go to fine-tune GPT2,

34
00:02:12.930 --> 00:02:16.911
is effectively only looking backwards.

35
00:02:16.911 --> 00:02:20.250
And it's not looking forward,
it's the auto-aggressive piece, right?

36
00:02:20.250 --> 00:02:23.850
Bert is obviously just looking for
the context around everything.

37
00:02:26.090 --> 00:02:27.824
And this is the.

38
00:02:27.824 --> 00:02:32.578
We can actually see this where if
we Show 1 into ChatGPT, we'll see,

39
00:02:32.578 --> 00:02:36.526
as every token,
it will know about the previous ones, but

40
00:02:36.526 --> 00:02:41.300
it will nerf the next ones to a point
where there's no relation at all.

41
00:02:41.300 --> 00:02:44.554
So it can only look backwards.

42
00:02:44.554 --> 00:02:48.279
So we start with some kinda prompt, model
predicts probabilities for the next token.

43
00:02:48.279 --> 00:02:51.724
Decoding strategy selects one token,
and that token's added to the input,

44
00:02:51.724 --> 00:02:53.580
then we move on to the next token, right?

45
00:02:54.620 --> 00:02:58.488
So you can almost see that when you
use ChatGPT, and that streaming

46
00:02:58.488 --> 00:03:02.940
is both also to make it like you do not
have to wait forever to see a response.

47
00:03:02.940 --> 00:03:10.548
But effectively it's making stuff up
as it goes along statistically, right?

48
00:03:10.548 --> 00:03:14.984
It's saying like, okay, there's a token
that separates your prompt to its

49
00:03:14.984 --> 00:03:19.283
beginning and it's going to guess what
the first word it should say is, and

50
00:03:19.283 --> 00:03:21.671
then it's going to guess the next word and

51
00:03:21.671 --> 00:03:26.340
it's going to guess the next word until
it feels like it will actually generate.

52
00:03:26.340 --> 00:03:31.040
Like, actually,
the next word is to stop talking, right?

53
00:03:31.040 --> 00:03:33.210
The next word is,
I'm done speaking now, right,

54
00:03:33.210 --> 00:03:34.881
that was probably the next thing to do.

55
00:03:34.881 --> 00:03:37.479
And some of that's
informed by what we saw,

56
00:03:37.479 --> 00:03:40.509
a max token length or
something like that, right?

57
00:03:40.509 --> 00:03:43.657
In a lot of ways,
you can use the ability to be like,

58
00:03:43.657 --> 00:03:48.124
we're gonna hit that max token soon,
right, start winding this down,

59
00:03:48.124 --> 00:03:51.807
does play into the statistical
model at some point as well.

60
00:03:51.807 --> 00:03:55.919
We talked about temperature
that plays in here as well,

61
00:03:55.919 --> 00:03:58.638
which is how much spiciness we want.

62
00:03:58.638 --> 00:04:00.520
And we can actually see
that statistically.

63
00:04:00.520 --> 00:04:04.583
And we reference this top-K and
top-p, that will all play in as well,

64
00:04:04.583 --> 00:04:07.440
which is like,
how do we figure out the next word?

65
00:04:07.440 --> 00:04:10.962
Cuz it's always going to be
the same word every time, right,

66
00:04:10.962 --> 00:04:12.731
you don't get a lot of nuance.

67
00:04:12.731 --> 00:04:16.720
And you almost go down the same rabbit
hole, like, a little bit of like.

68
00:04:16.720 --> 00:04:19.621
Because if a sentence started
with the same three words,

69
00:04:19.621 --> 00:04:21.625
you'd always end up in the same place.

70
00:04:21.625 --> 00:04:24.747
So how do these two things work?

71
00:04:24.747 --> 00:04:28.096
So pure sampling.

72
00:04:28.096 --> 00:04:34.580
If you just said, hey, pick any other
word that could end poorly for you.

73
00:04:34.580 --> 00:04:35.780
Any word.

74
00:04:35.780 --> 00:04:41.603
No, Top case sampling is to pick.

75
00:04:41.603 --> 00:04:49.060
If you say 50 of the 50 most likely
next words, go pick one of them.

76
00:04:49.060 --> 00:04:54.667
But we saw that sometimes we had a
situation when we saw those earlier ones,

77
00:04:54.667 --> 00:04:59.562
the very beginning,
where the confidence level was 0.99 for

78
00:04:59.562 --> 00:05:03.890
one and then like 0.01 for
the next one, right?

79
00:05:03.890 --> 00:05:07.524
So that even if you said,
I'm gonna pick the top 50,

80
00:05:07.524 --> 00:05:10.850
the drop off after
the fifth could be huge.

81
00:05:10.850 --> 00:05:14.130
And you get garbage words after that,
right?

82
00:05:15.570 --> 00:05:17.726
And then the top P is like, okay,

83
00:05:17.726 --> 00:05:22.850
pick from all the ones that you
had a confidence level above 90%.

84
00:05:22.850 --> 00:05:24.740
Above 95%.

85
00:05:24.740 --> 00:05:25.860
Above 85%.

86
00:05:25.860 --> 00:05:29.040
Some of this is tweaking the knobs and
seeing, right?

87
00:05:29.040 --> 00:05:31.237
And you can set both of these right.

88
00:05:31.237 --> 00:05:34.356
But generally speaking, the top P is
the one you probably want, right?

89
00:05:34.356 --> 00:05:38.686
Cause, like, you're saying, like,
I don't know if there's, like,

90
00:05:38.686 --> 00:05:43.429
five words that are above 95% I feel
confident about, or 500, but, like,

91
00:05:43.429 --> 00:05:46.980
I should feel pretty confident
about the next word, right?

92
00:05:48.980 --> 00:05:50.638
That's usually the one you want,

93
00:05:50.638 --> 00:05:53.850
unless you know that you have
a different one that you don't want.

