WEBVTT

1
00:00:00.240 --> 00:00:04.016
&gt;&gt; Steve Kinney: But the interesting part
is that, I don't know, all the times,

2
00:00:04.016 --> 00:00:08.080
you see those people on YouTube
with the prompt engineering, right?

3
00:00:08.080 --> 00:00:09.837
They call, you know, there's just like,

4
00:00:09.837 --> 00:00:11.840
I figured out how to write
a prompt that does this.

5
00:00:11.840 --> 00:00:17.847
And I think that really did truly work
two years ago, but now it's like,

6
00:00:17.847 --> 00:00:22.760
turns out with a lot of stuff,
it does matter a little bit more.

7
00:00:22.760 --> 00:00:26.330
In fact, I'm gonna spoil a future slide.

8
00:00:26.330 --> 00:00:31.104
What's really interesting about this
is you not only have in the library

9
00:00:31.104 --> 00:00:35.810
support for prompts, you have support for
negative prompts, right?

10
00:00:35.810 --> 00:00:39.690
And if you think about it in terms of
the math piece, it's like, what is not.

11
00:00:39.690 --> 00:00:42.850
Yeah, yeah, like not this, right?

12
00:00:42.850 --> 00:00:48.210
And that will pull the actual statistics
to where you want it to go, right?

13
00:00:48.210 --> 00:00:51.823
And so, like, what you don't want is
actually like a field that you can fill

14
00:00:51.823 --> 00:00:54.490
out and
that will actually have an impact here.

15
00:00:54.490 --> 00:01:00.090
This is the recommended kinda
stack of things, right?

16
00:01:00.090 --> 00:01:00.610
And you don't.

17
00:01:00.610 --> 00:01:01.530
There's nothing.

18
00:01:01.530 --> 00:01:05.530
If you do not do this, you'll be okay.

19
00:01:05.530 --> 00:01:09.930
This is like the like, recommended
kind of like, way to structure.

20
00:01:09.930 --> 00:01:11.530
Like, what do you want, what style?

21
00:01:11.530 --> 00:01:16.953
If you see, if you ever use like
midjourney or something like that,

22
00:01:16.953 --> 00:01:23.250
they definitely like those, all of
the examples, so on and so forth, right?

23
00:01:23.250 --> 00:01:24.490
Yeah, so what subject do you want?

24
00:01:24.490 --> 00:01:28.722
The style, details, environment,
composition and lighting, I believe, like,

25
00:01:28.722 --> 00:01:32.896
actually, I truly do believe that the
composition lighting works because, like,

26
00:01:32.896 --> 00:01:36.477
you know that, like, it's very easy
to get the, like, camera data for

27
00:01:36.477 --> 00:01:39.050
the lens at least, you know,
and stuff like that.

28
00:01:39.050 --> 00:01:41.330
That is almost definitely in
the metadata on all these things.

29
00:01:41.330 --> 00:01:42.869
So as much as you're like,
that's not real,

30
00:01:42.869 --> 00:01:44.810
that's probably more real than
some of the other pieces.

31
00:01:46.720 --> 00:01:50.600
And yeah, like, I don't know that
masterpiece gets you anything better.

32
00:01:50.600 --> 00:01:55.375
But like, I don't know,
I was reading the docs,

33
00:01:55.375 --> 00:02:00.480
who am I to like, sure, it does, it works.

34
00:02:00.480 --> 00:02:02.120
And then we have those negative prompts,
right?

35
00:02:02.120 --> 00:02:03.920
The concepts you don't want, right?

36
00:02:03.920 --> 00:02:06.000
Like no watermarks or.

37
00:02:06.000 --> 00:02:06.640
You know what I mean?

38
00:02:06.640 --> 00:02:08.527
That stuff does, actually,

39
00:02:08.527 --> 00:02:14.120
the model will pull away from those
concepts during the denoising process.

40
00:02:14.120 --> 00:02:18.718
So in this case there's not necessarily
a concept of that in some of the at least

41
00:02:18.718 --> 00:02:20.400
older transformer models.

42
00:02:20.400 --> 00:02:25.017
I wonder with the reasoning steps in
the newer reasoning thinking models,

43
00:02:25.017 --> 00:02:30.360
maybe that process does something,
I think, a little bit more impactful.

44
00:02:30.360 --> 00:02:33.480
But in the older ones,
it's not built into it.

45
00:02:33.480 --> 00:02:35.480
But for these Image ones it is.

46
00:02:36.920 --> 00:02:42.689
And like I said before, especially
if we are seeking to do this on,

47
00:02:42.689 --> 00:02:48.100
like, the free tier or
whatever, there are some like.

48
00:02:48.100 --> 00:02:50.700
And all these things come at
some kind of cost, right?

49
00:02:50.700 --> 00:02:54.376
If there was no cost to making it faster,

50
00:02:54.376 --> 00:02:59.460
it would just,
that's how it would be, right?

51
00:02:59.460 --> 00:03:01.060
So we have this idea of a scheduler.

52
00:03:01.060 --> 00:03:04.260
Like, there is another one you
can swap in from hugging face.

53
00:03:05.300 --> 00:03:07.300
This attention slicing, right?

54
00:03:07.300 --> 00:03:09.880
Like, it does it in kind of chunks.

55
00:03:09.880 --> 00:03:12.120
It might be slower, but
you get higher quality.

56
00:03:14.120 --> 00:03:20.440
Do you want to offload idle parts of CPU
to reduce the VRAM and stuff like that?

57
00:03:21.880 --> 00:03:26.120
You can play around with all these
things and see how it works for you.

58
00:03:26.120 --> 00:03:30.877
I think I did play around with them at
great expense to my mental health in

59
00:03:30.877 --> 00:03:32.160
these notebooks.

60
00:03:32.160 --> 00:03:34.120
So you can kinda see what I did.

61
00:03:34.120 --> 00:03:35.480
I will be honest with you.

62
00:03:35.480 --> 00:03:39.840
Some of it was I was changing
numbers until I got what I wanted.

63
00:03:39.840 --> 00:03:43.120
I will say that there was
a ton of science all the time.

64
00:03:45.200 --> 00:03:49.600
There are tons of different
models you can choose from.

65
00:03:49.600 --> 00:03:52.800
I think most of the time,
I think just for speed.

66
00:03:52.800 --> 00:03:56.744
Again, like, I'm working under
the constraints of we don't want to go on

67
00:03:56.744 --> 00:03:58.480
forever waiting for things.

68
00:03:58.480 --> 00:04:02.160
So I sometimes chose the cheapest,
fastest model.

69
00:04:02.160 --> 00:04:06.131
But, like, if you're like, I am totally
okay going downstairs making a sandwich

70
00:04:06.131 --> 00:04:09.610
while I wait for this, you don't have
to make all the choices that I did.

71
00:04:11.770 --> 00:04:13.250
But actually, I think a few of them.

72
00:04:13.250 --> 00:04:15.170
I have the dropdowns where you can run it.

73
00:04:15.170 --> 00:04:16.370
Run it with a different model.

74
00:04:16.370 --> 00:04:17.650
You can swap in and out the models.

75
00:04:17.650 --> 00:04:19.690
That's the nice part of the hugging face.

76
00:04:19.690 --> 00:04:24.247
SDKs is, some of these, working with
those models is not always the same, but

77
00:04:24.247 --> 00:04:26.410
they put that abstraction over it.

78
00:04:26.410 --> 00:04:28.783
So, like, you just switch out
the string for the model and

79
00:04:28.783 --> 00:04:30.050
it downloads a different one.

80
00:04:30.050 --> 00:04:34.060
And it's great, so let's go play with it.

81
00:04:35.900 --> 00:04:40.802
I will say,
if your goal is to read every line of code

82
00:04:40.802 --> 00:04:45.140
with these, it is a little rougher, right?

83
00:04:45.140 --> 00:04:47.569
Cause there's just a lot
more knobs to tweak and

84
00:04:47.569 --> 00:04:51.100
a lot of stuff like that we did for
the optimization in this case.

85
00:04:51.100 --> 00:04:57.020
But the reward is really up there too,
though, right?

86
00:04:57.020 --> 00:05:00.780
Like, seeing a quote that looks
like a quote is like, cool.

87
00:05:02.170 --> 00:05:03.690
It's not Pygmy Hippo cool.

