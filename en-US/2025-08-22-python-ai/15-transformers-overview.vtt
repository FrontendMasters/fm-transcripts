WEBVTT

1
00:00:00.160 --> 00:00:04.824
&gt;&gt; Steve Kinney: So once we have our
tokens and the IDs related to those

2
00:00:04.824 --> 00:00:10.240
tokens, we get into this whole
Transformer thing, right?

3
00:00:10.240 --> 00:00:13.869
And like I said, in the pattern
that we've been seeing so far,

4
00:00:13.869 --> 00:00:18.045
we'll do the conceptual stuff and
then we'll pull it into a notebook and

5
00:00:18.045 --> 00:00:22.425
we'll kind of see and play around with it
and see also new and fun ways to break

6
00:00:22.425 --> 00:00:26.394
stuff that I didn't think about until
I had a bunch of friends in a room

7
00:00:26.394 --> 00:00:30.880
challenging other ways to think about
that will now live rent free in my head.

8
00:00:32.240 --> 00:00:37.295
So there will be some conceptual stuff and
then we will see it in practice,

9
00:00:37.295 --> 00:00:40.240
my sense was kinda doing
the two passes on.

10
00:00:40.240 --> 00:00:41.280
It was the right choice.

11
00:00:42.320 --> 00:00:44.400
That's stock photography, not AI art.

12
00:00:44.400 --> 00:00:46.160
I would like the record to show.

13
00:00:46.160 --> 00:00:50.920
But there is everyone's requisite
picture of a Transformer.

14
00:00:50.920 --> 00:00:55.720
So now we can all stop thinking about
Decepticons and Autobots and move on.

15
00:00:56.760 --> 00:01:02.707
So Transformer is effectively
the popular approach

16
00:01:02.707 --> 00:01:07.706
that has kind of kicked
off a lot of what we see

17
00:01:07.706 --> 00:01:12.990
these days, a 2017 paper, apparently.

18
00:01:12.990 --> 00:01:16.012
Attention is all you need
that came out of Google and

19
00:01:16.012 --> 00:01:19.385
it is the one powering all
these text generative models,

20
00:01:19.385 --> 00:01:23.181
not the extractive ones like
OpenAI's GPT and Meta's Llama and

21
00:01:23.181 --> 00:01:27.350
Google's Gemini and Anthropics Claude,
so on and so forth, right?

22
00:01:28.630 --> 00:01:32.254
It's funny because I think we think
about originally OpenAI and GPT,

23
00:01:32.254 --> 00:01:35.430
even though the paper came
out of Google originally.

24
00:01:35.430 --> 00:01:36.790
That's just how stuff works.

25
00:01:37.830 --> 00:01:41.161
And they are good at understanding
these long range dependencies within

26
00:01:41.161 --> 00:01:42.150
sentences, right?

27
00:01:42.150 --> 00:01:44.750
Again, not just thinking about
the word before and after it.

28
00:01:44.750 --> 00:01:49.324
Because as we know as people who speak
English, a lot of times something earlier

29
00:01:49.324 --> 00:01:52.550
in the sentence means something
later in the sentence.

30
00:01:53.830 --> 00:01:58.090
But as we saw before, what these
models do is they don't look forward,

31
00:01:58.090 --> 00:02:00.870
they're only looking backwards.

32
00:02:00.870 --> 00:02:05.481
They're only looking at
the previous tokens to guess

33
00:02:05.481 --> 00:02:08.150
what the next token should be.

34
00:02:11.190 --> 00:02:14.430
That is Core versus something like bert,
which is looking both ways.

35
00:02:14.430 --> 00:02:17.900
As we saw earlier with those fill
masks and all of those fun things.

36
00:02:17.900 --> 00:02:22.380
The one that is currently in the popular
imagination is only looking backwards.

37
00:02:22.380 --> 00:02:24.220
And we can actually see that
in a graph in a little bit.

38
00:02:26.460 --> 00:02:31.900
And so the whole idea is there
are three key components.

39
00:02:31.900 --> 00:02:34.577
We've got this idea of an embedding,
a transformer block and

40
00:02:34.577 --> 00:02:36.700
the output probabilities.

41
00:02:36.700 --> 00:02:39.131
The output probabilities we've
kind of already talked about,

42
00:02:39.131 --> 00:02:40.460
there'll be a slide for it.

43
00:02:40.460 --> 00:02:45.418
But are the basically like, hey, what
do we think the next token is going to

44
00:02:45.418 --> 00:02:50.010
be what is most likely the next
token given the previous one.

45
00:02:50.010 --> 00:02:52.236
And the embeddings are kind
of what we talked about,

46
00:02:52.236 --> 00:02:53.810
where we turn it into those vectors.

47
00:02:53.810 --> 00:02:56.730
So we kinda know the beginning,
we kinda know the end.

48
00:02:56.730 --> 00:03:00.090
The only kind of murky part
is this middle in the center.

49
00:03:01.210 --> 00:03:04.210
So again, embedding is breaking the words
apart and turning into numbers.

50
00:03:04.210 --> 00:03:07.051
As we kind of saw in that information,
there's some

51
00:03:07.051 --> 00:03:12.110
positional information as well in order
to capture the order of the words.

52
00:03:12.110 --> 00:03:15.150
And so we've got the semantic meeting and
the positional information.

53
00:03:17.790 --> 00:03:21.070
So then we get this attention mechanism,
right?

54
00:03:21.070 --> 00:03:25.787
And it's basically allowing any
given token to communicate or

55
00:03:25.787 --> 00:03:27.389
at least be aware of.

56
00:03:27.389 --> 00:03:31.350
How about that of the other tokens
to capture that contextual meaning.

57
00:03:31.350 --> 00:03:36.083
Again, the difference between
the banks of the old Raritan versus

58
00:03:36.083 --> 00:03:39.220
let's go rob some banks tomorrow, right?

59
00:03:39.220 --> 00:03:44.167
Like the other words in the sentence
add a lot of context to what

60
00:03:44.167 --> 00:03:49.180
the word banks means in
that given sentence, right?

61
00:03:49.180 --> 00:03:52.677
And so what happens is we can kind of
like look at each one of those and

62
00:03:52.677 --> 00:03:55.660
begin to map together
based on the other words.

63
00:03:55.660 --> 00:03:57.900
Kind of almost move the meaning, right?

64
00:03:57.900 --> 00:04:01.742
Like in a lot of these vector databases,
it's like each one of those tokens,

65
00:04:01.742 --> 00:04:04.060
numbers is in relation
to all the rest of them.

66
00:04:04.060 --> 00:04:06.980
And we kind of use when we say
a multi dimensional space.

67
00:04:06.980 --> 00:04:08.900
Good luck picturing that.

68
00:04:08.900 --> 00:04:12.422
But it is the ability to kinda like, where
is it in relation to the other words?

69
00:04:12.422 --> 00:04:14.340
Did they say thieves?

70
00:04:15.540 --> 00:04:18.820
Okay, I think I know
the context of that word now.

71
00:04:20.180 --> 00:04:21.860
Yes, I get it.

72
00:04:21.860 --> 00:04:23.060
We'll see some stuff in a second.

73
00:04:24.900 --> 00:04:26.340
All right,
I'm gonna take another run at that.

74
00:04:26.340 --> 00:04:29.380
As you can tell even from the slides,
I was like, that's gonna be confusing.

75
00:04:31.380 --> 00:04:33.410
So self attention is
like a group discussion.

76
00:04:33.410 --> 00:04:34.710
Each token can look at or

77
00:04:34.710 --> 00:04:38.610
talk to every other token to figure
out what version of itself it means.

78
00:04:39.970 --> 00:04:42.862
And then there's a time of quiet,
individual thinking time, right?

79
00:04:42.862 --> 00:04:45.410
After all the tokens have shared
all their information and

80
00:04:45.410 --> 00:04:49.330
played their weird guessing game with
each other about what they all mean.

81
00:04:49.330 --> 00:04:50.950
Each one can kind of look at itself and

82
00:04:50.950 --> 00:04:53.570
adjust its meaning based on
what it already knows, right?

83
00:04:53.570 --> 00:04:55.250
So it's like, okay, I'm in a sentence.

84
00:04:55.250 --> 00:04:59.486
The other words in this
sentence are burglar,

85
00:04:59.486 --> 00:05:03.420
hamburglar, [LAUGH] like whatever.

86
00:05:03.420 --> 00:05:11.580
I think I know which version of
Rob we're talking about again.

87
00:05:11.580 --> 00:05:14.644
The banks of the Hudson river
versus the banks that make deposit,

88
00:05:14.644 --> 00:05:18.489
it'll look at basically the meaning and
the relationships of those other words to

89
00:05:18.489 --> 00:05:21.180
figure out its own which
variation of itself it might be.

90
00:05:23.820 --> 00:05:26.740
Like I said before,
that output is where it comes out.

91
00:05:27.860 --> 00:05:31.900
You need to know this on a basis of
like a conceptual understanding.

92
00:05:31.900 --> 00:05:35.131
Like I said before,
there's not necessarily a quiz, right?

93
00:05:35.131 --> 00:05:37.727
But knowing that they look
at the tokens around them,

94
00:05:37.727 --> 00:05:40.901
they get a sense of what those words
mean to figure out where in that

95
00:05:40.901 --> 00:05:44.900
space their meaning of which version cuz
that sentiment analysis broke, right?

96
00:05:44.900 --> 00:05:48.455
The core piece is like, how do you not be
like the sentiment analysis that we saw in

97
00:05:48.455 --> 00:05:49.860
the very beginning, right?

98
00:05:49.860 --> 00:05:54.260
You take into consideration the other
words around you and what they might mean.

99
00:05:54.260 --> 00:05:58.856
We even saw that when we looked
at the text generation early on,

100
00:05:58.856 --> 00:06:03.886
where we saw that if you started out
in a very formal academic string,

101
00:06:03.886 --> 00:06:08.940
you ended up with a bunch of other
words that were formal, academic.

102
00:06:08.940 --> 00:06:13.558
In fact, we even saw, I think there
was one text generation example,

103
00:06:13.558 --> 00:06:19.060
which was it just said a long time ago in
a galaxy far away or something like that.

104
00:06:19.060 --> 00:06:23.774
And that was enough to put those words,
which could mean a lot of different things

105
00:06:23.774 --> 00:06:28.440
when you only have like your brain jumped
to the same thing my brain did, right?

106
00:06:28.440 --> 00:06:34.040
But the computer, like it was like
emperor with a capital E, mm-hm.

107
00:06:34.040 --> 00:06:38.393
Yeah, right, cuz again, like it looks at
those words in every individual token,

108
00:06:38.393 --> 00:06:40.840
looks at the relationship
of the other token.

109
00:06:40.840 --> 00:06:45.699
And what words kind of come around that
and begin to like shift themselves into

110
00:06:45.699 --> 00:06:50.120
position to do effectively the same
thing that our brains do, right?

111
00:06:52.600 --> 00:06:54.760
And that context is the important part.

112
00:06:56.760 --> 00:07:01.470
Banks can look at river, can look
at Hudson to know that means river,

113
00:07:01.470 --> 00:07:03.907
bank, bank, can look at robbed and

114
00:07:03.907 --> 00:07:08.640
thieves to see that it probably
means the Minneapolis Savings Bank.

115
00:07:08.640 --> 00:07:11.640
I don't know if that's a real bank,
but whatever.

116
00:07:11.640 --> 00:07:15.315
And that context is where it
could begin to get the sense and

117
00:07:15.315 --> 00:07:19.220
move itself into the right position for
the related context.

118
00:07:19.220 --> 00:07:22.708
And that's what separates it from those
very simple sentiment analysis and

119
00:07:22.708 --> 00:07:24.580
all those other things.

120
00:07:24.580 --> 00:07:26.792
So yeah, for the bank consensus, one,

121
00:07:26.792 --> 00:07:30.763
that vector gets shifted towards
the financial meaning for the one, and

122
00:07:30.763 --> 00:07:34.820
the second one, it gets shifted
towards the river edge meaning, right?

123
00:07:34.820 --> 00:07:38.820
And like we start to get a sense of
the meaning of the entire phrase.

124
00:07:38.820 --> 00:07:42.488
Cause each word is kind of shifting
itself in that second introspection time,

125
00:07:42.488 --> 00:07:44.220
right towards different meanings.

126
00:07:44.220 --> 00:07:48.392
Now all of a sudden we have a better sense
of what the whole thing means, right,

127
00:07:48.392 --> 00:07:51.302
through a lot of like math,
and that's why your GPU and

128
00:07:51.302 --> 00:07:54.680
your fans start spinning on your
computer and stuff like that.

129
00:07:54.680 --> 00:07:58.539
It is obviously a lot more
complicated than that, but

130
00:07:58.539 --> 00:08:02.240
conceptually that's what we're going for
here.

131
00:08:04.320 --> 00:08:07.542
Like I said before, then we try to guess
based on now we have some sense of

132
00:08:07.542 --> 00:08:09.200
the meaning, not just the words.

133
00:08:09.200 --> 00:08:13.120
We have some sense of the meaning that
informs what the next word is going to be.

134
00:08:13.120 --> 00:08:19.120
And then ideally we should be able to
guess it as we have all seen, sometimes.

