[00:00:00]
>> Steve Kinney: And so the ability to kind of create and fine tune with these, I think is absolutely fascinating. And it takes again almost everything we saw altogether in there as well. And I think you can do kind of creative things. I think with all these things there's obviously, we can opine on the kind of practical and day to day things, which again, I think the ability to then pull out data from specific documents, right?

[00:00:30]
Or the ability to kind of like arbitrarily classify stuff or pull out the nouns and stuff with that named entity recognition are all practical and useful. But I also think the areas where things become fun again. Cause there's only so many turns of the kind of eras of our industry where it's like a whole bunch of crazy new fun things that we never thought about doing and then those things are less magical again and all those things.

[00:00:58]
So I think there's a lot of opportunity for creative coding. Like I said earlier, we looked at a lot of interesting stuff with text and we did a few things with images. There's a lot more that you can do with images. But there's again, audio, there's video. And I think for a lot of these things, the interesting part is the intersection of how does the audio.

[00:01:18]
Could you mix and match these things together? Right, right. I think the fact that you can pull them all into whether, you know, hugging space also has this idea of spaces where you can like, they're not unlike what we saw in those Google Colab notebooks where you can like run code and host it incredibly easily.

[00:01:35]
But I even think the ability to kind of like, you know, tell a story with markdown, have access to GPUs, run stuff, you know, in storage and kind of share that kind of stuff makes things incredibly easy as well. But the important part is, I think for me, whether you do it in Python or like I said, you can do a lot of the tech stuff in Typescript, whether you use hugging face or grab the models yourself doesn't necessarily matter.

[00:01:57]
I think the important parts are. One is the immediate neural pathway unintended of when we think about AI, that we think about these big foundational models and we think about ChatGPT and just that one generative modality where we think about the fact that just grab one of those API keys and put a wrapper on top of it, versus when we looked at the thing where we could fine tune the style of the quotes on a very small model.

[00:02:29]
And fine tuning process I think ran in what under a few minutes on the free tier hardware with a Data set of 2,500 records on top of a small model, and we were able to drastically change as much as one can on a tiny model with a small data set, but effectively from rambling garbage to a structure that was consistent that ended in the right part with a very small data set on a very small model with very cheap hardware.

[00:02:59]
There are a lot of things that we can do with a lot of these tools outside of the grab a OpenAI API key and wrap it. To be clear, there's a lot you can do with that too, which I think is also incredibly important as well. But there are all these smaller, more practical things.

[00:03:15]
I think the big thing about a lot of this AI stuff is that you can take this unstructured data and bring structure to it incredibly easily. And then those are a lot of times the hard part of most applications, right? So being able to pull that in, I think becomes incredibly useful.

[00:03:29]
All right, means it killed it.

