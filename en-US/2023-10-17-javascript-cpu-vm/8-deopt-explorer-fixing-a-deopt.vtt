WEBVTT

1
00:00:00.000 --> 00:00:07.379
There is a tool called, Deopt Explorer,

2
00:00:07.379 --> 00:00:13.349
this is a tool that Microsoft has
written so let's back up a second,

3
00:00:13.349 --> 00:00:18.607
It is possible to run the node
with a special set of options.

4
00:00:18.607 --> 00:00:25.100
It tells the V8 to tell us about all
of these events when it's compiling,

5
00:00:25.100 --> 00:00:28.989
what is it compiling, what is doing, etc.

6
00:00:28.989 --> 00:00:32.509
And so what I did is I ran
it with a special way and

7
00:00:32.509 --> 00:00:38.106
you get this thing called get this log and
so for us, we got this deopt log,

8
00:00:38.106 --> 00:00:42.291
let's open it up and
it has basically these long list.

9
00:00:42.291 --> 00:00:47.661
These are human readable but
good luck reading this,

10
00:00:47.661 --> 00:00:52.911
it's ridiculously long in here,
but the nice thing

11
00:00:52.911 --> 00:01:00.086
about it is that when you have this
deopt explore you can open up the log.

12
00:01:05.062 --> 00:01:10.316
And when you open up the log,
it tells you about what the VM was doing,

13
00:01:10.316 --> 00:01:14.222
so first of all you can see,
let's make this bigger

14
00:01:16.405 --> 00:01:18.957
First of all, I am not an expert at this,

15
00:01:18.957 --> 00:01:23.763
I think I know more than an average person
about how all this stuff works, but

16
00:01:23.763 --> 00:01:28.438
I wouldn't consider myself an expert,
this rabbit hole goes very deep.

17
00:01:28.438 --> 00:01:33.007
What it shows is this program ran for
2 and a half seconds,

18
00:01:33.007 --> 00:01:38.432
out of that time, almost all of that
time was spent inside of my code.

19
00:01:38.432 --> 00:01:41.661
A small fraction was spent
inside of the program.

20
00:01:41.661 --> 00:01:45.227
Program is the V8, V8 is called
the Program, I don't know why they call it

21
00:01:45.227 --> 00:01:48.366
that way, it would be better to
call it V8 or something like that.

22
00:01:48.366 --> 00:01:52.640
None of the time we'll spend idling and
there were no GC events,right?

23
00:01:52.640 --> 00:01:54.668
So out of the total time running,

24
00:01:54.668 --> 00:01:59.448
you can see that by far the most time was
spent inside of my code, and the virtual

25
00:01:59.448 --> 00:02:03.950
machine itself took some amount of time
to compile my code and process it.

26
00:02:03.950 --> 00:02:10.306
Obviously, these numbers are super tiny
because the code we fed it is super small.

27
00:02:10.306 --> 00:02:15.204
The next thing you can see here is
you can see what code ran when and

28
00:02:15.204 --> 00:02:19.287
for how much time and
using which which processor, so

29
00:02:19.287 --> 00:02:23.843
you can see that at the beginning,
things go interpreted.

30
00:02:23.843 --> 00:02:29.175
And at some point it
transitions over to turbofan,

31
00:02:29.175 --> 00:02:32.895
which is the new optimized system.

32
00:02:32.895 --> 00:02:37.570
Over the years V8 had many different
compilers they had something

33
00:02:37.570 --> 00:02:42.494
called turbofans and of crankshaft I,
forget all the names it's just

34
00:02:42.494 --> 00:02:47.171
different internal implementations
that they have iterated over

35
00:02:47.171 --> 00:02:52.281
the years I believe turbofan is
the the latest iteration that they have.

36
00:02:52.281 --> 00:02:56.047
Again, most of these things work
the same on high enough level,

37
00:02:56.047 --> 00:02:59.969
it's the details that are different
that you should worry about.

38
00:02:59.969 --> 00:03:04.508
What I find it interesting though,
is you can actually see what's going on.

39
00:03:04.508 --> 00:03:09.591
Now notice what it's saying to you,
optimized functions that have been

40
00:03:09.591 --> 00:03:15.423
deoptimized multiple times, in other
words, this function when it was running,

41
00:03:15.423 --> 00:03:20.505
got deoptimized 3 times, 3 times
the V8 tried to compile this thing,

42
00:03:20.505 --> 00:03:24.535
and twice it got it got it wrong or
3 times it got it wrong?

43
00:03:24.535 --> 00:03:26.256
I don't know,
it depends on how you count it, right?

44
00:03:26.256 --> 00:03:30.907
Basically, it kept trying to compile this
thing, and the invariants kept changing on

45
00:03:30.907 --> 00:03:34.550
it and so it had to recompile it over and
over and over again, right?

46
00:03:34.550 --> 00:03:38.374
Until it finally got to the last one,
which was happy to, the first

47
00:03:38.374 --> 00:03:42.951
one was fast, because it was compiled
using invariants that were incorrect and

48
00:03:42.951 --> 00:03:47.208
then it got a little slower but it was
good for the remainder of the things.

49
00:03:47.208 --> 00:03:50.572
And so if you can click on it you
can see which function it is now it

50
00:03:50.572 --> 00:03:54.971
used to be that this thing got highlighted
I don't know what happened I'm sorry.

51
00:03:54.971 --> 00:03:57.486
When I originally was
exploring this thing,

52
00:03:57.486 --> 00:04:01.721
it would nicely highlight the function
that's offending for some reason,

53
00:04:01.721 --> 00:04:04.645
it no longer does so, and
I don't know how to fix it.

54
00:04:04.645 --> 00:04:06.861
But it does a couple of things for you,

55
00:04:06.861 --> 00:04:11.239
it highlights things as you can see,
you can see that this is highlighted.

56
00:04:11.239 --> 00:04:15.236
We will talk about monomorphic reads, etc,
but these are basically good things that

57
00:04:15.236 --> 00:04:19.177
are happening here, this thing should have
been highlighted in red, saying like,

58
00:04:19.177 --> 00:04:21.695
this is the problem here,
this is why I deoptimized.

59
00:04:21.695 --> 00:04:26.282
I don't know why it no longer does it,
it should also be listed under

60
00:04:26.282 --> 00:04:30.145
the deopts over here,
it says that it deopts benchmark,

61
00:04:30.145 --> 00:04:33.775
but it doesn't list the function
as being the cause.

62
00:04:33.775 --> 00:04:38.360
So I apologize I don't know why this is no
longer the case, but I'll show you a more

63
00:04:38.360 --> 00:04:42.364
complicated example where the thing
works as it's supposed to, yes?

64
00:04:42.364 --> 00:04:46.224
&gt;&gt; Did it maybe get deoptimized 3 times
cuz you run it with four different

65
00:04:46.224 --> 00:04:47.934
functions and the fourth one?

66
00:04:47.934 --> 00:04:51.668
&gt;&gt; No, it will give the same
number even if I just did it once,

67
00:04:51.668 --> 00:04:56.259
I think the other times the deoptimization
was for different reasons.

68
00:04:56.259 --> 00:05:00.793
It's supposed to list the reasons here and
you notice it only lists one reason,

69
00:05:00.793 --> 00:05:05.395
it says insufficient type feedback and
if you click on this, it was something not

70
00:05:05.395 --> 00:05:09.542
happy with performance now, and
we can zoom in into it what's going on.

71
00:05:09.542 --> 00:05:14.856
So first reasons why it got deopt was
because of these other reasons and then

72
00:05:14.856 --> 00:05:20.771
later it deopt because of the function and
I really wish this would be highlighted.

73
00:05:20.771 --> 00:05:24.488
And I saw it highlighted before, but
it stopped, I don't know whether the node

74
00:05:24.488 --> 00:05:28.615
updated or what, something changed, and
it no longer highlights, sorry about that.

75
00:05:28.615 --> 00:05:32.855
But I'll show you other examples where
you can get kind of the insights.

76
00:05:32.855 --> 00:05:37.765
So the thing to show you is V8 may be
a black box but it turns out it's not

77
00:05:37.765 --> 00:05:42.777
totally a black box, there's a set
of flags you can pass into it right?

78
00:05:42.777 --> 00:05:48.302
And again,
the team behind the Deopt explorer

79
00:05:48.302 --> 00:05:54.971
actually made this invoke
this tool called dexnode..

80
00:05:54.971 --> 00:05:59.871
What it is is different versions of
node have different versions of V8 and

81
00:05:59.871 --> 00:06:04.454
because of that you have to pass in
different flags to it in order to get

82
00:06:04.454 --> 00:06:07.155
the right information out of it, okay?

83
00:06:07.155 --> 00:06:11.356
So to simplify the whole world they have
this tool called dexnode that figures all

84
00:06:11.356 --> 00:06:15.204
this stuff out for you, and then just
passes the right set of flags right?

85
00:06:15.204 --> 00:06:18.655
So this is basically node
with an extra thing, and

86
00:06:18.655 --> 00:06:22.927
I you can specify where you wanna
put the trace information out

87
00:06:22.927 --> 00:06:26.809
into the system before you
run the piece of code, okay?

88
00:06:26.809 --> 00:06:29.530
So with this,
function,you get this log, and

89
00:06:29.530 --> 00:06:32.795
this log can be opened up in
the dependency explorer, and

90
00:06:32.795 --> 00:06:36.687
you can explore things inside of it,
so I think this is kind of cool.

91
00:06:36.687 --> 00:06:43.202
We'll drive deeper into it, but
first, let's go back to our code.

92
00:06:45.888 --> 00:06:49.488
And let's talk about what
could we do to fix it,

93
00:06:49.488 --> 00:06:54.168
the thing to fix it is to realize
that this benchmark is wrong.

94
00:06:54.168 --> 00:06:59.144
The way this benchmark is implemented
is it assumes that the code will be in

95
00:06:59.144 --> 00:07:01.472
line and it doesn't really work so

96
00:07:01.472 --> 00:07:06.312
I have a second version of this exact
thing which I called the deopt fix.

97
00:07:06.312 --> 00:07:11.466
Where again I have the the same
function as matter of fact I import

98
00:07:11.466 --> 00:07:17.669
the functions from the other file, but
instead of having the benchmark being

99
00:07:17.669 --> 00:07:22.834
a single function that gets
different function passed into it.

100
00:07:22.834 --> 00:07:27.552
Notice now the benchmark is a function
that I can call as part of a while loop,

101
00:07:27.552 --> 00:07:30.726
and this function internally
does the counting and

102
00:07:30.726 --> 00:07:35.112
also returns false at the right
moment when it says I'm done, right?

103
00:07:35.112 --> 00:07:42.575
And so now the benchmark A and
benchmark B have separate call sites.

104
00:07:42.575 --> 00:07:46.887
And because the call sites are separate,
it is now safe for

105
00:07:46.887 --> 00:07:50.495
the VM to inline benchmark
A into the call site A,

106
00:07:50.495 --> 00:07:54.290
an inline benchmark B into
the call site B, right?

107
00:07:54.290 --> 00:07:58.694
And not only does it inline benchmark A
here, it will also inline the time A into

108
00:07:58.694 --> 00:08:02.992
this location and time B into this
location, and so on and so forth, right?

109
00:08:02.992 --> 00:08:08.242
So now, because we're not running
the same benchmark in the same location,

110
00:08:08.242 --> 00:08:12.781
the VM is free to inline everything and
will not have deopt events.

111
00:08:12.781 --> 00:08:14.717
I see confused faces.

112
00:08:14.717 --> 00:08:18.548
&gt;&gt; Could we take a look at
the create Benchmark function?

113
00:08:18.548 --> 00:08:19.929
&gt;&gt; Yeah, this one?

114
00:08:19.929 --> 00:08:25.570
&gt;&gt; Yeah, just
&gt;&gt; It's just a counter internally,

115
00:08:25.570 --> 00:08:31.110
and it runs the performance
now every once in a while.

116
00:08:31.110 --> 00:08:34.239
The way it works is
usually when you call it,

117
00:08:34.239 --> 00:08:37.291
the benchmark just increments a counter.

118
00:08:37.291 --> 00:08:40.203
Every once in a while,
the benchmark says okay,

119
00:08:40.203 --> 00:08:44.975
you've I've done enough loops let me look
at the time see if the time is enough.

120
00:08:44.975 --> 00:08:48.643
And eventually it says when it like has
enough of a time difference then it says,

121
00:08:48.643 --> 00:08:52.114
okay, I think you ran enough, let me
shut you down and the return is false.

122
00:08:52.114 --> 00:08:55.557
&gt;&gt; Before it was running like a certain
number of times, now it's running for

123
00:08:55.557 --> 00:08:56.768
a certain period of time?

124
00:08:56.768 --> 00:08:59.888
&gt;&gt; It runs it for a certain period
of time until it decides yet

125
00:08:59.888 --> 00:09:01.652
that there has run enough time.

126
00:09:01.652 --> 00:09:05.434
And so now if I run the dopt -fix,

127
00:09:05.434 --> 00:09:10.300
I should get about 4.6 microseconds for

128
00:09:10.300 --> 00:09:17.210
every single one well, no,
it gets the faster one, right?

129
00:09:17.210 --> 00:09:20.773
The faster one was 1.7, so
now it gets 1.7 or 1.9,

130
00:09:20.773 --> 00:09:25.620
approximately the same thing consistently
across the board because it doesn't

131
00:09:25.620 --> 00:09:28.339
get into the deoptimization thing, right?

132
00:09:28.339 --> 00:09:32.500
In other words, there is no call site
where the VM could have optimized and

133
00:09:32.500 --> 00:09:35.667
later realized, oops,
that was the wrong thing to do.

