WEBVTT

1
00:00:00.000 --> 00:00:03.972
So what do we learn basically
is that fundamentally,

2
00:00:03.972 --> 00:00:06.870
you have this memory array, right?

3
00:00:06.870 --> 00:00:10.014
And you have a CPU and the CPU reads and
writes into the memory and

4
00:00:10.014 --> 00:00:12.802
there is basically an address
that you tell the memory,

5
00:00:12.802 --> 00:00:15.614
which address do you want to read and
write out, right?

6
00:00:15.614 --> 00:00:19.780
And CPU basically processes and
internally has a bunch of registers.

7
00:00:19.780 --> 00:00:22.346
It has the arithmetic logic unit,
which basically means addition,

8
00:00:22.346 --> 00:00:24.000
multiplication, and so on.

9
00:00:24.000 --> 00:00:26.421
And you have the program counter,
stack pointer, etc.,

10
00:00:26.421 --> 00:00:28.610
to have the special instructions.

11
00:00:28.610 --> 00:00:33.554
So the physical machines really
understands only numbers, arithmetic,

12
00:00:33.554 --> 00:00:35.940
flat memory, right?

13
00:00:35.940 --> 00:00:39.181
It understands index access, so

14
00:00:39.181 --> 00:00:44.281
that's the idea of A0 plus some AE0,
A extend AE.

15
00:00:44.281 --> 00:00:48.078
It really understand subroutines and
I hopefully made point clear that

16
00:00:48.078 --> 00:00:51.949
subroutines are really dumbed down
version of a function call, right?

17
00:00:51.949 --> 00:00:54.958
There's many things missing in
a subroutine that would make it into

18
00:00:54.958 --> 00:00:57.669
a function call mainly,
there are no calling conventions.

19
00:00:57.669 --> 00:01:00.723
Calling conventions is on to
the compiler to produce, right?

20
00:01:00.723 --> 00:01:05.947
In other words, how to parameters
get into the subroutine, and how

21
00:01:05.947 --> 00:01:11.826
does the values get out of the subroutine,
and the idea of local variables.

22
00:01:11.826 --> 00:01:15.198
We haven't really talked about it,
but they usually go on a stack.

23
00:01:15.198 --> 00:01:19.350
So Fortran doesn't have
a concept of local variables.

24
00:01:19.350 --> 00:01:23.235
So in Fortran,
when you call a function recursively,

25
00:01:23.235 --> 00:01:28.140
you still have access to the same
variables and yeah recursion is fun.

26
00:01:28.140 --> 00:01:29.270
So that's your physical machine.

27
00:01:29.270 --> 00:01:31.679
And so out of this physical machine,

28
00:01:31.679 --> 00:01:35.110
somehow you have to make
an actual machine, right?

29
00:01:35.110 --> 00:01:37.530
And we have to make a JavaScript
virtual machine, right?

30
00:01:37.530 --> 00:01:40.610
Something that looks
like JavaScript to you.

31
00:01:40.610 --> 00:01:46.066
And so the first bizarre thing I'm gonna
show you is that how in the world is

32
00:01:46.066 --> 00:01:51.175
it possible that a plus b would be
significantly faster than b plus a?

33
00:01:51.175 --> 00:01:53.057
That makes no sense, right?

34
00:01:53.057 --> 00:01:55.022
Why should this be?

35
00:01:55.022 --> 00:02:00.228
So let's hop in back into our code,
so we're gonna just grab the count

36
00:02:00.228 --> 00:02:05.612
from the command line and I'm gonna
have a couple functions there a b c and

37
00:02:05.612 --> 00:02:09.780
d and if you look across these
functions are identical.

38
00:02:09.780 --> 00:02:12.720
The only difference is the value
that they returned, right?

39
00:02:12.720 --> 00:02:17.500
Sometimes there's 1, 2, 3 or
4 and we're gonna benchmark them.

40
00:02:17.500 --> 00:02:20.549
And so
we're gonna have a benchmark function.

41
00:02:20.549 --> 00:02:23.688
And the way the benchmark
will work is we'll say,

42
00:02:23.688 --> 00:02:26.923
console log,
shows which one is gonna be running.

43
00:02:26.923 --> 00:02:32.098
Grab the performance,
run the loop in some number of times,

44
00:02:32.098 --> 00:02:37.271
and then compute the finish time,
and then print out how long

45
00:02:37.271 --> 00:02:43.885
did it take to run the single iteration
of this particular function, right?

46
00:02:43.885 --> 00:02:47.810
So let's do that.

47
00:02:47.810 --> 00:02:49.410
Of course, I forgot the command.

48
00:02:49.410 --> 00:02:51.056
What am I running here?

49
00:02:51.056 --> 00:02:55.649
I think it's just there ,okay,
so an nr deopt.

50
00:02:58.354 --> 00:03:02.222
Okay, so we'll run it and we see that, for

51
00:03:02.222 --> 00:03:05.990
the most part, they're about the same.

52
00:03:05.990 --> 00:03:07.170
I don't know what happened to D.

53
00:03:07.170 --> 00:03:08.560
D is way slower.

54
00:03:08.560 --> 00:03:10.920
Probably the garbage
collection has kicked in.

55
00:03:10.920 --> 00:03:14.870
But the reason they're about the same is
because we're only running 10 iterations.

56
00:03:14.870 --> 00:03:18.250
So let's increase the number
of iterations that we run.

57
00:03:18.250 --> 00:03:23.300
And we get the first one is a little
slower, the next one has become faster.

58
00:03:23.300 --> 00:03:23.960
What's happening?

59
00:03:23.960 --> 00:03:28.035
Well, there is certainly startup costs
that exist inside of the VMs, and

60
00:03:28.035 --> 00:03:31.270
also, it takes a while before
they compile things, etc.

61
00:03:31.270 --> 00:03:36.024
So when the VM first starts running,
it runs an interpretive mode, and

62
00:03:36.024 --> 00:03:39.550
then later it switches into compile mode.

63
00:03:39.550 --> 00:03:42.480
And so, the why not compile
everything from the beginning?

64
00:03:42.480 --> 00:03:44.560
Well, it takes time to compile things,
right?

65
00:03:44.560 --> 00:03:49.021
And so you're doing a trade off being,
well, if I'm only running this code once,

66
00:03:49.021 --> 00:03:52.781
it's probably faster for me to just
run it and other on the other hand,

67
00:03:52.781 --> 00:03:56.605
if it's not a tight loop, it's probably
better for me to compile it and

68
00:03:56.605 --> 00:03:58.436
run it in a faster per iteration.

69
00:03:58.436 --> 00:04:04.500
And here you can see that originally
these loops start pretty slow.

70
00:04:04.500 --> 00:04:07.297
They take four microseconds to run, but

71
00:04:07.297 --> 00:04:12.644
as the VM warms up the performance
improves, it's the same exact function,

72
00:04:12.644 --> 00:04:18.090
you can see the functions is getting
better and faster and faster.

73
00:04:18.090 --> 00:04:22.351
So then we go to maybe a hundred and
now we're really cooking and you can see

74
00:04:22.351 --> 00:04:27.330
that the VM is really has gotten its
stride and it's running pretty good.

75
00:04:27.330 --> 00:04:29.870
And now let's go to even faster.

76
00:04:31.460 --> 00:04:34.658
And yeah,
now they're about the same, right?

77
00:04:34.658 --> 00:04:36.849
Let's go even more iterations.

78
00:04:37.990 --> 00:04:42.503
And the first two, looks like the last
two are really compiled at this point,

79
00:04:42.503 --> 00:04:45.030
you can see that it's down to eight.

80
00:04:45.030 --> 00:04:46.036
Let's go to even more iterations.

81
00:04:49.858 --> 00:04:53.821
Now all of them seem to be running in the
compiled mode and they run about the same

82
00:04:53.821 --> 00:04:57.809
but go, let's go even more iterations and
now we're things start to happen.

83
00:04:57.809 --> 00:05:03.670
What in the world, why is A so
much faster than everybody else?

84
00:05:03.670 --> 00:05:09.383
You notice that A is running about less
than 2 microseconds per iteration,

85
00:05:09.383 --> 00:05:14.024
whereas everybody else is about 4.6 or
so iterations, and

86
00:05:14.024 --> 00:05:18.060
I can keep going in terms of
the number of iterations.

87
00:05:18.060 --> 00:05:19.140
It's not gonna change.

88
00:05:19.140 --> 00:05:21.081
This number is gonna be pretty stable.

89
00:05:21.081 --> 00:05:25.023
At this point,
we are running as fast as we can, and

90
00:05:25.023 --> 00:05:29.280
yet the first one is way
faster than everybody else.

91
00:05:29.280 --> 00:05:31.985
Why?
What's going on in here?

92
00:05:31.985 --> 00:05:34.119
If you look at what
we're actually running,

93
00:05:34.119 --> 00:05:35.980
is we're running the same exact code.

94
00:05:37.130 --> 00:05:37.990
Why is that?

95
00:05:37.990 --> 00:05:42.678
And just to kind of prove a point,
I can switch,

96
00:05:42.678 --> 00:05:45.617
I can run B first, and then A.

97
00:05:45.617 --> 00:05:49.425
And then what we're gonna see is that it's
still the first one that ran was faster

98
00:05:49.425 --> 00:05:50.440
than the other ones.

99
00:05:51.990 --> 00:05:52.490
Why?

100
00:05:53.700 --> 00:05:54.330
What's going on?

101
00:05:55.500 --> 00:05:56.000
Anybody wants to take a guess?

102
00:06:01.938 --> 00:06:08.450
&gt;&gt; Is the value stored in a better place
in the CPU first one that goes in?

103
00:06:10.860 --> 00:06:11.790
&gt;&gt; Not quite.

104
00:06:12.950 --> 00:06:15.110
So look at this particular function here.

105
00:06:15.110 --> 00:06:18.096
&gt;&gt; What of caching?

106
00:06:18.096 --> 00:06:25.870
&gt;&gt; Caching would be a good guess, but it's
a caching in a way that you don't expect.

107
00:06:25.870 --> 00:06:27.350
So let me explain what's happening here.

108
00:06:29.200 --> 00:06:33.689
We run this function and this function
is iterating over and over the fn.

109
00:06:33.689 --> 00:06:39.517
And remember function is a subroutine with
this whole complicated overhead of like,

110
00:06:39.517 --> 00:06:44.345
I when I call a function, I have to push
values onto the stack, I have to make

111
00:06:44.345 --> 00:06:48.891
sure that I save all the registers
then I do work and then I return back.

112
00:06:48.891 --> 00:06:51.648
And in this case,
the actual work that we're doing,

113
00:06:51.648 --> 00:06:55.759
we're just adding two numbers together or
comparing and returning a number and

114
00:06:55.759 --> 00:06:59.684
that's so insignificant compared to
the cost of actually making the call is

115
00:06:59.684 --> 00:07:02.442
that the call is dominating
the cost of the function,

116
00:07:02.442 --> 00:07:06.980
the amount of work that we're actually
doing inside of the function.

117
00:07:06.980 --> 00:07:09.640
And so, what the VM does after
a while it says you know what,

118
00:07:09.640 --> 00:07:12.300
I see that you keep calling
this function here.

119
00:07:12.300 --> 00:07:13.350
I'm gonna inline it.

120
00:07:15.390 --> 00:07:19.101
And so it takes the function and
inlines it into this location, and

121
00:07:19.101 --> 00:07:23.342
now this loop can run a lot faster because
what happens is when you inline, so

122
00:07:23.342 --> 00:07:25.880
lemme let's back up how compilation works.

123
00:07:27.160 --> 00:07:28.530
Let's back up.

124
00:07:28.530 --> 00:07:31.722
One of the things that the compiler
has to do is look at the code and

125
00:07:31.722 --> 00:07:35.760
look at the local variables, and then
decide where do these local variables go?

126
00:07:35.760 --> 00:07:41.230
Do they go into registers,
or do they go into memory?

127
00:07:41.230 --> 00:07:45.393
You can imagine that if you have a lot
of local variables, you will exhaust all

128
00:07:45.393 --> 00:07:49.380
possible registers, and eventually
you have to go into memory, right?

129
00:07:49.380 --> 00:07:50.960
So, the compiler has to make some choices.

130
00:07:50.960 --> 00:07:53.180
Where do I store this stuff?

131
00:07:53.180 --> 00:07:56.220
Maybe it's temporary and
I can store it inside of a register.

132
00:07:56.220 --> 00:07:58.650
Maybe it's long enough that I have
to put it on memory, et cetera.

133
00:07:58.650 --> 00:07:59.619
It has to make choices.

134
00:08:00.790 --> 00:08:04.654
And so it looks at the program, and
whenever it comes across a function call,

135
00:08:04.654 --> 00:08:08.760
it doesn't look into the function
cuz that's something else, right?

136
00:08:08.760 --> 00:08:10.515
And so it only does optimization,

137
00:08:10.515 --> 00:08:14.700
figuring out what goes where based on what
it sees inside of its current function.

138
00:08:16.520 --> 00:08:21.377
So if you can inline the function then
the layout and assignment of registers can

139
00:08:21.377 --> 00:08:25.799
be better laid out because now you can
basically save yourself the making

140
00:08:25.799 --> 00:08:30.860
the call but not just saving yourself
the call the calling convention.

141
00:08:30.860 --> 00:08:34.719
Because it's inline disappears, and
instead the compiler looks at the whole

142
00:08:34.719 --> 00:08:38.461
function that's in lined and says,
if I just like lay out the registers

143
00:08:38.461 --> 00:08:41.818
differently, I can save myself
the trouble of going to the memory.

144
00:08:44.205 --> 00:08:45.430
Right?

145
00:08:45.430 --> 00:08:50.156
And so the function originally
was compiled once without

146
00:08:50.156 --> 00:08:52.130
the function in lined.

147
00:08:53.500 --> 00:08:55.191
And then the CPU ran for a while and

148
00:08:55.191 --> 00:08:59.550
the virtual machine notice you keep
running this thing over and over again.

149
00:08:59.550 --> 00:09:01.030
I think it'd be useful to inline it.

150
00:09:01.030 --> 00:09:04.624
So let's try to inline it see if I can get
better performance out of the system and

151
00:09:04.624 --> 00:09:07.810
sure enough, I can get so
much better performance, right?

152
00:09:07.810 --> 00:09:12.859
So the reason why B runs or
the the first one runs fast

153
00:09:12.859 --> 00:09:20.620
it's because the first one got inlined,
but now notice what happens next.

154
00:09:20.620 --> 00:09:23.839
Now we finish all the iteration,
we go up and

155
00:09:23.839 --> 00:09:27.670
now we run B with a different
value of the benchmark.

156
00:09:28.740 --> 00:09:33.290
And now we run this, and now the compiler
realizes, wow, I made a mistake.

157
00:09:34.560 --> 00:09:41.079
I inlined something that I thought was
constant, but it turns out it isn't.

158
00:09:41.079 --> 00:09:46.420
I have now observed that this function fn
is not the same function all the time.

159
00:09:46.420 --> 00:09:49.632
Sometimes it's fna, and
sometimes it's fnb, and

160
00:09:49.632 --> 00:09:52.440
therefore I've made a mistake, right?

161
00:09:52.440 --> 00:09:56.810
The compiler was trying to
do the best possible thing,

162
00:09:56.810 --> 00:10:03.660
given the knowledge it had, and up to that
point, it has always only seen function A.

163
00:10:04.750 --> 00:10:07.350
And therefore it was
a reasonable assumption to say,

164
00:10:07.350 --> 00:10:08.999
this is always gonna be a function A.

165
00:10:10.370 --> 00:10:16.206
But now when he saw an example of a Black
Swan, you know the Black Swan example?

166
00:10:16.206 --> 00:10:19.920
Everybody thinks there's only white swans
because that's all you've ever seen.

167
00:10:19.920 --> 00:10:22.505
But you only need one black swan
to kind of convince you like, no,

168
00:10:22.505 --> 00:10:24.090
there are different colors.

169
00:10:24.090 --> 00:10:25.500
You just don't have one, okay?

170
00:10:25.500 --> 00:10:28.999
So now it has seen a different function
and now the compiler is like, crap,

171
00:10:28.999 --> 00:10:31.290
I missed up I can't inline this anymore.

172
00:10:31.290 --> 00:10:35.536
Because I've seen that sometimes it's
function A and sometimes it's function B,

173
00:10:35.536 --> 00:10:39.750
and because of that,
the inline that I have done was incorrect.

174
00:10:39.750 --> 00:10:43.060
And that's called a deopt, right?

175
00:10:43.060 --> 00:10:46.400
The compiler was trying
to optimize something and

176
00:10:46.400 --> 00:10:51.093
because it had insufficient information,
it optimized something in

177
00:10:51.093 --> 00:10:55.980
an incorrect way, and so now it has
to back off from this optimization.

178
00:10:55.980 --> 00:11:01.038
And so deopt is when the compiler
gets to see a black swan go by and

179
00:11:01.038 --> 00:11:07.050
says, oops, the assumptions I have
made here, no longer hold true.

180
00:11:07.050 --> 00:11:10.230
And therefore the code that I
have generated is incorrect.

181
00:11:11.570 --> 00:11:15.191
What actually happens is
when the code is generated,

182
00:11:15.191 --> 00:11:17.810
the compiler leaves behind checks.

183
00:11:17.810 --> 00:11:22.843
So when it inlines the function A, there's
a hidden check that basically says,

184
00:11:22.843 --> 00:11:25.508
before you pretend everything is normal,

185
00:11:25.508 --> 00:11:29.669
double check that function A is
really the same function, right?

186
00:11:29.669 --> 00:11:33.720
And of course,
that check is always true until it isn't.

187
00:11:34.860 --> 00:11:39.710
And when it isn't,
the compiler is like, oops, I messed up.

188
00:11:39.710 --> 00:11:42.990
And this is what is called a deopt, right?

189
00:11:42.990 --> 00:11:49.420
And so in a deopt, it undoes the work and
says, okay, I cannot inline this.

190
00:11:49.420 --> 00:11:51.167
It marks this as non-inlinable and

191
00:11:51.167 --> 00:11:54.198
then continues running the code
in a non-inlined way because

192
00:11:54.198 --> 00:11:57.940
it now knows that sometimes it's
function A, sometimes it's function B.

193
00:11:57.940 --> 00:11:58.750
Why does this matter?

194
00:12:00.250 --> 00:12:05.990
It matters because it is so
easy to convince yourself of the wrong

195
00:12:05.990 --> 00:12:12.060
thing on microbenchmarks,
specifically because of this.

196
00:12:12.060 --> 00:12:16.032
When you make a microbenchmark, you're
saying, look how fast my code is, but

197
00:12:16.032 --> 00:12:20.630
what you're not doing is you're not
exercising all of the different paths.

198
00:12:20.630 --> 00:12:23.526
And as a result,
the VM looks at the code and

199
00:12:23.526 --> 00:12:28.700
says, all of these functions are constant,
I can inline them.

200
00:12:28.700 --> 00:12:33.540
And it does so, and it gives you
the illusion that the code you have just

201
00:12:33.540 --> 00:12:39.610
written performs a lot better than it
will actually perform in reality, right?

202
00:12:39.610 --> 00:12:44.986
Whenever you do micro benchmarks,
the reason why micro benchmarks are looked

203
00:12:44.986 --> 00:12:50.200
at with great skepticism, is because
stuff like this, it's so easy to kind

204
00:12:50.200 --> 00:12:55.346
of shoot yourself in the foot and
start measuring the wrong thing, right?

205
00:12:55.346 --> 00:13:00.329
And so in this particular case,
the question you should be

206
00:13:00.329 --> 00:13:04.916
asking yourself is how could
I have seen this coming?

207
00:13:08.550 --> 00:13:13.429
And the way you would know to answer the
question is that a lot of it is kind of

208
00:13:13.429 --> 00:13:16.344
experience of like when
you're doing it for

209
00:13:16.344 --> 00:13:19.580
a while you kind of know what to look for.

210
00:13:19.580 --> 00:13:23.072
The thing to look for here is to
recognize the fact you know what,

211
00:13:23.072 --> 00:13:27.339
this is gonna be a problem because when I
wrote the code I knew because I'm human

212
00:13:27.339 --> 00:13:30.120
I know more than a compiler does, right?

213
00:13:30.120 --> 00:13:34.920
I knew that this function is
going to change shape over time.

214
00:13:34.920 --> 00:13:39.190
We talk about shape as in the reference,
the kind of function we get here.

215
00:13:39.190 --> 00:13:41.540
It's changing shape here, right?

216
00:13:41.540 --> 00:13:45.618
So, the fancy term for it,
it's polymorphic, right?

217
00:13:45.618 --> 00:13:48.690
Poly means many more have means to change,
right?

218
00:13:48.690 --> 00:13:51.330
So it has many changes
that are happening there.

219
00:13:51.330 --> 00:13:53.960
So the fancy word for
this is that it's polymorphic.

220
00:13:53.960 --> 00:13:58.031
So the way the modern V8 or
modern virtual machines work is they,

221
00:13:58.031 --> 00:14:02.769
try to look for things that appear
constant, and if they notice basically,

222
00:14:02.769 --> 00:14:07.878
it executes this piece of code several
thousand times, and if in several thousand

223
00:14:07.878 --> 00:14:13.160
times it has never seen it to change, then
it just assumes that it must never change.

224
00:14:14.250 --> 00:14:17.970
And then that assumption is used
to better compile the output code.

225
00:14:19.590 --> 00:14:24.250
Until that assumption is no longer true,
and then things break.

226
00:14:24.250 --> 00:14:26.543
And this is when we get a deopt, right?

227
00:14:26.543 --> 00:14:32.660
So when when people talk about deopts
what it means is that the VM ran,

228
00:14:32.660 --> 00:14:37.196
it collected information
it observed the world and

229
00:14:37.196 --> 00:14:43.226
up to that point, it looked like
these set of invariants were true.

230
00:14:43.226 --> 00:14:47.700
Based on those invariants, it generated
code that later proved to be wrong.

231
00:14:47.700 --> 00:14:52.508
And so a deopt is whenever
the invariant that you thought was

232
00:14:52.508 --> 00:14:55.019
true turns out was not, okay?

233
00:14:55.019 --> 00:14:59.933
So if you have been coding for a while,
and as a human, whenever you see this

234
00:14:59.933 --> 00:15:05.549
thing, you should ask yourself, first of
all, many times it just doesn't matter,

235
00:15:05.549 --> 00:15:09.311
so don't assume that,
apply this everywhere, right?

236
00:15:09.311 --> 00:15:10.700
Decide whether it matters or not.

237
00:15:10.700 --> 00:15:14.895
When you have something that you think
matters in terms of performance,

238
00:15:14.895 --> 00:15:18.072
ask yourself,
is this function actually expensive?

239
00:15:18.072 --> 00:15:19.429
Is it monomorphic, right?

240
00:15:19.429 --> 00:15:21.460
Is this always gonna be
the same function or not?

241
00:15:22.490 --> 00:15:25.297
And if the answer is none,
it's a different function,

242
00:15:25.297 --> 00:15:29.480
then second question to ask is, well, is
the cost of calling the function compared

243
00:15:29.480 --> 00:15:33.050
to the amount of work the function
is doing significant, right?

244
00:15:33.050 --> 00:15:35.467
Because if this function is
something super expensive,

245
00:15:35.467 --> 00:15:39.020
it doesn't matter whether in lines or
does it makes no difference.

246
00:15:39.020 --> 00:15:46.570
And if it doesn't, then you might consider
for example, to do the inlining yourself.

247
00:15:46.570 --> 00:15:51.206
So let me give you an example, a typical
thing we might do is we might have

248
00:15:51.206 --> 00:15:54.120
a queue of a list of functions to run.

249
00:15:54.120 --> 00:15:57.000
And let's say you have two
different functions you run,

250
00:15:57.000 --> 00:16:00.066
either let's say add numbers or
multiply numbers, right?

251
00:16:00.066 --> 00:16:01.710
Those are pretty simple operations.

252
00:16:01.710 --> 00:16:05.140
And so
you put them inside of an array, and

253
00:16:05.140 --> 00:16:10.138
you tell the program to for over
the loop over the array, and

254
00:16:10.138 --> 00:16:13.280
then read the function and invoke it.

255
00:16:14.450 --> 00:16:17.617
What the VM will see is that those
are functions that are always different,

256
00:16:17.617 --> 00:16:18.579
I can't inline them.

257
00:16:19.750 --> 00:16:21.210
But what if you can inline it yourself?

258
00:16:21.210 --> 00:16:25.989
What if you put the two functions, you
inline the functions directly in there,

259
00:16:25.989 --> 00:16:30.336
and just put an if statement in front
of it, and then inside of the array,

260
00:16:30.336 --> 00:16:35.541
instead of putting the functions, you just
put a number, or boolean, true or false,

261
00:16:35.541 --> 00:16:40.576
meaning true means add the numbers, false
means to multiply the numbers, right?

262
00:16:40.576 --> 00:16:42.973
That alone will make the code run faster,

263
00:16:42.973 --> 00:16:47.973
because you fundamentally did the inlining
for it, and now you've made the invariant

264
00:16:47.973 --> 00:16:51.830
that the data flowing through
the system is monomorphic, right?

265
00:16:51.830 --> 00:16:54.279
You are always gonna get a boolean and

266
00:16:54.279 --> 00:16:57.601
the function you're calling
is always the same.

267
00:16:57.601 --> 00:17:00.460
And in some cases,
that might make a difference, right?

268
00:17:00.460 --> 00:17:04.400
We're talking here about two and a half
times faster in this particular case.

269
00:17:04.400 --> 00:17:08.760
So, again, it depends on
a situation that you might have.

270
00:17:08.760 --> 00:17:09.260
Yes?

271
00:17:10.960 --> 00:17:14.525
&gt;&gt; Is function declaration
faster than function expression

272
00:17:14.525 --> 00:17:18.169
because function expression
works with only references?

273
00:17:18.169 --> 00:17:19.360
&gt;&gt; There's no difference.

274
00:17:19.360 --> 00:17:21.921
To my knowledge, there is no difference,

275
00:17:21.921 --> 00:17:25.990
because even a function declaration
can close over other things.

276
00:17:25.990 --> 00:17:29.334
So the two have differences in
terms of how you declare them and

277
00:17:29.334 --> 00:17:33.773
how they're allocated, but at run time
my understanding is they're absolutely

278
00:17:33.773 --> 00:17:35.850
the same as far as the VM is concerned.

