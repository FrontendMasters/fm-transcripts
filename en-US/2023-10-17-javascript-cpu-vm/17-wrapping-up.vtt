WEBVTT

1
00:00:00.000 --> 00:00:03.814
That kind of was all of it,
hope you enjoyed it.

2
00:00:03.814 --> 00:00:06.795
I always find these things
super fascinating, and

3
00:00:06.795 --> 00:00:10.966
I really enjoy going deep down into
the rabbit holes of how things work.

4
00:00:10.966 --> 00:00:12.604
And again, for
me it's not about performance for

5
00:00:12.604 --> 00:00:14.484
me it's about just understanding
how the system works.

6
00:00:14.484 --> 00:00:20.701
I feel better when I understand
&gt;&gt; Its shifting is a good idea, right?

7
00:00:20.701 --> 00:00:24.520
Sometimes it is
&gt;&gt; Makes it more clear

8
00:00:24.520 --> 00:00:28.355
&gt;&gt; Yes [LAUGH]

9
00:00:28.355 --> 00:00:31.487
&gt;&gt; It's a question here on chat,

10
00:00:31.487 --> 00:00:35.582
what other tools for static analysis and

11
00:00:35.582 --> 00:00:39.400
performance should we look into
&gt;&gt; It's a good question.

12
00:00:39.400 --> 00:00:42.291
I don't know that many out there,

13
00:00:42.291 --> 00:00:48.274
I know there are tools that try to just
say what are the best practices and

14
00:00:48.274 --> 00:00:54.570
kind of linters will scream at you if
you don't do the best practice, etc.

15
00:00:54.570 --> 00:00:59.466
But that's more like make it easy for the
human to read rather than make it easy for

16
00:00:59.466 --> 00:01:05.194
the computer to execute I think in
terms of what is easy for the computer,

17
00:01:05.194 --> 00:01:09.250
you really only have one choice and
that is to ask the VM itself, right?

18
00:01:09.250 --> 00:01:11.277
There are special flags you
can pass into the VM, so

19
00:01:11.277 --> 00:01:14.320
the VM will tell you what's
actually happening underneath it.

20
00:01:14.320 --> 00:01:18.261
Because VMs change this all the time,
the way things used to work and

21
00:01:18.261 --> 00:01:19.712
the way things work now,

22
00:01:19.712 --> 00:01:24.090
what are the kinds of optimizations VMs
used to deal with change over time.

23
00:01:24.090 --> 00:01:29.090
So for example, the holey arrays used to
be an extreme penalty for doing that.

24
00:01:29.090 --> 00:01:32.665
Not so much anymore, I think we showed
that it was like twice as slow,

25
00:01:32.665 --> 00:01:34.588
it's not that big of a deal, right?

26
00:01:34.588 --> 00:01:38.080
Unless you do holey arrays and
then also do a prototype chain mess up,

27
00:01:38.080 --> 00:01:40.114
then you're really in a world of pain.

28
00:01:40.114 --> 00:01:42.070
But for the most part, it's not so bad.

29
00:01:42.070 --> 00:01:45.658
So these are all kinds of tricks
that change over the years.

30
00:01:45.658 --> 00:01:50.886
And so really the only way to know is to
to ask the VM using the special flags and

31
00:01:50.886 --> 00:01:53.024
say, hey, tell me the stuff.

32
00:01:53.024 --> 00:01:54.695
Yes
&gt;&gt; So

33
00:01:54.695 --> 00:01:58.686
should we basically try to avoid
touching prototypes altogether?

34
00:01:58.686 --> 00:02:00.816
&gt;&gt; I think that's a good
good idea in general, yes.

35
00:02:00.816 --> 00:02:05.916
Out outside of defining classes,
right, but even that,

36
00:02:05.916 --> 00:02:10.705
we have a special syntax for
right now, there should be

37
00:02:10.705 --> 00:02:15.720
very little reason to go and
mess with prototype chains.

38
00:02:15.720 --> 00:02:19.532
And yeah, and you can see how,
if you mess with the prototype chains,

39
00:02:19.532 --> 00:02:22.632
you kind of ruin it for
the VM because VM makes assumptions

40
00:02:22.632 --> 00:02:25.553
that the prototype chains
have not been messed with.

41
00:02:25.553 --> 00:02:29.434
And if it can make that assumption that it
can short circuit a whole bunch of work

42
00:02:35.718 --> 00:02:38.401
&gt;&gt; Where can we learn more?

43
00:02:38.401 --> 00:02:39.838
&gt;&gt; Where can you learn more?

44
00:02:39.838 --> 00:02:44.412
I've never seen kind of a comprehensive
place where you can learn about

45
00:02:44.412 --> 00:02:46.850
all these tricks I wish, V8 would, or

46
00:02:46.850 --> 00:02:51.441
like the V8 team would do a better
job kind of sharing this information.

47
00:02:51.441 --> 00:02:54.903
They have tech talks they've done,
there is pieces of these.

48
00:02:54.903 --> 00:02:58.791
This information is kind of scattered
all over the internet, but I never

49
00:02:58.791 --> 00:03:02.888
really seen it, put it in one exact
location where all the pieces are there.

50
00:03:02.888 --> 00:03:06.115
I think part of the problem is
that these tricks, as I said,

51
00:03:06.115 --> 00:03:07.674
they change over versions.

52
00:03:07.674 --> 00:03:14.377
The way things work kind of changes,
and it's not always the same.

53
00:03:14.377 --> 00:03:15.535
I think you had a question?

54
00:03:15.535 --> 00:03:18.301
&gt;&gt; Yeah, you mentioned multiple
times about micro-benchmarking and

55
00:03:18.301 --> 00:03:19.499
being very cautious with it.

56
00:03:19.499 --> 00:03:20.019
&gt;&gt; Yes,
&gt;&gt; So

57
00:03:20.019 --> 00:03:23.391
when it gets what's your approach
when you see wow, 60x improvement?

58
00:03:23.391 --> 00:03:26.094
Well, in the real world,
it's just not gonna be that good,

59
00:03:26.094 --> 00:03:28.956
but it might be better or do you
have to do something more to sort of

60
00:03:28.956 --> 00:03:31.887
make a reasonable assumption that
it'll be a little bit better?

61
00:03:31.887 --> 00:03:35.948
&gt;&gt; So I mean, if you have two benchmarks
and one shows better numbers,

62
00:03:35.948 --> 00:03:38.810
probably it's a encouraging result, right?

63
00:03:38.810 --> 00:03:42.700
So I think I would say that you
have to look at it overall.

64
00:03:42.700 --> 00:03:44.749
You have to take all your knowledge and
be, okay, so

65
00:03:44.749 --> 00:03:46.528
the benchmarks show in
the right direction.

66
00:03:46.528 --> 00:03:50.118
I've changed this code and
I think it's making it better, etc.

67
00:03:50.118 --> 00:03:54.963
And by putting it all together,
you can have a good feel for it.

68
00:03:54.963 --> 00:03:58.935
The caching is, is tricky because
there's two kinds of caches, right?

69
00:03:58.935 --> 00:04:02.950
There's the cache for the properties,
which we talked about, and

70
00:04:02.950 --> 00:04:05.073
then when it's fixed to 1024.

71
00:04:05.073 --> 00:04:11.038
But then the CPU also has an L0 and L1
cache, and those are also tricky because,

72
00:04:11.038 --> 00:04:14.897
[COUGH] what happens is if
you run code in a tight loop,

73
00:04:14.897 --> 00:04:18.965
the caches get primed, and
everything is a cache hit.

74
00:04:18.965 --> 00:04:23.038
But now if you start executing
code all over your code base,

75
00:04:23.038 --> 00:04:27.858
then you are a lot more likely to
have evictions and have cache misses.

76
00:04:27.858 --> 00:04:31.195
And so just by the fact that
your benchmark is small, and

77
00:04:31.195 --> 00:04:35.884
therefore all the code is on one pile,
that alone is making it faster, right?

78
00:04:35.884 --> 00:04:40.305
Then in reality, when you have code
spread across a huge codebase,

79
00:04:40.305 --> 00:04:44.573
that action alone, that the fact
that you spread it everywhere,

80
00:04:44.573 --> 00:04:48.085
that alone will probably
cause it to perform slower.

81
00:04:48.085 --> 00:04:50.575
Even though like in theory,
it shouldn't make any difference, right,

82
00:04:50.575 --> 00:04:52.836
because memory access memory
access doesn't matter where it is.

83
00:04:52.836 --> 00:04:58.559
But the fact that it's together, makes it
much more likely that you'll have a L0 and

84
00:04:58.559 --> 00:05:03.188
L1 cache hit,
Plus there's tricks you can do.

85
00:05:03.188 --> 00:05:07.880
For example, one of the things that modern
CPUs want to do is, they wanna make sure

86
00:05:07.880 --> 00:05:12.096
that their instruction processing
pipeline, they call it a pipeline cuz

87
00:05:12.096 --> 00:05:16.397
they really doing multiple instructions
all at once, it doesn't stall.

88
00:05:16.397 --> 00:05:19.589
Stall basically means that, I don't know
what to do next, because the memory hasn't

89
00:05:19.589 --> 00:05:22.079
gotten back to me, or I don't know,
there's an if statement, and

90
00:05:22.079 --> 00:05:25.630
therefore I don't know which way to go,
or something like that, it's a stall.

91
00:05:25.630 --> 00:05:26.880
And you wanna avoid stall, right?

92
00:05:26.880 --> 00:05:30.160
You wanna just keep the CPU crunching
through numbers as much as possible.

93
00:05:31.200 --> 00:05:36.010
And so, to keep the CPU from stalling,
there's two tricks it does, right?

94
00:05:36.010 --> 00:05:39.622
One is, I said, it does branch prediction
where it just says, if statement,

95
00:05:39.622 --> 00:05:41.997
I don't know which way I should go,
I don't care.

96
00:05:41.997 --> 00:05:43.363
Let's just choose one and

97
00:05:43.363 --> 00:05:47.647
keep going cuz I have a pretty good chance
that I will guess the correct branch, and

98
00:05:47.647 --> 00:05:51.790
then I can reuse this work,
I can commit the work as being good.

99
00:05:51.790 --> 00:05:56.350
The other way they do is they tell
the O0 cache to prefetch instructions.

100
00:05:56.350 --> 00:05:58.367
They know that,
if I fetch an instruction here,

101
00:05:58.367 --> 00:06:01.137
there's a good chance that I'm
gonna fetch the next one, right?

102
00:06:01.137 --> 00:06:04.079
Unless there's a jump or go subroutine,
there's an extremely high

103
00:06:04.079 --> 00:06:07.390
chance that the next instruction
is what I'm gonna go after.

104
00:06:07.390 --> 00:06:11.408
And so when they issue these
L2 caches to fetch us,

105
00:06:11.408 --> 00:06:14.290
they start fetching ahead of time.

106
00:06:14.290 --> 00:06:16.880
They wanna make sure that
the CPU's always busy, right?

107
00:06:18.640 --> 00:06:22.239
And so, this only typically works
better if the code is together.

108
00:06:22.239 --> 00:06:25.516
Once you spread the code all over
the place and introduce other things,

109
00:06:25.516 --> 00:06:27.762
that makes it much more
likely that won't work.

110
00:06:29.956 --> 00:06:34.238
So it's modern CPUs and
modern compilers have

111
00:06:34.238 --> 00:06:38.864
turned the whole thing into
a bit of a black magic.

112
00:06:38.864 --> 00:06:42.290
In theory, this instruction should be
faster than this other instruction.

113
00:06:42.290 --> 00:06:43.725
But what does it do in real life?

114
00:06:43.725 --> 00:06:47.204
There's only one way to know, let's build
a whole bunch of benchmarks, which I

115
00:06:47.204 --> 00:06:50.695
probably meant microbenchmark, and try to
guess and kind of see which one it is.

116
00:06:55.751 --> 00:06:59.890
That compiler optimization is a whole
separate thing that I don't know enough

117
00:06:59.890 --> 00:07:03.405
about, but
I think it'd be super fascinating talk.

118
00:07:03.405 --> 00:07:06.429
&gt;&gt; So a lot of this is like optimizing and

119
00:07:06.429 --> 00:07:12.700
it seems this sort of optimization is
really good for libraries and such.

120
00:07:12.700 --> 00:07:15.891
When it comes to web applications,
what sort of things,

121
00:07:15.891 --> 00:07:18.690
because of your experience
with the Qwik usage.

122
00:07:18.690 --> 00:07:23.048
&gt;&gt; So for frameworks, right, this makes
a lot of sense because for example,

123
00:07:23.048 --> 00:07:25.343
React has to do JSX different, right?

124
00:07:25.343 --> 00:07:25.917
&gt;&gt; Yeah.
&gt;&gt; So

125
00:07:25.917 --> 00:07:28.087
it better be as performant as possible.

126
00:07:28.087 --> 00:07:32.051
For you as a developer may be
a little less if you're just building

127
00:07:32.051 --> 00:07:37.093
an application, but still there might be
cases in your app, which are performance

128
00:07:37.093 --> 00:07:41.367
sensitive in which cases,
these things matter and think about them.

129
00:07:41.367 --> 00:07:42.933
And on some level, as I said,

130
00:07:42.933 --> 00:07:46.894
some of these things are just good ideas,
just don't pollute prototype.

131
00:07:46.894 --> 00:07:50.875
Don't create a holey arrays,
and just don't do these

132
00:07:50.875 --> 00:07:55.752
things because the code is actually
easier to deal with, right?

133
00:07:55.752 --> 00:07:58.947
If you have a class, make sure you
initialize all of the properties,

134
00:07:58.947 --> 00:08:01.163
even if you don't need them right now,
right?

135
00:08:01.163 --> 00:08:05.242
It's just a good idea,
I would argue that makes for better code.

136
00:08:05.242 --> 00:08:08.929
&gt;&gt; Yeah, and with the double equals,
you don't get any false positives.

137
00:08:08.929 --> 00:08:10.382
&gt;&gt; You don't get false positives, yes.

138
00:08:10.382 --> 00:08:13.021
&gt;&gt; You use using triple equals.

139
00:08:13.021 --> 00:08:17.604
&gt;&gt; Yes, so you can see, if somebody goes
and pollutes the prototype chain and

140
00:08:17.604 --> 00:08:19.277
messes with the valueOf,

141
00:08:19.277 --> 00:08:23.309
you can see how that has a huge
implication through the code base.

142
00:08:23.309 --> 00:08:26.280
Because all of a sudden,
all the double equals,

143
00:08:26.280 --> 00:08:31.076
they might actually follow different
rules because you made them different.

144
00:08:31.076 --> 00:08:34.186
So, go change
object.prototype.valueOf and

145
00:08:34.186 --> 00:08:37.821
see what happens in your performance of,
[LAUGH] your app.

146
00:08:37.821 --> 00:08:40.658
&gt;&gt; Thank you for
the eye-opening class, Arga says.

147
00:08:40.658 --> 00:08:42.453
Aaron says thank you.

148
00:08:42.453 --> 00:08:45.059
Amitar says thanks as well.

149
00:08:45.059 --> 00:08:50.736
On Twitch, fantastic chat,
class has been amazing.

150
00:08:50.736 --> 00:08:54.852
Several fantastic class,
fantastic class really interesting.

151
00:08:54.852 --> 00:08:58.058
Great job, thank you and
with that, good job.

152
00:08:58.058 --> 00:09:02.562
&gt;&gt; [APPLAUSE]
&gt;&gt; Thank you for listening to my bad dad

153
00:09:02.562 --> 00:09:06.811
jokes for, [LAUGH] for
this morning anyways.

154
00:09:06.811 --> 00:09:10.824
&gt;&gt; Tweet @mhevery-
&gt;&gt; Yes mhevery is-

155
00:09:10.824 --> 00:09:12.242
&gt;&gt; [CROSSTALK]

156
00:09:12.242 --> 00:09:13.363
&gt;&gt; If you have a dad joke,

157
00:09:13.363 --> 00:09:14.313
please send them.

158
00:09:14.313 --> 00:09:15.867
&gt;&gt; Yes, you can send me dad jokes.

159
00:09:15.867 --> 00:09:19.750
Actually a lot of people get
a kick when you install the Quick,

160
00:09:19.750 --> 00:09:22.976
the CLI will tell you a dad
joke when you install it.

161
00:09:22.976 --> 00:09:24.862
&gt;&gt; [LAUGH]

